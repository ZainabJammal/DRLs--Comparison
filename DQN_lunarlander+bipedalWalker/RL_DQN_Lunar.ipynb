{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pORIZPZ4xXpc",
        "outputId": "a92a9e03-d6d9-474f-aa2e-40a170f339f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install box2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2jgjH_NfxjGa",
        "outputId": "4dc0b34e-0ac2-4509-9246-41c188f95fd6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting box2d\n",
            "  Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (573 bytes)\n",
            "Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/3.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: box2d\n",
            "Successfully installed box2d-2.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYFc-qeWjfB-",
        "outputId": "373736b8-5b7a-4576-840b-714a146de827"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import multiprocessing\n",
        "import stable_baselines3\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.vec_env import VecNormalize"
      ],
      "metadata": {
        "id": "0iLCRF9nwn0e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, env, n_eval_episodes=10):\n",
        "    \"\"\"Evaluate the model on a given environment and return mean and std rewards.\"\"\"\n",
        "    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes)\n",
        "    return mean_reward, std_reward"
      ],
      "metadata": {
        "id": "XOZW12Jl0Tx8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Def"
      ],
      "metadata": {
        "id": "zfnMjN1F7D_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lunarlander(env, bs, lr):\n",
        "    # Create environment and model for LunarLander\n",
        "\n",
        "    env_lunar = make_vec_env(\"LunarLander-v3\", n_envs=env)\n",
        "    env_lunar = VecNormalize(env_lunar, norm_obs=True, norm_reward=True)\n",
        "    log = \"/content/drive/MyDrive/RL_models/dqn_lunarlanderEnv\"+str(env)+\"B\"+str(bs)+\"LR\"+str(lr)+\"/\"\n",
        "    dqn_model = DQN(\"MlpPolicy\", env_lunar, verbose=1, tensorboard_log=log,\n",
        "                    learning_rate = lr, batch_size = bs, gamma= 0.99,\n",
        "                    exploration_initial_eps = 1.0, exploration_final_eps= 0.01,\n",
        "                    exploration_fraction = 1, train_freq = 10, target_update_interval = 1000, learning_starts = 50)\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "    total_timesteps = 200000 # Define the total number of timesteps\n",
        "\n",
        "    for step in range(1, total_timesteps + 1, eval_freq):\n",
        "        # Train the model\n",
        "        dqn_model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "\n",
        "        # Evaluate the model on LunarLander\n",
        "        mean_reward, std_reward = evaluate_model(dqn_model, env_lunar, n_eval_episodes)\n",
        "\n",
        "        # Print evaluation results for LunarLander\n",
        "        print(f\"LunarLander - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "        #Stop the loop once reached target timesteps\n",
        "        if step == total_timesteps:\n",
        "            break\n",
        "\n",
        "    # Save model and normalization\n",
        "    dqn_model.save(log)\n",
        "    env_lunar.save(log+\".pkl\")  # This ensures it gets saved!\n",
        "\n",
        "    print(\"Model and VecNormalize stats saved!\")"
      ],
      "metadata": {
        "id": "XPnIS-02ypaW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. envs=1, batch size= 64, lr= 1e-4"
      ],
      "metadata": {
        "id": "DPo1IMGMncYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lunarlander(1, 64, 1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZpiqyNo0nO1",
        "outputId": "1e53025a-0c95-4489-e34c-74d5244cb256"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
            "/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 96       |\n",
            "|    ep_rew_mean      | -177     |\n",
            "|    exploration_rate | 0.962    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 940      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 384      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0702   |\n",
            "|    n_updates        | 33       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.5     |\n",
            "|    ep_rew_mean      | -171     |\n",
            "|    exploration_rate | 0.929    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 1207     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 716      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0868   |\n",
            "|    n_updates        | 66       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.6     |\n",
            "|    ep_rew_mean      | -172     |\n",
            "|    exploration_rate | 0.894    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 1314     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1075     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.037    |\n",
            "|    n_updates        | 102      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.2     |\n",
            "|    ep_rew_mean      | -189     |\n",
            "|    exploration_rate | 0.859    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 1414     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1427     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0279   |\n",
            "|    n_updates        | 137      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.1     |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.822    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 1462     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1802     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0345   |\n",
            "|    n_updates        | 175      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.1     |\n",
            "|    ep_rew_mean      | -196     |\n",
            "|    exploration_rate | 0.779    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 1514     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 2235     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0575   |\n",
            "|    n_updates        | 218      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.4     |\n",
            "|    ep_rew_mean      | -191     |\n",
            "|    exploration_rate | 0.73     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 1544     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 2728     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0109   |\n",
            "|    n_updates        | 267      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 99.8     |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.684    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 1473     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 3195     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0378   |\n",
            "|    n_updates        | 314      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 103      |\n",
            "|    ep_rew_mean      | -195     |\n",
            "|    exploration_rate | 0.634    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 1442     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 3695     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0497   |\n",
            "|    n_updates        | 364      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 103      |\n",
            "|    ep_rew_mean      | -193     |\n",
            "|    exploration_rate | 0.591    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 1397     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 4136     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0527   |\n",
            "|    n_updates        | 408      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.538    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 1371     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 4671     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0014   |\n",
            "|    n_updates        | 462      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 111      |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.474    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 1312     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 5310     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0152   |\n",
            "|    n_updates        | 525      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 115      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.406    |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 1319     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 5998     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0405   |\n",
            "|    n_updates        | 594      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 122      |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.323    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 1311     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 6839     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0268   |\n",
            "|    n_updates        | 678      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 127      |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.246    |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 1314     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 7616     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00136  |\n",
            "|    n_updates        | 756      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.139    |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 1291     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 8701     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00168  |\n",
            "|    n_updates        | 865      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 139      |\n",
            "|    ep_rew_mean      | -187     |\n",
            "|    exploration_rate | 0.0675   |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 1292     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 9419     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0215   |\n",
            "|    n_updates        | 936      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 1 | Mean Reward: -301.79 ± 79.61\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 139      |\n",
            "|    ep_rew_mean      | -192     |\n",
            "|    exploration_rate | 0.5      |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 1401     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10111    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0031   |\n",
            "|    n_updates        | 1006     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 145      |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.449    |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 1295     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 11124    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00421  |\n",
            "|    n_updates        | 1107     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 146      |\n",
            "|    ep_rew_mean      | -189     |\n",
            "|    exploration_rate | 0.416    |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 1320     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 11808    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000798 |\n",
            "|    n_updates        | 1175     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 146      |\n",
            "|    ep_rew_mean      | -192     |\n",
            "|    exploration_rate | 0.385    |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 1340     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 12417    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0199   |\n",
            "|    n_updates        | 1236     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 148      |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.351    |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 1342     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 13109    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0115   |\n",
            "|    n_updates        | 1305     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 149      |\n",
            "|    ep_rew_mean      | -191     |\n",
            "|    exploration_rate | 0.314    |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 1336     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 13856    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00248  |\n",
            "|    n_updates        | 1380     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | -189     |\n",
            "|    exploration_rate | 0.276    |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 1326     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 14634    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00241  |\n",
            "|    n_updates        | 1458     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 157      |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.217    |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 1258     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 15821    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00114  |\n",
            "|    n_updates        | 1577     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 162      |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.171    |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 1214     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 16740    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0135   |\n",
            "|    n_updates        | 1668     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 165      |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.144    |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 1194     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 17296    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00449  |\n",
            "|    n_updates        | 1724     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 167      |\n",
            "|    ep_rew_mean      | -187     |\n",
            "|    exploration_rate | 0.112    |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 1169     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 17942    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00266  |\n",
            "|    n_updates        | 1789     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 168      |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.0912   |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 1164     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 18359    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00981  |\n",
            "|    n_updates        | 1830     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 170      |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.0635   |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 1172     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 18920    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00113  |\n",
            "|    n_updates        | 1886     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 173      |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.0256   |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 1175     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 19685    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00522  |\n",
            "|    n_updates        | 1963     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 10001 | Mean Reward: -159.62 ± 55.29\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 178      |\n",
            "|    ep_rew_mean      | -180     |\n",
            "|    exploration_rate | 0.315    |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 1214     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20753    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00742  |\n",
            "|    n_updates        | 2070     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 185      |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.276    |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 1210     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 21926    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000841 |\n",
            "|    n_updates        | 2187     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 192      |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.238    |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 1191     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 23100    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000964 |\n",
            "|    n_updates        | 2304     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | -176     |\n",
            "|    exploration_rate | 0.22     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 1216     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 23645    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0237   |\n",
            "|    n_updates        | 2359     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 196      |\n",
            "|    ep_rew_mean      | -175     |\n",
            "|    exploration_rate | 0.193    |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 1223     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 24464    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0131   |\n",
            "|    n_updates        | 2441     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | -177     |\n",
            "|    exploration_rate | 0.162    |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 1222     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 25387    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00105  |\n",
            "|    n_updates        | 2533     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 201      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.131    |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 1217     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 26323    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00122  |\n",
            "|    n_updates        | 2627     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 203      |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.0974   |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 1205     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 27351    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0171   |\n",
            "|    n_updates        | 2730     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 206      |\n",
            "|    ep_rew_mean      | -175     |\n",
            "|    exploration_rate | 0.0601   |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 1198     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 28482    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000808 |\n",
            "|    n_updates        | 2843     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 20001 | Mean Reward: -257.50 ± 88.65\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 211      |\n",
            "|    ep_rew_mean      | -173     |\n",
            "|    exploration_rate | 0.236    |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 922      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30859    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00275  |\n",
            "|    n_updates        | 3080     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 215      |\n",
            "|    ep_rew_mean      | -173     |\n",
            "|    exploration_rate | 0.209    |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 1026     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 31975    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00133  |\n",
            "|    n_updates        | 3192     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 227      |\n",
            "|    ep_rew_mean      | -168     |\n",
            "|    exploration_rate | 0.164    |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 922      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 33765    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0142   |\n",
            "|    n_updates        | 3371     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 249      |\n",
            "|    ep_rew_mean      | -171     |\n",
            "|    exploration_rate | 0.0853   |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 719      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 36956    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00161  |\n",
            "|    n_updates        | 3690     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 30001 | Mean Reward: -91.94 ± 33.90\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 282      |\n",
            "|    ep_rew_mean      | -167     |\n",
            "|    exploration_rate | 0.188    |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 574      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 41000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00183  |\n",
            "|    n_updates        | 4094     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 300      |\n",
            "|    ep_rew_mean      | -162     |\n",
            "|    exploration_rate | 0.141    |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 639      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 43399    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0189   |\n",
            "|    n_updates        | 4334     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 315      |\n",
            "|    ep_rew_mean      | -161     |\n",
            "|    exploration_rate | 0.0972   |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 683      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 45597    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000917 |\n",
            "|    n_updates        | 4554     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 341      |\n",
            "|    ep_rew_mean      | -158     |\n",
            "|    exploration_rate | 0.0307   |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 661      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 48957    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00301  |\n",
            "|    n_updates        | 4890     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 40001 | Mean Reward: -78.18 ± 36.39\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 348      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.157    |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 1008     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 51093    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0156   |\n",
            "|    n_updates        | 5104     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 365      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.11     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 814      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 53928    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0415   |\n",
            "|    n_updates        | 5387     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 390      |\n",
            "|    ep_rew_mean      | -155     |\n",
            "|    exploration_rate | 0.0533   |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 747      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 57376    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00211  |\n",
            "|    n_updates        | 5732     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 50001 | Mean Reward: -118.35 ± 43.16\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 407      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.148    |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 1191     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60232    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00622  |\n",
            "|    n_updates        | 6018     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 435      |\n",
            "|    ep_rew_mean      | -147     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 664      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 63610    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00203  |\n",
            "|    n_updates        | 6355     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 468      |\n",
            "|    ep_rew_mean      | -140     |\n",
            "|    exploration_rate | 0.0465   |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 606      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 67422    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0012   |\n",
            "|    n_updates        | 6737     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 60001 | Mean Reward: -87.86 ± 58.84\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 503      |\n",
            "|    ep_rew_mean      | -136     |\n",
            "|    exploration_rate | 0.109    |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 642      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 72000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00132  |\n",
            "|    n_updates        | 7194     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 535      |\n",
            "|    ep_rew_mean      | -134     |\n",
            "|    exploration_rate | 0.06     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 556      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 75962    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00146  |\n",
            "|    n_updates        | 7591     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 565      |\n",
            "|    ep_rew_mean      | -133     |\n",
            "|    exploration_rate | 0.0105   |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 546      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 79962    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00313  |\n",
            "|    n_updates        | 7991     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 70001 | Mean Reward: -53.49 ± 18.69\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 593      |\n",
            "|    ep_rew_mean      | -129     |\n",
            "|    exploration_rate | 0.076    |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 586      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 84000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00218  |\n",
            "|    n_updates        | 8394     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 622      |\n",
            "|    ep_rew_mean      | -122     |\n",
            "|    exploration_rate | 0.032    |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 576      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 88000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00154  |\n",
            "|    n_updates        | 8794     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 80001 | Mean Reward: -46.58 ± 26.08\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 656      |\n",
            "|    ep_rew_mean      | -120     |\n",
            "|    exploration_rate | 0.0892   |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 451      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 92000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0478   |\n",
            "|    n_updates        | 9194     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 688      |\n",
            "|    ep_rew_mean      | -116     |\n",
            "|    exploration_rate | 0.0496   |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 485      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 96000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00166  |\n",
            "|    n_updates        | 9594     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 719      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 496      |\n",
            "|    time_elapsed     | 20       |\n",
            "|    total_timesteps  | 100000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00302  |\n",
            "|    n_updates        | 9994     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 90001 | Mean Reward: -37.41 ± 23.21\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 744      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.0693   |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 519      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 103409   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00177  |\n",
            "|    n_updates        | 10335    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 773      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.0333   |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 558      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 107409   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00243  |\n",
            "|    n_updates        | 10735    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 100001 | Mean Reward: -54.08 ± 18.89\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 802      |\n",
            "|    ep_rew_mean      | -96.5    |\n",
            "|    exploration_rate | 0.076    |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 627      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 112000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0016   |\n",
            "|    n_updates        | 11194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 827      |\n",
            "|    ep_rew_mean      | -94.1    |\n",
            "|    exploration_rate | 0.043    |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 623      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 116000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00264  |\n",
            "|    n_updates        | 11594    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 856      |\n",
            "|    ep_rew_mean      | -86.9    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 628      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 120000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00213  |\n",
            "|    n_updates        | 11994    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 110001 | Mean Reward: -49.96 ± 21.97\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 878      |\n",
            "|    ep_rew_mean      | -82.6    |\n",
            "|    exploration_rate | 0.0557   |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 606      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 124000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00508  |\n",
            "|    n_updates        | 12394    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 886      |\n",
            "|    ep_rew_mean      | -76.2    |\n",
            "|    exploration_rate | 0.0252   |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 596      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 128000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0017   |\n",
            "|    n_updates        | 12794    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 120001 | Mean Reward: -46.53 ± 21.63\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 886      |\n",
            "|    ep_rew_mean      | -74.1    |\n",
            "|    exploration_rate | 0.0666   |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 565      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 132000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00166  |\n",
            "|    n_updates        | 13194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 902      |\n",
            "|    ep_rew_mean      | -69.9    |\n",
            "|    exploration_rate | 0.0383   |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 606      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 136000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00186  |\n",
            "|    n_updates        | 13594    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 920      |\n",
            "|    ep_rew_mean      | -65.9    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 597      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 140000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00325  |\n",
            "|    n_updates        | 13994    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 130001 | Mean Reward: -47.69 ± 20.05\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 926      |\n",
            "|    ep_rew_mean      | -62.2    |\n",
            "|    exploration_rate | 0.0496   |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 601      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 144000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00217  |\n",
            "|    n_updates        | 14394    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 951      |\n",
            "|    ep_rew_mean      | -61.9    |\n",
            "|    exploration_rate | 0.0232   |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 603      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 148000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00678  |\n",
            "|    n_updates        | 14794    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 140001 | Mean Reward: -39.13 ± 22.75\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 963      |\n",
            "|    ep_rew_mean      | -58.2    |\n",
            "|    exploration_rate | 0.0595   |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 564      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 152000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00127  |\n",
            "|    n_updates        | 15194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 969      |\n",
            "|    ep_rew_mean      | -54.4    |\n",
            "|    exploration_rate | 0.0348   |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 531      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 156000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0102   |\n",
            "|    n_updates        | 15594    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 986      |\n",
            "|    ep_rew_mean      | -53.2    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 558      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 160000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00169  |\n",
            "|    n_updates        | 15994    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 150001 | Mean Reward: -39.78 ± 23.24\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 992      |\n",
            "|    ep_rew_mean      | -49.7    |\n",
            "|    exploration_rate | 0.0449   |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 572      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 164000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00225  |\n",
            "|    n_updates        | 16394    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 994      |\n",
            "|    ep_rew_mean      | -48.2    |\n",
            "|    exploration_rate | 0.0216   |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 559      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 168000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00176  |\n",
            "|    n_updates        | 16794    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 160001 | Mean Reward: -48.12 ± 17.31\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 994      |\n",
            "|    ep_rew_mean      | -46.4    |\n",
            "|    exploration_rate | 0.054    |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 533      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 172000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00243  |\n",
            "|    n_updates        | 17194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 994      |\n",
            "|    ep_rew_mean      | -45.1    |\n",
            "|    exploration_rate | 0.032    |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 555      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 176000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00363  |\n",
            "|    n_updates        | 17594    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 994      |\n",
            "|    ep_rew_mean      | -45.6    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 531      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 180000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00227  |\n",
            "|    n_updates        | 17994    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 170001 | Mean Reward: -39.07 ± 12.59\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 994      |\n",
            "|    ep_rew_mean      | -44.5    |\n",
            "|    exploration_rate | 0.0413   |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 614      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 184000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000778 |\n",
            "|    n_updates        | 18394    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 989      |\n",
            "|    ep_rew_mean      | -44.1    |\n",
            "|    exploration_rate | 0.023    |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 640      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 187508   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00282  |\n",
            "|    n_updates        | 18745    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 180001 | Mean Reward: -30.05 ± 22.94\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 989      |\n",
            "|    ep_rew_mean      | -43      |\n",
            "|    exploration_rate | 0.0496   |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 479      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 192000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00181  |\n",
            "|    n_updates        | 19194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 989      |\n",
            "|    ep_rew_mean      | -42.7    |\n",
            "|    exploration_rate | 0.0298   |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 527      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 196000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00276  |\n",
            "|    n_updates        | 19594    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 989      |\n",
            "|    ep_rew_mean      | -43.2    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 525      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 200000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00166  |\n",
            "|    n_updates        | 19994    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 190001 | Mean Reward: -25.47 ± 23.63\n",
            "Model and VecNormalize stats saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0001_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. envs=1, batch size= 64, lr= 3e-4"
      ],
      "metadata": {
        "id": "tRkowQUs_WVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lunarlander(1, 64, 3e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekbp0OPoAfJe",
        "outputId": "27cf81f1-741f-4aeb-b60f-7ba306f7dddf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86.8     |\n",
            "|    ep_rew_mean      | -134     |\n",
            "|    exploration_rate | 0.966    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 1859     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 347      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0105   |\n",
            "|    n_updates        | 29       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 99.8     |\n",
            "|    ep_rew_mean      | -169     |\n",
            "|    exploration_rate | 0.921    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 1844     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 798      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00417  |\n",
            "|    n_updates        | 74       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 95       |\n",
            "|    ep_rew_mean      | -149     |\n",
            "|    exploration_rate | 0.887    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 1844     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1140     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0187   |\n",
            "|    n_updates        | 108      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 95.9     |\n",
            "|    ep_rew_mean      | -174     |\n",
            "|    exploration_rate | 0.848    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 1833     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1534     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0512   |\n",
            "|    n_updates        | 148      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.3     |\n",
            "|    ep_rew_mean      | -155     |\n",
            "|    exploration_rate | 0.807    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 1809     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1946     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0352   |\n",
            "|    n_updates        | 189      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -139     |\n",
            "|    exploration_rate | 0.686    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 1261     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 3168     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0391   |\n",
            "|    n_updates        | 311      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 130      |\n",
            "|    ep_rew_mean      | -143     |\n",
            "|    exploration_rate | 0.641    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 1295     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 3631     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0049   |\n",
            "|    n_updates        | 358      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 128      |\n",
            "|    ep_rew_mean      | -144     |\n",
            "|    exploration_rate | 0.595    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 1318     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 4091     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.007    |\n",
            "|    n_updates        | 404      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 128      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.544    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 1271     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 4606     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00556  |\n",
            "|    n_updates        | 455      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 127      |\n",
            "|    ep_rew_mean      | -146     |\n",
            "|    exploration_rate | 0.498    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 1255     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 5073     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00441  |\n",
            "|    n_updates        | 502      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 127      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.445    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 1249     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 5608     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00253  |\n",
            "|    n_updates        | 555      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 128      |\n",
            "|    ep_rew_mean      | -151     |\n",
            "|    exploration_rate | 0.39     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 1218     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 6164     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00175  |\n",
            "|    n_updates        | 611      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.318    |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 1222     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 6893     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00219  |\n",
            "|    n_updates        | 684      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -159     |\n",
            "|    exploration_rate | 0.251    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 1228     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 7562     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00129  |\n",
            "|    n_updates        | 751      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 141      |\n",
            "|    ep_rew_mean      | -162     |\n",
            "|    exploration_rate | 0.163    |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 1226     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 8456     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00199  |\n",
            "|    n_updates        | 840      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 147      |\n",
            "|    ep_rew_mean      | -171     |\n",
            "|    exploration_rate | 0.0707   |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 1227     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 9387     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0511   |\n",
            "|    n_updates        | 933      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 1 | Mean Reward: -77.35 ± 45.10\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 150      |\n",
            "|    ep_rew_mean      | -172     |\n",
            "|    exploration_rate | 0.492    |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 1291     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10254    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0276   |\n",
            "|    n_updates        | 1020     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | -166     |\n",
            "|    exploration_rate | 0.459    |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 1182     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10926    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00127  |\n",
            "|    n_updates        | 1087     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 150      |\n",
            "|    ep_rew_mean      | -163     |\n",
            "|    exploration_rate | 0.434    |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 1271     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 11438    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00126  |\n",
            "|    n_updates        | 1138     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | -156     |\n",
            "|    exploration_rate | 0.401    |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 1299     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 12101    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0378   |\n",
            "|    n_updates        | 1205     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -156     |\n",
            "|    exploration_rate | 0.368    |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 1310     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 12758    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 1270     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -155     |\n",
            "|    exploration_rate | 0.329    |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 1265     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 13561    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00126  |\n",
            "|    n_updates        | 1351     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -155     |\n",
            "|    exploration_rate | 0.292    |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 1261     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 14313    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00219  |\n",
            "|    n_updates        | 1426     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.263    |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 1274     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 14884    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0313   |\n",
            "|    n_updates        | 1483     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 167      |\n",
            "|    ep_rew_mean      | -149     |\n",
            "|    exploration_rate | 0.174    |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 1134     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 16694    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0391   |\n",
            "|    n_updates        | 1664     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 183      |\n",
            "|    ep_rew_mean      | -153     |\n",
            "|    exploration_rate | 0.0739   |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 982      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 18710    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00118  |\n",
            "|    n_updates        | 1865     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 10001 | Mean Reward: -197.05 ± 62.92\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 192      |\n",
            "|    ep_rew_mean      | -149     |\n",
            "|    exploration_rate | 0.328    |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 957      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20359    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00904  |\n",
            "|    n_updates        | 2030     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 202      |\n",
            "|    ep_rew_mean      | -146     |\n",
            "|    exploration_rate | 0.283    |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 869      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 21733    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00799  |\n",
            "|    n_updates        | 2168     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 213      |\n",
            "|    ep_rew_mean      | -140     |\n",
            "|    exploration_rate | 0.235    |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 919      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 23195    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00224  |\n",
            "|    n_updates        | 2314     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 237      |\n",
            "|    ep_rew_mean      | -138     |\n",
            "|    exploration_rate | 0.14     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 713      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 26058    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0336   |\n",
            "|    n_updates        | 2600     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 260      |\n",
            "|    ep_rew_mean      | -141     |\n",
            "|    exploration_rate | 0.0253   |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 651      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 29536    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0212   |\n",
            "|    n_updates        | 2948     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 20001 | Mean Reward: -71.75 ± 29.40\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 281      |\n",
            "|    ep_rew_mean      | -137     |\n",
            "|    exploration_rate | 0.193    |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 579      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 32626    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0499   |\n",
            "|    n_updates        | 3257     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 317      |\n",
            "|    ep_rew_mean      | -131     |\n",
            "|    exploration_rate | 0.0935   |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 560      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 36626    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0179   |\n",
            "|    n_updates        | 3657     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 30001 | Mean Reward: -51.04 ± 25.44\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 352      |\n",
            "|    ep_rew_mean      | -125     |\n",
            "|    exploration_rate | 0.188    |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 537      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 41000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0024   |\n",
            "|    n_updates        | 4094     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 377      |\n",
            "|    ep_rew_mean      | -125     |\n",
            "|    exploration_rate | 0.129    |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 585      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 44004    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00567  |\n",
            "|    n_updates        | 4395     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 387      |\n",
            "|    ep_rew_mean      | -120     |\n",
            "|    exploration_rate | 0.098    |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 607      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 45558    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.005    |\n",
            "|    n_updates        | 4550     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 415      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.0317   |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 580      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 48906    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0288   |\n",
            "|    n_updates        | 4885     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 40001 | Mean Reward: -52.37 ± 43.73\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 448      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.126    |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 507      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 53000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00172  |\n",
            "|    n_updates        | 5294     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 464      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.0872   |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 587      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 55324    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0017   |\n",
            "|    n_updates        | 5527     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 487      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.0357   |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 581      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 58440    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0289   |\n",
            "|    n_updates        | 5838     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 50001 | Mean Reward: -22.84 ± 41.66\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 498      |\n",
            "|    ep_rew_mean      | -92      |\n",
            "|    exploration_rate | 0.138    |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 822      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 60924    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0352   |\n",
            "|    n_updates        | 6087     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 530      |\n",
            "|    ep_rew_mean      | -86.4    |\n",
            "|    exploration_rate | 0.0818   |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 659      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 64924    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00559  |\n",
            "|    n_updates        | 6487     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 541      |\n",
            "|    ep_rew_mean      | -87.4    |\n",
            "|    exploration_rate | 0.0556   |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 664      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 66777    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0108   |\n",
            "|    n_updates        | 6672     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 549      |\n",
            "|    ep_rew_mean      | -87.8    |\n",
            "|    exploration_rate | 0.0381   |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 689      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 68011    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00147  |\n",
            "|    n_updates        | 6796     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 60001 | Mean Reward: -115.59 ± 123.05\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 575      |\n",
            "|    ep_rew_mean      | -90.7    |\n",
            "|    exploration_rate | 0.105    |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 657      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 72322    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00622  |\n",
            "|    n_updates        | 7227     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 583      |\n",
            "|    ep_rew_mean      | -88.3    |\n",
            "|    exploration_rate | 0.0868   |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 714      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 73792    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0164   |\n",
            "|    n_updates        | 7374     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 610      |\n",
            "|    ep_rew_mean      | -86.9    |\n",
            "|    exploration_rate | 0.0436   |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 644      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 77285    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0268   |\n",
            "|    n_updates        | 7723     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 70001 | Mean Reward: -89.57 ± 59.14\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 632      |\n",
            "|    ep_rew_mean      | -81      |\n",
            "|    exploration_rate | 0.114    |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 806      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80582    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00268  |\n",
            "|    n_updates        | 8053     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 655      |\n",
            "|    ep_rew_mean      | -78.8    |\n",
            "|    exploration_rate | 0.082    |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 659      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 83453    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0222   |\n",
            "|    n_updates        | 8340     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 671      |\n",
            "|    ep_rew_mean      | -81.1    |\n",
            "|    exploration_rate | 0.0445   |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 629      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 86866    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0656   |\n",
            "|    n_updates        | 8681     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 80001 | Mean Reward: -50.59 ± 20.96\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 691      |\n",
            "|    ep_rew_mean      | -72.5    |\n",
            "|    exploration_rate | 0.0991   |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 509      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 91000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.109    |\n",
            "|    n_updates        | 9094     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 718      |\n",
            "|    ep_rew_mean      | -70.5    |\n",
            "|    exploration_rate | 0.0595   |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 503      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 95000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0276   |\n",
            "|    n_updates        | 9494     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 730      |\n",
            "|    ep_rew_mean      | -72.5    |\n",
            "|    exploration_rate | 0.034    |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 530      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 97578    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00231  |\n",
            "|    n_updates        | 9752     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 90001 | Mean Reward: 26.38 ± 83.12\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 755      |\n",
            "|    ep_rew_mean      | -68.6    |\n",
            "|    exploration_rate | 0.082    |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 529      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 102000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00147  |\n",
            "|    n_updates        | 10194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 757      |\n",
            "|    ep_rew_mean      | -69.5    |\n",
            "|    exploration_rate | 0.0548   |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 595      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 105025   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0103   |\n",
            "|    n_updates        | 10497    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 757      |\n",
            "|    ep_rew_mean      | -66.9    |\n",
            "|    exploration_rate | 0.0237   |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 588      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 108473   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0351   |\n",
            "|    n_updates        | 10842    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 100001 | Mean Reward: -33.94 ± 42.98\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 770      |\n",
            "|    ep_rew_mean      | -66.9    |\n",
            "|    exploration_rate | 0.0677   |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 577      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 113000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00423  |\n",
            "|    n_updates        | 11294    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 764      |\n",
            "|    ep_rew_mean      | -64.3    |\n",
            "|    exploration_rate | 0.0399   |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 543      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 116381   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0112   |\n",
            "|    n_updates        | 11633    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 110001 | Mean Reward: -59.05 ± 59.53\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 761      |\n",
            "|    ep_rew_mean      | -60.9    |\n",
            "|    exploration_rate | 0.0785   |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 610      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 121000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0394   |\n",
            "|    n_updates        | 12094    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 746      |\n",
            "|    ep_rew_mean      | -59.6    |\n",
            "|    exploration_rate | 0.0672   |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 603      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 122486   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0232   |\n",
            "|    n_updates        | 12243    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 770      |\n",
            "|    ep_rew_mean      | -58.6    |\n",
            "|    exploration_rate | 0.0368   |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 587      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 126486   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00791  |\n",
            "|    n_updates        | 12643    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 120001 | Mean Reward: -118.28 ± 138.36\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 777      |\n",
            "|    ep_rew_mean      | -56.7    |\n",
            "|    exploration_rate | 0.0736   |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 570      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 131000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0337   |\n",
            "|    n_updates        | 13094    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 773      |\n",
            "|    ep_rew_mean      | -51.3    |\n",
            "|    exploration_rate | 0.0478   |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 578      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 134661   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0136   |\n",
            "|    n_updates        | 13461    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 790      |\n",
            "|    ep_rew_mean      | -47.2    |\n",
            "|    exploration_rate | 0.0195   |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 575      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 138661   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0752   |\n",
            "|    n_updates        | 13861    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 130001 | Mean Reward: 67.17 ± 103.46\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 795      |\n",
            "|    ep_rew_mean      | -44.8    |\n",
            "|    exploration_rate | 0.0563   |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 669      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 142984   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00308  |\n",
            "|    n_updates        | 14293    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 803      |\n",
            "|    ep_rew_mean      | -42.2    |\n",
            "|    exploration_rate | 0.0377   |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 586      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 145796   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0117   |\n",
            "|    n_updates        | 14574    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 789      |\n",
            "|    ep_rew_mean      | -35.5    |\n",
            "|    exploration_rate | 0.0203   |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 622      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 148439   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00337  |\n",
            "|    n_updates        | 14838    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 140001 | Mean Reward: -43.93 ± 31.25\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 797      |\n",
            "|    ep_rew_mean      | -33.8    |\n",
            "|    exploration_rate | 0.0595   |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 478      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 152000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.135    |\n",
            "|    n_updates        | 15194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 821      |\n",
            "|    ep_rew_mean      | -30.2    |\n",
            "|    exploration_rate | 0.0375   |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 532      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 155553   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00287  |\n",
            "|    n_updates        | 15550    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 817      |\n",
            "|    ep_rew_mean      | -26      |\n",
            "|    exploration_rate | 0.0191   |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 565      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 158533   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00176  |\n",
            "|    n_updates        | 15848    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 150001 | Mean Reward: 36.81 ± 57.42\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 833      |\n",
            "|    ep_rew_mean      | -19.4    |\n",
            "|    exploration_rate | 0.0562   |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 777      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 162062   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0167   |\n",
            "|    n_updates        | 16201    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 826      |\n",
            "|    ep_rew_mean      | -10.4    |\n",
            "|    exploration_rate | 0.0399   |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 648      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 164863   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00414  |\n",
            "|    n_updates        | 16481    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 835      |\n",
            "|    ep_rew_mean      | -9.89    |\n",
            "|    exploration_rate | 0.018    |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 613      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 168624   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0166   |\n",
            "|    n_updates        | 16857    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 160001 | Mean Reward: -23.29 ± 42.01\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 831      |\n",
            "|    ep_rew_mean      | -8.03    |\n",
            "|    exploration_rate | 0.0554   |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 730      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 171737   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.047    |\n",
            "|    n_updates        | 17168    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 823      |\n",
            "|    ep_rew_mean      | 7.82     |\n",
            "|    exploration_rate | 0.0412   |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 707      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 174329   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0739   |\n",
            "|    n_updates        | 17427    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 813      |\n",
            "|    ep_rew_mean      | 16.4     |\n",
            "|    exploration_rate | 0.0249   |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 669      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 177288   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.117    |\n",
            "|    n_updates        | 17723    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 170001 | Mean Reward: 191.55 ± 37.38\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 804      |\n",
            "|    ep_rew_mean      | 23.4     |\n",
            "|    exploration_rate | 0.0582   |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 444      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 180746   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0263   |\n",
            "|    n_updates        | 18069    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 796      |\n",
            "|    ep_rew_mean      | 32.3     |\n",
            "|    exploration_rate | 0.0486   |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 599      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 182589   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0541   |\n",
            "|    n_updates        | 18253    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 777      |\n",
            "|    ep_rew_mean      | 38.5     |\n",
            "|    exploration_rate | 0.0377   |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 652      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 184690   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00156  |\n",
            "|    n_updates        | 18463    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 780      |\n",
            "|    ep_rew_mean      | 45.7     |\n",
            "|    exploration_rate | 0.0207   |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 636      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 187949   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0266   |\n",
            "|    n_updates        | 18789    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 180001 | Mean Reward: 136.34 ± 61.67\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 775      |\n",
            "|    ep_rew_mean      | 54.5     |\n",
            "|    exploration_rate | 0.0546   |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 783      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 190990   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00857  |\n",
            "|    n_updates        | 19093    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 765      |\n",
            "|    ep_rew_mean      | 63.3     |\n",
            "|    exploration_rate | 0.0404   |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 709      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 193866   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0839   |\n",
            "|    n_updates        | 19381    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 751      |\n",
            "|    ep_rew_mean      | 69.4     |\n",
            "|    exploration_rate | 0.0304   |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 718      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 195871   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00133  |\n",
            "|    n_updates        | 19582    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 740      |\n",
            "|    ep_rew_mean      | 72.3     |\n",
            "|    exploration_rate | 0.0174   |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 676      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 198495   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00115  |\n",
            "|    n_updates        | 19844    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 190001 | Mean Reward: 202.93 ± 27.36\n",
            "Model and VecNormalize stats saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B64LR0.0003_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. envs=1, batch size= 128, lr= 1e-4"
      ],
      "metadata": {
        "id": "Mrdn5NlCArGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lunarlander(1, 128, 1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDdUUbjnBwJV",
        "outputId": "ea854c6e-5900-406b-f5cc-46f2dc49ba59"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 66.5     |\n",
            "|    ep_rew_mean      | -78.8    |\n",
            "|    exploration_rate | 0.974    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 1767     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 266      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.188    |\n",
            "|    n_updates        | 21       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 76.5     |\n",
            "|    ep_rew_mean      | -144     |\n",
            "|    exploration_rate | 0.939    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 1693     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 612      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0223   |\n",
            "|    n_updates        | 56       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86.3     |\n",
            "|    ep_rew_mean      | -144     |\n",
            "|    exploration_rate | 0.897    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 1690     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1036     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0214   |\n",
            "|    n_updates        | 98       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86.7     |\n",
            "|    ep_rew_mean      | -137     |\n",
            "|    exploration_rate | 0.863    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 1708     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1387     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0212   |\n",
            "|    n_updates        | 133      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.2     |\n",
            "|    ep_rew_mean      | -156     |\n",
            "|    exploration_rate | 0.821    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 1707     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1804     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0242   |\n",
            "|    n_updates        | 175      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.8     |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.777    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 1680     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 2250     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0277   |\n",
            "|    n_updates        | 219      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 95.9     |\n",
            "|    ep_rew_mean      | -149     |\n",
            "|    exploration_rate | 0.734    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 1676     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 2684     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0594   |\n",
            "|    n_updates        | 263      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.3     |\n",
            "|    ep_rew_mean      | -137     |\n",
            "|    exploration_rate | 0.692    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 1664     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 3114     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.026    |\n",
            "|    n_updates        | 306      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 99       |\n",
            "|    ep_rew_mean      | -132     |\n",
            "|    exploration_rate | 0.647    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 1647     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 3563     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0111   |\n",
            "|    n_updates        | 351      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 104      |\n",
            "|    ep_rew_mean      | -134     |\n",
            "|    exploration_rate | 0.587    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 1617     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 4176     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0479   |\n",
            "|    n_updates        | 412      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | -145     |\n",
            "|    exploration_rate | 0.531    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 1586     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 4733     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0186   |\n",
            "|    n_updates        | 468      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 112      |\n",
            "|    ep_rew_mean      | -144     |\n",
            "|    exploration_rate | 0.47     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 1569     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 5355     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0585   |\n",
            "|    n_updates        | 530      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 115      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.41     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 1540     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 5963     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00247  |\n",
            "|    n_updates        | 591      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 119      |\n",
            "|    ep_rew_mean      | -156     |\n",
            "|    exploration_rate | 0.342    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 1513     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 6646     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00107  |\n",
            "|    n_updates        | 659      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 121      |\n",
            "|    ep_rew_mean      | -165     |\n",
            "|    exploration_rate | 0.28     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 1492     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 7272     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0321   |\n",
            "|    n_updates        | 722      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 123      |\n",
            "|    ep_rew_mean      | -173     |\n",
            "|    exploration_rate | 0.22     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 1469     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 7881     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0135   |\n",
            "|    n_updates        | 783      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 127      |\n",
            "|    ep_rew_mean      | -174     |\n",
            "|    exploration_rate | 0.142    |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 1438     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 8663     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0106   |\n",
            "|    n_updates        | 861      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 129      |\n",
            "|    ep_rew_mean      | -176     |\n",
            "|    exploration_rate | 0.0825   |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 1430     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 9268     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0167   |\n",
            "|    n_updates        | 921      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 1 | Mean Reward: -321.44 ± 128.53\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.494    |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 1385     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10216    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00822  |\n",
            "|    n_updates        | 1016     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.466    |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 1362     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10792    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00362  |\n",
            "|    n_updates        | 1074     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.43     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 1291     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 11525    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0104   |\n",
            "|    n_updates        | 1147     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.402    |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 1228     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 12072    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00605  |\n",
            "|    n_updates        | 1202     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.371    |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 1157     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 12700    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00137  |\n",
            "|    n_updates        | 1264     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 138      |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.336    |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 1110     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 13417    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00119  |\n",
            "|    n_updates        | 1336     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 140      |\n",
            "|    ep_rew_mean      | -189     |\n",
            "|    exploration_rate | 0.301    |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 1103     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 14124    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00705  |\n",
            "|    n_updates        | 1407     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 144      |\n",
            "|    ep_rew_mean      | -193     |\n",
            "|    exploration_rate | 0.265    |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 1124     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 14839    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0139   |\n",
            "|    n_updates        | 1478     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 148      |\n",
            "|    ep_rew_mean      | -196     |\n",
            "|    exploration_rate | 0.23     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 1130     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 15557    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000986 |\n",
            "|    n_updates        | 1550     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | -201     |\n",
            "|    exploration_rate | 0.194    |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 1140     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 16279    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00107  |\n",
            "|    n_updates        | 1622     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -204     |\n",
            "|    exploration_rate | 0.154    |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 1148     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 17096    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0116   |\n",
            "|    n_updates        | 1704     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 160      |\n",
            "|    ep_rew_mean      | -201     |\n",
            "|    exploration_rate | 0.109    |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 1153     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 18007    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00566  |\n",
            "|    n_updates        | 1795     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 171      |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.0325   |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 1088     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 19545    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00107  |\n",
            "|    n_updates        | 1949     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 10001 | Mean Reward: -155.78 ± 44.33\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -198     |\n",
            "|    exploration_rate | 0.251    |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 587      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 22705    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0174   |\n",
            "|    n_updates        | 2265     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 210      |\n",
            "|    ep_rew_mean      | -198     |\n",
            "|    exploration_rate | 0.191    |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 646      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 24528    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00396  |\n",
            "|    n_updates        | 2447     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 231      |\n",
            "|    ep_rew_mean      | -197     |\n",
            "|    exploration_rate | 0.106    |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 663      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 27079    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00715  |\n",
            "|    n_updates        | 2702     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 248      |\n",
            "|    ep_rew_mean      | -198     |\n",
            "|    exploration_rate | 0.0306   |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 648      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 29375    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00215  |\n",
            "|    n_updates        | 2932     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 20001 | Mean Reward: -117.88 ± 42.27\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 265      |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.213    |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 753      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 31805    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0291   |\n",
            "|    n_updates        | 3175     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 278      |\n",
            "|    ep_rew_mean      | -187     |\n",
            "|    exploration_rate | 0.164    |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 710      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 33789    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0118   |\n",
            "|    n_updates        | 3373     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 295      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.107    |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 680      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 36077    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00102  |\n",
            "|    n_updates        | 3602     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 310      |\n",
            "|    ep_rew_mean      | -176     |\n",
            "|    exploration_rate | 0.0535   |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 668      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 38242    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0237   |\n",
            "|    n_updates        | 3819     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 30001 | Mean Reward: -114.76 ± 24.78\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 323      |\n",
            "|    ep_rew_mean      | -169     |\n",
            "|    exploration_rate | 0.195    |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 833      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40681    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0147   |\n",
            "|    n_updates        | 4063     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 342      |\n",
            "|    ep_rew_mean      | -164     |\n",
            "|    exploration_rate | 0.146    |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 796      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 43136    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00203  |\n",
            "|    n_updates        | 4308     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 350      |\n",
            "|    ep_rew_mean      | -162     |\n",
            "|    exploration_rate | 0.114    |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 823      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 44754    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0381   |\n",
            "|    n_updates        | 4470     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 359      |\n",
            "|    ep_rew_mean      | -159     |\n",
            "|    exploration_rate | 0.0842   |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 808      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 46255    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000791 |\n",
            "|    n_updates        | 4620     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 372      |\n",
            "|    ep_rew_mean      | -157     |\n",
            "|    exploration_rate | 0.0426   |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 812      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 48356    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00318  |\n",
            "|    n_updates        | 4830     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 379      |\n",
            "|    ep_rew_mean      | -153     |\n",
            "|    exploration_rate | 0.0174   |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 810      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 49626    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00114  |\n",
            "|    n_updates        | 4957     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 40001 | Mean Reward: -138.96 ± 34.42\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 397      |\n",
            "|    ep_rew_mean      | -149     |\n",
            "|    exploration_rate | 0.137    |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 684      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 52298    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0227   |\n",
            "|    n_updates        | 5224     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 415      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.0981   |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 687      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 54660    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00724  |\n",
            "|    n_updates        | 5460     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 431      |\n",
            "|    ep_rew_mean      | -144     |\n",
            "|    exploration_rate | 0.0612   |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 678      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 56898    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0464   |\n",
            "|    n_updates        | 5684     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 437      |\n",
            "|    ep_rew_mean      | -140     |\n",
            "|    exploration_rate | 0.0398   |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 702      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 58193    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0132   |\n",
            "|    n_updates        | 5814     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 439      |\n",
            "|    ep_rew_mean      | -136     |\n",
            "|    exploration_rate | 0.0246   |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 728      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 59113    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0342   |\n",
            "|    n_updates        | 5906     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 50001 | Mean Reward: -145.64 ± 35.79\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 447      |\n",
            "|    ep_rew_mean      | -135     |\n",
            "|    exploration_rate | 0.137    |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 738      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 60987    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0068   |\n",
            "|    n_updates        | 6093     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 455      |\n",
            "|    ep_rew_mean      | -130     |\n",
            "|    exploration_rate | 0.116    |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 780      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 62526    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00352  |\n",
            "|    n_updates        | 6247     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 466      |\n",
            "|    ep_rew_mean      | -123     |\n",
            "|    exploration_rate | 0.0906   |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 708      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 64304    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00234  |\n",
            "|    n_updates        | 6425     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 473      |\n",
            "|    ep_rew_mean      | -121     |\n",
            "|    exploration_rate | 0.0679   |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 757      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 65905    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0427   |\n",
            "|    n_updates        | 6585     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 475      |\n",
            "|    ep_rew_mean      | -119     |\n",
            "|    exploration_rate | 0.0522   |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 794      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 67015    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0243   |\n",
            "|    n_updates        | 6696     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 467      |\n",
            "|    ep_rew_mean      | -117     |\n",
            "|    exploration_rate | 0.0429   |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 821      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 67671    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00239  |\n",
            "|    n_updates        | 6762     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 450      |\n",
            "|    ep_rew_mean      | -122     |\n",
            "|    exploration_rate | 0.0247   |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 851      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 68958    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00172  |\n",
            "|    n_updates        | 6890     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 60001 | Mean Reward: -130.36 ± 62.85\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 442      |\n",
            "|    ep_rew_mean      | -124     |\n",
            "|    exploration_rate | 0.13     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 1109     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70326    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0024   |\n",
            "|    n_updates        | 7027     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 427      |\n",
            "|    ep_rew_mean      | -125     |\n",
            "|    exploration_rate | 0.117    |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 1117     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 71345    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00229  |\n",
            "|    n_updates        | 7129     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 412      |\n",
            "|    ep_rew_mean      | -124     |\n",
            "|    exploration_rate | 0.107    |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 1153     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 72167    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0323   |\n",
            "|    n_updates        | 7211     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 402      |\n",
            "|    ep_rew_mean      | -127     |\n",
            "|    exploration_rate | 0.093    |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 1146     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 73295    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0146   |\n",
            "|    n_updates        | 7324     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 399      |\n",
            "|    ep_rew_mean      | -130     |\n",
            "|    exploration_rate | 0.0719   |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 1015     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 75001    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0238   |\n",
            "|    n_updates        | 7495     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 387      |\n",
            "|    ep_rew_mean      | -131     |\n",
            "|    exploration_rate | 0.0583   |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 1026     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 76096    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.036    |\n",
            "|    n_updates        | 7604     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 380      |\n",
            "|    ep_rew_mean      | -132     |\n",
            "|    exploration_rate | 0.0407   |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 1018     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 77521    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0146   |\n",
            "|    n_updates        | 7747     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 377      |\n",
            "|    ep_rew_mean      | -133     |\n",
            "|    exploration_rate | 0.0195   |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 969      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 79232    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00927  |\n",
            "|    n_updates        | 7918     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 70001 | Mean Reward: -120.21 ± 35.59\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 363      |\n",
            "|    ep_rew_mean      | -132     |\n",
            "|    exploration_rate | 0.116    |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 986      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80325    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00258  |\n",
            "|    n_updates        | 8027     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 367      |\n",
            "|    ep_rew_mean      | -132     |\n",
            "|    exploration_rate | 0.0946   |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 802      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 82311    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00151  |\n",
            "|    n_updates        | 8226     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 377      |\n",
            "|    ep_rew_mean      | -131     |\n",
            "|    exploration_rate | 0.0668   |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 743      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 84838    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0258   |\n",
            "|    n_updates        | 8478     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 384      |\n",
            "|    ep_rew_mean      | -128     |\n",
            "|    exploration_rate | 0.0363   |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 713      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 87610    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0118   |\n",
            "|    n_updates        | 8755     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 80001 | Mean Reward: -126.08 ± 43.94\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 398      |\n",
            "|    ep_rew_mean      | -128     |\n",
            "|    exploration_rate | 0.0968   |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 934      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 91228    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00982  |\n",
            "|    n_updates        | 9117     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 393      |\n",
            "|    ep_rew_mean      | -128     |\n",
            "|    exploration_rate | 0.0778   |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 819      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 93156    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00251  |\n",
            "|    n_updates        | 9310     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 396      |\n",
            "|    ep_rew_mean      | -125     |\n",
            "|    exploration_rate | 0.0513   |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 764      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 95827    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00224  |\n",
            "|    n_updates        | 9577     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 399      |\n",
            "|    ep_rew_mean      | -123     |\n",
            "|    exploration_rate | 0.0258   |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 751      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 98405    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 9835     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 90001 | Mean Reward: -211.67 ± 193.36\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 421      |\n",
            "|    ep_rew_mean      | -121     |\n",
            "|    exploration_rate | 0.0772   |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 796      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 102528   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00157  |\n",
            "|    n_updates        | 10247    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 447      |\n",
            "|    ep_rew_mean      | -120     |\n",
            "|    exploration_rate | 0.0462   |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 733      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 105973   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00219  |\n",
            "|    n_updates        | 10592    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 462      |\n",
            "|    ep_rew_mean      | -119     |\n",
            "|    exploration_rate | 0.0185   |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 674      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 109058   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00149  |\n",
            "|    n_updates        | 10900    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 100001 | Mean Reward: -45.39 ± 22.30\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 481      |\n",
            "|    ep_rew_mean      | -118     |\n",
            "|    exploration_rate | 0.0644   |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 685      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 113405   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0016   |\n",
            "|    n_updates        | 11335    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 503      |\n",
            "|    ep_rew_mean      | -116     |\n",
            "|    exploration_rate | 0.0314   |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 648      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 117405   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0288   |\n",
            "|    n_updates        | 11735    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 110001 | Mean Reward: -33.66 ± 20.00\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 527      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.0709   |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 629      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 122000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00883  |\n",
            "|    n_updates        | 12194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 556      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.0405   |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 588      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 126000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0305   |\n",
            "|    n_updates        | 12594    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 589      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 585      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 130000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00674  |\n",
            "|    n_updates        | 12994    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 120001 | Mean Reward: -47.76 ± 36.96\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 608      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.0582   |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 587      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 133183   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0166   |\n",
            "|    n_updates        | 13313    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 638      |\n",
            "|    ep_rew_mean      | -98      |\n",
            "|    exploration_rate | 0.0299   |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 590      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 137183   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0344   |\n",
            "|    n_updates        | 13713    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 130001 | Mean Reward: -19.27 ± 22.04\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 667      |\n",
            "|    ep_rew_mean      | -94.9    |\n",
            "|    exploration_rate | 0.0628   |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 481      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 142000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00142  |\n",
            "|    n_updates        | 14194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 699      |\n",
            "|    ep_rew_mean      | -91      |\n",
            "|    exploration_rate | 0.0364   |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 544      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 146000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00175  |\n",
            "|    n_updates        | 14594    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 728      |\n",
            "|    ep_rew_mean      | -85.9    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 530      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 150000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00148  |\n",
            "|    n_updates        | 14994    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 140001 | Mean Reward: -11.66 ± 21.24\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 751      |\n",
            "|    ep_rew_mean      | -81.7    |\n",
            "|    exploration_rate | 0.0471   |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 554      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 154000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00527  |\n",
            "|    n_updates        | 15394    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 780      |\n",
            "|    ep_rew_mean      | -77.6    |\n",
            "|    exploration_rate | 0.0224   |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 553      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 158000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0186   |\n",
            "|    n_updates        | 15794    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 150001 | Mean Reward: -23.91 ± 15.11\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 806      |\n",
            "|    ep_rew_mean      | -72.8    |\n",
            "|    exploration_rate | 0.0566   |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 546      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 162000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00552  |\n",
            "|    n_updates        | 16194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 828      |\n",
            "|    ep_rew_mean      | -67.1    |\n",
            "|    exploration_rate | 0.0333   |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 600      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 166000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00509  |\n",
            "|    n_updates        | 16594    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 858      |\n",
            "|    ep_rew_mean      | -62.4    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 585      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 170000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00649  |\n",
            "|    n_updates        | 16994    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 160001 | Mean Reward: -7.28 ± 28.51\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 878      |\n",
            "|    ep_rew_mean      | -57.2    |\n",
            "|    exploration_rate | 0.043    |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 482      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 174000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00164  |\n",
            "|    n_updates        | 17394    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 893      |\n",
            "|    ep_rew_mean      | -53.7    |\n",
            "|    exploration_rate | 0.021    |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 513      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 178000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0212   |\n",
            "|    n_updates        | 17794    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 170001 | Mean Reward: -18.39 ± 16.61\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 905      |\n",
            "|    ep_rew_mean      | -50      |\n",
            "|    exploration_rate | 0.0517   |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 409      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 182000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0185   |\n",
            "|    n_updates        | 18194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 918      |\n",
            "|    ep_rew_mean      | -44.5    |\n",
            "|    exploration_rate | 0.0308   |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 498      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 186000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0016   |\n",
            "|    n_updates        | 18594    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 939      |\n",
            "|    ep_rew_mean      | -41.1    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 527      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 190000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00214  |\n",
            "|    n_updates        | 18994    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 180001 | Mean Reward: -19.01 ± 21.35\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 952      |\n",
            "|    ep_rew_mean      | -38.2    |\n",
            "|    exploration_rate | 0.0397   |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 489      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 194000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000966 |\n",
            "|    n_updates        | 19394    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 966      |\n",
            "|    ep_rew_mean      | -34.2    |\n",
            "|    exploration_rate | 0.0199   |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 523      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 198000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.01     |\n",
            "|    n_updates        | 19794    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 190001 | Mean Reward: -15.87 ± 18.97\n",
            "Model and VecNormalize stats saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0001_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. envs=1, batch size= 128, lr=3e-4"
      ],
      "metadata": {
        "id": "lVfg_hMsEsZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lunarlander(1, 128, 3e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBPlftRfInSe",
        "outputId": "8e78db96-12e8-4c19-f62b-87a6e0fb9b9d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 82.5     |\n",
            "|    ep_rew_mean      | -202     |\n",
            "|    exploration_rate | 0.967    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 1850     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 330      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00413  |\n",
            "|    n_updates        | 27       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86.4     |\n",
            "|    ep_rew_mean      | -173     |\n",
            "|    exploration_rate | 0.932    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 1806     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 691      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0461   |\n",
            "|    n_updates        | 64       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.7     |\n",
            "|    ep_rew_mean      | -179     |\n",
            "|    exploration_rate | 0.901    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 1705     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1004     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0237   |\n",
            "|    n_updates        | 95       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.8     |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.867    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 1584     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1341     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0132   |\n",
            "|    n_updates        | 129      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 85.5     |\n",
            "|    ep_rew_mean      | -191     |\n",
            "|    exploration_rate | 0.831    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 1531     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1711     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0171   |\n",
            "|    n_updates        | 166      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.3     |\n",
            "|    ep_rew_mean      | -187     |\n",
            "|    exploration_rate | 0.793    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 1451     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 2095     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0141   |\n",
            "|    n_updates        | 204      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.8     |\n",
            "|    ep_rew_mean      | -177     |\n",
            "|    exploration_rate | 0.757    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 1447     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 2457     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00896  |\n",
            "|    n_updates        | 240      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.7     |\n",
            "|    ep_rew_mean      | -166     |\n",
            "|    exploration_rate | 0.713    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 1401     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 2902     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0468   |\n",
            "|    n_updates        | 285      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92.4     |\n",
            "|    ep_rew_mean      | -163     |\n",
            "|    exploration_rate | 0.671    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 1358     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 3325     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.01     |\n",
            "|    n_updates        | 327      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.1     |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.631    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 1380     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 3724     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0206   |\n",
            "|    n_updates        | 367      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.7     |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.575    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 1383     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 4297     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0253   |\n",
            "|    n_updates        | 424      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 99.9     |\n",
            "|    ep_rew_mean      | -145     |\n",
            "|    exploration_rate | 0.525    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 1391     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 4793     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00321  |\n",
            "|    n_updates        | 474      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 102      |\n",
            "|    ep_rew_mean      | -144     |\n",
            "|    exploration_rate | 0.473    |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 1402     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 5319     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00124  |\n",
            "|    n_updates        | 526      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -146     |\n",
            "|    exploration_rate | 0.414    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 1400     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 5921     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00857  |\n",
            "|    n_updates        | 587      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 107      |\n",
            "|    ep_rew_mean      | -147     |\n",
            "|    exploration_rate | 0.367    |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 1402     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 6397     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00679  |\n",
            "|    n_updates        | 634      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 112      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.289    |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 1389     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 7185     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0121   |\n",
            "|    n_updates        | 713      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 117      |\n",
            "|    ep_rew_mean      | -155     |\n",
            "|    exploration_rate | 0.213    |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 1376     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 7945     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0223   |\n",
            "|    n_updates        | 789      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 120      |\n",
            "|    ep_rew_mean      | -159     |\n",
            "|    exploration_rate | 0.146    |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 1362     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 8630     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00164  |\n",
            "|    n_updates        | 857      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 124      |\n",
            "|    ep_rew_mean      | -162     |\n",
            "|    exploration_rate | 0.0645   |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 1344     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 9449     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00537  |\n",
            "|    n_updates        | 939      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 1 | Mean Reward: -144.67 ± 53.80\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 126      |\n",
            "|    ep_rew_mean      | -158     |\n",
            "|    exploration_rate | 0.5      |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 1340     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10110    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00259  |\n",
            "|    n_updates        | 1005     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 127      |\n",
            "|    ep_rew_mean      | -160     |\n",
            "|    exploration_rate | 0.47     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 1370     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10710    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00557  |\n",
            "|    n_updates        | 1065     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 128      |\n",
            "|    ep_rew_mean      | -156     |\n",
            "|    exploration_rate | 0.438    |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 1356     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 11354    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0206   |\n",
            "|    n_updates        | 1130     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 130      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.403    |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 1343     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 12064    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00432  |\n",
            "|    n_updates        | 1201     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -153     |\n",
            "|    exploration_rate | 0.366    |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 1319     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 12812    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00661  |\n",
            "|    n_updates        | 1276     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.322    |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 1288     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 13696    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00832  |\n",
            "|    n_updates        | 1364     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 146      |\n",
            "|    ep_rew_mean      | -149     |\n",
            "|    exploration_rate | 0.257    |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 1132     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 15015    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00159  |\n",
            "|    n_updates        | 1496     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -149     |\n",
            "|    exploration_rate | 0.199    |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 1034     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 16184    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00108  |\n",
            "|    n_updates        | 1613     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 186      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.0277   |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 847      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 19642    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00303  |\n",
            "|    n_updates        | 1959     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 10001 | Mean Reward: -109.07 ± 41.68\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 195      |\n",
            "|    ep_rew_mean      | -141     |\n",
            "|    exploration_rate | 0.298    |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 802      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 21268    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.002    |\n",
            "|    n_updates        | 2121     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 220      |\n",
            "|    ep_rew_mean      | -140     |\n",
            "|    exploration_rate | 0.203    |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 655      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 24140    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00936  |\n",
            "|    n_updates        | 2408     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 252      |\n",
            "|    ep_rew_mean      | -139     |\n",
            "|    exploration_rate | 0.087    |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 667      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 27668    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00743  |\n",
            "|    n_updates        | 2761     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 20001 | Mean Reward: -57.95 ± 22.36\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 273      |\n",
            "|    ep_rew_mean      | -137     |\n",
            "|    exploration_rate | 0.251    |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 1089     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30259    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0254   |\n",
            "|    n_updates        | 3020     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 308      |\n",
            "|    ep_rew_mean      | -137     |\n",
            "|    exploration_rate | 0.152    |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 565      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 34259    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00464  |\n",
            "|    n_updates        | 3420     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 344      |\n",
            "|    ep_rew_mean      | -133     |\n",
            "|    exploration_rate | 0.0531   |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 561      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 38259    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00351  |\n",
            "|    n_updates        | 3820     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 30001 | Mean Reward: -48.76 ± 16.81\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 373      |\n",
            "|    ep_rew_mean      | -131     |\n",
            "|    exploration_rate | 0.163    |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 710      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 42256    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00256  |\n",
            "|    n_updates        | 4220     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 407      |\n",
            "|    ep_rew_mean      | -129     |\n",
            "|    exploration_rate | 0.0841   |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 602      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 46256    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0203   |\n",
            "|    n_updates        | 4620     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 40001 | Mean Reward: -37.98 ± 16.94\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 442      |\n",
            "|    ep_rew_mean      | -127     |\n",
            "|    exploration_rate | 0.158    |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 430      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 51000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0121   |\n",
            "|    n_updates        | 5094     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 477      |\n",
            "|    ep_rew_mean      | -124     |\n",
            "|    exploration_rate | 0.0925   |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 550      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 55000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00203  |\n",
            "|    n_updates        | 5494     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 511      |\n",
            "|    ep_rew_mean      | -118     |\n",
            "|    exploration_rate | 0.0265   |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 540      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 59000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00241  |\n",
            "|    n_updates        | 5894     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 50001 | Mean Reward: -39.46 ± 46.36\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 533      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.127    |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 741      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 61708    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00524  |\n",
            "|    n_updates        | 6165     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 565      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.0707   |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 601      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 65708    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00212  |\n",
            "|    n_updates        | 6565     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 597      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.0141   |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 587      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 69708    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0101   |\n",
            "|    n_updates        | 6965     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 60001 | Mean Reward: -74.07 ± 51.55\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 631      |\n",
            "|    ep_rew_mean      | -93.3    |\n",
            "|    exploration_rate | 0.0842   |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 514      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 74000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0283   |\n",
            "|    n_updates        | 7394     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 655      |\n",
            "|    ep_rew_mean      | -87.4    |\n",
            "|    exploration_rate | 0.0441   |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 510      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 77243    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00181  |\n",
            "|    n_updates        | 7719     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 676      |\n",
            "|    ep_rew_mean      | -87.9    |\n",
            "|    exploration_rate | 0.0102   |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 539      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 79984    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0113   |\n",
            "|    n_updates        | 7993     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 70001 | Mean Reward: -69.23 ± 23.32\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 696      |\n",
            "|    ep_rew_mean      | -82.9    |\n",
            "|    exploration_rate | 0.092    |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 772      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 82544    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00289  |\n",
            "|    n_updates        | 8249     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 721      |\n",
            "|    ep_rew_mean      | -82.1    |\n",
            "|    exploration_rate | 0.057    |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 626      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 85731    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00998  |\n",
            "|    n_updates        | 8568     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 745      |\n",
            "|    ep_rew_mean      | -82.6    |\n",
            "|    exploration_rate | 0.0228   |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 608      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 88836    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 8878     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 80001 | Mean Reward: -36.97 ± 22.17\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 772      |\n",
            "|    ep_rew_mean      | -80.2    |\n",
            "|    exploration_rate | 0.0793   |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 518      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 93000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00707  |\n",
            "|    n_updates        | 9294     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 803      |\n",
            "|    ep_rew_mean      | -77.2    |\n",
            "|    exploration_rate | 0.0397   |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 509      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 97000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0169   |\n",
            "|    n_updates        | 9694     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 90001 | Mean Reward: -59.40 ± 40.08\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 830      |\n",
            "|    ep_rew_mean      | -73.6    |\n",
            "|    exploration_rate | 0.091    |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 463      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 101000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00247  |\n",
            "|    n_updates        | 10094    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 858      |\n",
            "|    ep_rew_mean      | -68.7    |\n",
            "|    exploration_rate | 0.055    |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 486      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 105000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00323  |\n",
            "|    n_updates        | 10494    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 864      |\n",
            "|    ep_rew_mean      | -64.3    |\n",
            "|    exploration_rate | 0.019    |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 463      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 109000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0126   |\n",
            "|    n_updates        | 10894    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 100001 | Mean Reward: -34.59 ± 16.31\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 891      |\n",
            "|    ep_rew_mean      | -63.2    |\n",
            "|    exploration_rate | 0.0677   |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 546      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 113000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00209  |\n",
            "|    n_updates        | 11294    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 893      |\n",
            "|    ep_rew_mean      | -59      |\n",
            "|    exploration_rate | 0.042    |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 495      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 116124   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00256  |\n",
            "|    n_updates        | 11607    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 110001 | Mean Reward: -133.34 ± 122.97\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 898      |\n",
            "|    ep_rew_mean      | -55.6    |\n",
            "|    exploration_rate | 0.0785   |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 467      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 121000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00151  |\n",
            "|    n_updates        | 12094    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 913      |\n",
            "|    ep_rew_mean      | -54.2    |\n",
            "|    exploration_rate | 0.0481   |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 500      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 125000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00203  |\n",
            "|    n_updates        | 12494    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 913      |\n",
            "|    ep_rew_mean      | -51.8    |\n",
            "|    exploration_rate | 0.0176   |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 521      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 129000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00185  |\n",
            "|    n_updates        | 12894    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 120001 | Mean Reward: -41.64 ± 19.54\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 913      |\n",
            "|    ep_rew_mean      | -51.7    |\n",
            "|    exploration_rate | 0.0595   |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 561      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 133000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00575  |\n",
            "|    n_updates        | 13294    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 921      |\n",
            "|    ep_rew_mean      | -51.7    |\n",
            "|    exploration_rate | 0.0312   |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 574      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 137000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 13694    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 130001 | Mean Reward: -33.60 ± 20.62\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 921      |\n",
            "|    ep_rew_mean      | -51.3    |\n",
            "|    exploration_rate | 0.0694   |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 634      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 141000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00144  |\n",
            "|    n_updates        | 14094    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 921      |\n",
            "|    ep_rew_mean      | -50.6    |\n",
            "|    exploration_rate | 0.043    |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 537      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 145000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00184  |\n",
            "|    n_updates        | 14494    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 921      |\n",
            "|    ep_rew_mean      | -49.6    |\n",
            "|    exploration_rate | 0.0166   |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 564      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 149000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0143   |\n",
            "|    n_updates        | 14894    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 140001 | Mean Reward: -40.64 ± 19.47\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 921      |\n",
            "|    ep_rew_mean      | -49.7    |\n",
            "|    exploration_rate | 0.0533   |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 654      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 153000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00275  |\n",
            "|    n_updates        | 15294    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 934      |\n",
            "|    ep_rew_mean      | -48.4    |\n",
            "|    exploration_rate | 0.0286   |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 593      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 157000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0104   |\n",
            "|    n_updates        | 15694    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 150001 | Mean Reward: -44.26 ± 61.96\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 934      |\n",
            "|    ep_rew_mean      | -48.5    |\n",
            "|    exploration_rate | 0.0624   |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 598      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 161000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00183  |\n",
            "|    n_updates        | 16094    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 926      |\n",
            "|    ep_rew_mean      | -50.1    |\n",
            "|    exploration_rate | 0.0435   |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 627      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 164255   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00489  |\n",
            "|    n_updates        | 16420    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 926      |\n",
            "|    ep_rew_mean      | -50.3    |\n",
            "|    exploration_rate | 0.0202   |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 580      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 168255   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00483  |\n",
            "|    n_updates        | 16820    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 160001 | Mean Reward: -45.41 ± 20.57\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 934      |\n",
            "|    ep_rew_mean      | -49.1    |\n",
            "|    exploration_rate | 0.0485   |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 524      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 173000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00127  |\n",
            "|    n_updates        | 17294    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 946      |\n",
            "|    ep_rew_mean      | -46.9    |\n",
            "|    exploration_rate | 0.0265   |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 538      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 177000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0023   |\n",
            "|    n_updates        | 17694    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 170001 | Mean Reward: -70.98 ± 49.92\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 961      |\n",
            "|    ep_rew_mean      | -46.2    |\n",
            "|    exploration_rate | 0.0569   |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 427      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 181000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00135  |\n",
            "|    n_updates        | 18094    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 969      |\n",
            "|    ep_rew_mean      | -45.4    |\n",
            "|    exploration_rate | 0.0361   |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 548      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 185000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0379   |\n",
            "|    n_updates        | 18494    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 970      |\n",
            "|    ep_rew_mean      | -42.1    |\n",
            "|    exploration_rate | 0.0196   |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 529      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 188158   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0302   |\n",
            "|    n_updates        | 18810    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 180001 | Mean Reward: -75.82 ± 59.04\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 975      |\n",
            "|    ep_rew_mean      | -42      |\n",
            "|    exploration_rate | 0.0447   |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 527      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 193000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00183  |\n",
            "|    n_updates        | 19294    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 975      |\n",
            "|    ep_rew_mean      | -43.2    |\n",
            "|    exploration_rate | 0.0249   |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 530      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 197000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00156  |\n",
            "|    n_updates        | 19694    |\n",
            "----------------------------------\n",
            "LunarLander - Step: 190001 | Mean Reward: -89.82 ± 104.50\n",
            "Model and VecNormalize stats saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv1B128LR0.0003_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  5. envs=4, batch size= 64, lr=1e-4"
      ],
      "metadata": {
        "id": "r2nNOOsXM70o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lunarlander(4, 64, 1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egBei7bDNTuK",
        "outputId": "e0d8523e-0380-4974-a2c3-8bd6e7f0854f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 98.2     |\n",
            "|    ep_rew_mean      | -164     |\n",
            "|    exploration_rate | 0.95     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 3510     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 500      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00753  |\n",
            "|    n_updates        | 11       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 104      |\n",
            "|    ep_rew_mean      | -174     |\n",
            "|    exploration_rate | 0.907    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 3679     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 936      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0515   |\n",
            "|    n_updates        | 22       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 94.2     |\n",
            "|    ep_rew_mean      | -180     |\n",
            "|    exploration_rate | 0.867    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 3714     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1340     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00669  |\n",
            "|    n_updates        | 32       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.5     |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.836    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 3682     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1656     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00853  |\n",
            "|    n_updates        | 40       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.2     |\n",
            "|    ep_rew_mean      | -173     |\n",
            "|    exploration_rate | 0.8      |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 3616     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 2016     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0412   |\n",
            "|    n_updates        | 49       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91       |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.765    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 3598     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 2372     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00586  |\n",
            "|    n_updates        | 58       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.4     |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.731    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 3596     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 2716     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00266  |\n",
            "|    n_updates        | 66       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 95       |\n",
            "|    ep_rew_mean      | -226     |\n",
            "|    exploration_rate | 0.685    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 3577     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 3180     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0198   |\n",
            "|    n_updates        | 78       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 94.1     |\n",
            "|    ep_rew_mean      | -229     |\n",
            "|    exploration_rate | 0.656    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 3560     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 3476     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0328   |\n",
            "|    n_updates        | 85       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 95.9     |\n",
            "|    ep_rew_mean      | -225     |\n",
            "|    exploration_rate | 0.598    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 3514     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 4060     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0018   |\n",
            "|    n_updates        | 100      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.2     |\n",
            "|    ep_rew_mean      | -235     |\n",
            "|    exploration_rate | 0.565    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 3505     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 4392     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0272   |\n",
            "|    n_updates        | 108      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 96.9     |\n",
            "|    ep_rew_mean      | -232     |\n",
            "|    exploration_rate | 0.507    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 3514     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 4984     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0239   |\n",
            "|    n_updates        | 123      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 100      |\n",
            "|    ep_rew_mean      | -238     |\n",
            "|    exploration_rate | 0.462    |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 3510     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 5432     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0016   |\n",
            "|    n_updates        | 134      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 101      |\n",
            "|    ep_rew_mean      | -236     |\n",
            "|    exploration_rate | 0.423    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 3522     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 5828     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0513   |\n",
            "|    n_updates        | 144      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 101      |\n",
            "|    ep_rew_mean      | -236     |\n",
            "|    exploration_rate | 0.377    |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 3530     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 6292     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000903 |\n",
            "|    n_updates        | 156      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 102      |\n",
            "|    ep_rew_mean      | -235     |\n",
            "|    exploration_rate | 0.322    |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 3504     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 6844     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0204   |\n",
            "|    n_updates        | 170      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | -247     |\n",
            "|    exploration_rate | 0.284    |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 3445     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 7228     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000703 |\n",
            "|    n_updates        | 179      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -251     |\n",
            "|    exploration_rate | 0.227    |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 3412     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 7808     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00177  |\n",
            "|    n_updates        | 194      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -255     |\n",
            "|    exploration_rate | 0.192    |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 3394     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8164     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0011   |\n",
            "|    n_updates        | 203      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | -264     |\n",
            "|    exploration_rate | 0.151    |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 3360     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8572     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0179   |\n",
            "|    n_updates        | 213      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -260     |\n",
            "|    exploration_rate | 0.0967   |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 3332     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 9124     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0218   |\n",
            "|    n_updates        | 227      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -261     |\n",
            "|    exploration_rate | 0.054    |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 3324     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 9556     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0012   |\n",
            "|    n_updates        | 237      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | -261     |\n",
            "|    exploration_rate | 0.0155   |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 3310     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 9944     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000622 |\n",
            "|    n_updates        | 247      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 1 | Mean Reward: -383.06 ± 208.51\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -266     |\n",
            "|    exploration_rate | 0.48     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 3002     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10512    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0017   |\n",
            "|    n_updates        | 261      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -267     |\n",
            "|    exploration_rate | 0.459    |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 3241     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10932    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.001    |\n",
            "|    n_updates        | 272      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -273     |\n",
            "|    exploration_rate | 0.443    |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 3346     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 11252    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000799 |\n",
            "|    n_updates        | 280      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | -284     |\n",
            "|    exploration_rate | 0.423    |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 3424     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 11660    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00153  |\n",
            "|    n_updates        | 290      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -285     |\n",
            "|    exploration_rate | 0.404    |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 3473     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 12032    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00157  |\n",
            "|    n_updates        | 299      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | -286     |\n",
            "|    exploration_rate | 0.391    |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 3500     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 12312    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000627 |\n",
            "|    n_updates        | 306      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -290     |\n",
            "|    exploration_rate | 0.368    |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 3525     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 12760    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00106  |\n",
            "|    n_updates        | 317      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -293     |\n",
            "|    exploration_rate | 0.349    |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 3508     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 13156    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00195  |\n",
            "|    n_updates        | 327      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 107      |\n",
            "|    ep_rew_mean      | -293     |\n",
            "|    exploration_rate | 0.332    |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 3501     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 13496    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00132  |\n",
            "|    n_updates        | 336      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | -288     |\n",
            "|    exploration_rate | 0.311    |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 3472     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 13924    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0146   |\n",
            "|    n_updates        | 347      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | -288     |\n",
            "|    exploration_rate | 0.282    |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 3327     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 14504    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00181  |\n",
            "|    n_updates        | 361      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | -291     |\n",
            "|    exploration_rate | 0.258    |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 3320     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 14988    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0137   |\n",
            "|    n_updates        | 373      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | -294     |\n",
            "|    exploration_rate | 0.241    |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 3305     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 15328    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0119   |\n",
            "|    n_updates        | 382      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 109      |\n",
            "|    ep_rew_mean      | -302     |\n",
            "|    exploration_rate | 0.204    |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 3263     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 16084    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0226   |\n",
            "|    n_updates        | 401      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 110      |\n",
            "|    ep_rew_mean      | -306     |\n",
            "|    exploration_rate | 0.184    |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 3238     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 16476    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00123  |\n",
            "|    n_updates        | 410      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 111      |\n",
            "|    ep_rew_mean      | -312     |\n",
            "|    exploration_rate | 0.153    |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 3200     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 17112    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00066  |\n",
            "|    n_updates        | 426      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 112      |\n",
            "|    ep_rew_mean      | -317     |\n",
            "|    exploration_rate | 0.133    |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 3203     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 17516    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0167   |\n",
            "|    n_updates        | 436      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 111      |\n",
            "|    ep_rew_mean      | -317     |\n",
            "|    exploration_rate | 0.109    |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 3210     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 17992    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000629 |\n",
            "|    n_updates        | 448      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 109      |\n",
            "|    ep_rew_mean      | -311     |\n",
            "|    exploration_rate | 0.0904   |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 3216     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 18376    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000625 |\n",
            "|    n_updates        | 458      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | -308     |\n",
            "|    exploration_rate | 0.073    |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 3221     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 18728    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0223   |\n",
            "|    n_updates        | 467      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | -305     |\n",
            "|    exploration_rate | 0.0581   |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 3215     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 19028    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0146   |\n",
            "|    n_updates        | 474      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | -300     |\n",
            "|    exploration_rate | 0.0298   |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 3201     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 19600    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00497  |\n",
            "|    n_updates        | 488      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 10001 | Mean Reward: -339.07 ± 97.63\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 110      |\n",
            "|    ep_rew_mean      | -304     |\n",
            "|    exploration_rate | 0.334    |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 2820     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0111   |\n",
            "|    n_updates        | 503      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 109      |\n",
            "|    ep_rew_mean      | -301     |\n",
            "|    exploration_rate | 0.323    |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 2961     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20516    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000532 |\n",
            "|    n_updates        | 511      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 110      |\n",
            "|    ep_rew_mean      | -302     |\n",
            "|    exploration_rate | 0.309    |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 3078     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20936    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00142  |\n",
            "|    n_updates        | 522      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 110      |\n",
            "|    ep_rew_mean      | -301     |\n",
            "|    exploration_rate | 0.288    |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 3102     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 21564    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000813 |\n",
            "|    n_updates        | 538      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 110      |\n",
            "|    ep_rew_mean      | -307     |\n",
            "|    exploration_rate | 0.275    |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 3107     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 21956    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00141  |\n",
            "|    n_updates        | 547      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 111      |\n",
            "|    ep_rew_mean      | -304     |\n",
            "|    exploration_rate | 0.255    |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 3009     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 22588    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000937 |\n",
            "|    n_updates        | 563      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 112      |\n",
            "|    ep_rew_mean      | -302     |\n",
            "|    exploration_rate | 0.24     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 2803     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 23036    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00177  |\n",
            "|    n_updates        | 574      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 117      |\n",
            "|    ep_rew_mean      | -304     |\n",
            "|    exploration_rate | 0.211    |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 2513     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 23920    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00776  |\n",
            "|    n_updates        | 596      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 119      |\n",
            "|    ep_rew_mean      | -307     |\n",
            "|    exploration_rate | 0.193    |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 2458     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 24460    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00063  |\n",
            "|    n_updates        | 610      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 120      |\n",
            "|    ep_rew_mean      | -310     |\n",
            "|    exploration_rate | 0.177    |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 2406     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 24932    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000581 |\n",
            "|    n_updates        | 622      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 121      |\n",
            "|    ep_rew_mean      | -311     |\n",
            "|    exploration_rate | 0.163    |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 2402     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 25356    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000562 |\n",
            "|    n_updates        | 632      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 122      |\n",
            "|    ep_rew_mean      | -309     |\n",
            "|    exploration_rate | 0.147    |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 2353     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 25840    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000588 |\n",
            "|    n_updates        | 644      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 123      |\n",
            "|    ep_rew_mean      | -308     |\n",
            "|    exploration_rate | 0.128    |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 2327     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 26424    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0174   |\n",
            "|    n_updates        | 659      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 122      |\n",
            "|    ep_rew_mean      | -308     |\n",
            "|    exploration_rate | 0.113    |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 2363     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 26892    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00745  |\n",
            "|    n_updates        | 671      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 123      |\n",
            "|    ep_rew_mean      | -307     |\n",
            "|    exploration_rate | 0.0879   |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 2375     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 27640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00691  |\n",
            "|    n_updates        | 689      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 127      |\n",
            "|    ep_rew_mean      | -301     |\n",
            "|    exploration_rate | 0.0518   |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 2291     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 28732    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000701 |\n",
            "|    n_updates        | 717      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -295     |\n",
            "|    exploration_rate | 0.0253   |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 2152     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 29536    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000861 |\n",
            "|    n_updates        | 737      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 20001 | Mean Reward: -203.06 ± 123.66\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 130      |\n",
            "|    ep_rew_mean      | -287     |\n",
            "|    exploration_rate | 0.249    |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 2995     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30360    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00743  |\n",
            "|    n_updates        | 757      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 130      |\n",
            "|    ep_rew_mean      | -279     |\n",
            "|    exploration_rate | 0.235    |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 3001     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30904    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00442  |\n",
            "|    n_updates        | 771      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -273     |\n",
            "|    exploration_rate | 0.214    |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 2462     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 31740    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000693 |\n",
            "|    n_updates        | 792      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -273     |\n",
            "|    exploration_rate | 0.205    |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 2511     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 32108    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0136   |\n",
            "|    n_updates        | 801      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -270     |\n",
            "|    exploration_rate | 0.191    |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 2585     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32676    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000628 |\n",
            "|    n_updates        | 815      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -271     |\n",
            "|    exploration_rate | 0.178    |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 2656     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 33224    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00113  |\n",
            "|    n_updates        | 829      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 139      |\n",
            "|    ep_rew_mean      | -270     |\n",
            "|    exploration_rate | 0.151    |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 2572     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 34308    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000671 |\n",
            "|    n_updates        | 856      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 145      |\n",
            "|    ep_rew_mean      | -267     |\n",
            "|    exploration_rate | 0.139    |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 2536     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 34788    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00572  |\n",
            "|    n_updates        | 868      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 145      |\n",
            "|    ep_rew_mean      | -267     |\n",
            "|    exploration_rate | 0.119    |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 2536     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 35608    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00127  |\n",
            "|    n_updates        | 889      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 149      |\n",
            "|    ep_rew_mean      | -266     |\n",
            "|    exploration_rate | 0.0951   |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 2516     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 36560    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00694  |\n",
            "|    n_updates        | 912      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 153      |\n",
            "|    ep_rew_mean      | -261     |\n",
            "|    exploration_rate | 0.0768   |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 2495     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 37300    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0011   |\n",
            "|    n_updates        | 931      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -255     |\n",
            "|    exploration_rate | 0.0639   |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 2515     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 37824    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00874  |\n",
            "|    n_updates        | 944      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 156      |\n",
            "|    ep_rew_mean      | -249     |\n",
            "|    exploration_rate | 0.053    |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 2536     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 38264    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00282  |\n",
            "|    n_updates        | 955      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 156      |\n",
            "|    ep_rew_mean      | -244     |\n",
            "|    exploration_rate | 0.0361   |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 2557     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 38944    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00756  |\n",
            "|    n_updates        | 972      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 158      |\n",
            "|    ep_rew_mean      | -238     |\n",
            "|    exploration_rate | 0.0237   |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 2560     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 39448    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.003    |\n",
            "|    n_updates        | 985      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 30001 | Mean Reward: -190.21 ± 89.29\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -234     |\n",
            "|    exploration_rate | 0.203    |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 2886     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40264    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000735 |\n",
            "|    n_updates        | 1005     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -226     |\n",
            "|    exploration_rate | 0.194    |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 2964     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40720    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00281  |\n",
            "|    n_updates        | 1016     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 156      |\n",
            "|    ep_rew_mean      | -219     |\n",
            "|    exploration_rate | 0.183    |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 2754     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 41280    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00679  |\n",
            "|    n_updates        | 1030     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 156      |\n",
            "|    ep_rew_mean      | -214     |\n",
            "|    exploration_rate | 0.174    |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 2809     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 41740    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00249  |\n",
            "|    n_updates        | 1042     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -209     |\n",
            "|    exploration_rate | 0.164    |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 2863     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 42212    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000716 |\n",
            "|    n_updates        | 1054     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 157      |\n",
            "|    ep_rew_mean      | -209     |\n",
            "|    exploration_rate | 0.152    |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 2877     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 42824    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000431 |\n",
            "|    n_updates        | 1069     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 157      |\n",
            "|    ep_rew_mean      | -208     |\n",
            "|    exploration_rate | 0.135    |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 2868     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 43664    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 1090     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 158      |\n",
            "|    ep_rew_mean      | -208     |\n",
            "|    exploration_rate | 0.126    |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 2826     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 44144    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000959 |\n",
            "|    n_updates        | 1102     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -206     |\n",
            "|    exploration_rate | 0.113    |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 2824     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 44788    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00327  |\n",
            "|    n_updates        | 1118     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.0982   |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 2762     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 45544    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000962 |\n",
            "|    n_updates        | 1137     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -204     |\n",
            "|    exploration_rate | 0.0889   |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 2789     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 46016    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00308  |\n",
            "|    n_updates        | 1149     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -207     |\n",
            "|    exploration_rate | 0.0793   |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 2795     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 46500    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00118  |\n",
            "|    n_updates        | 1161     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 150      |\n",
            "|    ep_rew_mean      | -208     |\n",
            "|    exploration_rate | 0.0658   |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 2785     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 47184    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000507 |\n",
            "|    n_updates        | 1178     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -207     |\n",
            "|    exploration_rate | 0.0516   |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 2705     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 47900    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00148  |\n",
            "|    n_updates        | 1196     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 159      |\n",
            "|    ep_rew_mean      | -207     |\n",
            "|    exploration_rate | 0.0212   |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 2348     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 49432    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000692 |\n",
            "|    n_updates        | 1234     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 40001 | Mean Reward: -280.03 ± 90.31\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 164      |\n",
            "|    ep_rew_mean      | -207     |\n",
            "|    exploration_rate | 0.171    |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 2506     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50244    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00136  |\n",
            "|    n_updates        | 1255     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 163      |\n",
            "|    ep_rew_mean      | -210     |\n",
            "|    exploration_rate | 0.164    |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 2936     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50676    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00343  |\n",
            "|    n_updates        | 1265     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 159      |\n",
            "|    ep_rew_mean      | -212     |\n",
            "|    exploration_rate | 0.152    |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 2931     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 51376    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00229  |\n",
            "|    n_updates        | 1283     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 159      |\n",
            "|    ep_rew_mean      | -210     |\n",
            "|    exploration_rate | 0.143    |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 2783     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 51940    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00153  |\n",
            "|    n_updates        | 1297     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 156      |\n",
            "|    ep_rew_mean      | -215     |\n",
            "|    exploration_rate | 0.134    |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 2831     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 52512    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00116  |\n",
            "|    n_updates        | 1311     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 153      |\n",
            "|    ep_rew_mean      | -218     |\n",
            "|    exploration_rate | 0.125    |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 2797     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 53024    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000883 |\n",
            "|    n_updates        | 1324     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -221     |\n",
            "|    exploration_rate | 0.116    |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 2788     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 53604    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00364  |\n",
            "|    n_updates        | 1339     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 153      |\n",
            "|    ep_rew_mean      | -222     |\n",
            "|    exploration_rate | 0.104    |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 2798     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 54320    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00113  |\n",
            "|    n_updates        | 1356     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -226     |\n",
            "|    exploration_rate | 0.0926   |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 2757     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 54996    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00501  |\n",
            "|    n_updates        | 1373     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 156      |\n",
            "|    ep_rew_mean      | -225     |\n",
            "|    exploration_rate | 0.079    |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 2715     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 55816    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0039   |\n",
            "|    n_updates        | 1394     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 157      |\n",
            "|    ep_rew_mean      | -230     |\n",
            "|    exploration_rate | 0.067    |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 2694     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 56544    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00332  |\n",
            "|    n_updates        | 1412     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 163      |\n",
            "|    ep_rew_mean      | -239     |\n",
            "|    exploration_rate | 0.0534   |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 2542     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 57368    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00164  |\n",
            "|    n_updates        | 1433     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 165      |\n",
            "|    ep_rew_mean      | -247     |\n",
            "|    exploration_rate | 0.0364   |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 2511     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 58400    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0012   |\n",
            "|    n_updates        | 1458     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 167      |\n",
            "|    ep_rew_mean      | -250     |\n",
            "|    exploration_rate | 0.0262   |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 2487     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 59016    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00135  |\n",
            "|    n_updates        | 1474     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 169      |\n",
            "|    ep_rew_mean      | -255     |\n",
            "|    exploration_rate | 0.0177   |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 2505     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 59532    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00791  |\n",
            "|    n_updates        | 1487     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 50001 | Mean Reward: -234.50 ± 100.33\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 170      |\n",
            "|    ep_rew_mean      | -253     |\n",
            "|    exploration_rate | 0.138    |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 1818     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60976    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000908 |\n",
            "|    n_updates        | 1523     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 176      |\n",
            "|    ep_rew_mean      | -258     |\n",
            "|    exploration_rate | 0.121    |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 1829     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 62172    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00506  |\n",
            "|    n_updates        | 1553     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 179      |\n",
            "|    ep_rew_mean      | -257     |\n",
            "|    exploration_rate | 0.112    |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 1938     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 62760    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00955  |\n",
            "|    n_updates        | 1567     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 188      |\n",
            "|    ep_rew_mean      | -259     |\n",
            "|    exploration_rate | 0.0893   |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 1737     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 64396    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000398 |\n",
            "|    n_updates        | 1608     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | -260     |\n",
            "|    exploration_rate | 0.0775   |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 1788     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 65224    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0117   |\n",
            "|    n_updates        | 1629     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | -258     |\n",
            "|    exploration_rate | 0.0695   |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 1847     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 65796    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00059  |\n",
            "|    n_updates        | 1643     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | -259     |\n",
            "|    exploration_rate | 0.0609   |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 1898     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 66400    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0196   |\n",
            "|    n_updates        | 1658     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 195      |\n",
            "|    ep_rew_mean      | -256     |\n",
            "|    exploration_rate | 0.0526   |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 1953     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 66988    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00426  |\n",
            "|    n_updates        | 1673     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -259     |\n",
            "|    exploration_rate | 0.0352   |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 1986     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 68216    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00141  |\n",
            "|    n_updates        | 1704     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | -262     |\n",
            "|    exploration_rate | 0.0277   |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 1966     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 68748    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00149  |\n",
            "|    n_updates        | 1717     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | -258     |\n",
            "|    exploration_rate | 0.0179   |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 1972     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 69444    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00383  |\n",
            "|    n_updates        | 1735     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 60001 | Mean Reward: -186.96 ± 58.76\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 192      |\n",
            "|    ep_rew_mean      | -254     |\n",
            "|    exploration_rate | 0.125    |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 2208     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70676    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00136  |\n",
            "|    n_updates        | 1765     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 195      |\n",
            "|    ep_rew_mean      | -250     |\n",
            "|    exploration_rate | 0.118    |\n",
            "| time/               |          |\n",
            "|    episodes         | 480      |\n",
            "|    fps              | 2315     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 71292    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00107  |\n",
            "|    n_updates        | 1781     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 196      |\n",
            "|    ep_rew_mean      | -247     |\n",
            "|    exploration_rate | 0.111    |\n",
            "| time/               |          |\n",
            "|    episodes         | 484      |\n",
            "|    fps              | 2377     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 71820    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0013   |\n",
            "|    n_updates        | 1794     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | -243     |\n",
            "|    exploration_rate | 0.0973   |\n",
            "| time/               |          |\n",
            "|    episodes         | 488      |\n",
            "|    fps              | 2479     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 72948    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0011   |\n",
            "|    n_updates        | 1822     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 204      |\n",
            "|    ep_rew_mean      | -241     |\n",
            "|    exploration_rate | 0.0859   |\n",
            "| time/               |          |\n",
            "|    episodes         | 492      |\n",
            "|    fps              | 2330     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 73868    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000852 |\n",
            "|    n_updates        | 1845     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 208      |\n",
            "|    ep_rew_mean      | -235     |\n",
            "|    exploration_rate | 0.0741   |\n",
            "| time/               |          |\n",
            "|    episodes         | 496      |\n",
            "|    fps              | 2312     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 74820    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00117  |\n",
            "|    n_updates        | 1869     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 212      |\n",
            "|    ep_rew_mean      | -231     |\n",
            "|    exploration_rate | 0.0603   |\n",
            "| time/               |          |\n",
            "|    episodes         | 500      |\n",
            "|    fps              | 2288     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 75936    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00317  |\n",
            "|    n_updates        | 1897     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 220      |\n",
            "|    ep_rew_mean      | -228     |\n",
            "|    exploration_rate | 0.0389   |\n",
            "| time/               |          |\n",
            "|    episodes         | 504      |\n",
            "|    fps              | 2054     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 77664    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00103  |\n",
            "|    n_updates        | 1940     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 223      |\n",
            "|    ep_rew_mean      | -223     |\n",
            "|    exploration_rate | 0.029    |\n",
            "| time/               |          |\n",
            "|    episodes         | 508      |\n",
            "|    fps              | 2068     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 78464    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000901 |\n",
            "|    n_updates        | 1960     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 228      |\n",
            "|    ep_rew_mean      | -218     |\n",
            "|    exploration_rate | 0.0144   |\n",
            "| time/               |          |\n",
            "|    episodes         | 512      |\n",
            "|    fps              | 2034     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 79644    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000834 |\n",
            "|    n_updates        | 1990     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 70001 | Mean Reward: -142.10 ± 100.79\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 226      |\n",
            "|    ep_rew_mean      | -212     |\n",
            "|    exploration_rate | 0.108    |\n",
            "| time/               |          |\n",
            "|    episodes         | 516      |\n",
            "|    fps              | 2344     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 81048    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00295  |\n",
            "|    n_updates        | 2025     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 233      |\n",
            "|    ep_rew_mean      | -211     |\n",
            "|    exploration_rate | 0.0916   |\n",
            "| time/               |          |\n",
            "|    episodes         | 520      |\n",
            "|    fps              | 1945     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 82584    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00391  |\n",
            "|    n_updates        | 2063     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 233      |\n",
            "|    ep_rew_mean      | -210     |\n",
            "|    exploration_rate | 0.0815   |\n",
            "| time/               |          |\n",
            "|    episodes         | 524      |\n",
            "|    fps              | 2036     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 83496    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000587 |\n",
            "|    n_updates        | 2086     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 241      |\n",
            "|    ep_rew_mean      | -206     |\n",
            "|    exploration_rate | 0.0682   |\n",
            "| time/               |          |\n",
            "|    episodes         | 528      |\n",
            "|    fps              | 1864     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 84708    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0202   |\n",
            "|    n_updates        | 2116     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 245      |\n",
            "|    ep_rew_mean      | -209     |\n",
            "|    exploration_rate | 0.0537   |\n",
            "| time/               |          |\n",
            "|    episodes         | 532      |\n",
            "|    fps              | 1784     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 86024    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.012    |\n",
            "|    n_updates        | 2149     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 246      |\n",
            "|    ep_rew_mean      | -206     |\n",
            "|    exploration_rate | 0.041    |\n",
            "| time/               |          |\n",
            "|    episodes         | 536      |\n",
            "|    fps              | 1717     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 87184    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000927 |\n",
            "|    n_updates        | 2178     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 247      |\n",
            "|    ep_rew_mean      | -206     |\n",
            "|    exploration_rate | 0.0283   |\n",
            "| time/               |          |\n",
            "|    episodes         | 540      |\n",
            "|    fps              | 1667     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 88340    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000644 |\n",
            "|    n_updates        | 2207     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 245      |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.0148   |\n",
            "| time/               |          |\n",
            "|    episodes         | 544      |\n",
            "|    fps              | 1700     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 89560    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00145  |\n",
            "|    n_updates        | 2237     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 80001 | Mean Reward: -122.04 ± 63.01\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 245      |\n",
            "|    ep_rew_mean      | -201     |\n",
            "|    exploration_rate | 0.101    |\n",
            "| time/               |          |\n",
            "|    episodes         | 548      |\n",
            "|    fps              | 1879     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 90768    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00784  |\n",
            "|    n_updates        | 2268     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 246      |\n",
            "|    ep_rew_mean      | -202     |\n",
            "|    exploration_rate | 0.0921   |\n",
            "| time/               |          |\n",
            "|    episodes         | 552      |\n",
            "|    fps              | 1885     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 91712    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000956 |\n",
            "|    n_updates        | 2291     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 259      |\n",
            "|    ep_rew_mean      | -195     |\n",
            "|    exploration_rate | 0.0782   |\n",
            "| time/               |          |\n",
            "|    episodes         | 556      |\n",
            "|    fps              | 1446     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 93112    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0109   |\n",
            "|    n_updates        | 2326     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 263      |\n",
            "|    ep_rew_mean      | -198     |\n",
            "|    exploration_rate | 0.0675   |\n",
            "| time/               |          |\n",
            "|    episodes         | 560      |\n",
            "|    fps              | 1571     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 94192    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00945  |\n",
            "|    n_updates        | 2353     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 272      |\n",
            "|    ep_rew_mean      | -199     |\n",
            "|    exploration_rate | 0.0431   |\n",
            "| time/               |          |\n",
            "|    episodes         | 564      |\n",
            "|    fps              | 1386     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 96660    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00077  |\n",
            "|    n_updates        | 2415     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 293      |\n",
            "|    ep_rew_mean      | -198     |\n",
            "|    exploration_rate | 0.0125   |\n",
            "| time/               |          |\n",
            "|    episodes         | 568      |\n",
            "|    fps              | 1096     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 99744    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0195   |\n",
            "|    n_updates        | 2492     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 90001 | Mean Reward: -197.99 ± 103.05\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 310      |\n",
            "|    ep_rew_mean      | -202     |\n",
            "|    exploration_rate | 0.0862   |\n",
            "| time/               |          |\n",
            "|    episodes         | 572      |\n",
            "|    fps              | 952      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 101532   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0227   |\n",
            "|    n_updates        | 2537     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 321      |\n",
            "|    ep_rew_mean      | -204     |\n",
            "|    exploration_rate | 0.0762   |\n",
            "| time/               |          |\n",
            "|    episodes         | 576      |\n",
            "|    fps              | 1050     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 102640   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000838 |\n",
            "|    n_updates        | 2564     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 325      |\n",
            "|    ep_rew_mean      | -207     |\n",
            "|    exploration_rate | 0.0496   |\n",
            "| time/               |          |\n",
            "|    episodes         | 580      |\n",
            "|    fps              | 1022     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 105604   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00287  |\n",
            "|    n_updates        | 2639     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 342      |\n",
            "|    ep_rew_mean      | -206     |\n",
            "|    exploration_rate | 0.0384   |\n",
            "| time/               |          |\n",
            "|    episodes         | 584      |\n",
            "|    fps              | 1061     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 106848   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00153  |\n",
            "|    n_updates        | 2670     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 343      |\n",
            "|    ep_rew_mean      | -209     |\n",
            "|    exploration_rate | 0.0215   |\n",
            "| time/               |          |\n",
            "|    episodes         | 588      |\n",
            "|    fps              | 1107     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 108720   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00515  |\n",
            "|    n_updates        | 2716     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 354      |\n",
            "|    ep_rew_mean      | -207     |\n",
            "|    exploration_rate | 0.0135   |\n",
            "| time/               |          |\n",
            "|    episodes         | 592      |\n",
            "|    fps              | 1133     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 109608   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00103  |\n",
            "|    n_updates        | 2739     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 100001 | Mean Reward: -219.89 ± 103.59\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 354      |\n",
            "|    ep_rew_mean      | -213     |\n",
            "|    exploration_rate | 0.0828   |\n",
            "| time/               |          |\n",
            "|    episodes         | 596      |\n",
            "|    fps              | 2159     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 111172   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.001    |\n",
            "|    n_updates        | 2778     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 359      |\n",
            "|    ep_rew_mean      | -217     |\n",
            "|    exploration_rate | 0.0644   |\n",
            "| time/               |          |\n",
            "|    episodes         | 600      |\n",
            "|    fps              | 1459     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 113412   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00103  |\n",
            "|    n_updates        | 2834     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 361      |\n",
            "|    ep_rew_mean      | -218     |\n",
            "|    exploration_rate | 0.0525   |\n",
            "| time/               |          |\n",
            "|    episodes         | 604      |\n",
            "|    fps              | 1264     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 114848   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00146  |\n",
            "|    n_updates        | 2870     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 368      |\n",
            "|    ep_rew_mean      | -224     |\n",
            "|    exploration_rate | 0.0375   |\n",
            "| time/               |          |\n",
            "|    episodes         | 608      |\n",
            "|    fps              | 1182     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 116672   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0116   |\n",
            "|    n_updates        | 2915     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 377      |\n",
            "|    ep_rew_mean      | -228     |\n",
            "|    exploration_rate | 0.0256   |\n",
            "| time/               |          |\n",
            "|    episodes         | 612      |\n",
            "|    fps              | 1182     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 118112   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00191  |\n",
            "|    n_updates        | 2951     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 382      |\n",
            "|    ep_rew_mean      | -228     |\n",
            "|    exploration_rate | 0.012    |\n",
            "| time/               |          |\n",
            "|    episodes         | 616      |\n",
            "|    fps              | 1228     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 119752   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000958 |\n",
            "|    n_updates        | 2992     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 110001 | Mean Reward: -178.41 ± 85.47\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 378      |\n",
            "|    ep_rew_mean      | -224     |\n",
            "|    exploration_rate | 0.0829   |\n",
            "| time/               |          |\n",
            "|    episodes         | 620      |\n",
            "|    fps              | 2640     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120432   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0021   |\n",
            "|    n_updates        | 3009     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 380      |\n",
            "|    ep_rew_mean      | -219     |\n",
            "|    exploration_rate | 0.0744   |\n",
            "| time/               |          |\n",
            "|    episodes         | 624      |\n",
            "|    fps              | 2303     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 121544   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00168  |\n",
            "|    n_updates        | 3037     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 377      |\n",
            "|    ep_rew_mean      | -218     |\n",
            "|    exploration_rate | 0.0667   |\n",
            "| time/               |          |\n",
            "|    episodes         | 628      |\n",
            "|    fps              | 2132     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 122548   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00094  |\n",
            "|    n_updates        | 3062     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 378      |\n",
            "|    ep_rew_mean      | -216     |\n",
            "|    exploration_rate | 0.0549   |\n",
            "| time/               |          |\n",
            "|    episodes         | 632      |\n",
            "|    fps              | 1939     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 124104   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00152  |\n",
            "|    n_updates        | 3101     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 381      |\n",
            "|    ep_rew_mean      | -213     |\n",
            "|    exploration_rate | 0.0438   |\n",
            "| time/               |          |\n",
            "|    episodes         | 636      |\n",
            "|    fps              | 1806     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 125564   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00118  |\n",
            "|    n_updates        | 3138     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 385      |\n",
            "|    ep_rew_mean      | -213     |\n",
            "|    exploration_rate | 0.0319   |\n",
            "| time/               |          |\n",
            "|    episodes         | 640      |\n",
            "|    fps              | 1763     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 127128   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00116  |\n",
            "|    n_updates        | 3177     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 384      |\n",
            "|    ep_rew_mean      | -215     |\n",
            "|    exploration_rate | 0.0211   |\n",
            "| time/               |          |\n",
            "|    episodes         | 644      |\n",
            "|    fps              | 1703     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 128548   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00965  |\n",
            "|    n_updates        | 3212     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 390      |\n",
            "|    ep_rew_mean      | -217     |\n",
            "|    exploration_rate | 0.0114   |\n",
            "| time/               |          |\n",
            "|    episodes         | 648      |\n",
            "|    fps              | 1672     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 129812   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00246  |\n",
            "|    n_updates        | 3244     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 120001 | Mean Reward: -246.64 ± 47.94\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 393      |\n",
            "|    ep_rew_mean      | -222     |\n",
            "|    exploration_rate | 0.0767   |\n",
            "| time/               |          |\n",
            "|    episodes         | 652      |\n",
            "|    fps              | 2301     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 130568   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00101  |\n",
            "|    n_updates        | 3263     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 381      |\n",
            "|    ep_rew_mean      | -226     |\n",
            "|    exploration_rate | 0.0715   |\n",
            "| time/               |          |\n",
            "|    episodes         | 656      |\n",
            "|    fps              | 2319     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 131296   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0272   |\n",
            "|    n_updates        | 3281     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 385      |\n",
            "|    ep_rew_mean      | -226     |\n",
            "|    exploration_rate | 0.0618   |\n",
            "| time/               |          |\n",
            "|    episodes         | 660      |\n",
            "|    fps              | 1971     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 132672   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.01     |\n",
            "|    n_updates        | 3315     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 377      |\n",
            "|    ep_rew_mean      | -221     |\n",
            "|    exploration_rate | 0.0509   |\n",
            "| time/               |          |\n",
            "|    episodes         | 664      |\n",
            "|    fps              | 1831     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 134212   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00181  |\n",
            "|    n_updates        | 3354     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 361      |\n",
            "|    ep_rew_mean      | -217     |\n",
            "|    exploration_rate | 0.0453   |\n",
            "| time/               |          |\n",
            "|    episodes         | 668      |\n",
            "|    fps              | 1787     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 135008   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00415  |\n",
            "|    n_updates        | 3374     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 345      |\n",
            "|    ep_rew_mean      | -212     |\n",
            "|    exploration_rate | 0.0388   |\n",
            "| time/               |          |\n",
            "|    episodes         | 672      |\n",
            "|    fps              | 1857     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 135932   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00341  |\n",
            "|    n_updates        | 3397     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 337      |\n",
            "|    ep_rew_mean      | -208     |\n",
            "|    exploration_rate | 0.0323   |\n",
            "| time/               |          |\n",
            "|    episodes         | 676      |\n",
            "|    fps              | 1887     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 136844   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000955 |\n",
            "|    n_updates        | 3420     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 337      |\n",
            "|    ep_rew_mean      | -206     |\n",
            "|    exploration_rate | 0.0183   |\n",
            "| time/               |          |\n",
            "|    episodes         | 680      |\n",
            "|    fps              | 1781     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 138820   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00102  |\n",
            "|    n_updates        | 3469     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 130001 | Mean Reward: -154.38 ± 147.02\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 324      |\n",
            "|    ep_rew_mean      | -209     |\n",
            "|    exploration_rate | 0.0698   |\n",
            "| time/               |          |\n",
            "|    episodes         | 684      |\n",
            "|    fps              | 1357     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140940   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00137  |\n",
            "|    n_updates        | 3522     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 327      |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.0606   |\n",
            "| time/               |          |\n",
            "|    episodes         | 688      |\n",
            "|    fps              | 1373     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 142332   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00198  |\n",
            "|    n_updates        | 3557     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 318      |\n",
            "|    ep_rew_mean      | -207     |\n",
            "|    exploration_rate | 0.0531   |\n",
            "| time/               |          |\n",
            "|    episodes         | 692      |\n",
            "|    fps              | 1414     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 143464   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00207  |\n",
            "|    n_updates        | 3585     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 321      |\n",
            "|    ep_rew_mean      | -206     |\n",
            "|    exploration_rate | 0.0449   |\n",
            "| time/               |          |\n",
            "|    episodes         | 696      |\n",
            "|    fps              | 1460     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 144708   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0171   |\n",
            "|    n_updates        | 3616     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 322      |\n",
            "|    ep_rew_mean      | -204     |\n",
            "|    exploration_rate | 0.037    |\n",
            "| time/               |          |\n",
            "|    episodes         | 700      |\n",
            "|    fps              | 1481     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 145912   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00447  |\n",
            "|    n_updates        | 3646     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 314      |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.0306   |\n",
            "| time/               |          |\n",
            "|    episodes         | 704      |\n",
            "|    fps              | 1561     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 146884   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0026   |\n",
            "|    n_updates        | 3671     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 305      |\n",
            "|    ep_rew_mean      | -200     |\n",
            "|    exploration_rate | 0.0234   |\n",
            "| time/               |          |\n",
            "|    episodes         | 708      |\n",
            "|    fps              | 1616     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 147972   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0146   |\n",
            "|    n_updates        | 3698     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 294      |\n",
            "|    ep_rew_mean      | -198     |\n",
            "|    exploration_rate | 0.0168   |\n",
            "| time/               |          |\n",
            "|    episodes         | 712      |\n",
            "|    fps              | 1644     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 148972   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00209  |\n",
            "|    n_updates        | 3723     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 140001 | Mean Reward: -182.36 ± 80.85\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 289      |\n",
            "|    ep_rew_mean      | -196     |\n",
            "|    exploration_rate | 0.0689   |\n",
            "| time/               |          |\n",
            "|    episodes         | 716      |\n",
            "|    fps              | 2120     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150476   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00751  |\n",
            "|    n_updates        | 3760     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 290      |\n",
            "|    ep_rew_mean      | -197     |\n",
            "|    exploration_rate | 0.0629   |\n",
            "| time/               |          |\n",
            "|    episodes         | 720      |\n",
            "|    fps              | 2009     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 151452   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00114  |\n",
            "|    n_updates        | 3785     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 294      |\n",
            "|    ep_rew_mean      | -199     |\n",
            "|    exploration_rate | 0.0504   |\n",
            "| time/               |          |\n",
            "|    episodes         | 724      |\n",
            "|    fps              | 1670     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 153468   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00641  |\n",
            "|    n_updates        | 3835     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 297      |\n",
            "|    ep_rew_mean      | -200     |\n",
            "|    exploration_rate | 0.0464   |\n",
            "| time/               |          |\n",
            "|    episodes         | 728      |\n",
            "|    fps              | 1684     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 154112   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00244  |\n",
            "|    n_updates        | 3851     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 293      |\n",
            "|    ep_rew_mean      | -198     |\n",
            "|    exploration_rate | 0.0419   |\n",
            "| time/               |          |\n",
            "|    episodes         | 732      |\n",
            "|    fps              | 1762     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 154844   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00124  |\n",
            "|    n_updates        | 3870     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 285      |\n",
            "|    ep_rew_mean      | -195     |\n",
            "|    exploration_rate | 0.0355   |\n",
            "| time/               |          |\n",
            "|    episodes         | 736      |\n",
            "|    fps              | 1857     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 155876   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00896  |\n",
            "|    n_updates        | 3895     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 282      |\n",
            "|    ep_rew_mean      | -193     |\n",
            "|    exploration_rate | 0.0296   |\n",
            "| time/               |          |\n",
            "|    episodes         | 740      |\n",
            "|    fps              | 1833     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 156832   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 3919     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 284      |\n",
            "|    ep_rew_mean      | -194     |\n",
            "|    exploration_rate | 0.0171   |\n",
            "| time/               |          |\n",
            "|    episodes         | 744      |\n",
            "|    fps              | 1782     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 158860   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0138   |\n",
            "|    n_updates        | 3970     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 278      |\n",
            "|    ep_rew_mean      | -192     |\n",
            "|    exploration_rate | 0.0112   |\n",
            "| time/               |          |\n",
            "|    episodes         | 748      |\n",
            "|    fps              | 1710     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 159808   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0259   |\n",
            "|    n_updates        | 3994     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 150001 | Mean Reward: -215.22 ± 41.10\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 280      |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.0638   |\n",
            "| time/               |          |\n",
            "|    episodes         | 752      |\n",
            "|    fps              | 1718     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 160756   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0323   |\n",
            "|    n_updates        | 4017     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 282      |\n",
            "|    ep_rew_mean      | -187     |\n",
            "|    exploration_rate | 0.0586   |\n",
            "| time/               |          |\n",
            "|    episodes         | 756      |\n",
            "|    fps              | 1906     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 161660   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00398  |\n",
            "|    n_updates        | 4040     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 279      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.0529   |\n",
            "| time/               |          |\n",
            "|    episodes         | 760      |\n",
            "|    fps              | 1907     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 162632   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00106  |\n",
            "|    n_updates        | 4064     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 281      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.0449   |\n",
            "| time/               |          |\n",
            "|    episodes         | 764      |\n",
            "|    fps              | 1876     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 164000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00468  |\n",
            "|    n_updates        | 4098     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 281      |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.0375   |\n",
            "| time/               |          |\n",
            "|    episodes         | 768      |\n",
            "|    fps              | 1798     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 165276   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00423  |\n",
            "|    n_updates        | 4130     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 287      |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.0291   |\n",
            "| time/               |          |\n",
            "|    episodes         | 772      |\n",
            "|    fps              | 1754     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 166720   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00127  |\n",
            "|    n_updates        | 4166     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 289      |\n",
            "|    ep_rew_mean      | -192     |\n",
            "|    exploration_rate | 0.0225   |\n",
            "| time/               |          |\n",
            "|    episodes         | 776      |\n",
            "|    fps              | 1738     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 167852   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00247  |\n",
            "|    n_updates        | 4195     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 288      |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.0175   |\n",
            "| time/               |          |\n",
            "|    episodes         | 780      |\n",
            "|    fps              | 1729     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 168716   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00215  |\n",
            "|    n_updates        | 4216     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 160001 | Mean Reward: -230.94 ± 41.85\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 287      |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.063    |\n",
            "| time/               |          |\n",
            "|    episodes         | 784      |\n",
            "|    fps              | 1933     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 170368   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0507   |\n",
            "|    n_updates        | 4258     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 288      |\n",
            "|    ep_rew_mean      | -192     |\n",
            "|    exploration_rate | 0.0562   |\n",
            "| time/               |          |\n",
            "|    episodes         | 788      |\n",
            "|    fps              | 1497     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 171592   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00282  |\n",
            "|    n_updates        | 4288     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 286      |\n",
            "|    ep_rew_mean      | -191     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 792      |\n",
            "|    fps              | 1713     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 172720   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00132  |\n",
            "|    n_updates        | 4316     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 284      |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.0458   |\n",
            "| time/               |          |\n",
            "|    episodes         | 796      |\n",
            "|    fps              | 1709     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 173488   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0027   |\n",
            "|    n_updates        | 4336     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 278      |\n",
            "|    ep_rew_mean      | -180     |\n",
            "|    exploration_rate | 0.0364   |\n",
            "| time/               |          |\n",
            "|    episodes         | 800      |\n",
            "|    fps              | 1639     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 175200   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00105  |\n",
            "|    n_updates        | 4378     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 283      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.0292   |\n",
            "| time/               |          |\n",
            "|    episodes         | 804      |\n",
            "|    fps              | 1528     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 176512   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00143  |\n",
            "|    n_updates        | 4411     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 285      |\n",
            "|    ep_rew_mean      | -179     |\n",
            "|    exploration_rate | 0.0252   |\n",
            "| time/               |          |\n",
            "|    episodes         | 808      |\n",
            "|    fps              | 1552     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 177236   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00478  |\n",
            "|    n_updates        | 4429     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 285      |\n",
            "|    ep_rew_mean      | -180     |\n",
            "|    exploration_rate | 0.0189   |\n",
            "| time/               |          |\n",
            "|    episodes         | 812      |\n",
            "|    fps              | 1616     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 178388   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00555  |\n",
            "|    n_updates        | 4458     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 286      |\n",
            "|    ep_rew_mean      | -180     |\n",
            "|    exploration_rate | 0.0144   |\n",
            "| time/               |          |\n",
            "|    episodes         | 816      |\n",
            "|    fps              | 1664     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 179204   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000983 |\n",
            "|    n_updates        | 4479     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 170001 | Mean Reward: -168.81 ± 143.55\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 285      |\n",
            "|    ep_rew_mean      | -177     |\n",
            "|    exploration_rate | 0.0579   |\n",
            "| time/               |          |\n",
            "|    episodes         | 820      |\n",
            "|    fps              | 1587     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 180808   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00327  |\n",
            "|    n_updates        | 4519     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 282      |\n",
            "|    ep_rew_mean      | -177     |\n",
            "|    exploration_rate | 0.0493   |\n",
            "| time/               |          |\n",
            "|    episodes         | 824      |\n",
            "|    fps              | 1238     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 182448   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0144   |\n",
            "|    n_updates        | 4560     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 288      |\n",
            "|    ep_rew_mean      | -179     |\n",
            "|    exploration_rate | 0.0432   |\n",
            "| time/               |          |\n",
            "|    episodes         | 828      |\n",
            "|    fps              | 1270     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 183624   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0078   |\n",
            "|    n_updates        | 4589     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 290      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.0384   |\n",
            "| time/               |          |\n",
            "|    episodes         | 832      |\n",
            "|    fps              | 1406     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 184544   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0313   |\n",
            "|    n_updates        | 4612     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 294      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.0297   |\n",
            "| time/               |          |\n",
            "|    episodes         | 836      |\n",
            "|    fps              | 1461     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 186224   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00377  |\n",
            "|    n_updates        | 4654     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 295      |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.0258   |\n",
            "| time/               |          |\n",
            "|    episodes         | 840      |\n",
            "|    fps              | 1487     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 186964   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00129  |\n",
            "|    n_updates        | 4673     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 294      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.0181   |\n",
            "| time/               |          |\n",
            "|    episodes         | 844      |\n",
            "|    fps              | 1553     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 188448   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00571  |\n",
            "|    n_updates        | 4710     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 293      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.0133   |\n",
            "| time/               |          |\n",
            "|    episodes         | 848      |\n",
            "|    fps              | 1557     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 189368   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0353   |\n",
            "|    n_updates        | 4733     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 180001 | Mean Reward: -147.56 ± 152.04\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 288      |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.0593   |\n",
            "| time/               |          |\n",
            "|    episodes         | 852      |\n",
            "|    fps              | 1147     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 190032   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 287      |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.0541   |\n",
            "| time/               |          |\n",
            "|    episodes         | 856      |\n",
            "|    fps              | 2079     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 191100   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0582   |\n",
            "|    n_updates        | 4776     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 288      |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.0498   |\n",
            "| time/               |          |\n",
            "|    episodes         | 860      |\n",
            "|    fps              | 2168     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 191964   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00144  |\n",
            "|    n_updates        | 4798     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 284      |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.043    |\n",
            "| time/               |          |\n",
            "|    episodes         | 864      |\n",
            "|    fps              | 2159     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 193328   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0059   |\n",
            "|    n_updates        | 4832     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 287      |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.0366   |\n",
            "| time/               |          |\n",
            "|    episodes         | 868      |\n",
            "|    fps              | 1983     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 194628   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0878   |\n",
            "|    n_updates        | 4864     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 282      |\n",
            "|    ep_rew_mean      | -177     |\n",
            "|    exploration_rate | 0.0315   |\n",
            "| time/               |          |\n",
            "|    episodes         | 872      |\n",
            "|    fps              | 2027     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 195652   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00148  |\n",
            "|    n_updates        | 4890     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 283      |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.0243   |\n",
            "| time/               |          |\n",
            "|    episodes         | 876      |\n",
            "|    fps              | 1952     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 197104   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0017   |\n",
            "|    n_updates        | 4926     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 289      |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.0181   |\n",
            "| time/               |          |\n",
            "|    episodes         | 880      |\n",
            "|    fps              | 1858     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 198372   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00144  |\n",
            "|    n_updates        | 4958     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 289      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.0122   |\n",
            "| time/               |          |\n",
            "|    episodes         | 884      |\n",
            "|    fps              | 1875     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 199552   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00811  |\n",
            "|    n_updates        | 4987     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 190001 | Mean Reward: -210.74 ± 30.15\n",
            "Model and VecNormalize stats saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0001_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. envs=4, batch size= 64, lr=3e-4"
      ],
      "metadata": {
        "id": "0ROIFLzsODMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lunarlander(4, 64, 3e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApZjRt3BOON3",
        "outputId": "c95f8ffa-0e44-4f45-d9ce-45773e1d8d7c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -216     |\n",
            "|    exploration_rate | 0.95     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 3789     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 508      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0143   |\n",
            "|    n_updates        | 11       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 98.1     |\n",
            "|    ep_rew_mean      | -176     |\n",
            "|    exploration_rate | 0.912    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 3644     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 892      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0093   |\n",
            "|    n_updates        | 21       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.2     |\n",
            "|    ep_rew_mean      | -191     |\n",
            "|    exploration_rate | 0.866    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 3809     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1356     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0108   |\n",
            "|    n_updates        | 32       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.7     |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.833    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 3858     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1684     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00512  |\n",
            "|    n_updates        | 41       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 94.8     |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.798    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 3864     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 2044     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0296   |\n",
            "|    n_updates        | 50       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.8     |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.761    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 3903     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 2416     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0422   |\n",
            "|    n_updates        | 59       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.8     |\n",
            "|    ep_rew_mean      | -174     |\n",
            "|    exploration_rate | 0.736    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 3888     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 2664     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0349   |\n",
            "|    n_updates        | 65       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.8     |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.698    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 3762     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 3048     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00193  |\n",
            "|    n_updates        | 75       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.7     |\n",
            "|    ep_rew_mean      | -172     |\n",
            "|    exploration_rate | 0.676    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 3646     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 3272     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00135  |\n",
            "|    n_updates        | 80       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 88       |\n",
            "|    ep_rew_mean      | -167     |\n",
            "|    exploration_rate | 0.647    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 3509     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 3564     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0633   |\n",
            "|    n_updates        | 88       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87       |\n",
            "|    ep_rew_mean      | -174     |\n",
            "|    exploration_rate | 0.609    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 3421     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 3948     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00731  |\n",
            "|    n_updates        | 97       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.8     |\n",
            "|    ep_rew_mean      | -164     |\n",
            "|    exploration_rate | 0.574    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 3363     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 4304     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.037    |\n",
            "|    n_updates        | 106      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.5     |\n",
            "|    ep_rew_mean      | -156     |\n",
            "|    exploration_rate | 0.546    |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 3333     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 4588     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00229  |\n",
            "|    n_updates        | 113      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.7     |\n",
            "|    ep_rew_mean      | -164     |\n",
            "|    exploration_rate | 0.522    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 3288     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 4828     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0313   |\n",
            "|    n_updates        | 119      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.1     |\n",
            "|    ep_rew_mean      | -172     |\n",
            "|    exploration_rate | 0.478    |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 3194     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 5268     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.067    |\n",
            "|    n_updates        | 130      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.8     |\n",
            "|    ep_rew_mean      | -169     |\n",
            "|    exploration_rate | 0.445    |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 3144     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 5604     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0507   |\n",
            "|    n_updates        | 139      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 85.1     |\n",
            "|    ep_rew_mean      | -180     |\n",
            "|    exploration_rate | 0.413    |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 3132     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 5932     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00237  |\n",
            "|    n_updates        | 147      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.9     |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.382    |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 3113     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 6240     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0179   |\n",
            "|    n_updates        | 154      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.9     |\n",
            "|    ep_rew_mean      | -196     |\n",
            "|    exploration_rate | 0.344    |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 3089     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 6628     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00498  |\n",
            "|    n_updates        | 164      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.9     |\n",
            "|    ep_rew_mean      | -195     |\n",
            "|    exploration_rate | 0.309    |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 3023     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 6976     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00986  |\n",
            "|    n_updates        | 173      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 85.3     |\n",
            "|    ep_rew_mean      | -200     |\n",
            "|    exploration_rate | 0.282    |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 2964     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 7256     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0234   |\n",
            "|    n_updates        | 180      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 85.6     |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.248    |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 2917     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 7592     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0225   |\n",
            "|    n_updates        | 188      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 85.5     |\n",
            "|    ep_rew_mean      | -204     |\n",
            "|    exploration_rate | 0.215    |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 2902     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 7928     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0642   |\n",
            "|    n_updates        | 197      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.9     |\n",
            "|    ep_rew_mean      | -206     |\n",
            "|    exploration_rate | 0.189    |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 2922     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8196     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00379  |\n",
            "|    n_updates        | 203      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.6     |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.159    |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 2943     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8492     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00176  |\n",
            "|    n_updates        | 211      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.5     |\n",
            "|    ep_rew_mean      | -201     |\n",
            "|    exploration_rate | 0.117    |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 2966     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 8924     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00552  |\n",
            "|    n_updates        | 222      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.8     |\n",
            "|    ep_rew_mean      | -204     |\n",
            "|    exploration_rate | 0.0769   |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 2970     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 9324     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00108  |\n",
            "|    n_updates        | 232      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.6     |\n",
            "|    ep_rew_mean      | -214     |\n",
            "|    exploration_rate | 0.0421   |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 2962     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 9676     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0501   |\n",
            "|    n_updates        | 240      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 1 | Mean Reward: -338.03 ± 187.66\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.5     |\n",
            "|    ep_rew_mean      | -219     |\n",
            "|    exploration_rate | 0.5      |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 2548     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10100    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0101   |\n",
            "|    n_updates        | 251      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.5     |\n",
            "|    ep_rew_mean      | -220     |\n",
            "|    exploration_rate | 0.484    |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 3347     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10424    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0286   |\n",
            "|    n_updates        | 259      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.5     |\n",
            "|    ep_rew_mean      | -219     |\n",
            "|    exploration_rate | 0.465    |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 3402     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10816    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00113  |\n",
            "|    n_updates        | 269      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.2     |\n",
            "|    ep_rew_mean      | -220     |\n",
            "|    exploration_rate | 0.442    |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 3525     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 11276    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0155   |\n",
            "|    n_updates        | 280      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.8     |\n",
            "|    ep_rew_mean      | -218     |\n",
            "|    exploration_rate | 0.422    |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 3501     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 11668    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0057   |\n",
            "|    n_updates        | 290      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86.6     |\n",
            "|    ep_rew_mean      | -223     |\n",
            "|    exploration_rate | 0.399    |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 3393     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 12136    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00122  |\n",
            "|    n_updates        | 302      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 88.1     |\n",
            "|    ep_rew_mean      | -224     |\n",
            "|    exploration_rate | 0.372    |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 3320     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 12696    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00111  |\n",
            "|    n_updates        | 316      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.9     |\n",
            "|    ep_rew_mean      | -226     |\n",
            "|    exploration_rate | 0.352    |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 3350     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 13100    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00157  |\n",
            "|    n_updates        | 326      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92       |\n",
            "|    ep_rew_mean      | -230     |\n",
            "|    exploration_rate | 0.337    |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 3313     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 13400    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0143   |\n",
            "|    n_updates        | 333      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92.6     |\n",
            "|    ep_rew_mean      | -240     |\n",
            "|    exploration_rate | 0.317    |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 3321     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 13788    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000789 |\n",
            "|    n_updates        | 343      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.3     |\n",
            "|    ep_rew_mean      | -237     |\n",
            "|    exploration_rate | 0.3      |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 3301     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 14144    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.023    |\n",
            "|    n_updates        | 352      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.6     |\n",
            "|    ep_rew_mean      | -239     |\n",
            "|    exploration_rate | 0.281    |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 3327     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 14520    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0129   |\n",
            "|    n_updates        | 361      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 94.8     |\n",
            "|    ep_rew_mean      | -242     |\n",
            "|    exploration_rate | 0.25     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 3283     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 15148    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0127   |\n",
            "|    n_updates        | 377      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.2     |\n",
            "|    ep_rew_mean      | -234     |\n",
            "|    exploration_rate | 0.221    |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 3203     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 15736    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00139  |\n",
            "|    n_updates        | 392      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 99.8     |\n",
            "|    ep_rew_mean      | -234     |\n",
            "|    exploration_rate | 0.194    |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 3187     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 16284    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0242   |\n",
            "|    n_updates        | 406      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 100      |\n",
            "|    ep_rew_mean      | -229     |\n",
            "|    exploration_rate | 0.174    |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 3185     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 16684    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00153  |\n",
            "|    n_updates        | 416      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 102      |\n",
            "|    ep_rew_mean      | -229     |\n",
            "|    exploration_rate | 0.144    |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 3165     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 17288    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0087   |\n",
            "|    n_updates        | 431      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 104      |\n",
            "|    ep_rew_mean      | -226     |\n",
            "|    exploration_rate | 0.118    |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 3151     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 17812    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00265  |\n",
            "|    n_updates        | 444      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | -220     |\n",
            "|    exploration_rate | 0.0904   |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 3115     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 18376    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00402  |\n",
            "|    n_updates        | 458      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 107      |\n",
            "|    ep_rew_mean      | -218     |\n",
            "|    exploration_rate | 0.0607   |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 3080     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 18976    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0107   |\n",
            "|    n_updates        | 473      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 111      |\n",
            "|    ep_rew_mean      | -216     |\n",
            "|    exploration_rate | 0.0359   |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 3021     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 19476    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00116  |\n",
            "|    n_updates        | 485      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 10001 | Mean Reward: -262.02 ± 155.65\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 114      |\n",
            "|    ep_rew_mean      | -217     |\n",
            "|    exploration_rate | 0.331    |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 2461     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20276    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00331  |\n",
            "|    n_updates        | 505      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 117      |\n",
            "|    ep_rew_mean      | -217     |\n",
            "|    exploration_rate | 0.319    |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 2626     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20624    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0206   |\n",
            "|    n_updates        | 514      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 118      |\n",
            "|    ep_rew_mean      | -213     |\n",
            "|    exploration_rate | 0.301    |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 2745     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 21180    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00888  |\n",
            "|    n_updates        | 528      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 119      |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.288    |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 2815     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 21572    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.012    |\n",
            "|    n_updates        | 538      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 121      |\n",
            "|    ep_rew_mean      | -202     |\n",
            "|    exploration_rate | 0.256    |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 2660     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 22556    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00184  |\n",
            "|    n_updates        | 562      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 126      |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.236    |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 2649     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 23140    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00402  |\n",
            "|    n_updates        | 577      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 128      |\n",
            "|    ep_rew_mean      | -206     |\n",
            "|    exploration_rate | 0.215    |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 2652     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 23792    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0022   |\n",
            "|    n_updates        | 593      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 130      |\n",
            "|    ep_rew_mean      | -206     |\n",
            "|    exploration_rate | 0.2      |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 2678     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 24228    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00185  |\n",
            "|    n_updates        | 604      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 131      |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.185    |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 2694     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 24684    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00476  |\n",
            "|    n_updates        | 616      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.153    |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 2652     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 25652    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0052   |\n",
            "|    n_updates        | 640      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -200     |\n",
            "|    exploration_rate | 0.136    |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 2637     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 26172    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00517  |\n",
            "|    n_updates        | 653      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 139      |\n",
            "|    ep_rew_mean      | -195     |\n",
            "|    exploration_rate | 0.0959   |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 2514     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 27396    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00372  |\n",
            "|    n_updates        | 683      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 146      |\n",
            "|    ep_rew_mean      | -201     |\n",
            "|    exploration_rate | 0.0549   |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 2400     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 28640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0111   |\n",
            "|    n_updates        | 714      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -196     |\n",
            "|    exploration_rate | 0.0382   |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 2415     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 29144    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0256   |\n",
            "|    n_updates        | 727      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 156      |\n",
            "|    ep_rew_mean      | -193     |\n",
            "|    exploration_rate | 0.0149   |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 2402     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 29852    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00285  |\n",
            "|    n_updates        | 745      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 20001 | Mean Reward: -208.18 ± 102.60\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 158      |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.244    |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 1880     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30564    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00417  |\n",
            "|    n_updates        | 763      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 161      |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.23     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 1940     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 31108    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00241  |\n",
            "|    n_updates        | 776      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 163      |\n",
            "|    ep_rew_mean      | -193     |\n",
            "|    exploration_rate | 0.206    |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 1761     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32068    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00564  |\n",
            "|    n_updates        | 800      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 164      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.19     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 1851     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32736    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00151  |\n",
            "|    n_updates        | 817      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 173      |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.146    |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 1695     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 34504    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000949 |\n",
            "|    n_updates        | 861      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 180      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.116    |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 1712     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 35732    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00106  |\n",
            "|    n_updates        | 892      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 188      |\n",
            "|    ep_rew_mean      | -179     |\n",
            "|    exploration_rate | 0.0785   |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 1595     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 37232    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00224  |\n",
            "|    n_updates        | 929      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.0451   |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 1643     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 38580    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000888 |\n",
            "|    n_updates        | 963      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 30001 | Mean Reward: -320.16 ± 137.81\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 205      |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.197    |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 1518     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40568    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000855 |\n",
            "|    n_updates        | 1013     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 210      |\n",
            "|    ep_rew_mean      | -187     |\n",
            "|    exploration_rate | 0.148    |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 1169     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 43020    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00698  |\n",
            "|    n_updates        | 1074     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 238      |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.0818   |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 977      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 46376    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 1158     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 258      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.049    |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 919      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 48028    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00182  |\n",
            "|    n_updates        | 1199     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 40001 | Mean Reward: -141.92 ± 63.94\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 290      |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.113    |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 792      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 53776    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00179  |\n",
            "|    n_updates        | 1343     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 306      |\n",
            "|    ep_rew_mean      | -180     |\n",
            "|    exploration_rate | 0.0796   |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 849      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 55780    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00246  |\n",
            "|    n_updates        | 1393     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 323      |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.0406   |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 903      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 58148    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0162   |\n",
            "|    n_updates        | 1452     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 50001 | Mean Reward: -97.37 ± 22.21\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 339      |\n",
            "|    ep_rew_mean      | -180     |\n",
            "|    exploration_rate | 0.107    |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 913      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 63156    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00767  |\n",
            "|    n_updates        | 1577     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 360      |\n",
            "|    ep_rew_mean      | -179     |\n",
            "|    exploration_rate | 0.096    |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 860      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 63920    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00128  |\n",
            "|    n_updates        | 1596     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 368      |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.0757   |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 987      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 65356    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0564   |\n",
            "|    n_updates        | 1632     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 381      |\n",
            "|    ep_rew_mean      | -179     |\n",
            "|    exploration_rate | 0.0433   |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 1007     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 67648    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00308  |\n",
            "|    n_updates        | 1690     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 60001 | Mean Reward: -128.41 ± 86.27\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 395      |\n",
            "|    ep_rew_mean      | -173     |\n",
            "|    exploration_rate | 0.129    |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 1977     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70356    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00394  |\n",
            "|    n_updates        | 1757     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 404      |\n",
            "|    ep_rew_mean      | -174     |\n",
            "|    exploration_rate | 0.108    |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 1526     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 72076    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00532  |\n",
            "|    n_updates        | 1800     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 412      |\n",
            "|    ep_rew_mean      | -172     |\n",
            "|    exploration_rate | 0.0798   |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 1331     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 74356    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0548   |\n",
            "|    n_updates        | 1857     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 437      |\n",
            "|    ep_rew_mean      | -167     |\n",
            "|    exploration_rate | 0.0303   |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 972      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 78356    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00943  |\n",
            "|    n_updates        | 1957     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 456      |\n",
            "|    ep_rew_mean      | -166     |\n",
            "|    exploration_rate | 0.013    |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 943      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 79760    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000874 |\n",
            "|    n_updates        | 1992     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 70001 | Mean Reward: -235.40 ± 28.22\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 464      |\n",
            "|    ep_rew_mean      | -168     |\n",
            "|    exploration_rate | 0.101    |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 1446     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 81748    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00629  |\n",
            "|    n_updates        | 2042     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 484      |\n",
            "|    ep_rew_mean      | -162     |\n",
            "|    exploration_rate | 0.0713   |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 1222     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 84428    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00105  |\n",
            "|    n_updates        | 2109     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 510      |\n",
            "|    ep_rew_mean      | -158     |\n",
            "|    exploration_rate | 0.0433   |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 990      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 86976    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00253  |\n",
            "|    n_updates        | 2173     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 80001 | Mean Reward: -86.79 ± 85.39\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 519      |\n",
            "|    ep_rew_mean      | -151     |\n",
            "|    exploration_rate | 0.102    |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 852      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 90744    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00203  |\n",
            "|    n_updates        | 2267     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 535      |\n",
            "|    ep_rew_mean      | -153     |\n",
            "|    exploration_rate | 0.0803   |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 933      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 92896    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00131  |\n",
            "|    n_updates        | 2321     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 562      |\n",
            "|    ep_rew_mean      | -143     |\n",
            "|    exploration_rate | 0.0407   |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 807      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 96896    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0353   |\n",
            "|    n_updates        | 2421     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 90001 | Mean Reward: -160.32 ± 58.72\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 587      |\n",
            "|    ep_rew_mean      | -144     |\n",
            "|    exploration_rate | 0.0999   |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 483      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 100008   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 582      |\n",
            "|    ep_rew_mean      | -145     |\n",
            "|    exploration_rate | 0.0858   |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 1992     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 101576   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0132   |\n",
            "|    n_updates        | 2538     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 582      |\n",
            "|    ep_rew_mean      | -141     |\n",
            "|    exploration_rate | 0.0658   |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 1097     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 103800   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00112  |\n",
            "|    n_updates        | 2593     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 592      |\n",
            "|    ep_rew_mean      | -133     |\n",
            "|    exploration_rate | 0.0594   |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 1058     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 104508   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0209   |\n",
            "|    n_updates        | 2611     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 584      |\n",
            "|    ep_rew_mean      | -129     |\n",
            "|    exploration_rate | 0.0511   |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 1179     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 105436   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000986 |\n",
            "|    n_updates        | 2634     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 577      |\n",
            "|    ep_rew_mean      | -129     |\n",
            "|    exploration_rate | 0.0257   |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 1047     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 108252   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0305   |\n",
            "|    n_updates        | 2705     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 564      |\n",
            "|    ep_rew_mean      | -132     |\n",
            "|    exploration_rate | 0.0175   |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 1060     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 109172   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00599  |\n",
            "|    n_updates        | 2728     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 100001 | Mean Reward: -96.90 ± 31.03\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 542      |\n",
            "|    ep_rew_mean      | -130     |\n",
            "|    exploration_rate | 0.0888   |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 1040     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110452   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0111   |\n",
            "|    n_updates        | 2760     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 534      |\n",
            "|    ep_rew_mean      | -129     |\n",
            "|    exploration_rate | 0.0719   |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 1219     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 112492   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0538   |\n",
            "|    n_updates        | 2811     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 526      |\n",
            "|    ep_rew_mean      | -127     |\n",
            "|    exploration_rate | 0.065    |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 1303     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 113336   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00194  |\n",
            "|    n_updates        | 2832     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 509      |\n",
            "|    ep_rew_mean      | -126     |\n",
            "|    exploration_rate | 0.0616   |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 1400     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 113740   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0329   |\n",
            "|    n_updates        | 2842     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 487      |\n",
            "|    ep_rew_mean      | -125     |\n",
            "|    exploration_rate | 0.0562   |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 1512     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 114400   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00224  |\n",
            "|    n_updates        | 2858     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 480      |\n",
            "|    ep_rew_mean      | -127     |\n",
            "|    exploration_rate | 0.0499   |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 1549     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 115164   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00132  |\n",
            "|    n_updates        | 2878     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 470      |\n",
            "|    ep_rew_mean      | -129     |\n",
            "|    exploration_rate | 0.0379   |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 1444     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 116620   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00132  |\n",
            "|    n_updates        | 2914     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 468      |\n",
            "|    ep_rew_mean      | -134     |\n",
            "|    exploration_rate | 0.0285   |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 1362     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 117752   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00317  |\n",
            "|    n_updates        | 2942     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 462      |\n",
            "|    ep_rew_mean      | -135     |\n",
            "|    exploration_rate | 0.0172   |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 1424     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 119132   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00149  |\n",
            "|    n_updates        | 2977     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 110001 | Mean Reward: -93.90 ± 59.69\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 461      |\n",
            "|    ep_rew_mean      | -137     |\n",
            "|    exploration_rate | 0.079    |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 611      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 120936   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0464   |\n",
            "|    n_updates        | 3022     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 442      |\n",
            "|    ep_rew_mean      | -135     |\n",
            "|    exploration_rate | 0.0654   |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 860      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 122728   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0413   |\n",
            "|    n_updates        | 3067     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 434      |\n",
            "|    ep_rew_mean      | -141     |\n",
            "|    exploration_rate | 0.041    |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 937      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 125924   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000992 |\n",
            "|    n_updates        | 3147     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 440      |\n",
            "|    ep_rew_mean      | -140     |\n",
            "|    exploration_rate | 0.0311   |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 908      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 127228   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00105  |\n",
            "|    n_updates        | 3179     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 436      |\n",
            "|    ep_rew_mean      | -144     |\n",
            "|    exploration_rate | 0.0106   |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 946      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 129924   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00128  |\n",
            "|    n_updates        | 3247     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 120001 | Mean Reward: -149.99 ± 81.12\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 441      |\n",
            "|    ep_rew_mean      | -145     |\n",
            "|    exploration_rate | 0.0524   |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 980      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 134000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00103  |\n",
            "|    n_updates        | 3348     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 446      |\n",
            "|    ep_rew_mean      | -146     |\n",
            "|    exploration_rate | 0.0251   |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 967      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 137868   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00106  |\n",
            "|    n_updates        | 3445     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 130001 | Mean Reward: -145.77 ± 43.31\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 463      |\n",
            "|    ep_rew_mean      | -147     |\n",
            "|    exploration_rate | 0.0591   |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 767      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 142560   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000928 |\n",
            "|    n_updates        | 3562     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 463      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.0327   |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 831      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 146560   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00186  |\n",
            "|    n_updates        | 3662     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 140001 | Mean Reward: -111.12 ± 41.13\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 462      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.0676   |\n",
            "| time/               |          |\n",
            "|    episodes         | 480      |\n",
            "|    fps              | 1517     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150696   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00157  |\n",
            "|    n_updates        | 3766     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 489      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.0428   |\n",
            "| time/               |          |\n",
            "|    episodes         | 484      |\n",
            "|    fps              | 896      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 154696   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00214  |\n",
            "|    n_updates        | 3866     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 501      |\n",
            "|    ep_rew_mean      | -151     |\n",
            "|    exploration_rate | 0.0195   |\n",
            "| time/               |          |\n",
            "|    episodes         | 488      |\n",
            "|    fps              | 809      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 158472   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00166  |\n",
            "|    n_updates        | 3960     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 500      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.0102   |\n",
            "| time/               |          |\n",
            "|    episodes         | 492      |\n",
            "|    fps              | 796      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 159972   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0523   |\n",
            "|    n_updates        | 3998     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 150001 | Mean Reward: -132.82 ± 56.55\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 519      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.0449   |\n",
            "| time/               |          |\n",
            "|    episodes         | 496      |\n",
            "|    fps              | 919      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 164000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0106   |\n",
            "|    n_updates        | 4098     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 534      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.0216   |\n",
            "| time/               |          |\n",
            "|    episodes         | 500      |\n",
            "|    fps              | 895      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 168000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0014   |\n",
            "|    n_updates        | 4198     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 160001 | Mean Reward: -97.90 ± 23.22\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 559      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.0456   |\n",
            "| time/               |          |\n",
            "|    episodes         | 504      |\n",
            "|    fps              | 731      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 173532   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0444   |\n",
            "|    n_updates        | 4337     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 573      |\n",
            "|    ep_rew_mean      | -158     |\n",
            "|    exploration_rate | 0.0415   |\n",
            "| time/               |          |\n",
            "|    episodes         | 508      |\n",
            "|    fps              | 788      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 174280   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00313  |\n",
            "|    n_updates        | 4355     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 591      |\n",
            "|    ep_rew_mean      | -157     |\n",
            "|    exploration_rate | 0.021    |\n",
            "| time/               |          |\n",
            "|    episodes         | 512      |\n",
            "|    fps              | 807      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 178000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00203  |\n",
            "|    n_updates        | 4448     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 170001 | Mean Reward: -146.07 ± 15.51\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 609      |\n",
            "|    ep_rew_mean      | -156     |\n",
            "|    exploration_rate | 0.0492   |\n",
            "| time/               |          |\n",
            "|    episodes         | 516      |\n",
            "|    fps              | 966      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 182476   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00177  |\n",
            "|    n_updates        | 4560     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 642      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.0284   |\n",
            "| time/               |          |\n",
            "|    episodes         | 520      |\n",
            "|    fps              | 809      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 186476   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00123  |\n",
            "|    n_updates        | 4660     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 180001 | Mean Reward: -143.42 ± 29.05\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 702      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.0397   |\n",
            "| time/               |          |\n",
            "|    episodes         | 524      |\n",
            "|    fps              | 887      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 194000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0639   |\n",
            "|    n_updates        | 4848     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 733      |\n",
            "|    ep_rew_mean      | -146     |\n",
            "|    exploration_rate | 0.0199   |\n",
            "| time/               |          |\n",
            "|    episodes         | 528      |\n",
            "|    fps              | 782      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 198000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00238  |\n",
            "|    n_updates        | 4948     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 733      |\n",
            "|    ep_rew_mean      | -145     |\n",
            "|    exploration_rate | 0.0176   |\n",
            "| time/               |          |\n",
            "|    episodes         | 532      |\n",
            "|    fps              | 817      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 198472   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00893  |\n",
            "|    n_updates        | 4960     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 190001 | Mean Reward: -122.72 ± 17.59\n",
            "Model and VecNormalize stats saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B64LR0.0003_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. envs=4, batch size= 128, lr=1e-4"
      ],
      "metadata": {
        "id": "xZ3ynjOZZo7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lunarlander(4, 128, 1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no2wM4QIZ9XJ",
        "outputId": "739ac682-66dd-43ff-fc58-4fa35824105d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 102      |\n",
            "|    ep_rew_mean      | -175     |\n",
            "|    exploration_rate | 0.95     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 3053     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 508      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0412   |\n",
            "|    n_updates        | 11       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 85.9     |\n",
            "|    ep_rew_mean      | -166     |\n",
            "|    exploration_rate | 0.922    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 3198     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 788      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0711   |\n",
            "|    n_updates        | 18       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 88.9     |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.88     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 3153     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1216     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.189    |\n",
            "|    n_updates        | 29       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.6     |\n",
            "|    ep_rew_mean      | -172     |\n",
            "|    exploration_rate | 0.84     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 2991     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1612     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0036   |\n",
            "|    n_updates        | 39       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.5     |\n",
            "|    ep_rew_mean      | -169     |\n",
            "|    exploration_rate | 0.81     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 2937     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1916     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.024    |\n",
            "|    n_updates        | 46       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.8     |\n",
            "|    ep_rew_mean      | -164     |\n",
            "|    exploration_rate | 0.778    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 2937     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 2240     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0801   |\n",
            "|    n_updates        | 54       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.6     |\n",
            "|    ep_rew_mean      | -167     |\n",
            "|    exploration_rate | 0.739    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 2984     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 2632     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0891   |\n",
            "|    n_updates        | 64       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.9     |\n",
            "|    ep_rew_mean      | -173     |\n",
            "|    exploration_rate | 0.69     |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 2963     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 3136     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0182   |\n",
            "|    n_updates        | 77       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92.3     |\n",
            "|    ep_rew_mean      | -171     |\n",
            "|    exploration_rate | 0.659    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 2946     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 3448     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0191   |\n",
            "|    n_updates        | 85       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.1     |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.619    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 2915     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 3852     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0018   |\n",
            "|    n_updates        | 95       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.4     |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.586    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 2889     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 4184     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00352  |\n",
            "|    n_updates        | 103      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.2     |\n",
            "|    ep_rew_mean      | -179     |\n",
            "|    exploration_rate | 0.563    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 2840     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 4412     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0709   |\n",
            "|    n_updates        | 109      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.5     |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.53     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 2853     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 4744     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0402   |\n",
            "|    n_updates        | 117      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.6     |\n",
            "|    ep_rew_mean      | -191     |\n",
            "|    exploration_rate | 0.49     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 2910     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 5152     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0354   |\n",
            "|    n_updates        | 127      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.8     |\n",
            "|    ep_rew_mean      | -194     |\n",
            "|    exploration_rate | 0.446    |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 2954     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 5592     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0138   |\n",
            "|    n_updates        | 138      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.6     |\n",
            "|    ep_rew_mean      | -196     |\n",
            "|    exploration_rate | 0.41     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 2992     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 5964     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0707   |\n",
            "|    n_updates        | 148      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.3     |\n",
            "|    ep_rew_mean      | -199     |\n",
            "|    exploration_rate | 0.38     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 3019     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 6260     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0018   |\n",
            "|    n_updates        | 155      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90       |\n",
            "|    ep_rew_mean      | -195     |\n",
            "|    exploration_rate | 0.351    |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 3038     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 6560     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0389   |\n",
            "|    n_updates        | 162      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.7     |\n",
            "|    ep_rew_mean      | -194     |\n",
            "|    exploration_rate | 0.313    |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 3066     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 6944     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00188  |\n",
            "|    n_updates        | 172      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.5     |\n",
            "|    ep_rew_mean      | -197     |\n",
            "|    exploration_rate | 0.275    |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 3089     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 7328     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0477   |\n",
            "|    n_updates        | 182      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90       |\n",
            "|    ep_rew_mean      | -199     |\n",
            "|    exploration_rate | 0.241    |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 3102     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 7668     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0308   |\n",
            "|    n_updates        | 190      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.2     |\n",
            "|    ep_rew_mean      | -194     |\n",
            "|    exploration_rate | 0.191    |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 3099     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8176     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00522  |\n",
            "|    n_updates        | 203      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.9     |\n",
            "|    ep_rew_mean      | -191     |\n",
            "|    exploration_rate | 0.161    |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 3115     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8472     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0308   |\n",
            "|    n_updates        | 210      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.1     |\n",
            "|    ep_rew_mean      | -192     |\n",
            "|    exploration_rate | 0.136    |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 3128     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8728     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0031   |\n",
            "|    n_updates        | 217      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89       |\n",
            "|    ep_rew_mean      | -193     |\n",
            "|    exploration_rate | 0.109    |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 3137     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 9004     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0578   |\n",
            "|    n_updates        | 224      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.6     |\n",
            "|    ep_rew_mean      | -193     |\n",
            "|    exploration_rate | 0.0821   |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 3153     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 9272     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.027    |\n",
            "|    n_updates        | 230      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.6     |\n",
            "|    ep_rew_mean      | -196     |\n",
            "|    exploration_rate | 0.0496   |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 3166     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 9600     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.02     |\n",
            "|    n_updates        | 238      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87       |\n",
            "|    ep_rew_mean      | -201     |\n",
            "|    exploration_rate | 0.0124   |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 3167     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 9976     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00684  |\n",
            "|    n_updates        | 248      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 1 | Mean Reward: -228.85 ± 128.43\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86.5     |\n",
            "|    ep_rew_mean      | -197     |\n",
            "|    exploration_rate | 0.503    |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 2136     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10040    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86.2     |\n",
            "|    ep_rew_mean      | -199     |\n",
            "|    exploration_rate | 0.484    |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 3535     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10416    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0183   |\n",
            "|    n_updates        | 259      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.3     |\n",
            "|    ep_rew_mean      | -202     |\n",
            "|    exploration_rate | 0.46     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 3661     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10916    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0291   |\n",
            "|    n_updates        | 271      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 88.3     |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.436    |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 3554     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 11384    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0384   |\n",
            "|    n_updates        | 283      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.5     |\n",
            "|    ep_rew_mean      | -204     |\n",
            "|    exploration_rate | 0.417    |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 3595     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 11776    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0135   |\n",
            "|    n_updates        | 293      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 88.1     |\n",
            "|    ep_rew_mean      | -202     |\n",
            "|    exploration_rate | 0.397    |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 3585     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 12184    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0446   |\n",
            "|    n_updates        | 303      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.4     |\n",
            "|    ep_rew_mean      | -200     |\n",
            "|    exploration_rate | 0.361    |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 3483     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 12904    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00714  |\n",
            "|    n_updates        | 321      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.5     |\n",
            "|    ep_rew_mean      | -197     |\n",
            "|    exploration_rate | 0.347    |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 3466     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 13200    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00494  |\n",
            "|    n_updates        | 328      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.6     |\n",
            "|    ep_rew_mean      | -196     |\n",
            "|    exploration_rate | 0.331    |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 3468     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 13512    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.035    |\n",
            "|    n_updates        | 336      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92       |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.315    |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 3492     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 13840    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0123   |\n",
            "|    n_updates        | 344      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92.4     |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.291    |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 3492     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 14316    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0323   |\n",
            "|    n_updates        | 356      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92.5     |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.272    |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 3506     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 14704    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00501  |\n",
            "|    n_updates        | 366      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.6     |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.238    |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 3474     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 15384    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00196  |\n",
            "|    n_updates        | 383      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 95.7     |\n",
            "|    ep_rew_mean      | -179     |\n",
            "|    exploration_rate | 0.216    |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 3456     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 15840    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0394   |\n",
            "|    n_updates        | 394      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.7     |\n",
            "|    ep_rew_mean      | -193     |\n",
            "|    exploration_rate | 0.188    |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 3427     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 16396    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0253   |\n",
            "|    n_updates        | 408      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 101      |\n",
            "|    ep_rew_mean      | -192     |\n",
            "|    exploration_rate | 0.162    |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 3362     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 16936    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0219   |\n",
            "|    n_updates        | 422      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 103      |\n",
            "|    ep_rew_mean      | -187     |\n",
            "|    exploration_rate | 0.124    |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 3335     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 17700    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0251   |\n",
            "|    n_updates        | 441      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 104      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.0977   |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 3271     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 18228    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0101   |\n",
            "|    n_updates        | 454      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 109      |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.0704   |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 3241     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 18780    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0136   |\n",
            "|    n_updates        | 468      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 110      |\n",
            "|    ep_rew_mean      | -192     |\n",
            "|    exploration_rate | 0.0276   |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 3222     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 19644    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00871  |\n",
            "|    n_updates        | 490      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 10001 | Mean Reward: -264.92 ± 118.77\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 114      |\n",
            "|    ep_rew_mean      | -195     |\n",
            "|    exploration_rate | 0.337    |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 2361     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20080    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0088   |\n",
            "|    n_updates        | 500      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 119      |\n",
            "|    ep_rew_mean      | -201     |\n",
            "|    exploration_rate | 0.313    |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 2707     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20832    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00793  |\n",
            "|    n_updates        | 519      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 123      |\n",
            "|    ep_rew_mean      | -204     |\n",
            "|    exploration_rate | 0.285    |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 2766     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 21668    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00107  |\n",
            "|    n_updates        | 540      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 126      |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.269    |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 2831     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 22164    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0145   |\n",
            "|    n_updates        | 553      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 129      |\n",
            "|    ep_rew_mean      | -204     |\n",
            "|    exploration_rate | 0.25     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 2835     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 22736    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0165   |\n",
            "|    n_updates        | 567      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -207     |\n",
            "|    exploration_rate | 0.234    |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 2836     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 23224    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0211   |\n",
            "|    n_updates        | 579      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -211     |\n",
            "|    exploration_rate | 0.216    |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 2874     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 23772    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0237   |\n",
            "|    n_updates        | 593      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -209     |\n",
            "|    exploration_rate | 0.191    |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 2914     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 24528    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00615  |\n",
            "|    n_updates        | 612      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 137      |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.175    |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 2941     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 25000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0139   |\n",
            "|    n_updates        | 623      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 139      |\n",
            "|    ep_rew_mean      | -207     |\n",
            "|    exploration_rate | 0.155    |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 2977     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 25620    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00312  |\n",
            "|    n_updates        | 639      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 143      |\n",
            "|    ep_rew_mean      | -215     |\n",
            "|    exploration_rate | 0.129    |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 2964     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 26408    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0157   |\n",
            "|    n_updates        | 659      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 145      |\n",
            "|    ep_rew_mean      | -217     |\n",
            "|    exploration_rate | 0.101    |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 2965     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 27252    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00905  |\n",
            "|    n_updates        | 680      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 146      |\n",
            "|    ep_rew_mean      | -224     |\n",
            "|    exploration_rate | 0.0833   |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 2952     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 27780    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00266  |\n",
            "|    n_updates        | 693      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 147      |\n",
            "|    ep_rew_mean      | -226     |\n",
            "|    exploration_rate | 0.069    |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 2969     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 28212    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00721  |\n",
            "|    n_updates        | 704      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 149      |\n",
            "|    ep_rew_mean      | -230     |\n",
            "|    exploration_rate | 0.0546   |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 2968     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 28648    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00597  |\n",
            "|    n_updates        | 715      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 150      |\n",
            "|    ep_rew_mean      | -231     |\n",
            "|    exploration_rate | 0.0324   |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 2972     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 29320    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00678  |\n",
            "|    n_updates        | 731      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -230     |\n",
            "|    exploration_rate | 0.0118   |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 2957     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 29944    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0133   |\n",
            "|    n_updates        | 747      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 20001 | Mean Reward: -195.12 ± 96.40\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 157      |\n",
            "|    ep_rew_mean      | -234     |\n",
            "|    exploration_rate | 0.24     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 1852     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30696    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00238  |\n",
            "|    n_updates        | 766      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 158      |\n",
            "|    ep_rew_mean      | -234     |\n",
            "|    exploration_rate | 0.223    |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 1940     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 31376    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00296  |\n",
            "|    n_updates        | 783      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 161      |\n",
            "|    ep_rew_mean      | -228     |\n",
            "|    exploration_rate | 0.203    |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 2014     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32200    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00123  |\n",
            "|    n_updates        | 803      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 163      |\n",
            "|    ep_rew_mean      | -233     |\n",
            "|    exploration_rate | 0.18     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 1993     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 33148    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.016    |\n",
            "|    n_updates        | 827      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 165      |\n",
            "|    ep_rew_mean      | -238     |\n",
            "|    exploration_rate | 0.163    |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 1994     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 33828    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00889  |\n",
            "|    n_updates        | 844      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 165      |\n",
            "|    ep_rew_mean      | -239     |\n",
            "|    exploration_rate | 0.142    |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 2131     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 34672    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0104   |\n",
            "|    n_updates        | 865      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 164      |\n",
            "|    ep_rew_mean      | -240     |\n",
            "|    exploration_rate | 0.13     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 2171     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 35164    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0084   |\n",
            "|    n_updates        | 878      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 165      |\n",
            "|    ep_rew_mean      | -233     |\n",
            "|    exploration_rate | 0.11     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 2242     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 35956    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00799  |\n",
            "|    n_updates        | 897      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 166      |\n",
            "|    ep_rew_mean      | -234     |\n",
            "|    exploration_rate | 0.0897   |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 2289     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 36780    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00425  |\n",
            "|    n_updates        | 918      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 166      |\n",
            "|    ep_rew_mean      | -229     |\n",
            "|    exploration_rate | 0.0712   |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 2313     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 37528    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00299  |\n",
            "|    n_updates        | 937      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 166      |\n",
            "|    ep_rew_mean      | -228     |\n",
            "|    exploration_rate | 0.0575   |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 2340     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 38080    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00951  |\n",
            "|    n_updates        | 950      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 167      |\n",
            "|    ep_rew_mean      | -227     |\n",
            "|    exploration_rate | 0.037    |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 2359     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 38908    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00337  |\n",
            "|    n_updates        | 971      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 169      |\n",
            "|    ep_rew_mean      | -231     |\n",
            "|    exploration_rate | 0.0173   |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 2362     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 39704    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00474  |\n",
            "|    n_updates        | 991      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 30001 | Mean Reward: -97.35 ± 18.91\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 171      |\n",
            "|    ep_rew_mean      | -229     |\n",
            "|    exploration_rate | 0.201    |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 2735     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40364    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00451  |\n",
            "|    n_updates        | 1008     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 172      |\n",
            "|    ep_rew_mean      | -222     |\n",
            "|    exploration_rate | 0.189    |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 2767     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40964    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00623  |\n",
            "|    n_updates        | 1023     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 171      |\n",
            "|    ep_rew_mean      | -220     |\n",
            "|    exploration_rate | 0.176    |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 2857     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 41632    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00514  |\n",
            "|    n_updates        | 1039     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 174      |\n",
            "|    ep_rew_mean      | -221     |\n",
            "|    exploration_rate | 0.158    |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 2764     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 42520    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00978  |\n",
            "|    n_updates        | 1061     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -219     |\n",
            "|    exploration_rate | 0.146    |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 2765     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 43124    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0106   |\n",
            "|    n_updates        | 1077     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -211     |\n",
            "|    exploration_rate | 0.132    |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 2762     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 43848    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0031   |\n",
            "|    n_updates        | 1095     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.119    |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 2814     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 44492    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0236   |\n",
            "|    n_updates        | 1111     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -201     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 2820     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 45436    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00704  |\n",
            "|    n_updates        | 1134     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 181      |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.0885   |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 2722     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 46036    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00402  |\n",
            "|    n_updates        | 1149     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 181      |\n",
            "|    ep_rew_mean      | -202     |\n",
            "|    exploration_rate | 0.0757   |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 2788     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 46680    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00418  |\n",
            "|    n_updates        | 1165     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 181      |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.0622   |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 2819     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 47364    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00455  |\n",
            "|    n_updates        | 1183     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 184      |\n",
            "|    ep_rew_mean      | -208     |\n",
            "|    exploration_rate | 0.0461   |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 2766     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 48176    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00758  |\n",
            "|    n_updates        | 1203     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 182      |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.0246   |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 2714     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 49264    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0058   |\n",
            "|    n_updates        | 1230     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 183      |\n",
            "|    ep_rew_mean      | -198     |\n",
            "|    exploration_rate | 0.0133   |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 2680     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 49832    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00861  |\n",
            "|    n_updates        | 1244     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 40001 | Mean Reward: -87.87 ± 102.48\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 180      |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.167    |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 3136     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50468    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00346  |\n",
            "|    n_updates        | 1260     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 178      |\n",
            "|    ep_rew_mean      | -187     |\n",
            "|    exploration_rate | 0.155    |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 2940     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 51216    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0151   |\n",
            "|    n_updates        | 1279     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 178      |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.14     |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 2717     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 52112    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00192  |\n",
            "|    n_updates        | 1301     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 182      |\n",
            "|    ep_rew_mean      | -189     |\n",
            "|    exploration_rate | 0.125    |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 2661     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 53040    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00289  |\n",
            "|    n_updates        | 1324     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 185      |\n",
            "|    ep_rew_mean      | -187     |\n",
            "|    exploration_rate | 0.104    |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 2435     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 54300    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00453  |\n",
            "|    n_updates        | 1356     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.0825   |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 2342     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 55608    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000978 |\n",
            "|    n_updates        | 1389     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 196      |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.0649   |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 2196     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 56672    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00932  |\n",
            "|    n_updates        | 1415     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.0478   |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 2076     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 57712    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00231  |\n",
            "|    n_updates        | 1441     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 202      |\n",
            "|    ep_rew_mean      | -179     |\n",
            "|    exploration_rate | 0.0305   |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 1990     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 58756    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00132  |\n",
            "|    n_updates        | 1467     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 205      |\n",
            "|    ep_rew_mean      | -175     |\n",
            "|    exploration_rate | 0.0158   |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 1992     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 59648    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0174   |\n",
            "|    n_updates        | 1490     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 50001 | Mean Reward: -128.62 ± 114.47\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 204      |\n",
            "|    ep_rew_mean      | -166     |\n",
            "|    exploration_rate | 0.15     |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 1951     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60120    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00993  |\n",
            "|    n_updates        | 1501     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 207      |\n",
            "|    ep_rew_mean      | -165     |\n",
            "|    exploration_rate | 0.139    |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 2029     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60908    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00277  |\n",
            "|    n_updates        | 1521     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 208      |\n",
            "|    ep_rew_mean      | -164     |\n",
            "|    exploration_rate | 0.129    |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 2233     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 61616    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00549  |\n",
            "|    n_updates        | 1539     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 211      |\n",
            "|    ep_rew_mean      | -166     |\n",
            "|    exploration_rate | 0.112    |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 2125     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 62776    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00603  |\n",
            "|    n_updates        | 1568     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 211      |\n",
            "|    ep_rew_mean      | -165     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 2197     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 63620    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.011    |\n",
            "|    n_updates        | 1589     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 214      |\n",
            "|    ep_rew_mean      | -164     |\n",
            "|    exploration_rate | 0.0838   |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 2065     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 64780    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00106  |\n",
            "|    n_updates        | 1618     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 221      |\n",
            "|    ep_rew_mean      | -168     |\n",
            "|    exploration_rate | 0.0681   |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 1994     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 65892    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0231   |\n",
            "|    n_updates        | 1646     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 221      |\n",
            "|    ep_rew_mean      | -170     |\n",
            "|    exploration_rate | 0.0567   |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 2066     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 66696    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00318  |\n",
            "|    n_updates        | 1666     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 223      |\n",
            "|    ep_rew_mean      | -169     |\n",
            "|    exploration_rate | 0.0468   |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 2095     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 67396    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00222  |\n",
            "|    n_updates        | 1683     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -165     |\n",
            "|    exploration_rate | 0.0235   |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 2110     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 69044    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00565  |\n",
            "|    n_updates        | 1725     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 228      |\n",
            "|    ep_rew_mean      | -163     |\n",
            "|    exploration_rate | 0.0114   |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 2108     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 69904    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00737  |\n",
            "|    n_updates        | 1746     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 60001 | Mean Reward: -146.36 ± 93.96\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 234      |\n",
            "|    ep_rew_mean      | -162     |\n",
            "|    exploration_rate | 0.119    |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 1766     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 71220    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00389  |\n",
            "|    n_updates        | 1779     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 236      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.102    |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 1607     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 72592    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00212  |\n",
            "|    n_updates        | 1813     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 243      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.0887   |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 1500     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 73640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0223   |\n",
            "|    n_updates        | 1839     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 248      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.0687   |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 1487     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 75260    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00396  |\n",
            "|    n_updates        | 1880     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 255      |\n",
            "|    ep_rew_mean      | -155     |\n",
            "|    exploration_rate | 0.056    |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 1534     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 76280    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00097  |\n",
            "|    n_updates        | 1905     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 260      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.0437   |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 1607     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 77280    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0178   |\n",
            "|    n_updates        | 1930     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 264      |\n",
            "|    ep_rew_mean      | -153     |\n",
            "|    exploration_rate | 0.0252   |\n",
            "| time/               |          |\n",
            "|    episodes         | 480      |\n",
            "|    fps              | 1650     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 78772    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.021    |\n",
            "|    n_updates        | 1968     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 70001 | Mean Reward: -141.11 ± 59.20\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 270      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.112    |\n",
            "| time/               |          |\n",
            "|    episodes         | 484      |\n",
            "|    fps              | 1541     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80728    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0024   |\n",
            "|    n_updates        | 2017     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 272      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.0997   |\n",
            "| time/               |          |\n",
            "|    episodes         | 488      |\n",
            "|    fps              | 1639     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 81848    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0318   |\n",
            "|    n_updates        | 2045     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 271      |\n",
            "|    ep_rew_mean      | -145     |\n",
            "|    exploration_rate | 0.0871   |\n",
            "| time/               |          |\n",
            "|    episodes         | 492      |\n",
            "|    fps              | 1732     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 82992    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0253   |\n",
            "|    n_updates        | 2073     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 271      |\n",
            "|    ep_rew_mean      | -147     |\n",
            "|    exploration_rate | 0.0717   |\n",
            "| time/               |          |\n",
            "|    episodes         | 496      |\n",
            "|    fps              | 1732     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 84388    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0056   |\n",
            "|    n_updates        | 2108     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 275      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.0551   |\n",
            "| time/               |          |\n",
            "|    episodes         | 500      |\n",
            "|    fps              | 1624     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 85904    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0216   |\n",
            "|    n_updates        | 2146     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 280      |\n",
            "|    ep_rew_mean      | -149     |\n",
            "|    exploration_rate | 0.0417   |\n",
            "| time/               |          |\n",
            "|    episodes         | 504      |\n",
            "|    fps              | 1564     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 87116    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00247  |\n",
            "|    n_updates        | 2176     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 281      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.0273   |\n",
            "| time/               |          |\n",
            "|    episodes         | 508      |\n",
            "|    fps              | 1639     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 88424    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00405  |\n",
            "|    n_updates        | 2209     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 80001 | Mean Reward: -209.83 ± 74.38\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 295      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.108    |\n",
            "| time/               |          |\n",
            "|    episodes         | 512      |\n",
            "|    fps              | 1149     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 90088    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00685  |\n",
            "|    n_updates        | 2251     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 308      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.0736   |\n",
            "| time/               |          |\n",
            "|    episodes         | 516      |\n",
            "|    fps              | 929      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 93576    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00361  |\n",
            "|    n_updates        | 2338     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 320      |\n",
            "|    ep_rew_mean      | -157     |\n",
            "|    exploration_rate | 0.0612   |\n",
            "| time/               |          |\n",
            "|    episodes         | 520      |\n",
            "|    fps              | 1034     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 94832    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0236   |\n",
            "|    n_updates        | 2369     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 336      |\n",
            "|    ep_rew_mean      | -158     |\n",
            "|    exploration_rate | 0.0374   |\n",
            "| time/               |          |\n",
            "|    episodes         | 524      |\n",
            "|    fps              | 1029     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 97236    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.03     |\n",
            "|    n_updates        | 2429     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 347      |\n",
            "|    ep_rew_mean      | -158     |\n",
            "|    exploration_rate | 0.0115   |\n",
            "| time/               |          |\n",
            "|    episodes         | 528      |\n",
            "|    fps              | 1060     |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 99844    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0383   |\n",
            "|    n_updates        | 2495     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 90001 | Mean Reward: -194.97 ± 77.35\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 360      |\n",
            "|    ep_rew_mean      | -163     |\n",
            "|    exploration_rate | 0.0798   |\n",
            "| time/               |          |\n",
            "|    episodes         | 532      |\n",
            "|    fps              | 1212     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 102244   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00927  |\n",
            "|    n_updates        | 2555     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 362      |\n",
            "|    ep_rew_mean      | -160     |\n",
            "|    exploration_rate | 0.0602   |\n",
            "| time/               |          |\n",
            "|    episodes         | 536      |\n",
            "|    fps              | 1354     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 104424   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0122   |\n",
            "|    n_updates        | 2609     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 392      |\n",
            "|    ep_rew_mean      | -160     |\n",
            "|    exploration_rate | 0.0242   |\n",
            "| time/               |          |\n",
            "|    episodes         | 540      |\n",
            "|    fps              | 958      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 108424   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00295  |\n",
            "|    n_updates        | 2709     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 100001 | Mean Reward: -136.02 ± 58.41\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 404      |\n",
            "|    ep_rew_mean      | -158     |\n",
            "|    exploration_rate | 0.0799   |\n",
            "| time/               |          |\n",
            "|    episodes         | 544      |\n",
            "|    fps              | 1720     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 111532   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0033   |\n",
            "|    n_updates        | 2787     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 417      |\n",
            "|    ep_rew_mean      | -155     |\n",
            "|    exploration_rate | 0.0593   |\n",
            "| time/               |          |\n",
            "|    episodes         | 548      |\n",
            "|    fps              | 1321     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 114020   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00147  |\n",
            "|    n_updates        | 2849     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 428      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.041    |\n",
            "| time/               |          |\n",
            "|    episodes         | 552      |\n",
            "|    fps              | 1155     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 116244   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00712  |\n",
            "|    n_updates        | 2905     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 447      |\n",
            "|    ep_rew_mean      | -156     |\n",
            "|    exploration_rate | 0.0114   |\n",
            "| time/               |          |\n",
            "|    episodes         | 556      |\n",
            "|    fps              | 1020     |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 119832   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00994  |\n",
            "|    n_updates        | 2994     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 110001 | Mean Reward: -130.47 ± 80.62\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 463      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.0564   |\n",
            "| time/               |          |\n",
            "|    episodes         | 560      |\n",
            "|    fps              | 919      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 123908   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00325  |\n",
            "|    n_updates        | 3096     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 473      |\n",
            "|    ep_rew_mean      | -153     |\n",
            "|    exploration_rate | 0.0431   |\n",
            "| time/               |          |\n",
            "|    episodes         | 564      |\n",
            "|    fps              | 1036     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 125660   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00106  |\n",
            "|    n_updates        | 3140     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 478      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.0276   |\n",
            "| time/               |          |\n",
            "|    episodes         | 568      |\n",
            "|    fps              | 1088     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 127688   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0026   |\n",
            "|    n_updates        | 3191     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 487      |\n",
            "|    ep_rew_mean      | -149     |\n",
            "|    exploration_rate | 0.0121   |\n",
            "| time/               |          |\n",
            "|    episodes         | 572      |\n",
            "|    fps              | 1096     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 129724   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0022   |\n",
            "|    n_updates        | 3242     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 120001 | Mean Reward: -154.16 ± 65.46\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 506      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.0655   |\n",
            "| time/               |          |\n",
            "|    episodes         | 576      |\n",
            "|    fps              | 1130     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 132156   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00166  |\n",
            "|    n_updates        | 3302     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 515      |\n",
            "|    ep_rew_mean      | -151     |\n",
            "|    exploration_rate | 0.0551   |\n",
            "| time/               |          |\n",
            "|    episodes         | 580      |\n",
            "|    fps              | 1166     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 133628   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0152   |\n",
            "|    n_updates        | 3339     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 516      |\n",
            "|    ep_rew_mean      | -151     |\n",
            "|    exploration_rate | 0.039    |\n",
            "| time/               |          |\n",
            "|    episodes         | 584      |\n",
            "|    fps              | 1166     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 135904   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0134   |\n",
            "|    n_updates        | 3396     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 523      |\n",
            "|    ep_rew_mean      | -149     |\n",
            "|    exploration_rate | 0.0268   |\n",
            "| time/               |          |\n",
            "|    episodes         | 588      |\n",
            "|    fps              | 1159     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 137628   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00266  |\n",
            "|    n_updates        | 3439     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 130001 | Mean Reward: -65.50 ± 29.09\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 529      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.0727   |\n",
            "| time/               |          |\n",
            "|    episodes         | 592      |\n",
            "|    fps              | 838      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140500   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00205  |\n",
            "|    n_updates        | 3511     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 537      |\n",
            "|    ep_rew_mean      | -141     |\n",
            "|    exploration_rate | 0.0629   |\n",
            "| time/               |          |\n",
            "|    episodes         | 596      |\n",
            "|    fps              | 996      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 141980   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0061   |\n",
            "|    n_updates        | 3548     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 540      |\n",
            "|    ep_rew_mean      | -136     |\n",
            "|    exploration_rate | 0.0485   |\n",
            "| time/               |          |\n",
            "|    episodes         | 600      |\n",
            "|    fps              | 1207     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 144160   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00574  |\n",
            "|    n_updates        | 3602     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 554      |\n",
            "|    ep_rew_mean      | -132     |\n",
            "|    exploration_rate | 0.0331   |\n",
            "| time/               |          |\n",
            "|    episodes         | 604      |\n",
            "|    fps              | 1133     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 146496   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00282  |\n",
            "|    n_updates        | 3661     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 566      |\n",
            "|    ep_rew_mean      | -131     |\n",
            "|    exploration_rate | 0.0179   |\n",
            "| time/               |          |\n",
            "|    episodes         | 608      |\n",
            "|    fps              | 1095     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 148800   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00802  |\n",
            "|    n_updates        | 3718     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 140001 | Mean Reward: -70.14 ± 50.45\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 572      |\n",
            "|    ep_rew_mean      | -129     |\n",
            "|    exploration_rate | 0.0652   |\n",
            "| time/               |          |\n",
            "|    episodes         | 612      |\n",
            "|    fps              | 1067     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 151072   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00375  |\n",
            "|    n_updates        | 3775     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 568      |\n",
            "|    ep_rew_mean      | -124     |\n",
            "|    exploration_rate | 0.0572   |\n",
            "| time/               |          |\n",
            "|    episodes         | 616      |\n",
            "|    fps              | 1079     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 152376   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00368  |\n",
            "|    n_updates        | 3808     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 568      |\n",
            "|    ep_rew_mean      | -121     |\n",
            "|    exploration_rate | 0.0397   |\n",
            "| time/               |          |\n",
            "|    episodes         | 620      |\n",
            "|    fps              | 1187     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 155192   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00318  |\n",
            "|    n_updates        | 3878     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 570      |\n",
            "|    ep_rew_mean      | -119     |\n",
            "|    exploration_rate | 0.0265   |\n",
            "| time/               |          |\n",
            "|    episodes         | 624      |\n",
            "|    fps              | 1151     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 157332   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00538  |\n",
            "|    n_updates        | 3932     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 150001 | Mean Reward: -95.15 ± 34.99\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 582      |\n",
            "|    ep_rew_mean      | -119     |\n",
            "|    exploration_rate | 0.066    |\n",
            "| time/               |          |\n",
            "|    episodes         | 628      |\n",
            "|    fps              | 748      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 160384   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0816   |\n",
            "|    n_updates        | 4008     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 590      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.0427   |\n",
            "| time/               |          |\n",
            "|    episodes         | 632      |\n",
            "|    fps              | 994      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 164384   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00153  |\n",
            "|    n_updates        | 4108     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 613      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.0235   |\n",
            "| time/               |          |\n",
            "|    episodes         | 636      |\n",
            "|    fps              | 942      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 167680   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00473  |\n",
            "|    n_updates        | 4190     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 160001 | Mean Reward: -121.03 ± 16.26\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 622      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.043    |\n",
            "| time/               |          |\n",
            "|    episodes         | 640      |\n",
            "|    fps              | 749      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 174000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0603   |\n",
            "|    n_updates        | 4348     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 630      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.0278   |\n",
            "| time/               |          |\n",
            "|    episodes         | 644      |\n",
            "|    fps              | 855      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 176764   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0139   |\n",
            "|    n_updates        | 4418     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 170001 | Mean Reward: -103.77 ± 21.44\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 655      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.0413   |\n",
            "| time/               |          |\n",
            "|    episodes         | 648      |\n",
            "|    fps              | 951      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 184000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00461  |\n",
            "|    n_updates        | 4598     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 666      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.0204   |\n",
            "| time/               |          |\n",
            "|    episodes         | 652      |\n",
            "|    fps              | 967      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 188000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0089   |\n",
            "|    n_updates        | 4698     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 180001 | Mean Reward: -100.02 ± 14.36\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 661      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.0487   |\n",
            "| time/               |          |\n",
            "|    episodes         | 656      |\n",
            "|    fps              | 1315     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 192188   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00226  |\n",
            "|    n_updates        | 4803     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 662      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.0358   |\n",
            "| time/               |          |\n",
            "|    episodes         | 660      |\n",
            "|    fps              | 1200     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 194784   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0115   |\n",
            "|    n_updates        | 4868     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 679      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.016    |\n",
            "| time/               |          |\n",
            "|    episodes         | 664      |\n",
            "|    fps              | 1052     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 198784   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0102   |\n",
            "|    n_updates        | 4968     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 190001 | Mean Reward: -98.39 ± 26.38\n",
            "Model and VecNormalize stats saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0001_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. envs=4, batch size= 128, lr=3e-4"
      ],
      "metadata": {
        "id": "jmxuaOXkaGpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lunarlander(4, 128, 3e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsX1PKS8aUEe",
        "outputId": "ded223ad-eb8e-4fdd-d2f5-f7725ec07ea3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
            "/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 91.2     |\n",
            "|    ep_rew_mean      | -128     |\n",
            "|    exploration_rate | 0.956    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 506      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 444      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00936  |\n",
            "|    n_updates        | 10       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 103      |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.908    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 712      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 928      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0198   |\n",
            "|    n_updates        | 22       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 102      |\n",
            "|    ep_rew_mean      | -213     |\n",
            "|    exploration_rate | 0.865    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 837      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1364     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0209   |\n",
            "|    n_updates        | 33       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 96.7     |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.827    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 925      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1748     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0372   |\n",
            "|    n_updates        | 42       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 95       |\n",
            "|    ep_rew_mean      | -176     |\n",
            "|    exploration_rate | 0.791    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 981      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 2108     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0316   |\n",
            "|    n_updates        | 51       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 98.9     |\n",
            "|    ep_rew_mean      | -172     |\n",
            "|    exploration_rate | 0.745    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 1050     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 2580     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00613  |\n",
            "|    n_updates        | 63       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 101      |\n",
            "|    ep_rew_mean      | -169     |\n",
            "|    exploration_rate | 0.696    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 1109     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 3072     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0122   |\n",
            "|    n_updates        | 75       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 102      |\n",
            "|    ep_rew_mean      | -177     |\n",
            "|    exploration_rate | 0.653    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 1159     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 3500     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00666  |\n",
            "|    n_updates        | 86       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -168     |\n",
            "|    exploration_rate | 0.604    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 1227     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 4000     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0472   |\n",
            "|    n_updates        | 98       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | -179     |\n",
            "|    exploration_rate | 0.54     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 1309     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 4648     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0415   |\n",
            "|    n_updates        | 115      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 113      |\n",
            "|    ep_rew_mean      | -193     |\n",
            "|    exploration_rate | 0.486    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 1365     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 5188     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00652  |\n",
            "|    n_updates        | 128      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 117      |\n",
            "|    ep_rew_mean      | -206     |\n",
            "|    exploration_rate | 0.408    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 1433     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 5980     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0273   |\n",
            "|    n_updates        | 148      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 119      |\n",
            "|    ep_rew_mean      | -208     |\n",
            "|    exploration_rate | 0.368    |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 1465     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 6388     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00155  |\n",
            "|    n_updates        | 158      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 122      |\n",
            "|    ep_rew_mean      | -217     |\n",
            "|    exploration_rate | 0.299    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 1489     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 7084     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0214   |\n",
            "|    n_updates        | 176      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 124      |\n",
            "|    ep_rew_mean      | -222     |\n",
            "|    exploration_rate | 0.244    |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 1479     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 7640     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0119   |\n",
            "|    n_updates        | 189      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 127      |\n",
            "|    ep_rew_mean      | -228     |\n",
            "|    exploration_rate | 0.17     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 1468     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 8384     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0264   |\n",
            "|    n_updates        | 208      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 128      |\n",
            "|    ep_rew_mean      | -235     |\n",
            "|    exploration_rate | 0.104    |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 1468     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 9052     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00345  |\n",
            "|    n_updates        | 225      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -243     |\n",
            "|    exploration_rate | 0.0286   |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 1457     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 9812     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00993  |\n",
            "|    n_updates        | 244      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 1 | Mean Reward: -383.10 ± 157.53\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 131      |\n",
            "|    ep_rew_mean      | -255     |\n",
            "|    exploration_rate | 0.504    |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 910      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10028    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -253     |\n",
            "|    exploration_rate | 0.469    |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 1315     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10728    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00625  |\n",
            "|    n_updates        | 267      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -252     |\n",
            "|    exploration_rate | 0.436    |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 1449     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 11384    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0194   |\n",
            "|    n_updates        | 283      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -248     |\n",
            "|    exploration_rate | 0.408    |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 1623     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 11960    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0224   |\n",
            "|    n_updates        | 297      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -248     |\n",
            "|    exploration_rate | 0.384    |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 1682     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 12436    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00253  |\n",
            "|    n_updates        | 309      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -246     |\n",
            "|    exploration_rate | 0.34     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 1655     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 13324    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00075  |\n",
            "|    n_updates        | 332      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -245     |\n",
            "|    exploration_rate | 0.304    |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 1577     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 14052    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00631  |\n",
            "|    n_updates        | 350      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 138      |\n",
            "|    ep_rew_mean      | -244     |\n",
            "|    exploration_rate | 0.26     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 1435     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 14952    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0134   |\n",
            "|    n_updates        | 372      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 139      |\n",
            "|    ep_rew_mean      | -243     |\n",
            "|    exploration_rate | 0.213    |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 1343     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 15908    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000629 |\n",
            "|    n_updates        | 396      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 150      |\n",
            "|    ep_rew_mean      | -243     |\n",
            "|    exploration_rate | 0.187    |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 1365     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 16424    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0198   |\n",
            "|    n_updates        | 409      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -251     |\n",
            "|    exploration_rate | 0.164    |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 1400     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 16888    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00599  |\n",
            "|    n_updates        | 421      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -253     |\n",
            "|    exploration_rate | 0.128    |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 1440     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 17620    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00779  |\n",
            "|    n_updates        | 439      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 158      |\n",
            "|    ep_rew_mean      | -256     |\n",
            "|    exploration_rate | 0.0934   |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 1475     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 18316    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0302   |\n",
            "|    n_updates        | 456      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 160      |\n",
            "|    ep_rew_mean      | -260     |\n",
            "|    exploration_rate | 0.066    |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 1498     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 18868    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00272  |\n",
            "|    n_updates        | 470      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 160      |\n",
            "|    ep_rew_mean      | -260     |\n",
            "|    exploration_rate | 0.0316   |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 1528     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 19564    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00568  |\n",
            "|    n_updates        | 488      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 10001 | Mean Reward: -269.17 ± 100.42\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 160      |\n",
            "|    ep_rew_mean      | -264     |\n",
            "|    exploration_rate | 0.331    |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 2037     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20284    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0171   |\n",
            "|    n_updates        | 506      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 161      |\n",
            "|    ep_rew_mean      | -262     |\n",
            "|    exploration_rate | 0.308    |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 2080     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20956    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00213  |\n",
            "|    n_updates        | 522      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 160      |\n",
            "|    ep_rew_mean      | -263     |\n",
            "|    exploration_rate | 0.29     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 2102     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 21512    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00206  |\n",
            "|    n_updates        | 536      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 159      |\n",
            "|    ep_rew_mean      | -257     |\n",
            "|    exploration_rate | 0.274    |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 2133     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 22008    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00838  |\n",
            "|    n_updates        | 549      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 160      |\n",
            "|    ep_rew_mean      | -259     |\n",
            "|    exploration_rate | 0.251    |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 2060     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 22704    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0113   |\n",
            "|    n_updates        | 566      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 162      |\n",
            "|    ep_rew_mean      | -251     |\n",
            "|    exploration_rate | 0.226    |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 1987     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 23468    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0053   |\n",
            "|    n_updates        | 585      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 164      |\n",
            "|    ep_rew_mean      | -245     |\n",
            "|    exploration_rate | 0.19     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 1910     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 24532    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00518  |\n",
            "|    n_updates        | 612      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 165      |\n",
            "|    ep_rew_mean      | -240     |\n",
            "|    exploration_rate | 0.163    |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 1862     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 25364    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0159   |\n",
            "|    n_updates        | 633      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 170      |\n",
            "|    ep_rew_mean      | -233     |\n",
            "|    exploration_rate | 0.135    |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 1684     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 26212    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00444  |\n",
            "|    n_updates        | 654      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 169      |\n",
            "|    ep_rew_mean      | -224     |\n",
            "|    exploration_rate | 0.117    |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 1657     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 26764    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0052   |\n",
            "|    n_updates        | 668      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 171      |\n",
            "|    ep_rew_mean      | -218     |\n",
            "|    exploration_rate | 0.0876   |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 1604     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 27648    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00185  |\n",
            "|    n_updates        | 690      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 172      |\n",
            "|    ep_rew_mean      | -217     |\n",
            "|    exploration_rate | 0.065    |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 1592     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 28332    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00359  |\n",
            "|    n_updates        | 707      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 172      |\n",
            "|    ep_rew_mean      | -226     |\n",
            "|    exploration_rate | 0.0319   |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 1458     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 29336    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00449  |\n",
            "|    n_updates        | 732      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 20001 | Mean Reward: -100.26 ± 60.74\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 177      |\n",
            "|    ep_rew_mean      | -229     |\n",
            "|    exploration_rate | 0.248    |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 1730     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30364    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0086   |\n",
            "|    n_updates        | 758      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 179      |\n",
            "|    ep_rew_mean      | -223     |\n",
            "|    exploration_rate | 0.23     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 1792     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 31100    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00143  |\n",
            "|    n_updates        | 776      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 181      |\n",
            "|    ep_rew_mean      | -220     |\n",
            "|    exploration_rate | 0.207    |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 1606     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32048    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00428  |\n",
            "|    n_updates        | 800      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | -218     |\n",
            "|    exploration_rate | 0.184    |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 1580     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32964    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00876  |\n",
            "|    n_updates        | 823      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | -225     |\n",
            "|    exploration_rate | 0.146    |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 1327     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 34500    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00595  |\n",
            "|    n_updates        | 861      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -222     |\n",
            "|    exploration_rate | 0.104    |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 1257     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 36188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000875 |\n",
            "|    n_updates        | 903      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 206      |\n",
            "|    ep_rew_mean      | -217     |\n",
            "|    exploration_rate | 0.0382   |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 1009     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 38860    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00335  |\n",
            "|    n_updates        | 970      |\n",
            "----------------------------------\n",
            "LunarLander - Step: 30001 | Mean Reward: -225.50 ± 72.58\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -217     |\n",
            "|    exploration_rate | 0.205    |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 1228     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40132    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00185  |\n",
            "|    n_updates        | 1002     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 226      |\n",
            "|    ep_rew_mean      | -220     |\n",
            "|    exploration_rate | 0.181    |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 1447     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 41384    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00296  |\n",
            "|    n_updates        | 1033     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 238      |\n",
            "|    ep_rew_mean      | -218     |\n",
            "|    exploration_rate | 0.145    |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 1071     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 43164    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0023   |\n",
            "|    n_updates        | 1078     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 243      |\n",
            "|    ep_rew_mean      | -212     |\n",
            "|    exploration_rate | 0.111    |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 1041     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 44876    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0155   |\n",
            "|    n_updates        | 1120     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 259      |\n",
            "|    ep_rew_mean      | -211     |\n",
            "|    exploration_rate | 0.0793   |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 914      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 46500    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0428   |\n",
            "|    n_updates        | 1161     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 268      |\n",
            "|    ep_rew_mean      | -212     |\n",
            "|    exploration_rate | 0.0491   |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 944      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 48024    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00656  |\n",
            "|    n_updates        | 1199     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 277      |\n",
            "|    ep_rew_mean      | -211     |\n",
            "|    exploration_rate | 0.0293   |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 923      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 49024    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00239  |\n",
            "|    n_updates        | 1224     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 40001 | Mean Reward: -228.52 ± 30.11\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 284      |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.169    |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 1003     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50336    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00265  |\n",
            "|    n_updates        | 1257     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 295      |\n",
            "|    ep_rew_mean      | -206     |\n",
            "|    exploration_rate | 0.142    |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 1020     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 51980    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0016   |\n",
            "|    n_updates        | 1298     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 301      |\n",
            "|    ep_rew_mean      | -200     |\n",
            "|    exploration_rate | 0.113    |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 880      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 53764    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00576  |\n",
            "|    n_updates        | 1343     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 308      |\n",
            "|    ep_rew_mean      | -200     |\n",
            "|    exploration_rate | 0.0934   |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 841      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 54948    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00947  |\n",
            "|    n_updates        | 1372     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 314      |\n",
            "|    ep_rew_mean      | -202     |\n",
            "|    exploration_rate | 0.0681   |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 890      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 56480    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000751 |\n",
            "|    n_updates        | 1410     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 325      |\n",
            "|    ep_rew_mean      | -201     |\n",
            "|    exploration_rate | 0.0373   |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 880      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 58348    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00425  |\n",
            "|    n_updates        | 1457     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 326      |\n",
            "|    ep_rew_mean      | -201     |\n",
            "|    exploration_rate | 0.017    |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 923      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 59576    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0125   |\n",
            "|    n_updates        | 1488     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 50001 | Mean Reward: -163.36 ± 22.04\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 330      |\n",
            "|    ep_rew_mean      | -202     |\n",
            "|    exploration_rate | 0.139    |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 1470     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60912    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00246  |\n",
            "|    n_updates        | 1521     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 336      |\n",
            "|    ep_rew_mean      | -196     |\n",
            "|    exploration_rate | 0.123    |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 1380     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 62008    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00302  |\n",
            "|    n_updates        | 1549     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 340      |\n",
            "|    ep_rew_mean      | -194     |\n",
            "|    exploration_rate | 0.107    |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 1243     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 63172    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00224  |\n",
            "|    n_updates        | 1578     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 351      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.079    |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 882      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 65124    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00195  |\n",
            "|    n_updates        | 1627     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 353      |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.0636   |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 920      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 66212    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00531  |\n",
            "|    n_updates        | 1654     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 357      |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.0458   |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 976      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 67468    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00102  |\n",
            "|    n_updates        | 1685     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 361      |\n",
            "|    ep_rew_mean      | -189     |\n",
            "|    exploration_rate | 0.0342   |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 995      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 68292    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00111  |\n",
            "|    n_updates        | 1706     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 358      |\n",
            "|    ep_rew_mean      | -191     |\n",
            "|    exploration_rate | 0.0123   |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 1029     |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 69836    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00131  |\n",
            "|    n_updates        | 1744     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 60001 | Mean Reward: -158.70 ± 48.16\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 353      |\n",
            "|    ep_rew_mean      | -187     |\n",
            "|    exploration_rate | 0.124    |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 1598     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70812    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00116  |\n",
            "|    n_updates        | 1769     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 352      |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.109    |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 1158     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 72004    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00909  |\n",
            "|    n_updates        | 1799     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 343      |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 1296     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 72692    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.022    |\n",
            "|    n_updates        | 1816     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 330      |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.0874   |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 1361     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 73748    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00956  |\n",
            "|    n_updates        | 1842     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 331      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.0702   |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 1273     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 75136    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00154  |\n",
            "|    n_updates        | 1877     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 325      |\n",
            "|    ep_rew_mean      | -180     |\n",
            "|    exploration_rate | 0.0587   |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 1264     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 76068    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00327  |\n",
            "|    n_updates        | 1900     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 330      |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.0346   |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 1106     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 78012    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0186   |\n",
            "|    n_updates        | 1949     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 322      |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.019    |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 1056     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 79272    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00429  |\n",
            "|    n_updates        | 1980     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 70001 | Mean Reward: -192.28 ± 69.85\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 316      |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.113    |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 1449     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80668    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000845 |\n",
            "|    n_updates        | 2015     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 317      |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.0901   |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 1012     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 82720    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00123  |\n",
            "|    n_updates        | 2066     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 326      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.0697   |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 978      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 84576    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0326   |\n",
            "|    n_updates        | 2113     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 328      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.0513   |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 869      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 86248    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00448  |\n",
            "|    n_updates        | 2155     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 326      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.0406   |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 865      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 87216    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0063   |\n",
            "|    n_updates        | 2179     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 318      |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.0258   |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 902      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 88568    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00283  |\n",
            "|    n_updates        | 2213     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 80001 | Mean Reward: -165.26 ± 39.47\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 318      |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.104    |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 850      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 90516    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00886  |\n",
            "|    n_updates        | 2261     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 316      |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.0889   |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 769      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 92028    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0012   |\n",
            "|    n_updates        | 2299     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 321      |\n",
            "|    ep_rew_mean      | -181     |\n",
            "|    exploration_rate | 0.0669   |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 729      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 94256    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 2355     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 334      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.0388   |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 729      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 97088    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00772  |\n",
            "|    n_updates        | 2426     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 346      |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.0257   |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 738      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 98412    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00308  |\n",
            "|    n_updates        | 2459     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 90001 | Mean Reward: -150.81 ± 51.09\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 366      |\n",
            "|    ep_rew_mean      | -187     |\n",
            "|    exploration_rate | 0.0848   |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 605      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 101692   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0233   |\n",
            "|    n_updates        | 2541     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 366      |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.0634   |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 646      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 104072   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0157   |\n",
            "|    n_updates        | 2600     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 382      |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.0438   |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 532      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 106244   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00189  |\n",
            "|    n_updates        | 2655     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 393      |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.026    |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 577      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 108224   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00379  |\n",
            "|    n_updates        | 2704     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 100001 | Mean Reward: -190.36 ± 55.76\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 397      |\n",
            "|    ep_rew_mean      | -186     |\n",
            "|    exploration_rate | 0.0893   |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 902      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110392   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0112   |\n",
            "|    n_updates        | 2758     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 423      |\n",
            "|    ep_rew_mean      | -183     |\n",
            "|    exploration_rate | 0.0563   |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 664      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 114392   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00721  |\n",
            "|    n_updates        | 2858     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 444      |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.0265   |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 590      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 118000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00454  |\n",
            "|    n_updates        | 2948     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 110001 | Mean Reward: -171.69 ± 42.30\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 457      |\n",
            "|    ep_rew_mean      | -182     |\n",
            "|    exploration_rate | 0.0816   |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 750      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120596   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0047   |\n",
            "|    n_updates        | 3013     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 487      |\n",
            "|    ep_rew_mean      | -180     |\n",
            "|    exploration_rate | 0.0512   |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 482      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 124596   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00281  |\n",
            "|    n_updates        | 3113     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 515      |\n",
            "|    ep_rew_mean      | -179     |\n",
            "|    exploration_rate | 0.0252   |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 551      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 128000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00103  |\n",
            "|    n_updates        | 3198     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 120001 | Mean Reward: -140.60 ± 43.80\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 539      |\n",
            "|    ep_rew_mean      | -179     |\n",
            "|    exploration_rate | 0.0614   |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 539      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 132736   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00125  |\n",
            "|    n_updates        | 3317     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 557      |\n",
            "|    ep_rew_mean      | -177     |\n",
            "|    exploration_rate | 0.0459   |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 519      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 134924   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00106  |\n",
            "|    n_updates        | 3372     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 570      |\n",
            "|    ep_rew_mean      | -174     |\n",
            "|    exploration_rate | 0.0176   |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 491      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 138924   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00541  |\n",
            "|    n_updates        | 3472     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 130001 | Mean Reward: -202.31 ± 43.47\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 588      |\n",
            "|    ep_rew_mean      | -171     |\n",
            "|    exploration_rate | 0.0598   |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 777      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 142460   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00223  |\n",
            "|    n_updates        | 3560     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 619      |\n",
            "|    ep_rew_mean      | -164     |\n",
            "|    exploration_rate | 0.0334   |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 550      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 146460   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00152  |\n",
            "|    n_updates        | 3660     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 140001 | Mean Reward: -108.82 ± 14.28\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 656      |\n",
            "|    ep_rew_mean      | -158     |\n",
            "|    exploration_rate | 0.0471   |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 526      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 154000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00483  |\n",
            "|    n_updates        | 3848     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 683      |\n",
            "|    ep_rew_mean      | -155     |\n",
            "|    exploration_rate | 0.0224   |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 493      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 158000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00083  |\n",
            "|    n_updates        | 3948     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 150001 | Mean Reward: -99.38 ± 22.43\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 704      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.0449   |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 454      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 164000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000988 |\n",
            "|    n_updates        | 4098     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 738      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.0216   |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 442      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 168000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00184  |\n",
            "|    n_updates        | 4198     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 160001 | Mean Reward: -263.42 ± 45.85\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 737      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.0648   |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 781      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 170036   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 760      |\n",
            "|    ep_rew_mean      | -149     |\n",
            "|    exploration_rate | 0.0428   |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 434      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 174036   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00478  |\n",
            "|    n_updates        | 4349     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 783      |\n",
            "|    ep_rew_mean      | -147     |\n",
            "|    exploration_rate | 0.0208   |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 430      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 178036   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0199   |\n",
            "|    n_updates        | 4449     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 170001 | Mean Reward: -73.48 ± 18.66\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 813      |\n",
            "|    ep_rew_mean      | -141     |\n",
            "|    exploration_rate | 0.0413   |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 426      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 184000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0202   |\n",
            "|    n_updates        | 4598     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 818      |\n",
            "|    ep_rew_mean      | -135     |\n",
            "|    exploration_rate | 0.0204   |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 448      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 188000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.017    |\n",
            "|    n_updates        | 4698     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 180001 | Mean Reward: -82.48 ± 14.23\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 834      |\n",
            "|    ep_rew_mean      | -128     |\n",
            "|    exploration_rate | 0.0397   |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 563      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 194000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00118  |\n",
            "|    n_updates        | 4848     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 851      |\n",
            "|    ep_rew_mean      | -122     |\n",
            "|    exploration_rate | 0.0199   |\n",
            "| time/               |          |\n",
            "|    episodes         | 480      |\n",
            "|    fps              | 507      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 198000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00152  |\n",
            "|    n_updates        | 4948     |\n",
            "----------------------------------\n",
            "LunarLander - Step: 190001 | Mean Reward: -63.73 ± 20.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_lunarlanderEnv4B128LR0.0003_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and VecNormalize stats saved!\n"
          ]
        }
      ]
    }
  ]
}