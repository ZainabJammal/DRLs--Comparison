{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnV7WHdzd4oU",
        "outputId": "9b5625a9-be99-422c-d11b-2bc925ccc4f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install box2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "871N16n9eYPa",
        "outputId": "be6c00a9-360e-4c3d-fbc2-901533c08d10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: box2d in /usr/local/lib/python3.11/dist-packages (2.3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'shimmy>=2.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL36UW_immus",
        "outputId": "8c45ab5f-284a-4bb8-ecc5-c05c95b59a24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shimmy>=2.0 in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from shimmy>=2.0) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.11/dist-packages (from shimmy>=2.0) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7-T2y7afjF9",
        "outputId": "b36d1bd4-b847-48ff-8554-fd29eea9fc70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import imageio\n",
        "import os\n",
        "import multiprocessing\n",
        "import stable_baselines3\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import DQN\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.vec_env import VecNormalize"
      ],
      "metadata": {
        "id": "4bPZSbCRecL9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, env, n_eval_episodes=10):\n",
        "    \"\"\"Evaluate the model on a given environment and return mean and std rewards.\"\"\"\n",
        "    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes)\n",
        "    return mean_reward, std_reward"
      ],
      "metadata": {
        "id": "8mNtsQtimQ4v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discretizing the Action Space"
      ],
      "metadata": {
        "id": "eKVioBihljsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiscretizedBipedalWalker(gym.Wrapper):\n",
        "    def __init__(self, env, num_bins=5):\n",
        "        super(DiscretizedBipedalWalker, self).__init__(env)\n",
        "        self.num_bins = num_bins\n",
        "\n",
        "        # Create a discrete action space with `num_bins^4` possible actions (since action space has 4 dimensions)\n",
        "        self.action_space = spaces.Discrete(num_bins**4)\n",
        "\n",
        "        # Create bin edges for each action dimension\n",
        "        self.action_bins = np.linspace(-1, 1, num_bins)  # Binning the continuous range [-1, 1]\n",
        "\n",
        "    def step(self, action):\n",
        "        # Convert discrete action into 4D continuous action\n",
        "        action_indices = np.unravel_index(action, (self.num_bins,) * 4)\n",
        "        continuous_action = np.array([self.action_bins[i] for i in action_indices], dtype=np.float32)\n",
        "        return self.env.step(continuous_action)\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        return self.env.reset(**kwargs)"
      ],
      "metadata": {
        "id": "N9QsC6z5gXJG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Def"
      ],
      "metadata": {
        "id": "GUEbowivgaWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker(n_env, bs, lr):\n",
        "    # Create the discretized environment & Wrap in vectorized env\n",
        "    env_bipedal = make_vec_env(lambda: DiscretizedBipedalWalker(gym.make(\"BipedalWalker-v3\"), num_bins=5), n_envs=n_env)\n",
        "    log = \"/content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv\"+str(n_env)+\"B\"+str(bs)+\"LR\"+str(lr)+\"/\"\n",
        "    model_b = DQN(\"MlpPolicy\", env_bipedal, learning_rate= lr, buffer_size=1000000, learning_starts=10000, batch_size= bs, tensorboard_log= log,\n",
        "                  tau=0.005, gamma=0.99, train_freq=(4, \"step\"), gradient_steps=1, target_update_interval=1000, verbose=1,\n",
        "                  exploration_fraction=0.2, exploration_final_eps=0.02, exploration_initial_eps=1.0, policy_kwargs=dict(net_arch=[256, 256]))\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        # Train the model\n",
        "        model_b.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "\n",
        "        # Evaluate the model on BipedalWalker\n",
        "        mean_reward, std_reward = evaluate_model(model_b, env_bipedal, n_eval_episodes)\n",
        "\n",
        "        # Print evaluation results for BipedalWalker\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    # Save the trained model for BipedalWalker\n",
        "    model_b.save(log)"
      ],
      "metadata": {
        "id": "wP2Y_48nf-eq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. env = 1, batch size= 64, lr = 1e-4"
      ],
      "metadata": {
        "id": "yJno5QuWjCcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_bipedalwalker(1, 64, 1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBF6F268jDuj",
        "outputId": "2e44ec29-bc4a-4c46-e251-b851da1f33ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
            "/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 833      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 3444     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 3332     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.03e+03 |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 3451     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8209     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -87.93 ± 1.37\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 930      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 604      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 11356    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00649  |\n",
            "|    n_updates        | 338      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 725      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 602      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 11798    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00567  |\n",
            "|    n_updates        | 449      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 597      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 604      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 12133    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00623  |\n",
            "|    n_updates        | 533      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 520      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 606      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 12676    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00422  |\n",
            "|    n_updates        | 668      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 474      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 609      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 13472    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00415  |\n",
            "|    n_updates        | 867      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 443      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 582      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 14353    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00673  |\n",
            "|    n_updates        | 1088     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 400      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 573      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 14576    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0051   |\n",
            "|    n_updates        | 1143     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 444      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 562      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 17967    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00345  |\n",
            "|    n_updates        | 1991     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -73.34 ± 43.61\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 418      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 504      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20070    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00228  |\n",
            "|    n_updates        | 2517     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 387      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 524      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20221    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00184  |\n",
            "|    n_updates        | 2555     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 361      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 575      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20432    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00318  |\n",
            "|    n_updates        | 2607     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 369      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 621      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 22332    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00343  |\n",
            "|    n_updates        | 3082     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 348      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 621      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 22577    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00359  |\n",
            "|    n_updates        | 3144     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 388      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 570      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 26518    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00205  |\n",
            "|    n_updates        | 4129     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -104.34 ± 1.63\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 416      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 588      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 31191    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 5297     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 440      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 579      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 34562    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00196  |\n",
            "|    n_updates        | 6140     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 425      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 585      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 35213    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00192  |\n",
            "|    n_updates        | 6303     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 446      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 594      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 38598    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00173  |\n",
            "|    n_updates        | 7149     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -83.73 ± 53.07\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 429      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 586      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40158    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00407  |\n",
            "|    n_updates        | 7539     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 429      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 627      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 41933    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00213  |\n",
            "|    n_updates        | 7983     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 447      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 583      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 45268    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00102  |\n",
            "|    n_updates        | 8816     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 463      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 592      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 48646    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00168  |\n",
            "|    n_updates        | 9661     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 448      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 594      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 49000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0015   |\n",
            "|    n_updates        | 9749     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -23.77 ± 11.36\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 433      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 627      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 51749    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00143  |\n",
            "|    n_updates        | 10437    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 401      |\n",
            "|    ep_rew_mean      | -99.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 577      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 53494    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0016   |\n",
            "|    n_updates        | 10873    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 393      |\n",
            "|    ep_rew_mean      | -97.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 599      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 55640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00196  |\n",
            "|    n_updates        | 11409    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 395      |\n",
            "|    ep_rew_mean      | -97.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 602      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 56253    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00151  |\n",
            "|    n_updates        | 11563    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 394      |\n",
            "|    ep_rew_mean      | -97.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 603      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 56459    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00183  |\n",
            "|    n_updates        | 11614    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -88.62 ± 39.56\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 421      |\n",
            "|    ep_rew_mean      | -95.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 568      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60040    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00215  |\n",
            "|    n_updates        | 12509    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 431      |\n",
            "|    ep_rew_mean      | -94.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 644      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 61836    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00269  |\n",
            "|    n_updates        | 12958    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 425      |\n",
            "|    ep_rew_mean      | -94.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 647      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 62133    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00198  |\n",
            "|    n_updates        | 13033    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 436      |\n",
            "|    ep_rew_mean      | -94.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 653      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 63389    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00149  |\n",
            "|    n_updates        | 13347    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 420      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 620      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 65250    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00161  |\n",
            "|    n_updates        | 13812    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 432      |\n",
            "|    ep_rew_mean      | -93.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 619      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 67086    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00179  |\n",
            "|    n_updates        | 14271    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 436      |\n",
            "|    ep_rew_mean      | -93.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 620      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 67542    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00209  |\n",
            "|    n_updates        | 14385    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 436      |\n",
            "|    ep_rew_mean      | -93.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 620      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 67828    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00181  |\n",
            "|    n_updates        | 14456    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 436      |\n",
            "|    ep_rew_mean      | -93.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 625      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 69679    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00153  |\n",
            "|    n_updates        | 14919    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -53.93 ± 44.94\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 437      |\n",
            "|    ep_rew_mean      | -93      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 621      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70076    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00178  |\n",
            "|    n_updates        | 15018    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 416      |\n",
            "|    ep_rew_mean      | -93.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 640      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 71923    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00206  |\n",
            "|    n_updates        | 15480    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 401      |\n",
            "|    ep_rew_mean      | -92.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 628      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 73882    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00183  |\n",
            "|    n_updates        | 15970    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 386      |\n",
            "|    ep_rew_mean      | -91.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 625      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 75701    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00184  |\n",
            "|    n_updates        | 16425    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 398      |\n",
            "|    ep_rew_mean      | -90.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 599      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 77595    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00149  |\n",
            "|    n_updates        | 16898    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -100.48 ± 2.75\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 398      |\n",
            "|    ep_rew_mean      | -90.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 623      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 81667    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 17916    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 414      |\n",
            "|    ep_rew_mean      | -91      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 582      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 83633    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00228  |\n",
            "|    n_updates        | 18408    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 400      |\n",
            "|    ep_rew_mean      | -92      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 569      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 84031    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000983 |\n",
            "|    n_updates        | 18507    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 385      |\n",
            "|    ep_rew_mean      | -92.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 587      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 85806    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00145  |\n",
            "|    n_updates        | 18951    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 369      |\n",
            "|    ep_rew_mean      | -93.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 594      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 87624    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00115  |\n",
            "|    n_updates        | 19405    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 368      |\n",
            "|    ep_rew_mean      | -93.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 596      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 87917    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 19479    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 353      |\n",
            "|    ep_rew_mean      | -93.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 597      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 88153    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00157  |\n",
            "|    n_updates        | 19538    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 338      |\n",
            "|    ep_rew_mean      | -94.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 598      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 88375    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0019   |\n",
            "|    n_updates        | 19593    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 322      |\n",
            "|    ep_rew_mean      | -95.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 601      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 88934    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00135  |\n",
            "|    n_updates        | 19733    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 320      |\n",
            "|    ep_rew_mean      | -95.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 601      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 89314    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00192  |\n",
            "|    n_updates        | 19828    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 320      |\n",
            "|    ep_rew_mean      | -95.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 601      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 89516    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00308  |\n",
            "|    n_updates        | 19878    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -98.87 ± 0.17\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 290      |\n",
            "|    ep_rew_mean      | -96.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 462      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 90291    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00133  |\n",
            "|    n_updates        | 20072    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 290      |\n",
            "|    ep_rew_mean      | -96.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 549      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 92135    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00172  |\n",
            "|    n_updates        | 20533    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 336      |\n",
            "|    ep_rew_mean      | -93.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 600      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 97011    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00165  |\n",
            "|    n_updates        | 21752    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 327      |\n",
            "|    ep_rew_mean      | -93.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 596      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 97336    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00187  |\n",
            "|    n_updates        | 21833    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 311      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 587      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 97607    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00136  |\n",
            "|    n_updates        | 21901    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 296      |\n",
            "|    ep_rew_mean      | -95      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 578      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 97973    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000669 |\n",
            "|    n_updates        | 21993    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 310      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 590      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 99772    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00142  |\n",
            "|    n_updates        | 22442    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: -110.09 ± 0.55\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 325      |\n",
            "|    ep_rew_mean      | -93.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 602      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 101712   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00164  |\n",
            "|    n_updates        | 22927    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 324      |\n",
            "|    ep_rew_mean      | -93.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 601      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 103530   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000884 |\n",
            "|    n_updates        | 23382    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 324      |\n",
            "|    ep_rew_mean      | -93.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 598      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 103816   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00145  |\n",
            "|    n_updates        | 23453    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 339      |\n",
            "|    ep_rew_mean      | -92.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 572      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 107177   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00102  |\n",
            "|    n_updates        | 24294    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -109.88 ± 11.72\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 338      |\n",
            "|    ep_rew_mean      | -92.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 460      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110136   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00159  |\n",
            "|    n_updates        | 25033    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 338      |\n",
            "|    ep_rew_mean      | -92.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 529      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 111967   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00102  |\n",
            "|    n_updates        | 25491    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 322      |\n",
            "|    ep_rew_mean      | -93.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 536      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 112251   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000952 |\n",
            "|    n_updates        | 25562    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 322      |\n",
            "|    ep_rew_mean      | -93.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 575      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 115588   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00119  |\n",
            "|    n_updates        | 26396    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 305      |\n",
            "|    ep_rew_mean      | -92.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 575      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 115863   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00228  |\n",
            "|    n_updates        | 26465    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 320      |\n",
            "|    ep_rew_mean      | -91.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 566      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 117693   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00089  |\n",
            "|    n_updates        | 26923    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 305      |\n",
            "|    ep_rew_mean      | -92.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 564      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 117991   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0016   |\n",
            "|    n_updates        | 26997    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 290      |\n",
            "|    ep_rew_mean      | -93.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 566      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 118317   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00191  |\n",
            "|    n_updates        | 27079    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -2.63 ± 2.10\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 306      |\n",
            "|    ep_rew_mean      | -92.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 582      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120324   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00146  |\n",
            "|    n_updates        | 27580    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 306      |\n",
            "|    ep_rew_mean      | -93.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 561      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 120581   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00131  |\n",
            "|    n_updates        | 27645    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 307      |\n",
            "|    ep_rew_mean      | -93      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 559      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 120837   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00222  |\n",
            "|    n_updates        | 27709    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 319      |\n",
            "|    ep_rew_mean      | -92      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 575      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 122621   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00347  |\n",
            "|    n_updates        | 28155    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 319      |\n",
            "|    ep_rew_mean      | -91.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 576      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 122964   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000615 |\n",
            "|    n_updates        | 28240    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 320      |\n",
            "|    ep_rew_mean      | -92      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 579      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 123272   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00116  |\n",
            "|    n_updates        | 28317    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 334      |\n",
            "|    ep_rew_mean      | -91.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 589      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 125045   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00222  |\n",
            "|    n_updates        | 28761    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 319      |\n",
            "|    ep_rew_mean      | -92.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 592      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 125355   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00105  |\n",
            "|    n_updates        | 28838    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -83.45 ± 39.29\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 304      |\n",
            "|    ep_rew_mean      | -93.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 557      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 130078   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00232  |\n",
            "|    n_updates        | 30019    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 304      |\n",
            "|    ep_rew_mean      | -93.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 587      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 130374   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00115  |\n",
            "|    n_updates        | 30093    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 304      |\n",
            "|    ep_rew_mean      | -93.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 607      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 130671   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00139  |\n",
            "|    n_updates        | 30167    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 304      |\n",
            "|    ep_rew_mean      | -93.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 623      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 131049   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00101  |\n",
            "|    n_updates        | 30262    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 306      |\n",
            "|    ep_rew_mean      | -93.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 552      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 133007   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 30751    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 292      |\n",
            "|    ep_rew_mean      | -94.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 556      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 133474   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00124  |\n",
            "|    n_updates        | 30868    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 292      |\n",
            "|    ep_rew_mean      | -94.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 578      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 135285   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00144  |\n",
            "|    n_updates        | 31321    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 293      |\n",
            "|    ep_rew_mean      | -94.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 582      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 135637   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00117  |\n",
            "|    n_updates        | 31409    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 293      |\n",
            "|    ep_rew_mean      | -94.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 573      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 138976   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00247  |\n",
            "|    n_updates        | 32243    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 276      |\n",
            "|    ep_rew_mean      | -95.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 574      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 139240   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00127  |\n",
            "|    n_updates        | 32309    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -20.76 ± 39.27\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 278      |\n",
            "|    ep_rew_mean      | -95.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 527      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 142002   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00184  |\n",
            "|    n_updates        | 33000    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 309      |\n",
            "|    ep_rew_mean      | -94      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 574      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 145418   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.5      |\n",
            "|    n_updates        | 33854    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 280      |\n",
            "|    ep_rew_mean      | -95.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 577      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 145846   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00338  |\n",
            "|    n_updates        | 33961    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 312      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 572      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 149243   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00174  |\n",
            "|    n_updates        | 34810    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 296      |\n",
            "|    ep_rew_mean      | -95.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 572      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 149557   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 34889    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 296      |\n",
            "|    ep_rew_mean      | -95.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 574      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 149847   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00164  |\n",
            "|    n_updates        | 34961    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: -47.54 ± 44.99\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 295      |\n",
            "|    ep_rew_mean      | -95.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 566      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150153   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000895 |\n",
            "|    n_updates        | 35038    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 294      |\n",
            "|    ep_rew_mean      | -95.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 543      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 151986   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000646 |\n",
            "|    n_updates        | 35496    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 303      |\n",
            "|    ep_rew_mean      | -95.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 562      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 153140   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00188  |\n",
            "|    n_updates        | 35784    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 319      |\n",
            "|    ep_rew_mean      | -95      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 588      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 154940   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00103  |\n",
            "|    n_updates        | 36234    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 335      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 600      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 158338   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00158  |\n",
            "|    n_updates        | 37084    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -106.39 ± 14.03\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 365      |\n",
            "|    ep_rew_mean      | -92.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 633      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 161770   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000845 |\n",
            "|    n_updates        | 37942    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 366      |\n",
            "|    ep_rew_mean      | -92.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 626      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 162119   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000983 |\n",
            "|    n_updates        | 38029    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 366      |\n",
            "|    ep_rew_mean      | -92.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 627      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 163930   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00245  |\n",
            "|    n_updates        | 38482    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 397      |\n",
            "|    ep_rew_mean      | -91.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 598      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 167295   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00165  |\n",
            "|    n_updates        | 39323    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 386      |\n",
            "|    ep_rew_mean      | -91.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 599      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 169572   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00108  |\n",
            "|    n_updates        | 39892    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -54.81 ± 46.39\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 386      |\n",
            "|    ep_rew_mean      | -91.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 576      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 170086   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00113  |\n",
            "|    n_updates        | 40021    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 386      |\n",
            "|    ep_rew_mean      | -91.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 600      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 170373   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 40093    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 385      |\n",
            "|    ep_rew_mean      | -91.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 600      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 170685   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000981 |\n",
            "|    n_updates        | 40171    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 384      |\n",
            "|    ep_rew_mean      | -90.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 598      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 172529   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000913 |\n",
            "|    n_updates        | 40632    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 384      |\n",
            "|    ep_rew_mean      | -91      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 608      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 172973   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0023   |\n",
            "|    n_updates        | 40743    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 370      |\n",
            "|    ep_rew_mean      | -92      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 609      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 173362   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000885 |\n",
            "|    n_updates        | 40840    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 372      |\n",
            "|    ep_rew_mean      | -92.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 607      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 173874   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000883 |\n",
            "|    n_updates        | 40968    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 357      |\n",
            "|    ep_rew_mean      | -93.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 582      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 175716   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000856 |\n",
            "|    n_updates        | 41428    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -73.79 ± 45.91\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 403      |\n",
            "|    ep_rew_mean      | -90.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 513      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 181600   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00121  |\n",
            "|    n_updates        | 42899    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 432      |\n",
            "|    ep_rew_mean      | -88.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 585      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 186526   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00166  |\n",
            "|    n_updates        | 44131    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 403      |\n",
            "|    ep_rew_mean      | -90      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 580      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 187075   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 44268    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 417      |\n",
            "|    ep_rew_mean      | -89.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 480      |\n",
            "|    fps              | 575      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 188861   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00217  |\n",
            "|    n_updates        | 44715    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: -72.92 ± 46.02\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 401      |\n",
            "|    ep_rew_mean      | -90.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 484      |\n",
            "|    fps              | 554      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 191852   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00104  |\n",
            "|    n_updates        | 45462    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 414      |\n",
            "|    ep_rew_mean      | -90.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 488      |\n",
            "|    fps              | 529      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 193435   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000952 |\n",
            "|    n_updates        | 45858    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 445      |\n",
            "|    ep_rew_mean      | -88.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 492      |\n",
            "|    fps              | 554      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 196789   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000606 |\n",
            "|    n_updates        | 46697    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 461      |\n",
            "|    ep_rew_mean      | -87.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 496      |\n",
            "|    fps              | 552      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 198636   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00376  |\n",
            "|    n_updates        | 47158    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 450      |\n",
            "|    ep_rew_mean      | -88.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 500      |\n",
            "|    fps              | 549      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 199418   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00354  |\n",
            "|    n_updates        | 47354    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: -111.33 ± 2.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0001_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. env = 1, batch size= 64, lr = 3e-4"
      ],
      "metadata": {
        "id": "GxS9te-1ntYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_bipedalwalker(1, 64, 3e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duY2_XnXjTJq",
        "outputId": "be94f788-5856-4ae8-a15b-6ef5efaaf913"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 829      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 3402     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 3316     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 830      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 3416     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 6638     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 830      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 3433     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 9956     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -105.17 ± 16.03\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 672      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 572      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 10796    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00272  |\n",
            "|    n_updates        | 198      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 576      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 565      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 11562    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00375  |\n",
            "|    n_updates        | 390      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 560      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 522      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 13484    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00253  |\n",
            "|    n_updates        | 870      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 504      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 533      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 14152    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00283  |\n",
            "|    n_updates        | 1037     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 595      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 561      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 19081    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00113  |\n",
            "|    n_updates        | 2270     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -114.82 ± 1.23\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 540      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 565      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20279    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00204  |\n",
            "|    n_updates        | 2569     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 531      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 578      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 22077    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00153  |\n",
            "|    n_updates        | 3019     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 488      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 575      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 22331    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00161  |\n",
            "|    n_updates        | 3082     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 485      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 593      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 24129    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00243  |\n",
            "|    n_updates        | 3532     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 481      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 574      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 25870    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00283  |\n",
            "|    n_updates        | 3967     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 500      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 576      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 28867    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000768 |\n",
            "|    n_updates        | 4716     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -105.40 ± 0.96\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 499      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 615      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 31924    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00231  |\n",
            "|    n_updates        | 5480     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 472      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 579      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 32185    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00382  |\n",
            "|    n_updates        | 5546     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 494      |\n",
            "|    ep_rew_mean      | -99.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 569      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 35547    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00218  |\n",
            "|    n_updates        | 6386     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 518      |\n",
            "|    ep_rew_mean      | -98.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 581      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 39316    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 7328     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -110.50 ± 1.42\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 539      |\n",
            "|    ep_rew_mean      | -96.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 626      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 43200    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00158  |\n",
            "|    n_updates        | 8299     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 519      |\n",
            "|    ep_rew_mean      | -98      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 630      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 43812    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00134  |\n",
            "|    n_updates        | 8452     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 514      |\n",
            "|    ep_rew_mean      | -99.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 629      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 45432    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0316   |\n",
            "|    n_updates        | 8857     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 511      |\n",
            "|    ep_rew_mean      | -98.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 599      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 47221    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00301  |\n",
            "|    n_updates        | 9305     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 508      |\n",
            "|    ep_rew_mean      | -98.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 604      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 49012    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.39     |\n",
            "|    n_updates        | 9752     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -106.18 ± 3.36\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 506      |\n",
            "|    ep_rew_mean      | -97.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 624      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 51772    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00189  |\n",
            "|    n_updates        | 10442    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 503      |\n",
            "|    ep_rew_mean      | -97.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 570      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 53542    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.52     |\n",
            "|    n_updates        | 10885    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 488      |\n",
            "|    ep_rew_mean      | -96.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 581      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 55307    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00101  |\n",
            "|    n_updates        | 11326    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 460      |\n",
            "|    ep_rew_mean      | -96.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 586      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 55881    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 11470    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 433      |\n",
            "|    ep_rew_mean      | -97.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 593      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 56510    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00157  |\n",
            "|    n_updates        | 11627    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 430      |\n",
            "|    ep_rew_mean      | -97.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 598      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 57007    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00136  |\n",
            "|    n_updates        | 11751    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -29.81 ± 50.73\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 456      |\n",
            "|    ep_rew_mean      | -94.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 602      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 61600    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00718  |\n",
            "|    n_updates        | 12899    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 455      |\n",
            "|    ep_rew_mean      | -93.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 598      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 63421    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00114  |\n",
            "|    n_updates        | 13355    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 482      |\n",
            "|    ep_rew_mean      | -92.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 596      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 66780    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00184  |\n",
            "|    n_updates        | 14194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 436      |\n",
            "|    ep_rew_mean      | -93.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 595      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 67079    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000697 |\n",
            "|    n_updates        | 14269    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 441      |\n",
            "|    ep_rew_mean      | -93.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 600      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 67955    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0137   |\n",
            "|    n_updates        | 14488    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -41.93 ± 45.28\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 441      |\n",
            "|    ep_rew_mean      | -93.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 583      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70175    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 15043    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 442      |\n",
            "|    ep_rew_mean      | -93.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 591      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70457    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00463  |\n",
            "|    n_updates        | 15114    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 442      |\n",
            "|    ep_rew_mean      | -93      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 623      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 72248    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 3.08     |\n",
            "|    n_updates        | 15561    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 437      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 633      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 73505    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00172  |\n",
            "|    n_updates        | 15876    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 471      |\n",
            "|    ep_rew_mean      | -91.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 608      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 79905    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00125  |\n",
            "|    n_updates        | 17476    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -101.46 ± 0.41\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 455      |\n",
            "|    ep_rew_mean      | -91.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 577      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80348    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0133   |\n",
            "|    n_updates        | 17586    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 456      |\n",
            "|    ep_rew_mean      | -91.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 521      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 80659    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00326  |\n",
            "|    n_updates        | 17664    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 425      |\n",
            "|    ep_rew_mean      | -92.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 493      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 80945    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00154  |\n",
            "|    n_updates        | 17736    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 405      |\n",
            "|    ep_rew_mean      | -93.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 469      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 82701    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0088   |\n",
            "|    n_updates        | 18175    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 402      |\n",
            "|    ep_rew_mean      | -92.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 481      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 86033    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0113   |\n",
            "|    n_updates        | 19008    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 414      |\n",
            "|    ep_rew_mean      | -91.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 490      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 87866    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00114  |\n",
            "|    n_updates        | 19466    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 404      |\n",
            "|    ep_rew_mean      | -90.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 497      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 88472    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00467  |\n",
            "|    n_updates        | 19617    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -112.26 ± 9.86\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 435      |\n",
            "|    ep_rew_mean      | -89.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 587      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 94858    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00156  |\n",
            "|    n_updates        | 21214    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 450      |\n",
            "|    ep_rew_mean      | -88.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 587      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 98195    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 22048    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: -104.20 ± 0.66\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 453      |\n",
            "|    ep_rew_mean      | -88      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 493      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 101600   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00146  |\n",
            "|    n_updates        | 22899    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 484      |\n",
            "|    ep_rew_mean      | -86.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 566      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 106475   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000947 |\n",
            "|    n_updates        | 24118    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 470      |\n",
            "|    ep_rew_mean      | -86.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 569      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 106836   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0012   |\n",
            "|    n_updates        | 24208    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 483      |\n",
            "|    ep_rew_mean      | -85.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 561      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 108695   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00123  |\n",
            "|    n_updates        | 24673    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -105.12 ± 0.69\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 525      |\n",
            "|    ep_rew_mean      | -82.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 591      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 114873   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00177  |\n",
            "|    n_updates        | 26218    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 539      |\n",
            "|    ep_rew_mean      | -81.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 600      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 116761   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.146    |\n",
            "|    n_updates        | 26690    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -100.87 ± 12.11\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 539      |\n",
            "|    ep_rew_mean      | -81.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 518      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120133   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0006   |\n",
            "|    n_updates        | 27533    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 538      |\n",
            "|    ep_rew_mean      | -81.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 513      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 121935   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00133  |\n",
            "|    n_updates        | 27983    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 507      |\n",
            "|    ep_rew_mean      | -83.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 520      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 122158   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00136  |\n",
            "|    n_updates        | 28039    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 538      |\n",
            "|    ep_rew_mean      | -82      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 576      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 125514   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000778 |\n",
            "|    n_updates        | 28878    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 531      |\n",
            "|    ep_rew_mean      | -81.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 578      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 125749   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000643 |\n",
            "|    n_updates        | 28937    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 546      |\n",
            "|    ep_rew_mean      | -81.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 571      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 129056   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0016   |\n",
            "|    n_updates        | 29763    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -110.15 ± 0.17\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 546      |\n",
            "|    ep_rew_mean      | -81.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 609      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 130219   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00116  |\n",
            "|    n_updates        | 30054    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 531      |\n",
            "|    ep_rew_mean      | -82.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 639      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 130462   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00106  |\n",
            "|    n_updates        | 30115    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 552      |\n",
            "|    ep_rew_mean      | -80.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 641      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 133811   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.48     |\n",
            "|    n_updates        | 30952    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 491      |\n",
            "|    ep_rew_mean      | -83.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 634      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 134186   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000966 |\n",
            "|    n_updates        | 31046    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 506      |\n",
            "|    ep_rew_mean      | -82.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 603      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 135951   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00509  |\n",
            "|    n_updates        | 31487    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 505      |\n",
            "|    ep_rew_mean      | -82.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 603      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 136217   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00113  |\n",
            "|    n_updates        | 31554    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 539      |\n",
            "|    ep_rew_mean      | -82      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 605      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 139855   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0101   |\n",
            "|    n_updates        | 32463    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -100.58 ± 2.33\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 524      |\n",
            "|    ep_rew_mean      | -82.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 593      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140256   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00143  |\n",
            "|    n_updates        | 32563    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 493      |\n",
            "|    ep_rew_mean      | -84.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 609      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140527   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 32631    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 508      |\n",
            "|    ep_rew_mean      | -84.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 570      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 143870   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0055   |\n",
            "|    n_updates        | 33467    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 520      |\n",
            "|    ep_rew_mean      | -83.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 595      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 145663   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00147  |\n",
            "|    n_updates        | 33915    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 477      |\n",
            "|    ep_rew_mean      | -85.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 598      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 146196   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00154  |\n",
            "|    n_updates        | 34048    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 462      |\n",
            "|    ep_rew_mean      | -86.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 604      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 148019   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 34504    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 445      |\n",
            "|    ep_rew_mean      | -87.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 598      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 148374   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.53     |\n",
            "|    n_updates        | 34593    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: -102.40 ± 2.20\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 414      |\n",
            "|    ep_rew_mean      | -89.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 638      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 151777   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00246  |\n",
            "|    n_updates        | 35444    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 429      |\n",
            "|    ep_rew_mean      | -89.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 639      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 153602   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00189  |\n",
            "|    n_updates        | 35900    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 426      |\n",
            "|    ep_rew_mean      | -90.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 619      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 155180   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0167   |\n",
            "|    n_updates        | 36294    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 379      |\n",
            "|    ep_rew_mean      | -93      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 609      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 155359   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000688 |\n",
            "|    n_updates        | 36339    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 378      |\n",
            "|    ep_rew_mean      | -93.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 591      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 157174   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00798  |\n",
            "|    n_updates        | 36793    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 367      |\n",
            "|    ep_rew_mean      | -94.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 593      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 159363   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00179  |\n",
            "|    n_updates        | 37340    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -98.24 ± 16.03\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 368      |\n",
            "|    ep_rew_mean      | -94.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 529      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 161808   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00151  |\n",
            "|    n_updates        | 37951    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 368      |\n",
            "|    ep_rew_mean      | -95.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 534      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 162018   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00289  |\n",
            "|    n_updates        | 38004    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 352      |\n",
            "|    ep_rew_mean      | -95.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 576      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 163840   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00212  |\n",
            "|    n_updates        | 38459    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 368      |\n",
            "|    ep_rew_mean      | -95      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 589      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 165665   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00199  |\n",
            "|    n_updates        | 38916    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 354      |\n",
            "|    ep_rew_mean      | -95.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 600      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 167533   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0796   |\n",
            "|    n_updates        | 39383    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -93.71 ± 26.49\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 370      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 502      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 170065   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0013   |\n",
            "|    n_updates        | 40016    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 401      |\n",
            "|    ep_rew_mean      | -92.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 615      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 173423   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00201  |\n",
            "|    n_updates        | 40855    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 371      |\n",
            "|    ep_rew_mean      | -94      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 611      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 173702   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00223  |\n",
            "|    n_updates        | 40925    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 416      |\n",
            "|    ep_rew_mean      | -91.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 591      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 178602   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000969 |\n",
            "|    n_updates        | 42150    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 402      |\n",
            "|    ep_rew_mean      | -93      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 592      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 178966   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00093  |\n",
            "|    n_updates        | 42241    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 403      |\n",
            "|    ep_rew_mean      | -93.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 592      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 179283   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00233  |\n",
            "|    n_updates        | 42320    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -92.00 ± 26.45\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 374      |\n",
            "|    ep_rew_mean      | -94.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 550      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 180157   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000833 |\n",
            "|    n_updates        | 42539    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 407      |\n",
            "|    ep_rew_mean      | -92.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 572      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 183633   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000942 |\n",
            "|    n_updates        | 43408    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 408      |\n",
            "|    ep_rew_mean      | -92.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 575      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 184049   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00282  |\n",
            "|    n_updates        | 43512    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 393      |\n",
            "|    ep_rew_mean      | -93.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 584      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 185913   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00139  |\n",
            "|    n_updates        | 43978    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 394      |\n",
            "|    ep_rew_mean      | -93.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 575      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 187816   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00154  |\n",
            "|    n_updates        | 44453    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 407      |\n",
            "|    ep_rew_mean      | -93      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 577      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 189616   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00116  |\n",
            "|    n_updates        | 44903    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 391      |\n",
            "|    ep_rew_mean      | -93.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 577      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 189863   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00107  |\n",
            "|    n_updates        | 44965    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: -111.97 ± 3.13\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 406      |\n",
            "|    ep_rew_mean      | -93.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 608      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 191727   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00121  |\n",
            "|    n_updates        | 45431    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 391      |\n",
            "|    ep_rew_mean      | -93.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 606      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 192010   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000844 |\n",
            "|    n_updates        | 45502    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 375      |\n",
            "|    ep_rew_mean      | -94.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 601      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 192304   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0014   |\n",
            "|    n_updates        | 45575    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 377      |\n",
            "|    ep_rew_mean      | -93.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 589      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 194062   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.018    |\n",
            "|    n_updates        | 46015    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 409      |\n",
            "|    ep_rew_mean      | -92      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 580      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 197464   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0034   |\n",
            "|    n_updates        | 46865    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 394      |\n",
            "|    ep_rew_mean      | -92.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 579      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 197765   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0015   |\n",
            "|    n_updates        | 46941    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 376      |\n",
            "|    ep_rew_mean      | -92.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 581      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 198134   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00075  |\n",
            "|    n_updates        | 47033    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: -8.61 ± 5.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B64LR0.0003_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. env = 1, batch size= 128, lr = 1e-4"
      ],
      "metadata": {
        "id": "Ys3TDgoonzTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_bipedalwalker(1, 128, 1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBERjYtZn2s-",
        "outputId": "8795f862-713f-4dbc-b371-c2dae62a162e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 834      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 3402     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 3334     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 618      |\n",
            "|    ep_rew_mean      | -120     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 3385     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 4942     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 562      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 3430     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 6747     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -109.46 ± 0.46\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 534      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 467      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10120    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0149   |\n",
            "|    n_updates        | 29       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 439      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 446      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10350    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0132   |\n",
            "|    n_updates        | 87       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 380      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 407      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 10691    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00986  |\n",
            "|    n_updates        | 172      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 341      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 403      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 11105    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00742  |\n",
            "|    n_updates        | 276      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 309      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 421      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 11462    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0052   |\n",
            "|    n_updates        | 365      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 291      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 433      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 12027    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00673  |\n",
            "|    n_updates        | 506      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 267      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 437      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 12253    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00688  |\n",
            "|    n_updates        | 563      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 289      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 471      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 14300    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00468  |\n",
            "|    n_updates        | 1074     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 273      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 475      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 14665    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.781    |\n",
            "|    n_updates        | 1166     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 260      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 479      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 15103    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00595  |\n",
            "|    n_updates        | 1275     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 304      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 478      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 18574    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00368  |\n",
            "|    n_updates        | 2143     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -84.69 ± 38.36\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 292      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 456      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20162    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 2540     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 280      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 465      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 20563    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00295  |\n",
            "|    n_updates        | 2640     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 292      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 496      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 22537    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 3134     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 317      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 486      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 25491    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00288  |\n",
            "|    n_updates        | 3872     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 324      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 488      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 27270    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00433  |\n",
            "|    n_updates        | 4317     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 338      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 492      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 29672    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00243  |\n",
            "|    n_updates        | 4917     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -103.83 ± 0.84\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 326      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 469      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30208    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00215  |\n",
            "|    n_updates        | 5051     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 358      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 525      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 34388    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00254  |\n",
            "|    n_updates        | 6096     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 363      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 501      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 36219    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.767    |\n",
            "|    n_updates        | 6554     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 382      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 507      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 39550    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0039   |\n",
            "|    n_updates        | 7387     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -96.73 ± 2.50\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 385      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 441      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 41734    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00104  |\n",
            "|    n_updates        | 7933     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 400      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 479      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 46617    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00221  |\n",
            "|    n_updates        | 9154     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 387      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 475      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 46865    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0035   |\n",
            "|    n_updates        | 9216     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -97.43 ± 24.61\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 387      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 492      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50122    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00148  |\n",
            "|    n_updates        | 10030    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 387      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 498      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 51951    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00179  |\n",
            "|    n_updates        | 10487    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 419      |\n",
            "|    ep_rew_mean      | -98      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 479      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 55352    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00159  |\n",
            "|    n_updates        | 11337    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 427      |\n",
            "|    ep_rew_mean      | -97.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 487      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 56568    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00364  |\n",
            "|    n_updates        | 11641    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 441      |\n",
            "|    ep_rew_mean      | -96.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 477      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 58362    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0015   |\n",
            "|    n_updates        | 12090    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -33.29 ± 41.81\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 443      |\n",
            "|    ep_rew_mean      | -96.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 378      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60302    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00271  |\n",
            "|    n_updates        | 12575    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 471      |\n",
            "|    ep_rew_mean      | -95.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 500      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 63687    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00183  |\n",
            "|    n_updates        | 13421    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 519      |\n",
            "|    ep_rew_mean      | -92.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 490      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 68640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00143  |\n",
            "|    n_updates        | 14659    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 502      |\n",
            "|    ep_rew_mean      | -91.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 490      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 68986    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00462  |\n",
            "|    n_updates        | 14746    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -48.65 ± 40.33\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 519      |\n",
            "|    ep_rew_mean      | -90.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 517      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 71990    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00135  |\n",
            "|    n_updates        | 15497    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 533      |\n",
            "|    ep_rew_mean      | -89.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 510      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 73858    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0016   |\n",
            "|    n_updates        | 15964    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 533      |\n",
            "|    ep_rew_mean      | -88.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 494      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 77294    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00254  |\n",
            "|    n_updates        | 16823    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 531      |\n",
            "|    ep_rew_mean      | -87.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 495      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 77602    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00124  |\n",
            "|    n_updates        | 16900    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 531      |\n",
            "|    ep_rew_mean      | -87.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 497      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 78010    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00181  |\n",
            "|    n_updates        | 17002    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -65.53 ± 42.65\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 529      |\n",
            "|    ep_rew_mean      | -86.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 442      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80044    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00188  |\n",
            "|    n_updates        | 17510    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 533      |\n",
            "|    ep_rew_mean      | -85.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 505      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 83390    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00334  |\n",
            "|    n_updates        | 18347    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 548      |\n",
            "|    ep_rew_mean      | -84.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 490      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 86749    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00147  |\n",
            "|    n_updates        | 19187    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 542      |\n",
            "|    ep_rew_mean      | -85.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 496      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 88452    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00116  |\n",
            "|    n_updates        | 19612    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -91.96 ± 20.97\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 587      |\n",
            "|    ep_rew_mean      | -82.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 492      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 94800    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.78     |\n",
            "|    n_updates        | 21199    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 579      |\n",
            "|    ep_rew_mean      | -82      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 485      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 98187    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.77     |\n",
            "|    n_updates        | 22046    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: -103.46 ± 0.13\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 597      |\n",
            "|    ep_rew_mean      | -81.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 459      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 102043   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00294  |\n",
            "|    n_updates        | 23010    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 567      |\n",
            "|    ep_rew_mean      | -82.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 463      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 102339   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00151  |\n",
            "|    n_updates        | 23084    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 552      |\n",
            "|    ep_rew_mean      | -83.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 466      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 102666   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00142  |\n",
            "|    n_updates        | 23166    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 521      |\n",
            "|    ep_rew_mean      | -84.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 477      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 104451   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00143  |\n",
            "|    n_updates        | 23612    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 552      |\n",
            "|    ep_rew_mean      | -83.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 477      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 107775   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00285  |\n",
            "|    n_updates        | 24443    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 552      |\n",
            "|    ep_rew_mean      | -82.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 481      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 109589   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00128  |\n",
            "|    n_updates        | 24897    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -24.78 ± 42.07\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 537      |\n",
            "|    ep_rew_mean      | -83.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 475      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110141   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.759    |\n",
            "|    n_updates        | 25035    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 552      |\n",
            "|    ep_rew_mean      | -82.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 488      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 115055   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00474  |\n",
            "|    n_updates        | 26263    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 543      |\n",
            "|    ep_rew_mean      | -82.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 490      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 115365   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00408  |\n",
            "|    n_updates        | 26341    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 563      |\n",
            "|    ep_rew_mean      | -82.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 495      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 119136   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00158  |\n",
            "|    n_updates        | 27283    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -100.09 ± 1.27\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 562      |\n",
            "|    ep_rew_mean      | -82.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 461      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120424   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00222  |\n",
            "|    n_updates        | 27605    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 578      |\n",
            "|    ep_rew_mean      | -81      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 484      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 125333   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00215  |\n",
            "|    n_updates        | 28833    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 562      |\n",
            "|    ep_rew_mean      | -81.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 484      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 128707   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00164  |\n",
            "|    n_updates        | 29676    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -98.46 ± 33.64\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 580      |\n",
            "|    ep_rew_mean      | -81.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 485      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 132124   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0038   |\n",
            "|    n_updates        | 30530    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 589      |\n",
            "|    ep_rew_mean      | -82.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 497      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 135171   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00148  |\n",
            "|    n_updates        | 31292    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 604      |\n",
            "|    ep_rew_mean      | -81.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 488      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 138531   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.802    |\n",
            "|    n_updates        | 32132    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 573      |\n",
            "|    ep_rew_mean      | -84      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 489      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 138896   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00173  |\n",
            "|    n_updates        | 32223    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 574      |\n",
            "|    ep_rew_mean      | -84.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 490      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 139246   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000714 |\n",
            "|    n_updates        | 32311    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 574      |\n",
            "|    ep_rew_mean      | -84.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 491      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 139629   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00497  |\n",
            "|    n_updates        | 32407    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -29.57 ± 46.94\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 574      |\n",
            "|    ep_rew_mean      | -84.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 507      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 141814   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00158  |\n",
            "|    n_updates        | 32953    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 575      |\n",
            "|    ep_rew_mean      | -84.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 479      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 145229   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.769    |\n",
            "|    n_updates        | 33807    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 575      |\n",
            "|    ep_rew_mean      | -85.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 486      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 148668   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00209  |\n",
            "|    n_updates        | 34666    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: -60.85 ± 44.35\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 561      |\n",
            "|    ep_rew_mean      | -84.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 542      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150272   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00163  |\n",
            "|    n_updates        | 35067    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 531      |\n",
            "|    ep_rew_mean      | -86.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 492      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 152102   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00418  |\n",
            "|    n_updates        | 35525    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 518      |\n",
            "|    ep_rew_mean      | -88.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 483      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 154169   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.764    |\n",
            "|    n_updates        | 36042    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 530      |\n",
            "|    ep_rew_mean      | -87.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 480      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 159036   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.63     |\n",
            "|    n_updates        | 37258    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -45.14 ± 19.75\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 575      |\n",
            "|    ep_rew_mean      | -85.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 507      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 164843   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0103   |\n",
            "|    n_updates        | 38710    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -96.66 ± 1.34\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 621      |\n",
            "|    ep_rew_mean      | -83.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 501      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 170089   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.754    |\n",
            "|    n_updates        | 40022    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 607      |\n",
            "|    ep_rew_mean      | -83.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 524      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 170466   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00273  |\n",
            "|    n_updates        | 40116    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 592      |\n",
            "|    ep_rew_mean      | -84.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 467      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 172336   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00174  |\n",
            "|    n_updates        | 40583    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 594      |\n",
            "|    ep_rew_mean      | -84.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 491      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 174316   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00188  |\n",
            "|    n_updates        | 41078    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 639      |\n",
            "|    ep_rew_mean      | -82      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 490      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 179199   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 42299    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -93.66 ± 5.69\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 623      |\n",
            "|    ep_rew_mean      | -83      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 475      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 183317   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00231  |\n",
            "|    n_updates        | 43329    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 684      |\n",
            "|    ep_rew_mean      | -80      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 487      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 189717   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00125  |\n",
            "|    n_updates        | 44929    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: -40.23 ± 4.55\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 681      |\n",
            "|    ep_rew_mean      | -79.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 514      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 193476   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00539  |\n",
            "|    n_updates        | 45868    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 697      |\n",
            "|    ep_rew_mean      | -78.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 490      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 195480   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000692 |\n",
            "|    n_updates        | 46369    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 653      |\n",
            "|    ep_rew_mean      | -81.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 489      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 196061   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00808  |\n",
            "|    n_updates        | 46515    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 638      |\n",
            "|    ep_rew_mean      | -81.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 494      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 197887   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0116   |\n",
            "|    n_updates        | 46971    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: -89.87 ± 38.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0001_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. env = 1, batch size= 128, lr = 3e-4"
      ],
      "metadata": {
        "id": "irbX_bLGoAxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_bipedalwalker(1, 128, 3e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2NceCekoDxf",
        "outputId": "c57cdf64-bab2-4e9a-8389-85ee74568c70"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86.2     |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.831    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 2202     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 345      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 396      |\n",
            "|    ep_rew_mean      | -133     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 2647     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 3165     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 412      |\n",
            "|    ep_rew_mean      | -125     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 2895     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 4950     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 424      |\n",
            "|    ep_rew_mean      | -120     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 3022     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 6780     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -107.79 ± 4.98\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 511      |\n",
            "|    ep_rew_mean      | -118     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 471      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10243    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00721  |\n",
            "|    n_updates        | 60       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 440      |\n",
            "|    ep_rew_mean      | -117     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 502      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 10570    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.782    |\n",
            "|    n_updates        | 142      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 398      |\n",
            "|    ep_rew_mean      | -116     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 504      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 11153    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00485  |\n",
            "|    n_updates        | 288      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 368      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 508      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 11782    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00455  |\n",
            "|    n_updates        | 445      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 421      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 483      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 15173    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0024   |\n",
            "|    n_updates        | 1293     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 417      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 492      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 16693    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00212  |\n",
            "|    n_updates        | 1673     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 435      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 498      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 19164    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00253  |\n",
            "|    n_updates        | 2290     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -88.30 ± 31.50\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 418      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 505      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20134    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 2533     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 410      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 498      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 21369    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.682    |\n",
            "|    n_updates        | 2842     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 404      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 489      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 22724    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.751    |\n",
            "|    n_updates        | 3180     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 426      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 479      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 25652    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00452  |\n",
            "|    n_updates        | 3912     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 405      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 480      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 25998    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.767    |\n",
            "|    n_updates        | 3999     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 405      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 480      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 27621    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00242  |\n",
            "|    n_updates        | 4405     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -97.58 ± 34.41\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 410      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 486      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30101    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00601  |\n",
            "|    n_updates        | 5025     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 423      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 460      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 32793    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00327  |\n",
            "|    n_updates        | 5698     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 482      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 478      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 39193    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.654    |\n",
            "|    n_updates        | 7298     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 462      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 478      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 39402    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0021   |\n",
            "|    n_updates        | 7350     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -91.03 ± 29.03\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 464      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 448      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 42039    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00259  |\n",
            "|    n_updates        | 8009     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 497      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 465      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 46915    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.724    |\n",
            "|    n_updates        | 9228     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 479      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 462      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 47199    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00262  |\n",
            "|    n_updates        | 9299     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 481      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 468      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 49341    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.002    |\n",
            "|    n_updates        | 9835     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -111.49 ± 20.39\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 483      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 471      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50116    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0075   |\n",
            "|    n_updates        | 10028    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 458      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 470      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50443    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00252  |\n",
            "|    n_updates        | 10110    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 474      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 456      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 53815    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00185  |\n",
            "|    n_updates        | 10953    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 460      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 459      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 54286    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.105    |\n",
            "|    n_updates        | 11071    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 460      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 458      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 57728    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00311  |\n",
            "|    n_updates        | 11931    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -67.44 ± 23.20\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 490      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 493      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 61648    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00525  |\n",
            "|    n_updates        | 12911    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 518      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 483      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 65073    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0187   |\n",
            "|    n_updates        | 13768    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 530      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 488      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 66861    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.751    |\n",
            "|    n_updates        | 14215    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -105.31 ± 1.84\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 529      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 502      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 71600    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0021   |\n",
            "|    n_updates        | 15399    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 533      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 501      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 73462    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00373  |\n",
            "|    n_updates        | 15865    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 542      |\n",
            "|    ep_rew_mean      | -99.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 480      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 76875    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00231  |\n",
            "|    n_updates        | 16718    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 551      |\n",
            "|    ep_rew_mean      | -98.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 487      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 78676    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0017   |\n",
            "|    n_updates        | 17168    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -100.60 ± 26.35\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 541      |\n",
            "|    ep_rew_mean      | -98.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 343      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80206    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00926  |\n",
            "|    n_updates        | 17551    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 546      |\n",
            "|    ep_rew_mean      | -97.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 455      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 82011    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.672    |\n",
            "|    n_updates        | 18002    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 519      |\n",
            "|    ep_rew_mean      | -96.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 461      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 82234    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00155  |\n",
            "|    n_updates        | 18058    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 519      |\n",
            "|    ep_rew_mean      | -96.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 467      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 82583    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00533  |\n",
            "|    n_updates        | 18145    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 536      |\n",
            "|    ep_rew_mean      | -95.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 473      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 85933    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00215  |\n",
            "|    n_updates        | 18983    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 535      |\n",
            "|    ep_rew_mean      | -95.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 464      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 87749    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0028   |\n",
            "|    n_updates        | 19437    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 525      |\n",
            "|    ep_rew_mean      | -94.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 466      |\n",
            "|    time_elapsed     | 20       |\n",
            "|    total_timesteps  | 89468    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00409  |\n",
            "|    n_updates        | 19866    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -102.93 ± 1.66\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 464      |\n",
            "|    ep_rew_mean      | -95.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 482      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 90188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00193  |\n",
            "|    n_updates        | 20046    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 495      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 447      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 93491    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00829  |\n",
            "|    n_updates        | 20872    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 493      |\n",
            "|    ep_rew_mean      | -93.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 458      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 95339    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.774    |\n",
            "|    n_updates        | 21334    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 463      |\n",
            "|    ep_rew_mean      | -94      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 453      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 97184    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00321  |\n",
            "|    n_updates        | 21795    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 464      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 455      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 97546    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00197  |\n",
            "|    n_updates        | 21886    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: -26.10 ± 30.70\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 476      |\n",
            "|    ep_rew_mean      | -92.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 498      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 101678   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00999  |\n",
            "|    n_updates        | 22919    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 473      |\n",
            "|    ep_rew_mean      | -92.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 501      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 101932   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0101   |\n",
            "|    n_updates        | 22982    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 519      |\n",
            "|    ep_rew_mean      | -89.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 490      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 106818   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00408  |\n",
            "|    n_updates        | 24204    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 488      |\n",
            "|    ep_rew_mean      | -90.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 491      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 107078   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00201  |\n",
            "|    n_updates        | 24269    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 487      |\n",
            "|    ep_rew_mean      | -89.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 491      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 107484   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00151  |\n",
            "|    n_updates        | 24370    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 472      |\n",
            "|    ep_rew_mean      | -90      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 491      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 109411   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.715    |\n",
            "|    n_updates        | 24852    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 444      |\n",
            "|    ep_rew_mean      | -91.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 484      |\n",
            "|    time_elapsed     | 20       |\n",
            "|    total_timesteps  | 109873   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0173   |\n",
            "|    n_updates        | 24968    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -102.41 ± 0.59\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 412      |\n",
            "|    ep_rew_mean      | -92.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 445      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110185   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0018   |\n",
            "|    n_updates        | 25046    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 414      |\n",
            "|    ep_rew_mean      | -92.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 492      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 112111   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00361  |\n",
            "|    n_updates        | 25527    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 399      |\n",
            "|    ep_rew_mean      | -92.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 495      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 113930   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0579   |\n",
            "|    n_updates        | 25982    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 398      |\n",
            "|    ep_rew_mean      | -92.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 480      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 115782   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.425    |\n",
            "|    n_updates        | 26445    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 367      |\n",
            "|    ep_rew_mean      | -93.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 482      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 116008   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00193  |\n",
            "|    n_updates        | 26501    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 367      |\n",
            "|    ep_rew_mean      | -93.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 489      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 117833   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00193  |\n",
            "|    n_updates        | 26958    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -93.77 ± 23.90\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 382      |\n",
            "|    ep_rew_mean      | -92.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 444      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120043   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00292  |\n",
            "|    n_updates        | 27510    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 383      |\n",
            "|    ep_rew_mean      | -93      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 430      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 121917   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00384  |\n",
            "|    n_updates        | 27979    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 383      |\n",
            "|    ep_rew_mean      | -93      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 437      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 122196   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00787  |\n",
            "|    n_updates        | 28048    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 383      |\n",
            "|    ep_rew_mean      | -92.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 439      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 122493   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00544  |\n",
            "|    n_updates        | 28123    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 383      |\n",
            "|    ep_rew_mean      | -92.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 473      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 125866   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.47     |\n",
            "|    n_updates        | 28966    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 367      |\n",
            "|    ep_rew_mean      | -92.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 467      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 126127   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0023   |\n",
            "|    n_updates        | 29031    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 353      |\n",
            "|    ep_rew_mean      | -93.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 461      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 126417   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.47     |\n",
            "|    n_updates        | 29104    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 352      |\n",
            "|    ep_rew_mean      | -92.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 460      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 126662   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.766    |\n",
            "|    n_updates        | 29165    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 323      |\n",
            "|    ep_rew_mean      | -94.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 463      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 127008   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00224  |\n",
            "|    n_updates        | 29251    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 323      |\n",
            "|    ep_rew_mean      | -94.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 467      |\n",
            "|    time_elapsed     | 18       |\n",
            "|    total_timesteps  | 128884   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0143   |\n",
            "|    n_updates        | 29720    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -82.90 ± 38.74\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 338      |\n",
            "|    ep_rew_mean      | -93.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 469      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 133247   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00247  |\n",
            "|    n_updates        | 30811    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 368      |\n",
            "|    ep_rew_mean      | -91.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 464      |\n",
            "|    time_elapsed     | 14       |\n",
            "|    total_timesteps  | 136604   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.477    |\n",
            "|    n_updates        | 31650    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -78.40 ± 38.74\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 369      |\n",
            "|    ep_rew_mean      | -91.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 422      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 141600   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00494  |\n",
            "|    n_updates        | 32899    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 369      |\n",
            "|    ep_rew_mean      | -91.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 427      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 141874   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00248  |\n",
            "|    n_updates        | 32968    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 323      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 434      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 142199   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00133  |\n",
            "|    n_updates        | 33049    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 325      |\n",
            "|    ep_rew_mean      | -94.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 439      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 142618   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0245   |\n",
            "|    n_updates        | 33154    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 324      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 444      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 142984   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.196    |\n",
            "|    n_updates        | 33245    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 308      |\n",
            "|    ep_rew_mean      | -94.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 450      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 143249   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.72     |\n",
            "|    n_updates        | 33312    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 306      |\n",
            "|    ep_rew_mean      | -94.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 453      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 143564   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0372   |\n",
            "|    n_updates        | 33390    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 307      |\n",
            "|    ep_rew_mean      | -94.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 457      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 143916   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00673  |\n",
            "|    n_updates        | 33478    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 292      |\n",
            "|    ep_rew_mean      | -95.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 459      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 144313   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0988   |\n",
            "|    n_updates        | 33578    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 277      |\n",
            "|    ep_rew_mean      | -95.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 459      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 144646   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0278   |\n",
            "|    n_updates        | 33661    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 262      |\n",
            "|    ep_rew_mean      | -96.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 462      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 144997   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.713    |\n",
            "|    n_updates        | 33749    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 262      |\n",
            "|    ep_rew_mean      | -96      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 464      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 145291   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.405    |\n",
            "|    n_updates        | 33822    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 248      |\n",
            "|    ep_rew_mean      | -96.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 462      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 145727   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00197  |\n",
            "|    n_updates        | 33931    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 234      |\n",
            "|    ep_rew_mean      | -97.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 455      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 146019   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.61     |\n",
            "|    n_updates        | 34004    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 233      |\n",
            "|    ep_rew_mean      | -97.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 456      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 147793   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00187  |\n",
            "|    n_updates        | 34448    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: -103.81 ± 15.61\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 248      |\n",
            "|    ep_rew_mean      | -96.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 454      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150191   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00373  |\n",
            "|    n_updates        | 35047    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 247      |\n",
            "|    ep_rew_mean      | -96      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 460      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150440   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00887  |\n",
            "|    n_updates        | 35109    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 216      |\n",
            "|    ep_rew_mean      | -97.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 415      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 150676   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.522    |\n",
            "|    n_updates        | 35168    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 232      |\n",
            "|    ep_rew_mean      | -96.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 433      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 152505   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00213  |\n",
            "|    n_updates        | 35626    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 263      |\n",
            "|    ep_rew_mean      | -95      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 459      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 155913   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00196  |\n",
            "|    n_updates        | 36478    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 294      |\n",
            "|    ep_rew_mean      | -93.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 464      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 159261   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.134    |\n",
            "|    n_updates        | 37315    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -42.61 ± 30.75\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 293      |\n",
            "|    ep_rew_mean      | -93.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 538      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 160261   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0263   |\n",
            "|    n_updates        | 37565    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 292      |\n",
            "|    ep_rew_mean      | -93      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 498      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 162027   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00243  |\n",
            "|    n_updates        | 38006    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 262      |\n",
            "|    ep_rew_mean      | -94.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 500      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 162376   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00715  |\n",
            "|    n_updates        | 38093    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 262      |\n",
            "|    ep_rew_mean      | -94.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 486      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 165721   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.936    |\n",
            "|    n_updates        | 38930    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 247      |\n",
            "|    ep_rew_mean      | -95.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 490      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 167597   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00246  |\n",
            "|    n_updates        | 39399    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 247      |\n",
            "|    ep_rew_mean      | -95.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 489      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 167899   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00394  |\n",
            "|    n_updates        | 39474    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 261      |\n",
            "|    ep_rew_mean      | -94.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 483      |\n",
            "|    time_elapsed     | 20       |\n",
            "|    total_timesteps  | 169666   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00274  |\n",
            "|    n_updates        | 39916    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -97.44 ± 1.80\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 276      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 496      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 171863   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.788    |\n",
            "|    n_updates        | 40465    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 274      |\n",
            "|    ep_rew_mean      | -94.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 493      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 172074   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00177  |\n",
            "|    n_updates        | 40518    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 274      |\n",
            "|    ep_rew_mean      | -94.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 487      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 172324   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00564  |\n",
            "|    n_updates        | 40580    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 289      |\n",
            "|    ep_rew_mean      | -93.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 483      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 174111   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00238  |\n",
            "|    n_updates        | 41027    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 303      |\n",
            "|    ep_rew_mean      | -92.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 464      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 175863   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00135  |\n",
            "|    n_updates        | 41465    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 302      |\n",
            "|    ep_rew_mean      | -92.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 467      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 176219   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.699    |\n",
            "|    n_updates        | 41554    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 302      |\n",
            "|    ep_rew_mean      | -92.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 468      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 176480   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0133   |\n",
            "|    n_updates        | 41619    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 317      |\n",
            "|    ep_rew_mean      | -91.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 471      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 178331   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0108   |\n",
            "|    n_updates        | 42082    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -110.70 ± 0.95\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 332      |\n",
            "|    ep_rew_mean      | -91.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 348      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 180201   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.56     |\n",
            "|    n_updates        | 42550    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 345      |\n",
            "|    ep_rew_mean      | -90.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 447      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 181944   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.115    |\n",
            "|    n_updates        | 42985    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 345      |\n",
            "|    ep_rew_mean      | -90.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 452      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 182200   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00636  |\n",
            "|    n_updates        | 43049    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 345      |\n",
            "|    ep_rew_mean      | -90.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 466      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 184028   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00235  |\n",
            "|    n_updates        | 43506    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 346      |\n",
            "|    ep_rew_mean      | -90.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 465      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 185899   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0142   |\n",
            "|    n_updates        | 43974    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 362      |\n",
            "|    ep_rew_mean      | -89.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 469      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 187702   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0172   |\n",
            "|    n_updates        | 44425    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 362      |\n",
            "|    ep_rew_mean      | -89.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 471      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 187990   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0017   |\n",
            "|    n_updates        | 44497    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 362      |\n",
            "|    ep_rew_mean      | -89.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 474      |\n",
            "|    time_elapsed     | 20       |\n",
            "|    total_timesteps  | 189813   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00236  |\n",
            "|    n_updates        | 44953    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: -16.03 ± 13.93\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 362      |\n",
            "|    ep_rew_mean      | -89.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 472      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 193355   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0061   |\n",
            "|    n_updates        | 45838    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 334      |\n",
            "|    ep_rew_mean      | -90.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 480      |\n",
            "|    fps              | 474      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 193919   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.483    |\n",
            "|    n_updates        | 45979    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 351      |\n",
            "|    ep_rew_mean      | -90.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 484      |\n",
            "|    fps              | 475      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 195940   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00264  |\n",
            "|    n_updates        | 46484    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 352      |\n",
            "|    ep_rew_mean      | -90.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 488      |\n",
            "|    fps              | 480      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 197805   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0937   |\n",
            "|    n_updates        | 46951    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 368      |\n",
            "|    ep_rew_mean      | -89      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 492      |\n",
            "|    fps              | 472      |\n",
            "|    time_elapsed     | 20       |\n",
            "|    total_timesteps  | 199668   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00523  |\n",
            "|    n_updates        | 47416    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: -97.69 ± 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv1B128LR0.0003_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. env = 4, batch size= 64, lr = 1e-4"
      ],
      "metadata": {
        "id": "SM_xJ6tcoIyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_bipedalwalker(4, 64, 1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ01BO0LoJ_i",
        "outputId": "d85273d9-075f-4835-dfe3-8028b6d88fc7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 71.2     |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.757    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 3210     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 496      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 664      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 4120     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 6896     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 604      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 4106     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 8012     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -122.40 ± 5.62\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 474      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 1513     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10408    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0186   |\n",
            "|    n_updates        | 25       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 397      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 1483     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10676    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0163   |\n",
            "|    n_updates        | 42       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 341      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 1539     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 11112    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0176   |\n",
            "|    n_updates        | 69       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 309      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 1555     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 11640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.57     |\n",
            "|    n_updates        | 102      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 292      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 1579     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 12276    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.57     |\n",
            "|    n_updates        | 142      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 262      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 1584     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 12564    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00896  |\n",
            "|    n_updates        | 160      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 250      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 1593     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 12884    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0154   |\n",
            "|    n_updates        | 180      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 234      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 1587     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 13156    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0159   |\n",
            "|    n_updates        | 197      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 221      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 1586     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 13776    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0133   |\n",
            "|    n_updates        | 235      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 210      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 1596     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 14124    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00926  |\n",
            "|    n_updates        | 257      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 201      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 1616     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 14612    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0145   |\n",
            "|    n_updates        | 288      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 202      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 1613     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 15856    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0113   |\n",
            "|    n_updates        | 365      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 210      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 1615     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 16408    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0131   |\n",
            "|    n_updates        | 400      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 203      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 1612     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 16652    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00824  |\n",
            "|    n_updates        | 415      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 1618     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 16940    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0101   |\n",
            "|    n_updates        | 433      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 1613     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 17576    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00896  |\n",
            "|    n_updates        | 473      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 189      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 1560     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 18412    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0107   |\n",
            "|    n_updates        | 525      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 1536     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 18952    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00791  |\n",
            "|    n_updates        | 559      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 186      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 1521     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 19340    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0116   |\n",
            "|    n_updates        | 583      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 183      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 1496     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 19604    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0119   |\n",
            "|    n_updates        | 600      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 179      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 1490     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 19984    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0122   |\n",
            "|    n_updates        | 623      |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -96.28 ± 18.08\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 1528     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20860    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00925  |\n",
            "|    n_updates        | 678      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 1568     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 21352    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00696  |\n",
            "|    n_updates        | 709      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 164      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 1619     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 22280    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.017    |\n",
            "|    n_updates        | 767      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 150      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 1602     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 22900    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 806      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 149      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 1598     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 23508    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0101   |\n",
            "|    n_updates        | 844      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 1603     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 23768    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0111   |\n",
            "|    n_updates        | 860      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 1612     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 24176    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 885      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 150      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 1614     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 24512    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.68     |\n",
            "|    n_updates        | 906      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 145      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 1626     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 25032    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 939      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 146      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 1630     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 25868    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00672  |\n",
            "|    n_updates        | 991      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 147      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 1615     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 26592    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00668  |\n",
            "|    n_updates        | 1036     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 160      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 1604     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 27116    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00835  |\n",
            "|    n_updates        | 1069     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 161      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 1596     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 27580    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00797  |\n",
            "|    n_updates        | 1098     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 174      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 1585     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 28764    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00867  |\n",
            "|    n_updates        | 1172     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -90.59 ± 11.68\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 1594     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30496    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.012    |\n",
            "|    n_updates        | 1280     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 184      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 1630     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30900    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00943  |\n",
            "|    n_updates        | 1306     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 177      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 1681     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 31452    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1340     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 177      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 1665     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32040    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00827  |\n",
            "|    n_updates        | 1377     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 180      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 1651     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32564    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1410     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 182      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 1659     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32844    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1427     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 179      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 1631     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 33360    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.12     |\n",
            "|    n_updates        | 1459     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 1615     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 33660    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.57     |\n",
            "|    n_updates        | 1478     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 174      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 1594     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 34120    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1507     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 1577     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 34452    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1528     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 1569     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 34792    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00891  |\n",
            "|    n_updates        | 1549     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 159      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 1573     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 35176    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00741  |\n",
            "|    n_updates        | 1573     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 158      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 1582     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 35448    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00811  |\n",
            "|    n_updates        | 1590     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 138      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 1585     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 35716    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0111   |\n",
            "|    n_updates        | 1607     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 1592     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 35988    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1624     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 137      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 1578     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 36512    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0112   |\n",
            "|    n_updates        | 1656     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 1579     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 36940    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00849  |\n",
            "|    n_updates        | 1683     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 1585     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 37380    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1711     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 138      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 1590     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 37620    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0102   |\n",
            "|    n_updates        | 1726     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 140      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 1592     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 38188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1761     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 141      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 1595     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 38748    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00862  |\n",
            "|    n_updates        | 1796     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 140      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 1591     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 39264    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00842  |\n",
            "|    n_updates        | 1828     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 130      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 1592     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 39636    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.67     |\n",
            "|    n_updates        | 1852     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -114.60 ± 1.99\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 129      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 1360     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40132    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1883     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 114      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 1602     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40384    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1898     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 98.2     |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 1560     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40780    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00754  |\n",
            "|    n_updates        | 1923     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 98.4     |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 1550     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 41244    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0086   |\n",
            "|    n_updates        | 1952     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.3     |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 1537     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 41912    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00699  |\n",
            "|    n_updates        | 1994     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.8     |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 1551     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 42364    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00569  |\n",
            "|    n_updates        | 2022     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 95.3     |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 1580     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 43068    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00765  |\n",
            "|    n_updates        | 2066     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 96.8     |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 1389     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 45088    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.009    |\n",
            "|    n_updates        | 2192     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 112      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 1377     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 45440    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00597  |\n",
            "|    n_updates        | 2214     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 110      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 1400     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 46032    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00456  |\n",
            "|    n_updates        | 2251     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 109      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 1425     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 47212    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00641  |\n",
            "|    n_updates        | 2325     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -113.52 ± 32.25\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 126      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 1408     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50360    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00868  |\n",
            "|    n_updates        | 2522     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 124      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 1442     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 51128    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 2570     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 143      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 1531     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 52072    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0106   |\n",
            "|    n_updates        | 2629     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 144      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 1514     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 52640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 2664     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 147      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 1525     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 54276    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00455  |\n",
            "|    n_updates        | 2767     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 171      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 1396     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 56044    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00765  |\n",
            "|    n_updates        | 2877     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 170      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 1362     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 56668    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00634  |\n",
            "|    n_updates        | 2916     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 178      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 1373     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 57208    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 2950     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 188      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 1399     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 58360    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 3022     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -95.81 ± 19.00\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 188      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 1549     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60164    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 3135     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 185      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 1598     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60844    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0051   |\n",
            "|    n_updates        | 3177     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 185      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 1581     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 62024    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00455  |\n",
            "|    n_updates        | 3251     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 202      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 1559     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 63320    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00529  |\n",
            "|    n_updates        | 3332     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 213      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 1536     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 63652    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00592  |\n",
            "|    n_updates        | 3353     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 218      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 1578     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 65484    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 3467     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 233      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 1587     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 65848    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 3490     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 234      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 1600     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 66272    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00722  |\n",
            "|    n_updates        | 3516     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 233      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 1611     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 66728    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00813  |\n",
            "|    n_updates        | 3545     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 239      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 1604     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 67260    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00563  |\n",
            "|    n_updates        | 3578     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 239      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 1600     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 67500    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0051   |\n",
            "|    n_updates        | 3593     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 236      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 1593     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 67680    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 3604     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 232      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 1585     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 67996    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0067   |\n",
            "|    n_updates        | 3624     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 1506     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 69880    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00559  |\n",
            "|    n_updates        | 3742     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -83.32 ± 16.89\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 226      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 1666     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70504    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00525  |\n",
            "|    n_updates        | 3781     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 237      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 1680     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 73064    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 3941     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 221      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 1662     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 73812    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00569  |\n",
            "|    n_updates        | 3988     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 221      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 1666     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 74336    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00369  |\n",
            "|    n_updates        | 4020     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 202      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 1657     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 74748    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00401  |\n",
            "|    n_updates        | 4046     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 215      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 1653     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 75152    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00671  |\n",
            "|    n_updates        | 4071     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 213      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 1648     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 75564    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00639  |\n",
            "|    n_updates        | 4097     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 189      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 1637     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 76076    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00485  |\n",
            "|    n_updates        | 4129     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 205      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 1635     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 76588    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00482  |\n",
            "|    n_updates        | 4161     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 196      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 1625     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 76920    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00622  |\n",
            "|    n_updates        | 4182     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 188      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 1616     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 77264    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 4203     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 188      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 1614     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 77716    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00421  |\n",
            "|    n_updates        | 4232     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 188      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 1613     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 78072    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00382  |\n",
            "|    n_updates        | 4254     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 186      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 1612     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 78468    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00481  |\n",
            "|    n_updates        | 4279     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 169      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 1614     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 78860    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00481  |\n",
            "|    n_updates        | 4303     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 1617     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 79356    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00419  |\n",
            "|    n_updates        | 4334     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 149      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 1615     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 79956    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00543  |\n",
            "|    n_updates        | 4372     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -98.83 ± 21.55\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 1512     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80232    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 4389     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 1691     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 81268    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 4454     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 182      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 1694     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 86728    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00744  |\n",
            "|    n_updates        | 4795     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 1689     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 87668    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00504  |\n",
            "|    n_updates        | 4854     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 1687     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 88364    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00291  |\n",
            "|    n_updates        | 4897     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 1677     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 88920    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00294  |\n",
            "|    n_updates        | 4932     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -99.91 ± 23.48\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 213      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 1301     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 90188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00522  |\n",
            "|    n_updates        | 5011     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 208      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 480      |\n",
            "|    fps              | 1185     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 90740    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 5046     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 204      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 484      |\n",
            "|    fps              | 1333     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 91404    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00319  |\n",
            "|    n_updates        | 5087     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 223      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 488      |\n",
            "|    fps              | 1496     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 93188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00368  |\n",
            "|    n_updates        | 5199     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 236      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 492      |\n",
            "|    fps              | 1533     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 97328    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00389  |\n",
            "|    n_updates        | 5457     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 252      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 496      |\n",
            "|    fps              | 1527     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 99172    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00489  |\n",
            "|    n_updates        | 5573     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: -84.59 ± 18.35\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 284      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 500      |\n",
            "|    fps              | 1182     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 101516   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00355  |\n",
            "|    n_updates        | 5719     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 284      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 504      |\n",
            "|    fps              | 1265     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 103112   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.005    |\n",
            "|    n_updates        | 5819     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 283      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 508      |\n",
            "|    fps              | 1318     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 103976   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 5873     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 314      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 512      |\n",
            "|    fps              | 1457     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 106604   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00451  |\n",
            "|    n_updates        | 6037     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 297      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 516      |\n",
            "|    fps              | 1481     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 107400   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00309  |\n",
            "|    n_updates        | 6087     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 297      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 520      |\n",
            "|    fps              | 1479     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 107808   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0062   |\n",
            "|    n_updates        | 6112     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 310      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 524      |\n",
            "|    fps              | 1479     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 108100   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00288  |\n",
            "|    n_updates        | 6131     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 307      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 528      |\n",
            "|    fps              | 1478     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 108280   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00276  |\n",
            "|    n_updates        | 6142     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 308      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 532      |\n",
            "|    fps              | 1477     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 108832   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 6176     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 308      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 536      |\n",
            "|    fps              | 1474     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 109256   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0033   |\n",
            "|    n_updates        | 6203     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 307      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 540      |\n",
            "|    fps              | 1477     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 109708   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00424  |\n",
            "|    n_updates        | 6231     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -92.84 ± 26.33\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 323      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 544      |\n",
            "|    fps              | 1405     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110280   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00446  |\n",
            "|    n_updates        | 6267     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 337      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 548      |\n",
            "|    fps              | 1437     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110528   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 6282     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 336      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 552      |\n",
            "|    fps              | 1480     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110840   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00321  |\n",
            "|    n_updates        | 6302     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 335      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 556      |\n",
            "|    fps              | 1466     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 111008   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00384  |\n",
            "|    n_updates        | 6312     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 288      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 560      |\n",
            "|    fps              | 1487     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 111268   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00487  |\n",
            "|    n_updates        | 6329     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 272      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 564      |\n",
            "|    fps              | 1527     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 112208   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00324  |\n",
            "|    n_updates        | 6387     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 268      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 568      |\n",
            "|    fps              | 1526     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 113360   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00509  |\n",
            "|    n_updates        | 6459     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 269      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 572      |\n",
            "|    fps              | 1501     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 115008   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00259  |\n",
            "|    n_updates        | 6562     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 250      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 576      |\n",
            "|    fps              | 1441     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 116176   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00197  |\n",
            "|    n_updates        | 6635     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 250      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 580      |\n",
            "|    fps              | 1403     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 117368   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 6710     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 296      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 584      |\n",
            "|    fps              | 1408     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 117792   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0053   |\n",
            "|    n_updates        | 6736     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 267      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 588      |\n",
            "|    fps              | 1426     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 118700   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00533  |\n",
            "|    n_updates        | 6793     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 254      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 592      |\n",
            "|    fps              | 1444     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 119536   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0051   |\n",
            "|    n_updates        | 6845     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -106.43 ± 3.96\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 238      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 596      |\n",
            "|    fps              | 1334     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120048   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00662  |\n",
            "|    n_updates        | 6877     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 208      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 600      |\n",
            "|    fps              | 1508     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120420   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00346  |\n",
            "|    n_updates        | 6901     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 604      |\n",
            "|    fps              | 1551     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120912   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00279  |\n",
            "|    n_updates        | 6931     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 195      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 608      |\n",
            "|    fps              | 1545     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 121420   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00411  |\n",
            "|    n_updates        | 6963     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 167      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 612      |\n",
            "|    fps              | 1556     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 121712   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00398  |\n",
            "|    n_updates        | 6981     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 167      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 616      |\n",
            "|    fps              | 1550     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 121912   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00341  |\n",
            "|    n_updates        | 6994     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 166      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 620      |\n",
            "|    fps              | 1542     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 122404   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 7025     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 153      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 624      |\n",
            "|    fps              | 1540     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 122764   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 7047     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 156      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 628      |\n",
            "|    fps              | 1525     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 123092   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 7068     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 156      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 632      |\n",
            "|    fps              | 1547     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 123768   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.2      |\n",
            "|    n_updates        | 7110     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 156      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 636      |\n",
            "|    fps              | 1572     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 124840   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.1      |\n",
            "|    n_updates        | 7177     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 157      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 640      |\n",
            "|    fps              | 1590     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 126300   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00544  |\n",
            "|    n_updates        | 7268     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 142      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 644      |\n",
            "|    fps              | 1592     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 127208   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0037   |\n",
            "|    n_updates        | 7325     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 129      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 648      |\n",
            "|    fps              | 1613     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 128872   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00252  |\n",
            "|    n_updates        | 7429     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 652      |\n",
            "|    fps              | 1607     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 129496   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00228  |\n",
            "|    n_updates        | 7468     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -96.31 ± 3.55\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 656      |\n",
            "|    fps              | 1338     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 130180   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00517  |\n",
            "|    n_updates        | 7511     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 660      |\n",
            "|    fps              | 1402     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 130384   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00257  |\n",
            "|    n_updates        | 7523     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 664      |\n",
            "|    fps              | 1438     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 130716   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00265  |\n",
            "|    n_updates        | 7544     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 668      |\n",
            "|    fps              | 1451     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 131160   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 7572     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 174      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 672      |\n",
            "|    fps              | 1352     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 131620   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00272  |\n",
            "|    n_updates        | 7601     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 174      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 676      |\n",
            "|    fps              | 1304     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 132024   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00321  |\n",
            "|    n_updates        | 7626     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 174      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 680      |\n",
            "|    fps              | 1241     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 132580   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0024   |\n",
            "|    n_updates        | 7661     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 129      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 684      |\n",
            "|    fps              | 1245     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 133344   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00434  |\n",
            "|    n_updates        | 7708     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 129      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 688      |\n",
            "|    fps              | 1261     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 134080   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00283  |\n",
            "|    n_updates        | 7754     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 128      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 692      |\n",
            "|    fps              | 1318     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 135064   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 7816     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 145      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 696      |\n",
            "|    fps              | 1398     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 137388   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00488  |\n",
            "|    n_updates        | 7961     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 160      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 700      |\n",
            "|    fps              | 1410     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 138316   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00178  |\n",
            "|    n_updates        | 8019     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -84.52 ± 27.31\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 159      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 704      |\n",
            "|    fps              | 1555     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140572   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 8160     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 158      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 708      |\n",
            "|    fps              | 1627     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 141884   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 8242     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 171      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 712      |\n",
            "|    fps              | 1587     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 142476   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00357  |\n",
            "|    n_updates        | 8279     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 716      |\n",
            "|    fps              | 1412     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 144256   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 8390     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 207      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 720      |\n",
            "|    fps              | 1372     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 145444   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.64     |\n",
            "|    n_updates        | 8465     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 206      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 724      |\n",
            "|    fps              | 1413     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 146944   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00337  |\n",
            "|    n_updates        | 8558     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 220      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 728      |\n",
            "|    fps              | 1474     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 149012   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.63     |\n",
            "|    n_updates        | 8688     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: -108.52 ± 1.62\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 220      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 732      |\n",
            "|    fps              | 1413     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150196   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 8762     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 219      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 736      |\n",
            "|    fps              | 1470     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150424   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00344  |\n",
            "|    n_updates        | 8776     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 218      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 740      |\n",
            "|    fps              | 1447     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150632   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0022   |\n",
            "|    n_updates        | 8789     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 218      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 744      |\n",
            "|    fps              | 1497     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150952   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00519  |\n",
            "|    n_updates        | 8809     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 217      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 748      |\n",
            "|    fps              | 1560     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 151388   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00368  |\n",
            "|    n_updates        | 8836     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 174      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 752      |\n",
            "|    fps              | 1556     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 151744   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0026   |\n",
            "|    n_updates        | 8858     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 173      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 756      |\n",
            "|    fps              | 1537     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 151956   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00374  |\n",
            "|    n_updates        | 8872     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 177      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 760      |\n",
            "|    fps              | 1560     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 153120   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00278  |\n",
            "|    n_updates        | 8944     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 178      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 764      |\n",
            "|    fps              | 1572     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 153984   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00239  |\n",
            "|    n_updates        | 8998     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 768      |\n",
            "|    fps              | 1593     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 158292   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00342  |\n",
            "|    n_updates        | 9268     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 220      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 772      |\n",
            "|    fps              | 1594     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 158792   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00205  |\n",
            "|    n_updates        | 9299     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -114.63 ± 1.63\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 220      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 776      |\n",
            "|    fps              | 1380     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 160120   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00194  |\n",
            "|    n_updates        | 9382     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 220      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 780      |\n",
            "|    fps              | 1280     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 160392   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 9399     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 219      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 784      |\n",
            "|    fps              | 1199     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 161120   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00343  |\n",
            "|    n_updates        | 9444     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 227      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 788      |\n",
            "|    fps              | 1340     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 164432   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00209  |\n",
            "|    n_updates        | 9651     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 226      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 792      |\n",
            "|    fps              | 1397     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 165772   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00293  |\n",
            "|    n_updates        | 9735     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 225      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 796      |\n",
            "|    fps              | 1419     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 166732   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00248  |\n",
            "|    n_updates        | 9795     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 225      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 800      |\n",
            "|    fps              | 1428     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 167088   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00474  |\n",
            "|    n_updates        | 9817     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 224      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 804      |\n",
            "|    fps              | 1432     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 167348   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 9834     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 239      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 808      |\n",
            "|    fps              | 1451     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 168148   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00369  |\n",
            "|    n_updates        | 9884     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -108.45 ± 0.79\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 224      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 812      |\n",
            "|    fps              | 1363     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 170456   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00272  |\n",
            "|    n_updates        | 10028    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 205      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 816      |\n",
            "|    fps              | 1497     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 171032   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00181  |\n",
            "|    n_updates        | 10064    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 820      |\n",
            "|    fps              | 1545     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 171716   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 10107    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 210      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 824      |\n",
            "|    fps              | 1613     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 175908   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00233  |\n",
            "|    n_updates        | 10369    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 210      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 828      |\n",
            "|    fps              | 1614     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 176400   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 10399    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 209      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 832      |\n",
            "|    fps              | 1614     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 176836   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 10427    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 223      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 836      |\n",
            "|    fps              | 1615     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 177288   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 10455    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 224      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 840      |\n",
            "|    fps              | 1616     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 177696   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00307  |\n",
            "|    n_updates        | 10480    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 224      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 844      |\n",
            "|    fps              | 1611     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 178164   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.006    |\n",
            "|    n_updates        | 10510    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 224      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 848      |\n",
            "|    fps              | 1601     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 178620   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00255  |\n",
            "|    n_updates        | 10538    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 852      |\n",
            "|    fps              | 1559     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 179260   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 10578    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 223      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 856      |\n",
            "|    fps              | 1521     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 179988   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00347  |\n",
            "|    n_updates        | 10624    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -69.90 ± 43.38\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 220      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 860      |\n",
            "|    fps              | 1425     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 180600   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00248  |\n",
            "|    n_updates        | 10662    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 220      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 864      |\n",
            "|    fps              | 1546     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 181376   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00142  |\n",
            "|    n_updates        | 10710    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 205      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 868      |\n",
            "|    fps              | 1570     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 182040   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00281  |\n",
            "|    n_updates        | 10752    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 872      |\n",
            "|    fps              | 1565     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 182644   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00277  |\n",
            "|    n_updates        | 10790    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 192      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 876      |\n",
            "|    fps              | 1598     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 183668   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00267  |\n",
            "|    n_updates        | 10854    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 207      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 880      |\n",
            "|    fps              | 1604     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 184948   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00387  |\n",
            "|    n_updates        | 10934    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 208      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 884      |\n",
            "|    fps              | 1623     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 186312   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00289  |\n",
            "|    n_updates        | 11019    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 888      |\n",
            "|    fps              | 1620     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 187632   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00356  |\n",
            "|    n_updates        | 11101    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 229      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 892      |\n",
            "|    fps              | 1608     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 188736   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0046   |\n",
            "|    n_updates        | 11170    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: -101.78 ± 5.03\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 215      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 896      |\n",
            "|    fps              | 960      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 190148   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0027   |\n",
            "|    n_updates        | 11259    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 900      |\n",
            "|    fps              | 1115     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 190508   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0023   |\n",
            "|    n_updates        | 11281    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 214      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 904      |\n",
            "|    fps              | 1410     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 195924   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 11620    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 229      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 908      |\n",
            "|    fps              | 1441     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 197268   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0022   |\n",
            "|    n_updates        | 11704    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 244      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 912      |\n",
            "|    fps              | 1448     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 197656   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00267  |\n",
            "|    n_updates        | 11728    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 243      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 916      |\n",
            "|    fps              | 1461     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 198092   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00243  |\n",
            "|    n_updates        | 11755    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 243      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 920      |\n",
            "|    fps              | 1464     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 198412   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 11775    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 221      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 924      |\n",
            "|    fps              | 1469     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 199184   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 11823    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: -110.16 ± 2.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0001_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. env = 4, batch size= 64, lr = 3e-4"
      ],
      "metadata": {
        "id": "hd1cuZHyoX9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_bipedalwalker(4, 64, 3e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJVFP6mXoVIk",
        "outputId": "31bbf139-c70d-4c55-8c4e-562741ff9f27"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 65       |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.796    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 3159     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 416      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 69.1     |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.526    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 3539     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 968      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 323      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 4074     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 6888     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 358      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 4056     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 7368     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 380      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 4045     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 7760     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 329      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 4024     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8320     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -124.39 ± 0.76\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 297      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 1589     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10384    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0242   |\n",
            "|    n_updates        | 23       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 391      |\n",
            "|    ep_rew_mean      | -121     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 1544     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10608    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0199   |\n",
            "|    n_updates        | 37       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 359      |\n",
            "|    ep_rew_mean      | -120     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 1638     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 11244    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0144   |\n",
            "|    n_updates        | 77       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 334      |\n",
            "|    ep_rew_mean      | -120     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 1601     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 12148    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00794  |\n",
            "|    n_updates        | 134      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 325      |\n",
            "|    ep_rew_mean      | -120     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 1609     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 12428    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00913  |\n",
            "|    n_updates        | 151      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 308      |\n",
            "|    ep_rew_mean      | -119     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 1590     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 13232    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0066   |\n",
            "|    n_updates        | 201      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 297      |\n",
            "|    ep_rew_mean      | -119     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 1589     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 13568    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00806  |\n",
            "|    n_updates        | 222      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 281      |\n",
            "|    ep_rew_mean      | -118     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 1579     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 13796    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0092   |\n",
            "|    n_updates        | 237      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 267      |\n",
            "|    ep_rew_mean      | -118     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 1582     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 14188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00641  |\n",
            "|    n_updates        | 261      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 255      |\n",
            "|    ep_rew_mean      | -117     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 1579     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 14452    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00791  |\n",
            "|    n_updates        | 278      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 244      |\n",
            "|    ep_rew_mean      | -117     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 1573     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 14944    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00678  |\n",
            "|    n_updates        | 308      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 234      |\n",
            "|    ep_rew_mean      | -116     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 1574     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 15392    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00515  |\n",
            "|    n_updates        | 336      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 235      |\n",
            "|    ep_rew_mean      | -116     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 1592     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 16948    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00692  |\n",
            "|    n_updates        | 434      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 236      |\n",
            "|    ep_rew_mean      | -116     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 1590     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 17640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0114   |\n",
            "|    n_updates        | 477      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 229      |\n",
            "|    ep_rew_mean      | -116     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 1608     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 19116    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0038   |\n",
            "|    n_updates        | 569      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 228      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 1602     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 19716    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00531  |\n",
            "|    n_updates        | 607      |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -113.59 ± 7.42\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 221      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 1648     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20240    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00583  |\n",
            "|    n_updates        | 639      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 215      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 1523     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20760    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00689  |\n",
            "|    n_updates        | 672      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 210      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 1526     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 21372    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 710      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 212      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 1564     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 22244    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00446  |\n",
            "|    n_updates        | 765      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 218      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 1586     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 23056    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00746  |\n",
            "|    n_updates        | 815      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 1616     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 23720    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.004    |\n",
            "|    n_updates        | 857      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 183      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 1625     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 24016    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 875      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 167      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 1631     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 24332    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00429  |\n",
            "|    n_updates        | 895      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 166      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 1626     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 24488    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00458  |\n",
            "|    n_updates        | 905      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 165      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 1608     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 24876    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00306  |\n",
            "|    n_updates        | 929      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 137      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 1488     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 26344    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00406  |\n",
            "|    n_updates        | 1021     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 1462     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 26800    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00622  |\n",
            "|    n_updates        | 1049     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 1435     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 27324    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 3.12     |\n",
            "|    n_updates        | 1082     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 128      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 1444     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 27696    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00429  |\n",
            "|    n_updates        | 1105     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 1473     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 28884    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00766  |\n",
            "|    n_updates        | 1180     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -109.76 ± 2.59\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 131      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 1593     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30160    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0058   |\n",
            "|    n_updates        | 1259     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 1641     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00221  |\n",
            "|    n_updates        | 1289     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 1674     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 31136    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00284  |\n",
            "|    n_updates        | 1320     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 1685     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 31868    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00452  |\n",
            "|    n_updates        | 1366     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 139      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 1661     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32072    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0046   |\n",
            "|    n_updates        | 1379     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 139      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 1643     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32488    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00425  |\n",
            "|    n_updates        | 1405     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 1657     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 33332    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00432  |\n",
            "|    n_updates        | 1458     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 127      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 1655     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 33764    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00535  |\n",
            "|    n_updates        | 1485     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 131      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 1641     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 34540    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 3.1      |\n",
            "|    n_updates        | 1533     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 1641     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 34984    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00451  |\n",
            "|    n_updates        | 1561     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 1635     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 35356    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 3.11     |\n",
            "|    n_updates        | 1584     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 1628     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 35860    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0051   |\n",
            "|    n_updates        | 1616     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 140      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 1611     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 38252    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00342  |\n",
            "|    n_updates        | 1765     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 139      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 1621     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 39772    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 1860     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -112.91 ± 1.06\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 1651     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40488    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 1905     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 126      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 1746     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 41720    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00459  |\n",
            "|    n_updates        | 1982     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 127      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 1768     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 42348    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 2021     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 1582     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 43404    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 2087     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 144      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 1484     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 44064    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 3.09     |\n",
            "|    n_updates        | 2128     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 149      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 1409     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 45116    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 2194     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 138      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 1428     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 45884    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00381  |\n",
            "|    n_updates        | 2242     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 143      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 1448     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 47288    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00347  |\n",
            "|    n_updates        | 2330     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 1460     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 47880    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00234  |\n",
            "|    n_updates        | 2367     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 163      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 1465     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 48292    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00333  |\n",
            "|    n_updates        | 2393     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 157      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 1491     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 49480    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.003    |\n",
            "|    n_updates        | 2467     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -102.27 ± 3.61\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 156      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 1531     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50268    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00377  |\n",
            "|    n_updates        | 2516     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 156      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 1652     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50776    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00442  |\n",
            "|    n_updates        | 2548     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 158      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 1648     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 51392    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00288  |\n",
            "|    n_updates        | 2586     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 1616     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 51956    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00355  |\n",
            "|    n_updates        | 2622     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 159      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 1582     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 53756    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00435  |\n",
            "|    n_updates        | 2734     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 159      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 1586     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 54332    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00469  |\n",
            "|    n_updates        | 2770     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 171      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 1620     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 56792    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00293  |\n",
            "|    n_updates        | 2924     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 182      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 1611     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 57232    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00359  |\n",
            "|    n_updates        | 2951     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 177      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 1603     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 57632    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00479  |\n",
            "|    n_updates        | 2976     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 169      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 1603     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 58148    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 3.1      |\n",
            "|    n_updates        | 3009     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 179      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 1613     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 58640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00242  |\n",
            "|    n_updates        | 3039     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -96.07 ± 35.35\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 178      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 1362     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00397  |\n",
            "|    n_updates        | 3136     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 171      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 1512     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 61572    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00427  |\n",
            "|    n_updates        | 3223     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 210      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 1610     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 65372    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0038   |\n",
            "|    n_updates        | 3460     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -100.93 ± 3.07\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 226      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 1476     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70112    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00342  |\n",
            "|    n_updates        | 3756     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 224      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 1406     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70412    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00301  |\n",
            "|    n_updates        | 3775     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 221      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 1198     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70988    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 3811     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 231      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 1422     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 76612    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 4163     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 254      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 1431     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 77460    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00267  |\n",
            "|    n_updates        | 4216     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 250      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 1435     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 78152    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00515  |\n",
            "|    n_updates        | 4259     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 248      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 1437     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 78636    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 4289     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 260      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 1451     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 79552    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0108   |\n",
            "|    n_updates        | 4346     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -77.03 ± 6.49\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 250      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 1162     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80432    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00592  |\n",
            "|    n_updates        | 4401     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 240      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 1445     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 81248    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00244  |\n",
            "|    n_updates        | 4452     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 238      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 1486     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 82564    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00471  |\n",
            "|    n_updates        | 4535     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 239      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 1566     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 84036    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 4627     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 239      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 1557     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 85392    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 4711     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 282      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 1575     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 86924    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0045   |\n",
            "|    n_updates        | 4807     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -79.92 ± 37.24\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 299      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 1156     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 91576    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00195  |\n",
            "|    n_updates        | 5098     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 306      |\n",
            "|    ep_rew_mean      | -99.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 1351     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 93560    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0127   |\n",
            "|    n_updates        | 5222     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 337      |\n",
            "|    ep_rew_mean      | -98.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 1476     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 97132    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 5445     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 338      |\n",
            "|    ep_rew_mean      | -98.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 1504     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 98944    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00142  |\n",
            "|    n_updates        | 5558     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: -14.23 ± 2.28\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 343      |\n",
            "|    ep_rew_mean      | -97.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 1592     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 100268   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00245  |\n",
            "|    n_updates        | 5641     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 405      |\n",
            "|    ep_rew_mean      | -95.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 1664     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 106668   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0026   |\n",
            "|    n_updates        | 6041     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 406      |\n",
            "|    ep_rew_mean      | -95.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 1656     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 107064   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00396  |\n",
            "|    n_updates        | 6066     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 396      |\n",
            "|    ep_rew_mean      | -95.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 1649     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 107380   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00489  |\n",
            "|    n_updates        | 6086     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 396      |\n",
            "|    ep_rew_mean      | -95.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 1645     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 107688   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00486  |\n",
            "|    n_updates        | 6105     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 395      |\n",
            "|    ep_rew_mean      | -95.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 1652     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 108348   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00256  |\n",
            "|    n_updates        | 6146     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 359      |\n",
            "|    ep_rew_mean      | -96.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 1648     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 108968   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00175  |\n",
            "|    n_updates        | 6185     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 350      |\n",
            "|    ep_rew_mean      | -96.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 1637     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 109496   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 6218     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 352      |\n",
            "|    ep_rew_mean      | -96.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 1634     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 109872   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00143  |\n",
            "|    n_updates        | 6241     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -110.32 ± 0.84\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 352      |\n",
            "|    ep_rew_mean      | -97      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 1395     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110264   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00263  |\n",
            "|    n_updates        | 6266     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 336      |\n",
            "|    ep_rew_mean      | -97.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 1460     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110532   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00289  |\n",
            "|    n_updates        | 6283     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 304      |\n",
            "|    ep_rew_mean      | -99      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 1484     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110712   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.52     |\n",
            "|    n_updates        | 6294     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 302      |\n",
            "|    ep_rew_mean      | -98.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 1561     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 111068   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00241  |\n",
            "|    n_updates        | 6316     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 288      |\n",
            "|    ep_rew_mean      | -99.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 1573     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 111408   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00244  |\n",
            "|    n_updates        | 6337     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 288      |\n",
            "|    ep_rew_mean      | -99.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 1580     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 111664   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00181  |\n",
            "|    n_updates        | 6353     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 288      |\n",
            "|    ep_rew_mean      | -99.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 1563     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 112092   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00163  |\n",
            "|    n_updates        | 6380     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 289      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 1561     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 112428   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00167  |\n",
            "|    n_updates        | 6401     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 290      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 1562     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 112756   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 6422     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 291      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 1569     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 113460   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00165  |\n",
            "|    n_updates        | 6466     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 292      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 1576     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 114252   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00195  |\n",
            "|    n_updates        | 6515     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 277      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 1502     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 119860   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00127  |\n",
            "|    n_updates        | 6866     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -110.33 ± 3.36\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 261      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 1380     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120184   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00201  |\n",
            "|    n_updates        | 6886     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 244      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 1499     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120484   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0036   |\n",
            "|    n_updates        | 6905     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 213      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 1548     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120936   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00318  |\n",
            "|    n_updates        | 6933     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 1617     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 121828   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 6989     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 223      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 480      |\n",
            "|    fps              | 1617     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 128084   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00233  |\n",
            "|    n_updates        | 7380     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 177      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 484      |\n",
            "|    fps              | 1622     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 128620   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00235  |\n",
            "|    n_updates        | 7413     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 192      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 488      |\n",
            "|    fps              | 1623     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 129672   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 7479     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -86.63 ± 37.51\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 208      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 492      |\n",
            "|    fps              | 1335     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 130940   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00349  |\n",
            "|    n_updates        | 7558     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 228      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 496      |\n",
            "|    fps              | 1447     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 135988   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00437  |\n",
            "|    n_updates        | 7874     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 243      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 500      |\n",
            "|    fps              | 1455     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 136436   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 7902     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 256      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 504      |\n",
            "|    fps              | 1467     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 137340   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0026   |\n",
            "|    n_updates        | 7958     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 249      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 508      |\n",
            "|    fps              | 1476     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 137900   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00222  |\n",
            "|    n_updates        | 7993     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -85.50 ± 50.71\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 277      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 512      |\n",
            "|    fps              | 1351     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140208   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00179  |\n",
            "|    n_updates        | 8137     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 294      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 516      |\n",
            "|    fps              | 1493     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140560   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00179  |\n",
            "|    n_updates        | 8159     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 294      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 520      |\n",
            "|    fps              | 1515     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140764   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00329  |\n",
            "|    n_updates        | 8172     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 294      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 524      |\n",
            "|    fps              | 1501     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140984   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00213  |\n",
            "|    n_updates        | 8186     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 295      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 528      |\n",
            "|    fps              | 1531     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 141412   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00312  |\n",
            "|    n_updates        | 8213     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 294      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 532      |\n",
            "|    fps              | 1531     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 141984   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00519  |\n",
            "|    n_updates        | 8248     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 296      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 536      |\n",
            "|    fps              | 1464     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 142620   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00793  |\n",
            "|    n_updates        | 8288     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 297      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 540      |\n",
            "|    fps              | 1370     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 143328   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00236  |\n",
            "|    n_updates        | 8332     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 299      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 544      |\n",
            "|    fps              | 1317     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 144104   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0022   |\n",
            "|    n_updates        | 8381     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 327      |\n",
            "|    ep_rew_mean      | -99.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 548      |\n",
            "|    fps              | 1420     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 149248   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00247  |\n",
            "|    n_updates        | 8702     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: -82.87 ± 39.49\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 357      |\n",
            "|    ep_rew_mean      | -97.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 552      |\n",
            "|    fps              | 1738     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 151296   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00165  |\n",
            "|    n_updates        | 8830     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 401      |\n",
            "|    ep_rew_mean      | -95.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 556      |\n",
            "|    fps              | 1479     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 157612   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0028   |\n",
            "|    n_updates        | 9225     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 402      |\n",
            "|    ep_rew_mean      | -95      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 560      |\n",
            "|    fps              | 1478     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 158124   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00513  |\n",
            "|    n_updates        | 9257     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 402      |\n",
            "|    ep_rew_mean      | -95.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 564      |\n",
            "|    fps              | 1474     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 158668   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 9291     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -113.52 ± 0.89\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 403      |\n",
            "|    ep_rew_mean      | -95.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 568      |\n",
            "|    fps              | 1630     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 160212   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00185  |\n",
            "|    n_updates        | 9388     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 434      |\n",
            "|    ep_rew_mean      | -94      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 572      |\n",
            "|    fps              | 1700     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 166400   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.51     |\n",
            "|    n_updates        | 9774     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 446      |\n",
            "|    ep_rew_mean      | -93.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 576      |\n",
            "|    fps              | 1700     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 166900   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00185  |\n",
            "|    n_updates        | 9806     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 424      |\n",
            "|    ep_rew_mean      | -93.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 580      |\n",
            "|    fps              | 1697     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 167148   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 9821     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 409      |\n",
            "|    ep_rew_mean      | -94.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 584      |\n",
            "|    fps              | 1702     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 167800   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00164  |\n",
            "|    n_updates        | 9862     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 395      |\n",
            "|    ep_rew_mean      | -93.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 588      |\n",
            "|    fps              | 1695     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 168460   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00331  |\n",
            "|    n_updates        | 9903     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 380      |\n",
            "|    ep_rew_mean      | -94.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 592      |\n",
            "|    fps              | 1663     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 169788   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00218  |\n",
            "|    n_updates        | 9986     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -100.97 ± 26.72\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 360      |\n",
            "|    ep_rew_mean      | -95.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 596      |\n",
            "|    fps              | 1138     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 171008   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00166  |\n",
            "|    n_updates        | 10062    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 360      |\n",
            "|    ep_rew_mean      | -95.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 600      |\n",
            "|    fps              | 1272     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 171756   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 10109    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 360      |\n",
            "|    ep_rew_mean      | -94.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 604      |\n",
            "|    fps              | 1360     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 172924   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00439  |\n",
            "|    n_updates        | 10182    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 359      |\n",
            "|    ep_rew_mean      | -94.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 608      |\n",
            "|    fps              | 1393     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 173484   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 10217    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 329      |\n",
            "|    ep_rew_mean      | -96      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 612      |\n",
            "|    fps              | 1431     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 174324   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00107  |\n",
            "|    n_updates        | 10270    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 327      |\n",
            "|    ep_rew_mean      | -96.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 616      |\n",
            "|    fps              | 1463     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 174936   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 3.09     |\n",
            "|    n_updates        | 10308    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 328      |\n",
            "|    ep_rew_mean      | -96.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 620      |\n",
            "|    fps              | 1487     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 176212   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00388  |\n",
            "|    n_updates        | 10388    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 344      |\n",
            "|    ep_rew_mean      | -95.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 624      |\n",
            "|    fps              | 1512     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 178156   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00187  |\n",
            "|    n_updates        | 10509    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -92.68 ± 34.05\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 344      |\n",
            "|    ep_rew_mean      | -95.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 628      |\n",
            "|    fps              | 1471     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 180260   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00133  |\n",
            "|    n_updates        | 10641    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 343      |\n",
            "|    ep_rew_mean      | -95.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 632      |\n",
            "|    fps              | 1531     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 180768   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0017   |\n",
            "|    n_updates        | 10672    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 341      |\n",
            "|    ep_rew_mean      | -96      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 636      |\n",
            "|    fps              | 1595     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 181260   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0012   |\n",
            "|    n_updates        | 10703    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 340      |\n",
            "|    ep_rew_mean      | -95.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 640      |\n",
            "|    fps              | 1613     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 181784   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00127  |\n",
            "|    n_updates        | 10736    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 352      |\n",
            "|    ep_rew_mean      | -95.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 644      |\n",
            "|    fps              | 1588     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 182032   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0014   |\n",
            "|    n_updates        | 10751    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 322      |\n",
            "|    ep_rew_mean      | -96.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 648      |\n",
            "|    fps              | 1605     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 182548   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0024   |\n",
            "|    n_updates        | 10784    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 294      |\n",
            "|    ep_rew_mean      | -98.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 652      |\n",
            "|    fps              | 1366     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 184648   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00766  |\n",
            "|    n_updates        | 10915    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 263      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 656      |\n",
            "|    fps              | 1389     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 185572   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00136  |\n",
            "|    n_updates        | 10973    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 247      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 660      |\n",
            "|    fps              | 1480     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 189268   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00126  |\n",
            "|    n_updates        | 11204    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: -101.81 ± 26.45\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 263      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 664      |\n",
            "|    fps              | 1617     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 190264   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00278  |\n",
            "|    n_updates        | 11266    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 261      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 668      |\n",
            "|    fps              | 1590     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 190852   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00187  |\n",
            "|    n_updates        | 11303    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 247      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 672      |\n",
            "|    fps              | 1568     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 191456   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 11340    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 231      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 676      |\n",
            "|    fps              | 1558     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 191908   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00106  |\n",
            "|    n_updates        | 11369    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 237      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 680      |\n",
            "|    fps              | 1550     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 194976   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00217  |\n",
            "|    n_updates        | 11560    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 267      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 684      |\n",
            "|    fps              | 1519     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 198912   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00193  |\n",
            "|    n_updates        | 11806    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: -113.00 ± 1.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B64LR0.0003_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. env = 4, batch size= 128, lr = 1e-4"
      ],
      "metadata": {
        "id": "ByiXq_rZodUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_bipedalwalker(4, 128, 1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyGkvaZsoa7q",
        "outputId": "581bddb6-b362-486f-f333-dee46f981c3d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.25e+03 |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 4109     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 6400     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 855      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 4118     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 7188     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 598      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 4099     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8552     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 468      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 4109     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 9796     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -83.86 ± 12.75\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 432      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 1179     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 13408    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00639  |\n",
            "|    n_updates        | 212      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 439      |\n",
            "|    ep_rew_mean      | -116     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 1190     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 13700    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.785    |\n",
            "|    n_updates        | 231      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 385      |\n",
            "|    ep_rew_mean      | -116     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 1205     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 14028    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00813  |\n",
            "|    n_updates        | 251      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 345      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 1220     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 14360    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00559  |\n",
            "|    n_updates        | 272      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 312      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 1236     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 14756    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00772  |\n",
            "|    n_updates        | 297      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 288      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 1261     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 15276    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00584  |\n",
            "|    n_updates        | 329      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 291      |\n",
            "|    ep_rew_mean      | -116     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 1276     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 15700    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00761  |\n",
            "|    n_updates        | 356      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 280      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 1277     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 16012    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0087   |\n",
            "|    n_updates        | 375      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 263      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 1278     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 16396    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00636  |\n",
            "|    n_updates        | 399      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 250      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 1279     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 16580    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.787    |\n",
            "|    n_updates        | 411      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 237      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 1281     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 16848    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.788    |\n",
            "|    n_updates        | 427      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 227      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 1290     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 17684    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00764  |\n",
            "|    n_updates        | 480      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 227      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 1296     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 18456    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00638  |\n",
            "|    n_updates        | 528      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 233      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 1307     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 19520    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.786    |\n",
            "|    n_updates        | 594      |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -101.86 ± 13.97\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 228      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 1368     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20128    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.788    |\n",
            "|    n_updates        | 632      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 253      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 1373     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 20832    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00955  |\n",
            "|    n_updates        | 676      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 244      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 1360     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 21120    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.785    |\n",
            "|    n_updates        | 694      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 240      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 1366     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 21800    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.783    |\n",
            "|    n_updates        | 737      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 235      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 1275     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 22104    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00743  |\n",
            "|    n_updates        | 756      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 229      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 1228     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 22368    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.786    |\n",
            "|    n_updates        | 772      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 1175     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 22612    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.57     |\n",
            "|    n_updates        | 788      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 174      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 1153     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 22876    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00958  |\n",
            "|    n_updates        | 804      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 160      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 1144     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 24036    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.784    |\n",
            "|    n_updates        | 877      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 167      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 1177     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 24652    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00796  |\n",
            "|    n_updates        | 915      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 173      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 1227     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 25836    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.34     |\n",
            "|    n_updates        | 989      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 170      |\n",
            "|    ep_rew_mean      | -115     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 1254     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 27364    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.34     |\n",
            "|    n_updates        | 1085     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 160      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 1258     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 27768    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00922  |\n",
            "|    n_updates        | 1110     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 170      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 1269     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 28268    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00747  |\n",
            "|    n_updates        | 1141     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 170      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 1279     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 29028    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00562  |\n",
            "|    n_updates        | 1189     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 1288     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 29564    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.784    |\n",
            "|    n_updates        | 1222     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -114     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 1291     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 29860    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1241     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -102.18 ± 26.97\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 181      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 1347     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30376    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00611  |\n",
            "|    n_updates        | 1273     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 189      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 1387     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30816    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.34     |\n",
            "|    n_updates        | 1300     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 1386     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 31264    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.784    |\n",
            "|    n_updates        | 1328     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 1398     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 31780    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00839  |\n",
            "|    n_updates        | 1361     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 1426     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32344    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0104   |\n",
            "|    n_updates        | 1396     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 1423     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 32740    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0054   |\n",
            "|    n_updates        | 1421     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 1401     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 33032    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00929  |\n",
            "|    n_updates        | 1439     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 182      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 1392     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 33364    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00671  |\n",
            "|    n_updates        | 1460     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 179      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 1396     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 33860    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00659  |\n",
            "|    n_updates        | 1491     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 1397     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 34220    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00859  |\n",
            "|    n_updates        | 1513     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 153      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 1360     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 34588    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00652  |\n",
            "|    n_updates        | 1536     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 150      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 1338     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 34856    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00676  |\n",
            "|    n_updates        | 1553     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 147      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 1311     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 35164    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00597  |\n",
            "|    n_updates        | 1572     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 1291     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 35464    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00802  |\n",
            "|    n_updates        | 1591     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 1285     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 35804    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00906  |\n",
            "|    n_updates        | 1612     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 1255     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 36076    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00892  |\n",
            "|    n_updates        | 1629     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 1242     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 36512    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.784    |\n",
            "|    n_updates        | 1656     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 144      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 1241     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 36936    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00665  |\n",
            "|    n_updates        | 1683     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 141      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 1245     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 37428    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1714     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 142      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 1288     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 38972    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00611  |\n",
            "|    n_updates        | 1810     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 145      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 1303     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 39816    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00661  |\n",
            "|    n_updates        | 1863     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -119.49 ± 2.53\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 1375     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40272    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00726  |\n",
            "|    n_updates        | 1891     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 1411     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40704    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00662  |\n",
            "|    n_updates        | 1918     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 1388     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40936    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00772  |\n",
            "|    n_updates        | 1933     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 1376     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 41284    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00614  |\n",
            "|    n_updates        | 1955     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 117      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 1371     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 41648    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.783    |\n",
            "|    n_updates        | 1977     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 1356     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 41944    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.786    |\n",
            "|    n_updates        | 1996     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 103      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 1347     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 42172    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.785    |\n",
            "|    n_updates        | 2010     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 103      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 1348     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 42312    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.781    |\n",
            "|    n_updates        | 2019     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 101      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 1359     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 42540    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.781    |\n",
            "|    n_updates        | 2033     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 96.7     |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 1375     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 42876    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.78     |\n",
            "|    n_updates        | 2054     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 96.8     |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 1377     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 43212    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.783    |\n",
            "|    n_updates        | 2075     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 96       |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 1376     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 43684    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.783    |\n",
            "|    n_updates        | 2105     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 96.5     |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 1377     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 44804    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00512  |\n",
            "|    n_updates        | 2175     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 1382     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 46876    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 2304     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 114      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 1383     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 47592    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 2349     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 126      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 1390     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 48208    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0054   |\n",
            "|    n_updates        | 2387     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 127      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 1387     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 48468    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00639  |\n",
            "|    n_updates        | 2404     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 1385     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 49636    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0045   |\n",
            "|    n_updates        | 2477     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -111.34 ± 0.76\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 945      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50180    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.782    |\n",
            "|    n_updates        | 2511     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 989      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50668    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.781    |\n",
            "|    n_updates        | 2541     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 1046     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 51300    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00576  |\n",
            "|    n_updates        | 2581     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 1176     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 52188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 2636     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 1263     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 53576    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.78     |\n",
            "|    n_updates        | 2723     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 146      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 1350     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 56088    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.779    |\n",
            "|    n_updates        | 2880     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 153      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 1347     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 56504    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00413  |\n",
            "|    n_updates        | 2906     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 1353     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 57344    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00611  |\n",
            "|    n_updates        | 2958     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 165      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 1348     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 57912    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.779    |\n",
            "|    n_updates        | 2994     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 164      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 1349     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 58180    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00485  |\n",
            "|    n_updates        | 3011     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -82.13 ± 42.60\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 163      |\n",
            "|    ep_rew_mean      | -113     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 1373     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60236    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.777    |\n",
            "|    n_updates        | 3139     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 165      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 1354     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60632    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00365  |\n",
            "|    n_updates        | 3164     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 181      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 1341     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 61016    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00715  |\n",
            "|    n_updates        | 3188     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 182      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 1326     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 61256    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.774    |\n",
            "|    n_updates        | 3203     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 181      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 1330     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 61768    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00494  |\n",
            "|    n_updates        | 3235     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 181      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 1331     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 62092    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00592  |\n",
            "|    n_updates        | 3255     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 182      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 1241     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 62640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00305  |\n",
            "|    n_updates        | 3289     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 183      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 1179     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 63140    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00412  |\n",
            "|    n_updates        | 3321     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 182      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 1165     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 63408    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0039   |\n",
            "|    n_updates        | 3337     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 181      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 1127     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 63724    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.782    |\n",
            "|    n_updates        | 3357     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 171      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 1156     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 64452    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.779    |\n",
            "|    n_updates        | 3403     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 162      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 1193     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 65476    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.1      |\n",
            "|    n_updates        | 3467     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 166      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 1236     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 66864    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.777    |\n",
            "|    n_updates        | 3553     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 166      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 1242     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 67380    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0044   |\n",
            "|    n_updates        | 3586     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 1243     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 67960    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.784    |\n",
            "|    n_updates        | 3622     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 1256     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 68640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00534  |\n",
            "|    n_updates        | 3664     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 1263     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 69252    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00442  |\n",
            "|    n_updates        | 3703     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -107.67 ± 12.88\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 1367     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70260    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00393  |\n",
            "|    n_updates        | 3766     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 1358     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70880    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.777    |\n",
            "|    n_updates        | 3804     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 1340     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 71424    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00564  |\n",
            "|    n_updates        | 3838     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 149      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 1347     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 71856    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.778    |\n",
            "|    n_updates        | 3865     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 1348     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 72436    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00362  |\n",
            "|    n_updates        | 3902     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 148      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 1353     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 72916    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00368  |\n",
            "|    n_updates        | 3932     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 137      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 1347     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 73128    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0046   |\n",
            "|    n_updates        | 3945     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 1342     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 73472    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.774    |\n",
            "|    n_updates        | 3966     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 135      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 1337     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 73676    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00314  |\n",
            "|    n_updates        | 3979     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 1319     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 74532    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 4033     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 138      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 1242     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 78600    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00398  |\n",
            "|    n_updates        | 4287     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 138      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 1253     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 79748    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.78     |\n",
            "|    n_updates        | 4359     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -105.60 ± 1.55\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 153      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 969      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80044    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.781    |\n",
            "|    n_updates        | 4377     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 1262     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80284    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00427  |\n",
            "|    n_updates        | 4392     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 150      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 1320     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80612    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00426  |\n",
            "|    n_updates        | 4413     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 1330     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 81180    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.778    |\n",
            "|    n_updates        | 4448     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 1315     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 81892    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00501  |\n",
            "|    n_updates        | 4493     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 1305     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 82636    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.779    |\n",
            "|    n_updates        | 4539     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 198      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 480      |\n",
            "|    fps              | 1325     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 88472    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 4904     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 213      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 484      |\n",
            "|    fps              | 1324     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 89172    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.782    |\n",
            "|    n_updates        | 4948     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -83.81 ± 40.43\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 488      |\n",
            "|    fps              | 1313     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 90264    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 5016     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 213      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 492      |\n",
            "|    fps              | 1278     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 90996    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00303  |\n",
            "|    n_updates        | 5062     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 213      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 496      |\n",
            "|    fps              | 1278     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 91384    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00312  |\n",
            "|    n_updates        | 5086     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 213      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 500      |\n",
            "|    fps              | 1276     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 91800    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 5112     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 213      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 504      |\n",
            "|    fps              | 1279     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 92120    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 5132     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 211      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 508      |\n",
            "|    fps              | 1289     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 92488    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00439  |\n",
            "|    n_updates        | 5155     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 211      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 512      |\n",
            "|    fps              | 1268     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 92920    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.777    |\n",
            "|    n_updates        | 5182     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 227      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 516      |\n",
            "|    fps              | 1264     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 93604    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00317  |\n",
            "|    n_updates        | 5225     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 212      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 520      |\n",
            "|    fps              | 1285     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 94156    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 5259     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: -99.94 ± 18.86\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 226      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 524      |\n",
            "|    fps              | 1334     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 100416   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 5650     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 227      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 528      |\n",
            "|    fps              | 1345     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 101316   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00379  |\n",
            "|    n_updates        | 5707     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 228      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 532      |\n",
            "|    fps              | 1353     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 102328   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00377  |\n",
            "|    n_updates        | 5770     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 229      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 536      |\n",
            "|    fps              | 1382     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 103500   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 5843     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 246      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 540      |\n",
            "|    fps              | 1374     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 104244   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00317  |\n",
            "|    n_updates        | 5890     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 248      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 544      |\n",
            "|    fps              | 1373     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 105320   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00497  |\n",
            "|    n_updates        | 5957     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 228      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 548      |\n",
            "|    fps              | 1377     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 105860   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00412  |\n",
            "|    n_updates        | 5991     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 229      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 552      |\n",
            "|    fps              | 1381     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 106684   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.32     |\n",
            "|    n_updates        | 6042     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 214      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 556      |\n",
            "|    fps              | 1383     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 107112   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00257  |\n",
            "|    n_updates        | 6069     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 230      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 560      |\n",
            "|    fps              | 1384     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 107360   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00304  |\n",
            "|    n_updates        | 6084     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 245      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 564      |\n",
            "|    fps              | 1379     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 107716   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 6107     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 245      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 568      |\n",
            "|    fps              | 1380     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 108092   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00281  |\n",
            "|    n_updates        | 6130     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 244      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 572      |\n",
            "|    fps              | 1377     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 108408   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 6150     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 244      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 576      |\n",
            "|    fps              | 1374     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 108808   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.775    |\n",
            "|    n_updates        | 6175     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 580      |\n",
            "|    fps              | 1352     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 109296   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 6205     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -110.33 ± 0.69\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 184      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 584      |\n",
            "|    fps              | 1087     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110392   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.777    |\n",
            "|    n_updates        | 6274     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 185      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 588      |\n",
            "|    fps              | 1163     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110584   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.778    |\n",
            "|    n_updates        | 6286     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 168      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 592      |\n",
            "|    fps              | 1249     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110916   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00365  |\n",
            "|    n_updates        | 6307     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 169      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 596      |\n",
            "|    fps              | 1289     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 111336   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00337  |\n",
            "|    n_updates        | 6333     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 169      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 600      |\n",
            "|    fps              | 1302     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 111668   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.779    |\n",
            "|    n_updates        | 6354     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 169      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 604      |\n",
            "|    fps              | 1316     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 111912   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 6369     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 170      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 608      |\n",
            "|    fps              | 1319     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 112224   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00295  |\n",
            "|    n_updates        | 6388     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 171      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 612      |\n",
            "|    fps              | 1323     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 112572   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.781    |\n",
            "|    n_updates        | 6410     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 616      |\n",
            "|    fps              | 1326     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 112904   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00241  |\n",
            "|    n_updates        | 6431     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 153      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 620      |\n",
            "|    fps              | 1332     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 113292   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00337  |\n",
            "|    n_updates        | 6455     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 139      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 624      |\n",
            "|    fps              | 1331     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 113912   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.777    |\n",
            "|    n_updates        | 6494     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 124      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 628      |\n",
            "|    fps              | 1344     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 115048   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00248  |\n",
            "|    n_updates        | 6565     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 124      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 632      |\n",
            "|    fps              | 1351     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 116540   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.781    |\n",
            "|    n_updates        | 6658     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 123      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 636      |\n",
            "|    fps              | 1347     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 117404   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.775    |\n",
            "|    n_updates        | 6712     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 109      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 640      |\n",
            "|    fps              | 1357     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 119260   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00318  |\n",
            "|    n_updates        | 6828     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 137      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 644      |\n",
            "|    fps              | 1359     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 119716   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00437  |\n",
            "|    n_updates        | 6857     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -106.18 ± 0.62\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 648      |\n",
            "|    fps              | 1358     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120200   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.78     |\n",
            "|    n_updates        | 6887     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 652      |\n",
            "|    fps              | 1413     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120880   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 6929     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 152      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 656      |\n",
            "|    fps              | 1362     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 121928   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00395  |\n",
            "|    n_updates        | 6995     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 183      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 660      |\n",
            "|    fps              | 1256     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 126796   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00292  |\n",
            "|    n_updates        | 7299     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 168      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 664      |\n",
            "|    fps              | 1261     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 127344   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.32     |\n",
            "|    n_updates        | 7333     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 169      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 668      |\n",
            "|    fps              | 1275     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 127948   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00435  |\n",
            "|    n_updates        | 7371     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 185      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 672      |\n",
            "|    fps              | 1281     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 128556   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00264  |\n",
            "|    n_updates        | 7409     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 186      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 676      |\n",
            "|    fps              | 1280     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 128984   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00253  |\n",
            "|    n_updates        | 7436     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 186      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 680      |\n",
            "|    fps              | 1276     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 129524   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00318  |\n",
            "|    n_updates        | 7470     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 185      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 684      |\n",
            "|    fps              | 1274     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 129984   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00433  |\n",
            "|    n_updates        | 7498     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -80.23 ± 37.86\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 204      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 688      |\n",
            "|    fps              | 1384     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 131740   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00284  |\n",
            "|    n_updates        | 7608     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 204      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 692      |\n",
            "|    fps              | 1377     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 132336   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 7645     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 217      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 696      |\n",
            "|    fps              | 1358     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 133024   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00282  |\n",
            "|    n_updates        | 7688     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 216      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 700      |\n",
            "|    fps              | 1341     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 133544   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00381  |\n",
            "|    n_updates        | 7721     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 232      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 704      |\n",
            "|    fps              | 1200     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 135644   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 7852     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 232      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 708      |\n",
            "|    fps              | 1211     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 136768   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00292  |\n",
            "|    n_updates        | 7922     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 243      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 712      |\n",
            "|    fps              | 1213     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 137832   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00277  |\n",
            "|    n_updates        | 7989     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 259      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 716      |\n",
            "|    fps              | 1248     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 139896   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00276  |\n",
            "|    n_updates        | 8118     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -116.25 ± 10.28\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 259      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 720      |\n",
            "|    fps              | 1357     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140284   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.775    |\n",
            "|    n_updates        | 8142     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 259      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 724      |\n",
            "|    fps              | 1347     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140636   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.778    |\n",
            "|    n_updates        | 8164     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 259      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 728      |\n",
            "|    fps              | 1361     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140944   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.774    |\n",
            "|    n_updates        | 8183     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 259      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 732      |\n",
            "|    fps              | 1336     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 141352   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00403  |\n",
            "|    n_updates        | 8209     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 260      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 736      |\n",
            "|    fps              | 1327     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 141956   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.767    |\n",
            "|    n_updates        | 8247     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 268      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 740      |\n",
            "|    fps              | 1401     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 145028   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.779    |\n",
            "|    n_updates        | 8439     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 238      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 744      |\n",
            "|    fps              | 1386     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 146316   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00319  |\n",
            "|    n_updates        | 8519     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 234      |\n",
            "|    ep_rew_mean      | -105     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 748      |\n",
            "|    fps              | 1384     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 147244   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0029   |\n",
            "|    n_updates        | 8577     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 248      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 752      |\n",
            "|    fps              | 1360     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 147500   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00429  |\n",
            "|    n_updates        | 8593     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 247      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 756      |\n",
            "|    fps              | 1347     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 147704   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00232  |\n",
            "|    n_updates        | 8606     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 201      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 760      |\n",
            "|    fps              | 1318     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 148124   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00367  |\n",
            "|    n_updates        | 8632     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 216      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 764      |\n",
            "|    fps              | 1303     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 148392   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 8649     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 214      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 768      |\n",
            "|    fps              | 1283     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 148704   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.777    |\n",
            "|    n_updates        | 8668     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 198      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 772      |\n",
            "|    fps              | 1266     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 148964   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00278  |\n",
            "|    n_updates        | 8685     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 776      |\n",
            "|    fps              | 1256     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 149124   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00328  |\n",
            "|    n_updates        | 8695     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 196      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 780      |\n",
            "|    fps              | 1257     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 149412   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00404  |\n",
            "|    n_updates        | 8713     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 784      |\n",
            "|    fps              | 1258     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 149780   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.782    |\n",
            "|    n_updates        | 8736     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: -61.18 ± 19.34\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 178      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 788      |\n",
            "|    fps              | 1284     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150380   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00216  |\n",
            "|    n_updates        | 8773     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 178      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 792      |\n",
            "|    fps              | 1311     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150840   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 8802     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 178      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 796      |\n",
            "|    fps              | 1300     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 151176   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00181  |\n",
            "|    n_updates        | 8823     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 178      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 800      |\n",
            "|    fps              | 1309     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 151584   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.78     |\n",
            "|    n_updates        | 8848     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 164      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 804      |\n",
            "|    fps              | 1300     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 151940   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 8871     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 178      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 808      |\n",
            "|    fps              | 1297     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 152124   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.775    |\n",
            "|    n_updates        | 8882     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 164      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 812      |\n",
            "|    fps              | 1285     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 152312   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 8894     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 149      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 816      |\n",
            "|    fps              | 1289     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 152756   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.09     |\n",
            "|    n_updates        | 8922     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 820      |\n",
            "|    fps              | 1302     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 153460   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.09     |\n",
            "|    n_updates        | 8966     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 158      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 824      |\n",
            "|    fps              | 1232     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 157640   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00226  |\n",
            "|    n_updates        | 9227     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 168      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 828      |\n",
            "|    fps              | 1242     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 158348   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.775    |\n",
            "|    n_updates        | 9271     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 182      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 832      |\n",
            "|    fps              | 1249     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 158712   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00254  |\n",
            "|    n_updates        | 9294     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 836      |\n",
            "|    fps              | 1258     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 159144   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 9321     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -103.67 ± 2.63\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 840      |\n",
            "|    fps              | 1230     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 160228   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.777    |\n",
            "|    n_updates        | 9389     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 188      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 844      |\n",
            "|    fps              | 1291     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 160544   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00491  |\n",
            "|    n_updates        | 9408     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 176      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 848      |\n",
            "|    fps              | 1251     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 160732   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 9420     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 161      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 852      |\n",
            "|    fps              | 1269     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 161052   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00211  |\n",
            "|    n_updates        | 9440     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 162      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 856      |\n",
            "|    fps              | 1285     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 161472   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00256  |\n",
            "|    n_updates        | 9466     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 162      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 860      |\n",
            "|    fps              | 1294     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 161780   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.78     |\n",
            "|    n_updates        | 9486     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 864      |\n",
            "|    fps              | 1318     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 162256   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 9515     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 868      |\n",
            "|    fps              | 1325     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 162556   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.775    |\n",
            "|    n_updates        | 9534     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 872      |\n",
            "|    fps              | 1336     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 162956   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00339  |\n",
            "|    n_updates        | 9559     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 876      |\n",
            "|    fps              | 1337     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 163192   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.772    |\n",
            "|    n_updates        | 9574     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 880      |\n",
            "|    fps              | 1346     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 163584   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.777    |\n",
            "|    n_updates        | 9598     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 154      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 884      |\n",
            "|    fps              | 1351     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 164016   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00347  |\n",
            "|    n_updates        | 9625     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 157      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 888      |\n",
            "|    fps              | 1348     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 164304   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00298  |\n",
            "|    n_updates        | 9643     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 157      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 892      |\n",
            "|    fps              | 1344     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 164552   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 9659     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 142      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 896      |\n",
            "|    fps              | 1343     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 164872   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.778    |\n",
            "|    n_updates        | 9679     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 141      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 900      |\n",
            "|    fps              | 1346     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 165160   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 9697     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 142      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 904      |\n",
            "|    fps              | 1349     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 165568   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00226  |\n",
            "|    n_updates        | 9722     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 128      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 908      |\n",
            "|    fps              | 1352     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 165960   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00284  |\n",
            "|    n_updates        | 9747     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 912      |\n",
            "|    fps              | 1359     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 167220   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.774    |\n",
            "|    n_updates        | 9826     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 916      |\n",
            "|    fps              | 1363     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 167792   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00287  |\n",
            "|    n_updates        | 9861     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 131      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 920      |\n",
            "|    fps              | 1366     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 168672   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.774    |\n",
            "|    n_updates        | 9916     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 124      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 924      |\n",
            "|    fps              | 1367     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 169120   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00412  |\n",
            "|    n_updates        | 9944     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 114      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 928      |\n",
            "|    fps              | 1370     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 169816   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 9988     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -109.99 ± 0.77\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 98.4     |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 932      |\n",
            "|    fps              | 960      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 170164   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.775    |\n",
            "|    n_updates        | 10010    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.5     |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 936      |\n",
            "|    fps              | 969      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 170440   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00278  |\n",
            "|    n_updates        | 10027    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84       |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 940      |\n",
            "|    fps              | 998      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 170812   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00209  |\n",
            "|    n_updates        | 10050    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.6     |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 944      |\n",
            "|    fps              | 1006     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 171520   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 10094    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 88.3     |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 948      |\n",
            "|    fps              | 1071     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 171936   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00268  |\n",
            "|    n_updates        | 10120    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 88.5     |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 952      |\n",
            "|    fps              | 1086     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 172168   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 10135    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89       |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 956      |\n",
            "|    fps              | 1141     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 172800   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.781    |\n",
            "|    n_updates        | 10174    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89       |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 960      |\n",
            "|    fps              | 1174     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 173324   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00373  |\n",
            "|    n_updates        | 10207    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86.9     |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 964      |\n",
            "|    fps              | 1217     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 174048   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.1      |\n",
            "|    n_updates        | 10252    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86.9     |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 968      |\n",
            "|    fps              | 1239     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 174848   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0033   |\n",
            "|    n_updates        | 10302    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.4     |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 972      |\n",
            "|    fps              | 1263     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 175832   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00551  |\n",
            "|    n_updates        | 10364    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 116      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 976      |\n",
            "|    fps              | 1296     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 179116   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.775    |\n",
            "|    n_updates        | 10569    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -101.74 ± 15.58\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 120      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 980      |\n",
            "|    fps              | 1475     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 180208   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 10637    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 984      |\n",
            "|    fps              | 1242     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 180584   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00309  |\n",
            "|    n_updates        | 10661    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 988      |\n",
            "|    fps              | 1196     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 180980   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00348  |\n",
            "|    n_updates        | 10686    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 992      |\n",
            "|    fps              | 1223     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 181264   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.775    |\n",
            "|    n_updates        | 10703    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 996      |\n",
            "|    fps              | 1174     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 181920   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00297  |\n",
            "|    n_updates        | 10744    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1000     |\n",
            "|    fps              | 1125     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 182152   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00274  |\n",
            "|    n_updates        | 10759    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1004     |\n",
            "|    fps              | 1070     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 182812   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00338  |\n",
            "|    n_updates        | 10800    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1008     |\n",
            "|    fps              | 1033     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 183356   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 10834    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 141      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1012     |\n",
            "|    fps              | 1087     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 184396   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.31     |\n",
            "|    n_updates        | 10899    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 145      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1016     |\n",
            "|    fps              | 1167     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 187228   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.779    |\n",
            "|    n_updates        | 11076    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1020     |\n",
            "|    fps              | 1230     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 189756   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.779    |\n",
            "|    n_updates        | 11234    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: -106.16 ± 4.82\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 174      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1024     |\n",
            "|    fps              | 1343     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 190284   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00184  |\n",
            "|    n_updates        | 11267    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 174      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1028     |\n",
            "|    fps              | 1244     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 190596   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0046   |\n",
            "|    n_updates        | 11287    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 174      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1032     |\n",
            "|    fps              | 1238     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 190892   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00274  |\n",
            "|    n_updates        | 11305    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 174      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1036     |\n",
            "|    fps              | 1237     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 191220   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.1      |\n",
            "|    n_updates        | 11326    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1040     |\n",
            "|    fps              | 1247     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 191576   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00267  |\n",
            "|    n_updates        | 11348    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1044     |\n",
            "|    fps              | 1246     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 191888   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.62     |\n",
            "|    n_updates        | 11367    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 171      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1048     |\n",
            "|    fps              | 1248     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 192116   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00232  |\n",
            "|    n_updates        | 11382    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 171      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1052     |\n",
            "|    fps              | 1258     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 192624   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.774    |\n",
            "|    n_updates        | 11413    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 173      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1056     |\n",
            "|    fps              | 1259     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 193128   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 11445    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 173      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1060     |\n",
            "|    fps              | 1269     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 193432   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00417  |\n",
            "|    n_updates        | 11464    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 173      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1064     |\n",
            "|    fps              | 1280     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 193768   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.782    |\n",
            "|    n_updates        | 11485    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 173      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1068     |\n",
            "|    fps              | 1317     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 194788   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.777    |\n",
            "|    n_updates        | 11549    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: -111.79 ± 1.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0001_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. env = 4, batch size= 128, lr = 3e-4"
      ],
      "metadata": {
        "id": "ObbtzIW0oiNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_bipedalwalker(4, 128, 3e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g99MT9HyohjZ",
        "outputId": "464ae17a-2667-46d4-874b-a30f1083a7fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 71.5     |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.769    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 3184     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 472      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 80.4     |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.414    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 3420     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 1196     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 207      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 3963     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 6400     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 365      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 3987     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 7668     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 384      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 3994     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 8676     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -124.71 ± 8.37\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 334      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 1239     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10176    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.014    |\n",
            "|    n_updates        | 10       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 297      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 1268     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10464    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0132   |\n",
            "|    n_updates        | 28       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 269      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 1298     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 10944    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0084   |\n",
            "|    n_updates        | 58       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 254      |\n",
            "|    ep_rew_mean      | -111     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 1321     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 11936    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.782    |\n",
            "|    n_updates        | 120      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 256      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 1325     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 12928    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.786    |\n",
            "|    n_updates        | 182      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 242      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 1342     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 13480    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00548  |\n",
            "|    n_updates        | 217      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 227      |\n",
            "|    ep_rew_mean      | -112     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 1343     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 14052    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00826  |\n",
            "|    n_updates        | 253      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 273      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 1255     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 19484    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.778    |\n",
            "|    n_updates        | 592      |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -48.30 ± 8.23\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 269      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 1418     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 22964    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00385  |\n",
            "|    n_updates        | 810      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 268      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 1409     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 23532    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 845      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 282      |\n",
            "|    ep_rew_mean      | -110     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 1404     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 23740    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00401  |\n",
            "|    n_updates        | 858      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 271      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 1387     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 24368    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00432  |\n",
            "|    n_updates        | 897      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 261      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 1378     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 24556    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00287  |\n",
            "|    n_updates        | 909      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 252      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 1337     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 25128    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00545  |\n",
            "|    n_updates        | 945      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 242      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 1281     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 25824    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00315  |\n",
            "|    n_updates        | 988      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 236      |\n",
            "|    ep_rew_mean      | -108     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 1241     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 27588    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.003    |\n",
            "|    n_updates        | 1099     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -103.45 ± 36.04\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 229      |\n",
            "|    ep_rew_mean      | -109     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 1365     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30276    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00404  |\n",
            "|    n_updates        | 1267     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 239      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 1464     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 30760    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.772    |\n",
            "|    n_updates        | 1297     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 233      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 1483     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 31268    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.778    |\n",
            "|    n_updates        | 1329     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 257      |\n",
            "|    ep_rew_mean      | -106     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 1417     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 37488    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00424  |\n",
            "|    n_updates        | 1717     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 303      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 1386     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 37928    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00253  |\n",
            "|    n_updates        | 1745     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 302      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 1354     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 38304    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.77     |\n",
            "|    n_updates        | 1768     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 289      |\n",
            "|    ep_rew_mean      | -104     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 1330     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 38792    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00287  |\n",
            "|    n_updates        | 1799     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 259      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 1296     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 39324    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00254  |\n",
            "|    n_updates        | 1832     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 243      |\n",
            "|    ep_rew_mean      | -103     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 1301     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 39884    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.781    |\n",
            "|    n_updates        | 1867     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -93.87 ± 45.00\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 258      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 1475     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 40792    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00313  |\n",
            "|    n_updates        | 1924     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 257      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 1418     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 41440    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.773    |\n",
            "|    n_updates        | 1964     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 272      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 1420     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 45860    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00196  |\n",
            "|    n_updates        | 2241     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 300      |\n",
            "|    ep_rew_mean      | -99.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 1396     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 47756    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0021   |\n",
            "|    n_updates        | 2359     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 308      |\n",
            "|    ep_rew_mean      | -98.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 1397     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 49004    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00193  |\n",
            "|    n_updates        | 2437     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -112.28 ± 5.37\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 307      |\n",
            "|    ep_rew_mean      | -98.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 937      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50176    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00166  |\n",
            "|    n_updates        | 2510     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 308      |\n",
            "|    ep_rew_mean      | -98.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 950      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 50912    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0031   |\n",
            "|    n_updates        | 2556     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 323      |\n",
            "|    ep_rew_mean      | -97.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 1259     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 56596    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00186  |\n",
            "|    n_updates        | 2912     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 316      |\n",
            "|    ep_rew_mean      | -97.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 1261     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 56936    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.774    |\n",
            "|    n_updates        | 2933     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 326      |\n",
            "|    ep_rew_mean      | -96.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 1269     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 57544    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0023   |\n",
            "|    n_updates        | 2971     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 309      |\n",
            "|    ep_rew_mean      | -96.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 1268     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 57816    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 2988     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 309      |\n",
            "|    ep_rew_mean      | -96.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 1272     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 58032    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.778    |\n",
            "|    n_updates        | 3001     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 308      |\n",
            "|    ep_rew_mean      | -97.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 1274     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 58304    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 3018     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 307      |\n",
            "|    ep_rew_mean      | -97.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 1276     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 58756    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00164  |\n",
            "|    n_updates        | 3047     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 308      |\n",
            "|    ep_rew_mean      | -97.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 1274     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 59360    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.768    |\n",
            "|    n_updates        | 3084     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -88.46 ± 21.46\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 321      |\n",
            "|    ep_rew_mean      | -97.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 1303     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 60448    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00293  |\n",
            "|    n_updates        | 3152     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 322      |\n",
            "|    ep_rew_mean      | -97.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 1320     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 61172    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00474  |\n",
            "|    n_updates        | 3198     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 338      |\n",
            "|    ep_rew_mean      | -97.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 1195     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 66936    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00219  |\n",
            "|    n_updates        | 3558     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -76.76 ± 45.73\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 368      |\n",
            "|    ep_rew_mean      | -95.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 1307     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 70404    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00405  |\n",
            "|    n_updates        | 3775     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 352      |\n",
            "|    ep_rew_mean      | -96.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 1350     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 71496    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00175  |\n",
            "|    n_updates        | 3843     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 321      |\n",
            "|    ep_rew_mean      | -98.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 1245     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 72116    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 3882     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 321      |\n",
            "|    ep_rew_mean      | -98.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 1164     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 73140    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00265  |\n",
            "|    n_updates        | 3946     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 326      |\n",
            "|    ep_rew_mean      | -98      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 1178     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 75160    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00289  |\n",
            "|    n_updates        | 4072     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 343      |\n",
            "|    ep_rew_mean      | -97.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 1209     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 76660    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00267  |\n",
            "|    n_updates        | 4166     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -88.14 ± 44.28\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 368      |\n",
            "|    ep_rew_mean      | -97      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 998      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 80532    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00304  |\n",
            "|    n_updates        | 4408     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 383      |\n",
            "|    ep_rew_mean      | -95.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 1035     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 82368    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00274  |\n",
            "|    n_updates        | 4522     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 399      |\n",
            "|    ep_rew_mean      | -94.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 1192     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 84484    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.774    |\n",
            "|    n_updates        | 4655     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 430      |\n",
            "|    ep_rew_mean      | -93.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 1304     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 89992    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.767    |\n",
            "|    n_updates        | 4999     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -96.00 ± 29.17\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 430      |\n",
            "|    ep_rew_mean      | -92.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 1381     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 91172    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0025   |\n",
            "|    n_updates        | 5073     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 434      |\n",
            "|    ep_rew_mean      | -92.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 1419     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 92220    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00155  |\n",
            "|    n_updates        | 5138     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 434      |\n",
            "|    ep_rew_mean      | -92.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 1380     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 92752    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.5      |\n",
            "|    n_updates        | 5171     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 458      |\n",
            "|    ep_rew_mean      | -91.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 1290     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 97248    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00138  |\n",
            "|    n_updates        | 5452     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: -30.29 ± 29.38\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 459      |\n",
            "|    ep_rew_mean      | -91.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 1013     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 100296   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.775    |\n",
            "|    n_updates        | 5643     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 464      |\n",
            "|    ep_rew_mean      | -91.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 1083     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 102552   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00199  |\n",
            "|    n_updates        | 5784     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 493      |\n",
            "|    ep_rew_mean      | -89.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 1278     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 107424   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.771    |\n",
            "|    n_updates        | 6088     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -109.70 ± 1.57\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 509      |\n",
            "|    ep_rew_mean      | -88.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 628      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110020   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0101   |\n",
            "|    n_updates        | 6251     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 507      |\n",
            "|    ep_rew_mean      | -88.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 1355     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110384   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00204  |\n",
            "|    n_updates        | 6273     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 507      |\n",
            "|    ep_rew_mean      | -88.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 1400     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 110816   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.775    |\n",
            "|    n_updates        | 6300     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 522      |\n",
            "|    ep_rew_mean      | -87.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 1268     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 116672   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0012   |\n",
            "|    n_updates        | 6666     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 552      |\n",
            "|    ep_rew_mean      | -85.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 1240     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 117112   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00179  |\n",
            "|    n_updates        | 6694     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 553      |\n",
            "|    ep_rew_mean      | -84.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 1246     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 118004   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00181  |\n",
            "|    n_updates        | 6750     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -10.84 ± 7.23\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 552      |\n",
            "|    ep_rew_mean      | -84.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 1364     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 120424   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00191  |\n",
            "|    n_updates        | 6901     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 521      |\n",
            "|    ep_rew_mean      | -85.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 1418     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 121176   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00443  |\n",
            "|    n_updates        | 6948     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 532      |\n",
            "|    ep_rew_mean      | -86.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 1274     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 126824   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.771    |\n",
            "|    n_updates        | 7301     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 532      |\n",
            "|    ep_rew_mean      | -87      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 1287     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 127404   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00279  |\n",
            "|    n_updates        | 7337     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 517      |\n",
            "|    ep_rew_mean      | -87.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 1302     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 128204   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.576    |\n",
            "|    n_updates        | 7387     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 519      |\n",
            "|    ep_rew_mean      | -87.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 1310     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 128724   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00347  |\n",
            "|    n_updates        | 7420     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 511      |\n",
            "|    ep_rew_mean      | -87.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 1314     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 129164   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00147  |\n",
            "|    n_updates        | 7447     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -105.83 ± 0.04\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 483      |\n",
            "|    ep_rew_mean      | -87.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 784      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 130016   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 468      |\n",
            "|    ep_rew_mean      | -88.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 1278     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 130284   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0011   |\n",
            "|    n_updates        | 7517     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 437      |\n",
            "|    ep_rew_mean      | -89.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 1334     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 130612   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.000929 |\n",
            "|    n_updates        | 7538     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 422      |\n",
            "|    ep_rew_mean      | -90.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 1389     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 131012   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0024   |\n",
            "|    n_updates        | 7563     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 375      |\n",
            "|    ep_rew_mean      | -92.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 1413     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 131288   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00636  |\n",
            "|    n_updates        | 7580     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 344      |\n",
            "|    ep_rew_mean      | -94.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 1405     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 131872   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.779    |\n",
            "|    n_updates        | 7616     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 325      |\n",
            "|    ep_rew_mean      | -94.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 1393     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 132864   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.772    |\n",
            "|    n_updates        | 7678     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 334      |\n",
            "|    ep_rew_mean      | -95.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 1391     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 134680   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0017   |\n",
            "|    n_updates        | 7792     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 310      |\n",
            "|    ep_rew_mean      | -95.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 1401     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 135852   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00154  |\n",
            "|    n_updates        | 7865     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 295      |\n",
            "|    ep_rew_mean      | -96.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 1405     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 138744   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.778    |\n",
            "|    n_updates        | 8046     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -84.67 ± 39.04\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 323      |\n",
            "|    ep_rew_mean      | -96      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 1395     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 140656   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00163  |\n",
            "|    n_updates        | 8165     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 292      |\n",
            "|    ep_rew_mean      | -98.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 1392     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 141516   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.776    |\n",
            "|    n_updates        | 8219     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 294      |\n",
            "|    ep_rew_mean      | -99.2    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 1407     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 142988   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00244  |\n",
            "|    n_updates        | 8311     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 295      |\n",
            "|    ep_rew_mean      | -99.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 1413     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 144288   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00205  |\n",
            "|    n_updates        | 8392     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 311      |\n",
            "|    ep_rew_mean      | -98.8    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 1390     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 146400   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00131  |\n",
            "|    n_updates        | 8524     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 332      |\n",
            "|    ep_rew_mean      | -99      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 1296     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 148276   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00333  |\n",
            "|    n_updates        | 8642     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: -93.98 ± 15.98\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 302      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 1150     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150184   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00399  |\n",
            "|    n_updates        | 8761     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 303      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 1328     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 150728   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00237  |\n",
            "|    n_updates        | 8795     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 304      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 1361     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 151316   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.52     |\n",
            "|    n_updates        | 8832     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 304      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 1414     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 151968   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00231  |\n",
            "|    n_updates        | 8872     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 272      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 1431     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 152812   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00234  |\n",
            "|    n_updates        | 8925     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 287      |\n",
            "|    ep_rew_mean      | -101     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 1442     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 158368   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00169  |\n",
            "|    n_updates        | 9272     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 303      |\n",
            "|    ep_rew_mean      | -100     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 1439     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 158808   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00125  |\n",
            "|    n_updates        | 9300     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 301      |\n",
            "|    ep_rew_mean      | -99.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 1437     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 159108   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00175  |\n",
            "|    n_updates        | 9319     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 316      |\n",
            "|    ep_rew_mean      | -99.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 1423     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 159468   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00175  |\n",
            "|    n_updates        | 9341     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 318      |\n",
            "|    ep_rew_mean      | -99.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 1401     |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 159864   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00233  |\n",
            "|    n_updates        | 9366     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -50.05 ± 55.93\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 318      |\n",
            "|    ep_rew_mean      | -99.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 1363     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 160896   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00278  |\n",
            "|    n_updates        | 9430     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 365      |\n",
            "|    ep_rew_mean      | -96.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 1341     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 162252   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.011    |\n",
            "|    n_updates        | 9515     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 395      |\n",
            "|    ep_rew_mean      | -96      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 1318     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 167896   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00251  |\n",
            "|    n_updates        | 9868     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 426      |\n",
            "|    ep_rew_mean      | -94.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 1290     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 168928   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00206  |\n",
            "|    n_updates        | 9932     |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -78.50 ± 41.96\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 426      |\n",
            "|    ep_rew_mean      | -95.1    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 1314     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 170244   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00222  |\n",
            "|    n_updates        | 10015    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 456      |\n",
            "|    ep_rew_mean      | -93.5    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 1431     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 174268   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.0014   |\n",
            "|    n_updates        | 10266    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 478      |\n",
            "|    ep_rew_mean      | -91.6    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 1408     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 176692   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00507  |\n",
            "|    n_updates        | 10418    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 492      |\n",
            "|    ep_rew_mean      | -90.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 1375     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 177100   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00465  |\n",
            "|    n_updates        | 10443    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -103.73 ± 25.43\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 462      |\n",
            "|    ep_rew_mean      | -92.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 1327     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 180192   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00166  |\n",
            "|    n_updates        | 10636    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 446      |\n",
            "|    ep_rew_mean      | -92.4    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 1366     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 182456   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00502  |\n",
            "|    n_updates        | 10778    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 477      |\n",
            "|    ep_rew_mean      | -90.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 1392     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 186592   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00275  |\n",
            "|    n_updates        | 11036    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 476      |\n",
            "|    ep_rew_mean      | -89.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 1387     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 189296   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 1.52     |\n",
            "|    n_updates        | 11205    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: -88.95 ± 28.86\n",
            "Logging to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003/DQN_0\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 476      |\n",
            "|    ep_rew_mean      | -89.3    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 1334     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 190224   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00332  |\n",
            "|    n_updates        | 11263    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 477      |\n",
            "|    ep_rew_mean      | -88.9    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 1388     |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 195000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.00605  |\n",
            "|    n_updates        | 11562    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 456      |\n",
            "|    ep_rew_mean      | -88.7    |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 1394     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 196016   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    loss             | 0.77     |\n",
            "|    n_updates        | 11625    |\n",
            "----------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: -102.69 ± 3.93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:281: UserWarning: Path '/content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003' is a folder. Will save instead to /content/drive/MyDrive/RL_models/dqn_bipedalwalkerEnv4B128LR0.0003_2\n",
            "  warnings.warn(f\"Path '{path}' is a folder. Will save instead to {path}_2\")\n"
          ]
        }
      ]
    }
  ]
}