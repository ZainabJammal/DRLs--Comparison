{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T4Y_ICQTqHNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a437bc0-5e54-40a7-901b-b8da0fbb7c67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aIF5sfCqIBn",
        "outputId": "8d91f545-bfe3-437a-a032-cbc5f46b0fd5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install box2d"
      ],
      "metadata": {
        "id": "vIFTP_VsrG94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0704b00a-6aa1-4e8b-c361-c80e6066d118"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting box2d\n",
            "  Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (573 bytes)\n",
            "Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/3.7 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/3.7 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: box2d\n",
            "Successfully installed box2d-2.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.env_util import make_vec_env"
      ],
      "metadata": {
        "id": "h_bBYBThqvhV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, env, n_eval_episodes=10):\n",
        "    \"\"\"Evaluate the model on a given environment and return mean and std rewards.\"\"\"\n",
        "    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes)\n",
        "    return mean_reward, std_reward"
      ],
      "metadata": {
        "id": "uCvpaicUqvr3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAC BipedalWalker"
      ],
      "metadata": {
        "id": "5tXKQaY4wTSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=1, batch size= 64, lr= 1e-4"
      ],
      "metadata": {
        "id": "vm9KwcIZxGuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker1():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=1)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/\",\n",
        "                learning_rate=1e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64\")"
      ],
      "metadata": {
        "id": "pT8tu9eZqv4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker1()"
      ],
      "metadata": {
        "id": "YQfNwzojqwDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=1, batch size= 128, lr= 1e-4"
      ],
      "metadata": {
        "id": "gj3SRF7RxJ2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker2():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=1)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/\",\n",
        "                learning_rate=1e-4, buffer_size=500000, batch_size=128, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128\")"
      ],
      "metadata": {
        "id": "xp6SruwrxOU9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker2()"
      ],
      "metadata": {
        "id": "1x1DpU4Mxcky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716b8c05-cb39-4d5b-ec01-b62589b31234"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
            "/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | -109     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 46       |\n",
            "|    time_elapsed    | 9        |\n",
            "|    total_timesteps | 458      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -92.4    |\n",
            "|    critic_loss     | 88.5     |\n",
            "|    ent_coef        | 0.934    |\n",
            "|    ent_coef_loss   | -0.426   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 714      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -118     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 1602     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -153     |\n",
            "|    critic_loss     | 10.8     |\n",
            "|    ent_coef        | 0.748    |\n",
            "|    ent_coef_loss   | -1.63    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3002     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 408      |\n",
            "|    ep_rew_mean     | -134     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 37       |\n",
            "|    time_elapsed    | 130      |\n",
            "|    total_timesteps | 4902     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -77.2    |\n",
            "|    critic_loss     | 3.51     |\n",
            "|    ent_coef        | 0.385    |\n",
            "|    ent_coef_loss   | -5.45    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 9602     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 425      |\n",
            "|    ep_rew_mean     | -136     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 37       |\n",
            "|    time_elapsed    | 180      |\n",
            "|    total_timesteps | 6793     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -45      |\n",
            "|    critic_loss     | 3.29     |\n",
            "|    ent_coef        | 0.265    |\n",
            "|    ent_coef_loss   | -7.33    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 13384    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 441      |\n",
            "|    ep_rew_mean     | -139     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 37       |\n",
            "|    time_elapsed    | 234      |\n",
            "|    total_timesteps | 8828     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -23.2    |\n",
            "|    critic_loss     | 2.1      |\n",
            "|    ent_coef        | 0.177    |\n",
            "|    ent_coef_loss   | -9.52    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 17454    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -84.27 ± 3.18\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 471      |\n",
            "|    ep_rew_mean     | -136     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 53       |\n",
            "|    total_timesteps | 11868    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.9    |\n",
            "|    critic_loss     | 6.58     |\n",
            "|    ent_coef        | 0.0983   |\n",
            "|    ent_coef_loss   | -9.67    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 23534    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 455      |\n",
            "|    ep_rew_mean     | -134     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 96       |\n",
            "|    total_timesteps | 13320    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.6    |\n",
            "|    critic_loss     | 4.84     |\n",
            "|    ent_coef        | 0.0759   |\n",
            "|    ent_coef_loss   | -9.96    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 26438    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 409      |\n",
            "|    ep_rew_mean     | -130     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 105      |\n",
            "|    total_timesteps | 13655    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -15.6    |\n",
            "|    critic_loss     | 43.6     |\n",
            "|    ent_coef        | 0.071    |\n",
            "|    ent_coef_loss   | -8.48    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 27108    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 372      |\n",
            "|    ep_rew_mean     | -128     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 115      |\n",
            "|    total_timesteps | 13984    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13.3    |\n",
            "|    critic_loss     | 42.2     |\n",
            "|    ent_coef        | 0.0665   |\n",
            "|    ent_coef_loss   | -9.89    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 27766    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -58.12 ± 1.80\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 458      |\n",
            "|    ep_rew_mean     | -123     |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 36       |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 20100    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.722    |\n",
            "|    critic_loss     | 0.839    |\n",
            "|    ent_coef        | 0.0209   |\n",
            "|    ent_coef_loss   | -8.74    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 39998    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 470      |\n",
            "|    ep_rew_mean     | -123     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 71       |\n",
            "|    total_timesteps | 22488    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.12     |\n",
            "|    critic_loss     | 1.58     |\n",
            "|    ent_coef        | 0.0136   |\n",
            "|    ent_coef_loss   | -4.41    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 44774    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 565      |\n",
            "|    ep_rew_mean     | -119     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 257      |\n",
            "|    total_timesteps | 28888    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.41    |\n",
            "|    critic_loss     | 0.527    |\n",
            "|    ent_coef        | 0.0081   |\n",
            "|    ent_coef_loss   | 0.445    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 57574    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -52.00 ± 3.00\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 536      |\n",
            "|    ep_rew_mean     | -118     |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 23       |\n",
            "|    total_timesteps | 30797    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.14     |\n",
            "|    critic_loss     | 0.539    |\n",
            "|    ent_coef        | 0.00748  |\n",
            "|    ent_coef_loss   | -0.962   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 61392    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 585      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 167      |\n",
            "|    total_timesteps | 35672    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.257   |\n",
            "|    critic_loss     | 0.533    |\n",
            "|    ent_coef        | 0.00562  |\n",
            "|    ent_coef_loss   | 0.87     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 71142    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -64.53 ± 17.02\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 628      |\n",
            "|    ep_rew_mean     | -114     |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 41600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.24     |\n",
            "|    critic_loss     | 0.396    |\n",
            "|    ent_coef        | 0.0054   |\n",
            "|    ent_coef_loss   | 2.61     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 82998    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 617      |\n",
            "|    ep_rew_mean     | -115     |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 101      |\n",
            "|    total_timesteps | 43408    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.65     |\n",
            "|    critic_loss     | 0.365    |\n",
            "|    ent_coef        | 0.00474  |\n",
            "|    ent_coef_loss   | -2.62    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 86614    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 652      |\n",
            "|    ep_rew_mean     | -113     |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 246      |\n",
            "|    total_timesteps | 48281    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.6      |\n",
            "|    critic_loss     | 0.59     |\n",
            "|    ent_coef        | 0.00407  |\n",
            "|    ent_coef_loss   | -1.17    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 96360    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -44.67 ± 23.13\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 642      |\n",
            "|    ep_rew_mean     | -113     |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 53       |\n",
            "|    total_timesteps | 51700    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.79     |\n",
            "|    critic_loss     | 0.658    |\n",
            "|    ent_coef        | 0.00426  |\n",
            "|    ent_coef_loss   | -2.01    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 103198   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 673      |\n",
            "|    ep_rew_mean     | -111     |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 206      |\n",
            "|    total_timesteps | 56623    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.47     |\n",
            "|    critic_loss     | 0.398    |\n",
            "|    ent_coef        | 0.00369  |\n",
            "|    ent_coef_loss   | -2.71    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 113044   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -111.99 ± 1.34\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 701      |\n",
            "|    ep_rew_mean     | -109     |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 46       |\n",
            "|    total_timesteps | 61600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.06     |\n",
            "|    critic_loss     | 0.906    |\n",
            "|    ent_coef        | 0.00385  |\n",
            "|    ent_coef_loss   | 0.108    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 122998   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 710      |\n",
            "|    ep_rew_mean     | -109     |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 149      |\n",
            "|    total_timesteps | 65110    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.56     |\n",
            "|    critic_loss     | 0.197    |\n",
            "|    ent_coef        | 0.00368  |\n",
            "|    ent_coef_loss   | -2.06    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 130018   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 733      |\n",
            "|    ep_rew_mean     | -108     |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 289      |\n",
            "|    total_timesteps | 69983    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.59     |\n",
            "|    critic_loss     | 0.187    |\n",
            "|    ent_coef        | 0.0038   |\n",
            "|    ent_coef_loss   | -1.6     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 139764   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -48.08 ± 1.94\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 770      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 183      |\n",
            "|    total_timesteps | 76400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.902    |\n",
            "|    critic_loss     | 0.155    |\n",
            "|    ent_coef        | 0.00319  |\n",
            "|    ent_coef_loss   | -1.79    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 152598   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 760      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 245      |\n",
            "|    total_timesteps | 78495    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.76     |\n",
            "|    critic_loss     | 0.331    |\n",
            "|    ent_coef        | 0.00319  |\n",
            "|    ent_coef_loss   | -4.04    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 156788   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -65.09 ± 5.58\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 764      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 94       |\n",
            "|    total_timesteps | 83200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.63     |\n",
            "|    critic_loss     | 0.248    |\n",
            "|    ent_coef        | 0.00327  |\n",
            "|    ent_coef_loss   | 2.96     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 166198   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 824      |\n",
            "|    ep_rew_mean     | -104     |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 277      |\n",
            "|    total_timesteps | 89600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.14     |\n",
            "|    critic_loss     | 0.209    |\n",
            "|    ent_coef        | 0.00296  |\n",
            "|    ent_coef_loss   | 1.57     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 178998   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -66.81 ± 1.90\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 861      |\n",
            "|    ep_rew_mean     | -102     |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 140      |\n",
            "|    total_timesteps | 94895    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.06     |\n",
            "|    critic_loss     | 0.0896   |\n",
            "|    ent_coef        | 0.00194  |\n",
            "|    ent_coef_loss   | 0.0186   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 189588   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: -49.09 ± 0.40\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 892      |\n",
            "|    ep_rew_mean     | -97      |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 45       |\n",
            "|    total_timesteps | 101600   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.36     |\n",
            "|    critic_loss     | 0.425    |\n",
            "|    ent_coef        | 0.00185  |\n",
            "|    ent_coef_loss   | 0.249    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 202998   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 938      |\n",
            "|    ep_rew_mean     | -93      |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 228      |\n",
            "|    total_timesteps | 108000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.12     |\n",
            "|    critic_loss     | 0.0355   |\n",
            "|    ent_coef        | 0.00174  |\n",
            "|    ent_coef_loss   | 1.02     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 215798   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -46.13 ± 6.18\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 981      |\n",
            "|    ep_rew_mean     | -88.8    |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 139      |\n",
            "|    total_timesteps | 114800   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.51     |\n",
            "|    critic_loss     | 0.0326   |\n",
            "|    ent_coef        | 0.00199  |\n",
            "|    ent_coef_loss   | 1.17     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 229398   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -94.38 ± 38.24\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.02e+03 |\n",
            "|    ep_rew_mean     | -85.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 45       |\n",
            "|    total_timesteps | 121600   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.8      |\n",
            "|    critic_loss     | 0.0505   |\n",
            "|    ent_coef        | 0.00164  |\n",
            "|    ent_coef_loss   | 0.292    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 242998   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.05e+03 |\n",
            "|    ep_rew_mean     | -83.2    |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 186      |\n",
            "|    total_timesteps | 126491   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.93     |\n",
            "|    critic_loss     | 0.0249   |\n",
            "|    ent_coef        | 0.00212  |\n",
            "|    ent_coef_loss   | 0.293    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 252780   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -29.91 ± 2.38\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.12e+03 |\n",
            "|    ep_rew_mean     | -81.3    |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 93       |\n",
            "|    total_timesteps | 133200   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.999    |\n",
            "|    critic_loss     | 0.0609   |\n",
            "|    ent_coef        | 0.00181  |\n",
            "|    ent_coef_loss   | -1.33    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 266198   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.18e+03 |\n",
            "|    ep_rew_mean     | -78.7    |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 280      |\n",
            "|    total_timesteps | 139600   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.89     |\n",
            "|    critic_loss     | 0.0422   |\n",
            "|    ent_coef        | 0.00237  |\n",
            "|    ent_coef_loss   | -0.0193  |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 278998   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -63.06 ± 26.06\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.19e+03 |\n",
            "|    ep_rew_mean     | -77.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 185      |\n",
            "|    total_timesteps | 146400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.09     |\n",
            "|    critic_loss     | 0.0245   |\n",
            "|    ent_coef        | 0.00181  |\n",
            "|    ent_coef_loss   | -1.64    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 292598   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: -26.70 ± 8.68\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.23e+03 |\n",
            "|    ep_rew_mean     | -73.8    |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 92       |\n",
            "|    total_timesteps | 153200   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.96     |\n",
            "|    critic_loss     | 0.0775   |\n",
            "|    ent_coef        | 0.00169  |\n",
            "|    ent_coef_loss   | -0.975   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 306198   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.2e+03  |\n",
            "|    ep_rew_mean     | -73.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 192      |\n",
            "|    total_timesteps | 156581   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.07     |\n",
            "|    critic_loss     | 0.0402   |\n",
            "|    ent_coef        | 0.0017   |\n",
            "|    ent_coef_loss   | -0.936   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 312960   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.23e+03 |\n",
            "|    ep_rew_mean     | -72.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 292      |\n",
            "|    total_timesteps | 159942   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.52     |\n",
            "|    critic_loss     | 0.24     |\n",
            "|    ent_coef        | 0.00177  |\n",
            "|    ent_coef_loss   | 2.19     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 319682   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -71.42 ± 29.83\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.23e+03 |\n",
            "|    ep_rew_mean     | -70.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 143      |\n",
            "|    total_timesteps | 164909   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.62     |\n",
            "|    critic_loss     | 0.114    |\n",
            "|    ent_coef        | 0.00194  |\n",
            "|    ent_coef_loss   | -0.495   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 329616   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -53.93 ± 10.25\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.24e+03 |\n",
            "|    ep_rew_mean     | -69.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 171600   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.01     |\n",
            "|    critic_loss     | 0.0361   |\n",
            "|    ent_coef        | 0.00198  |\n",
            "|    ent_coef_loss   | 0.34     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 342998   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.26e+03 |\n",
            "|    ep_rew_mean     | -67.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 150      |\n",
            "|    total_timesteps | 174953   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.85     |\n",
            "|    critic_loss     | 0.0321   |\n",
            "|    ent_coef        | 0.00177  |\n",
            "|    ent_coef_loss   | 0.116    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 349704   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -27.46 ± 4.03\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.27e+03 |\n",
            "|    ep_rew_mean     | -65.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 46       |\n",
            "|    total_timesteps | 181600   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.18     |\n",
            "|    critic_loss     | 0.0923   |\n",
            "|    ent_coef        | 0.0018   |\n",
            "|    ent_coef_loss   | -0.321   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 362998   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.32e+03 |\n",
            "|    ep_rew_mean     | -62.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 230      |\n",
            "|    total_timesteps | 188000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.07     |\n",
            "|    critic_loss     | 0.0165   |\n",
            "|    ent_coef        | 0.00175  |\n",
            "|    ent_coef_loss   | 2.27     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 375798   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: -36.03 ± 4.22\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.33e+03 |\n",
            "|    ep_rew_mean     | -60.2    |\n",
            "| time/              |          |\n",
            "|    episodes        | 176      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 143      |\n",
            "|    total_timesteps | 194800   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.48     |\n",
            "|    critic_loss     | 0.36     |\n",
            "|    ent_coef        | 0.00184  |\n",
            "|    ent_coef_loss   | -0.237   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 389398   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.33e+03 |\n",
            "|    ep_rew_mean     | -59      |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 286      |\n",
            "|    total_timesteps | 199669   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.08     |\n",
            "|    critic_loss     | 0.0337   |\n",
            "|    ent_coef        | 0.00168  |\n",
            "|    ent_coef_loss   | 0.232    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 399136   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: -80.07 ± 23.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=1, batch size= 64, lr= 3e-4"
      ],
      "metadata": {
        "id": "d__engEWxidZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker3():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=1)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/\",\n",
        "                learning_rate=3e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64\")"
      ],
      "metadata": {
        "id": "bnviimltxoZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker3()"
      ],
      "metadata": {
        "id": "zYHpa67gxr7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=1, batch size= 128, lr= 3e-4"
      ],
      "metadata": {
        "id": "Khw2A7o2yJcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker4():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=1)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/\",\n",
        "                learning_rate=3e-4, buffer_size=500000, batch_size=128, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128\")"
      ],
      "metadata": {
        "id": "WBgL8VbEyQ_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker4()"
      ],
      "metadata": {
        "id": "6vXUm1sVyXAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=4, batch size= 64, lr= 1e-4"
      ],
      "metadata": {
        "id": "A57LwjaZyn36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker5():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=4)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/\",\n",
        "                learning_rate=1e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64\")"
      ],
      "metadata": {
        "id": "NP9Rc1QVzA-x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker5()"
      ],
      "metadata": {
        "id": "q_0x4o7wz-7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f3ba21f-6a2e-44bc-8e70-74bd4e2b2cf1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 82.2     |\n",
            "|    ep_rew_mean     | -117     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 207      |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 388      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.56    |\n",
            "|    critic_loss     | 89.3     |\n",
            "|    ent_coef        | 0.986    |\n",
            "|    ent_coef_loss   | -0.0943  |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 142      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 77.2     |\n",
            "|    ep_rew_mean     | -112     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 182      |\n",
            "|    time_elapsed    | 5        |\n",
            "|    total_timesteps | 924      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.8    |\n",
            "|    critic_loss     | 7.44     |\n",
            "|    ent_coef        | 0.96     |\n",
            "|    ent_coef_loss   | -0.25    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 410      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 84.9     |\n",
            "|    ep_rew_mean     | -109     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 119      |\n",
            "|    time_elapsed    | 13       |\n",
            "|    total_timesteps | 1580     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -68.3    |\n",
            "|    critic_loss     | 301      |\n",
            "|    ent_coef        | 0.932    |\n",
            "|    ent_coef_loss   | -0.416   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 738      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 103      |\n",
            "|    ep_rew_mean     | -108     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 124      |\n",
            "|    time_elapsed    | 17       |\n",
            "|    total_timesteps | 2188     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -76.8    |\n",
            "|    critic_loss     | 7.47     |\n",
            "|    ent_coef        | 0.904    |\n",
            "|    ent_coef_loss   | -0.635   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1042     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 326      |\n",
            "|    ep_rew_mean     | -103     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 148      |\n",
            "|    time_elapsed    | 56       |\n",
            "|    total_timesteps | 8348     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -151     |\n",
            "|    critic_loss     | 86.6     |\n",
            "|    ent_coef        | 0.666    |\n",
            "|    ent_coef_loss   | -2.39    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4122     |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -45.89 ± 4.13\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 505      |\n",
            "|    ep_rew_mean     | -98.3    |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 154      |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 16400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -90.1    |\n",
            "|    critic_loss     | 31.7     |\n",
            "|    ent_coef        | 0.445    |\n",
            "|    ent_coef_loss   | -5       |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 8148     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 529      |\n",
            "|    ep_rew_mean     | -98.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 153      |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 17520    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -87      |\n",
            "|    critic_loss     | 27.6     |\n",
            "|    ent_coef        | 0.421    |\n",
            "|    ent_coef_loss   | -5.22    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 8708     |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -93.88 ± 14.53\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 527      |\n",
            "|    ep_rew_mean     | -100     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 146      |\n",
            "|    time_elapsed    | 4        |\n",
            "|    total_timesteps | 20616    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -74.2    |\n",
            "|    critic_loss     | 5.04     |\n",
            "|    ent_coef        | 0.361    |\n",
            "|    ent_coef_loss   | -6.27    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 10256    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 646      |\n",
            "|    ep_rew_mean     | -100     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 155      |\n",
            "|    time_elapsed    | 45       |\n",
            "|    total_timesteps | 27016    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -51.2    |\n",
            "|    critic_loss     | 3.42     |\n",
            "|    ent_coef        | 0.264    |\n",
            "|    ent_coef_loss   | -7.5     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 13456    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -64.08 ± 10.40\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 763      |\n",
            "|    ep_rew_mean     | -97.3    |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 154      |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 36400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.1    |\n",
            "|    critic_loss     | 1.29     |\n",
            "|    ent_coef        | 0.166    |\n",
            "|    ent_coef_loss   | -9.71    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 18148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -127.08 ± 41.17\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 761      |\n",
            "|    ep_rew_mean     | -98.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 143      |\n",
            "|    time_elapsed    | 4        |\n",
            "|    total_timesteps | 40616    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -21.4    |\n",
            "|    critic_loss     | 2.21     |\n",
            "|    ent_coef        | 0.134    |\n",
            "|    ent_coef_loss   | -10.5    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 20256    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 744      |\n",
            "|    ep_rew_mean     | -100     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 164      |\n",
            "|    time_elapsed    | 14       |\n",
            "|    total_timesteps | 42376    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.3    |\n",
            "|    critic_loss     | 0.985    |\n",
            "|    ent_coef        | 0.123    |\n",
            "|    ent_coef_loss   | -11.8    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 21136    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 781      |\n",
            "|    ep_rew_mean     | -99.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 159      |\n",
            "|    time_elapsed    | 46       |\n",
            "|    total_timesteps | 47480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13.6    |\n",
            "|    critic_loss     | 1.14     |\n",
            "|    ent_coef        | 0.0951   |\n",
            "|    ent_coef_loss   | -13.1    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 23688    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -122.93 ± 0.20\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 757      |\n",
            "|    ep_rew_mean     | -99.7    |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 125      |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 50312    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17.7    |\n",
            "|    critic_loss     | 0.671    |\n",
            "|    ent_coef        | 0.0828   |\n",
            "|    ent_coef_loss   | -12.4    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 25104    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 763      |\n",
            "|    ep_rew_mean     | -99.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 158      |\n",
            "|    time_elapsed    | 42       |\n",
            "|    total_timesteps | 56696    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.4    |\n",
            "|    critic_loss     | 0.422    |\n",
            "|    ent_coef        | 0.0606   |\n",
            "|    ent_coef_loss   | -14      |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 28296    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -54.64 ± 7.61\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 839      |\n",
            "|    ep_rew_mean     | -97.2    |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 157      |\n",
            "|    time_elapsed    | 40       |\n",
            "|    total_timesteps | 66400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.38    |\n",
            "|    critic_loss     | 4.95     |\n",
            "|    ent_coef        | 0.0374   |\n",
            "|    ent_coef_loss   | -16.7    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 33148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -109.09 ± 2.86\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 816      |\n",
            "|    ep_rew_mean     | -97.3    |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 164      |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 70264    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.6     |\n",
            "|    critic_loss     | 0.34     |\n",
            "|    ent_coef        | 0.0309   |\n",
            "|    ent_coef_loss   | -16.2    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 35080    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 817      |\n",
            "|    ep_rew_mean     | -98.7    |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 165      |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 70644    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.59    |\n",
            "|    critic_loss     | 0.201    |\n",
            "|    ent_coef        | 0.0304   |\n",
            "|    ent_coef_loss   | -16      |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 35270    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 790      |\n",
            "|    ep_rew_mean     | -100     |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 153      |\n",
            "|    time_elapsed    | 11       |\n",
            "|    total_timesteps | 71740    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.506   |\n",
            "|    critic_loss     | 0.419    |\n",
            "|    ent_coef        | 0.0288   |\n",
            "|    ent_coef_loss   | -17      |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 35818    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 754      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 157      |\n",
            "|    time_elapsed    | 15       |\n",
            "|    total_timesteps | 72376    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.895    |\n",
            "|    critic_loss     | 0.456    |\n",
            "|    ent_coef        | 0.028    |\n",
            "|    ent_coef_loss   | -12.8    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 36136    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 721      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 158      |\n",
            "|    time_elapsed    | 17       |\n",
            "|    total_timesteps | 72816    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.28    |\n",
            "|    critic_loss     | 0.795    |\n",
            "|    ent_coef        | 0.0275   |\n",
            "|    ent_coef_loss   | -11.9    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 36356    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 692      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 157      |\n",
            "|    time_elapsed    | 25       |\n",
            "|    total_timesteps | 73992    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.13    |\n",
            "|    critic_loss     | 0.483    |\n",
            "|    ent_coef        | 0.0262   |\n",
            "|    ent_coef_loss   | -10.1    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 36944    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 714      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 156      |\n",
            "|    time_elapsed    | 58       |\n",
            "|    total_timesteps | 79216    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.01    |\n",
            "|    critic_loss     | 0.418    |\n",
            "|    ent_coef        | 0.0206   |\n",
            "|    ent_coef_loss   | -13.5    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 39556    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -86.61 ± 1.68\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 751      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 155      |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 86400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.325    |\n",
            "|    critic_loss     | 0.401    |\n",
            "|    ent_coef        | 0.0147   |\n",
            "|    ent_coef_loss   | -16.3    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 43148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -96.46 ± 9.00\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 785      |\n",
            "|    ep_rew_mean     | -100     |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 161      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 96400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.14     |\n",
            "|    critic_loss     | 0.206    |\n",
            "|    ent_coef        | 0.00909  |\n",
            "|    ent_coef_loss   | -13.9    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 48148    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 787      |\n",
            "|    ep_rew_mean     | -100     |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 162      |\n",
            "|    time_elapsed    | 45       |\n",
            "|    total_timesteps | 97364    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.87     |\n",
            "|    critic_loss     | 0.579    |\n",
            "|    ent_coef        | 0.0087   |\n",
            "|    ent_coef_loss   | -11.2    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 48630    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 790      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 162      |\n",
            "|    time_elapsed    | 51       |\n",
            "|    total_timesteps | 98428    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.32     |\n",
            "|    critic_loss     | 0.385    |\n",
            "|    ent_coef        | 0.00836  |\n",
            "|    ent_coef_loss   | -13      |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 49162    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: -97.06 ± 14.10\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 856      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 159      |\n",
            "|    time_elapsed    | 40       |\n",
            "|    total_timesteps | 106400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.55     |\n",
            "|    critic_loss     | 0.694    |\n",
            "|    ent_coef        | 0.0064   |\n",
            "|    ent_coef_loss   | -10.4    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 53148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -64.01 ± 9.00\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 898      |\n",
            "|    ep_rew_mean     | -100     |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 161      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 116400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.97     |\n",
            "|    critic_loss     | 0.362    |\n",
            "|    ent_coef        | 0.00445  |\n",
            "|    ent_coef_loss   | -4.5     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 58148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -106.92 ± 0.04\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 912      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 164      |\n",
            "|    time_elapsed    | 38       |\n",
            "|    total_timesteps | 126400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.08     |\n",
            "|    critic_loss     | 1.07     |\n",
            "|    ent_coef        | 0.00389  |\n",
            "|    ent_coef_loss   | 0.574    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 63148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -121.47 ± 0.91\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 897      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 187      |\n",
            "|    time_elapsed    | 0        |\n",
            "|    total_timesteps | 130144   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.145    |\n",
            "|    critic_loss     | 0.335    |\n",
            "|    ent_coef        | 0.00434  |\n",
            "|    ent_coef_loss   | 0.646    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 65020    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 889      |\n",
            "|    ep_rew_mean     | -103     |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 162      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 136400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.94     |\n",
            "|    critic_loss     | 6.32     |\n",
            "|    ent_coef        | 0.00359  |\n",
            "|    ent_coef_loss   | 4.56     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 68148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -50.85 ± 10.53\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 918      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 160      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 146400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.36     |\n",
            "|    critic_loss     | 0.0724   |\n",
            "|    ent_coef        | 0.0025   |\n",
            "|    ent_coef_loss   | -7       |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 73148    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 889      |\n",
            "|    ep_rew_mean     | -102     |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 158      |\n",
            "|    time_elapsed    | 44       |\n",
            "|    total_timesteps | 147112   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.08     |\n",
            "|    critic_loss     | 0.319    |\n",
            "|    ent_coef        | 0.00247  |\n",
            "|    ent_coef_loss   | -3.76    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 73504    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 831      |\n",
            "|    ep_rew_mean     | -103     |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 159      |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 147640   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.36     |\n",
            "|    critic_loss     | 0.391    |\n",
            "|    ent_coef        | 0.00244  |\n",
            "|    ent_coef_loss   | 0.831    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 73768    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 799      |\n",
            "|    ep_rew_mean     | -103     |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 158      |\n",
            "|    time_elapsed    | 57       |\n",
            "|    total_timesteps | 149084   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.09     |\n",
            "|    critic_loss     | 0.558    |\n",
            "|    ent_coef        | 0.00234  |\n",
            "|    ent_coef_loss   | -6.11    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 74490    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: -108.29 ± 0.05\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 780      |\n",
            "|    ep_rew_mean     | -103     |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 180      |\n",
            "|    time_elapsed    | 0        |\n",
            "|    total_timesteps | 150168   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.31     |\n",
            "|    critic_loss     | 0.3      |\n",
            "|    ent_coef        | 0.00227  |\n",
            "|    ent_coef_loss   | -1.21    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 75032    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 764      |\n",
            "|    ep_rew_mean     | -103     |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 162      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 156400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.47     |\n",
            "|    critic_loss     | 0.337    |\n",
            "|    ent_coef        | 0.00237  |\n",
            "|    ent_coef_loss   | 6.77     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 78148    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 764      |\n",
            "|    ep_rew_mean     | -103     |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 159      |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 156700   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.43     |\n",
            "|    critic_loss     | 0.556    |\n",
            "|    ent_coef        | 0.00239  |\n",
            "|    ent_coef_loss   | 4.1      |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 78298    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -91.88 ± 11.65\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 794      |\n",
            "|    ep_rew_mean     | -102     |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 160      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 166400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.1      |\n",
            "|    critic_loss     | 0.256    |\n",
            "|    ent_coef        | 0.00231  |\n",
            "|    ent_coef_loss   | 2.53     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 83148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -61.43 ± 7.71\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 794      |\n",
            "|    ep_rew_mean     | -102     |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 154      |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 176400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.08     |\n",
            "|    critic_loss     | 0.328    |\n",
            "|    ent_coef        | 0.00224  |\n",
            "|    ent_coef_loss   | 3.53     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 88148    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 779      |\n",
            "|    ep_rew_mean     | -103     |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 155      |\n",
            "|    time_elapsed    | 43       |\n",
            "|    total_timesteps | 176796   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.1      |\n",
            "|    critic_loss     | 0.358    |\n",
            "|    ent_coef        | 0.00224  |\n",
            "|    ent_coef_loss   | 0.709    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 88346    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -74.22 ± 6.46\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 801      |\n",
            "|    ep_rew_mean     | -99.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 156      |\n",
            "|    time_elapsed    | 40       |\n",
            "|    total_timesteps | 186400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.5      |\n",
            "|    critic_loss     | 0.402    |\n",
            "|    ent_coef        | 0.0021   |\n",
            "|    ent_coef_loss   | 4.74     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 93148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: -49.35 ± 6.46\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 813      |\n",
            "|    ep_rew_mean     | -100     |\n",
            "| time/              |          |\n",
            "|    episodes        | 176      |\n",
            "|    fps             | 156      |\n",
            "|    time_elapsed    | 12       |\n",
            "|    total_timesteps | 191892   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.35     |\n",
            "|    critic_loss     | 0.4      |\n",
            "|    ent_coef        | 0.00201  |\n",
            "|    ent_coef_loss   | 4.91     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 95894    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 852      |\n",
            "|    ep_rew_mean     | -100     |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 159      |\n",
            "|    time_elapsed    | 51       |\n",
            "|    total_timesteps | 198292   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.93     |\n",
            "|    critic_loss     | 0.083    |\n",
            "|    ent_coef        | 0.00206  |\n",
            "|    ent_coef_loss   | -0.602   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 99094    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: -60.88 ± 6.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=4, batch size= 128, lr= 1e-4"
      ],
      "metadata": {
        "id": "zJKqGMFdyu9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker6():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=4)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/\",\n",
        "                learning_rate=1e-4, buffer_size=500000, batch_size=128, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128\")"
      ],
      "metadata": {
        "id": "RmPsFe9Nzv1U"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker6()"
      ],
      "metadata": {
        "id": "izU9O7CV0BF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6888e3a6-f876-4481-9db7-5b1e6ee7fff8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 69.2     |\n",
            "|    ep_rew_mean     | -109     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 146      |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 304      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.39    |\n",
            "|    critic_loss     | 45.7     |\n",
            "|    ent_coef        | 0.99     |\n",
            "|    ent_coef_loss   | -0.0665  |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 100      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 87.1     |\n",
            "|    ep_rew_mean     | -114     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 139      |\n",
            "|    time_elapsed    | 6        |\n",
            "|    total_timesteps | 952      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -42.6    |\n",
            "|    critic_loss     | 129      |\n",
            "|    ent_coef        | 0.959    |\n",
            "|    ent_coef_loss   | -0.253   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 424      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 93       |\n",
            "|    ep_rew_mean     | -112     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 140      |\n",
            "|    time_elapsed    | 8        |\n",
            "|    total_timesteps | 1248     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -57.4    |\n",
            "|    critic_loss     | 76.2     |\n",
            "|    ent_coef        | 0.946    |\n",
            "|    ent_coef_loss   | -0.356   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 572      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 186      |\n",
            "|    ep_rew_mean     | -111     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 56       |\n",
            "|    total_timesteps | 7636     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -137     |\n",
            "|    critic_loss     | 4.38     |\n",
            "|    ent_coef        | 0.691    |\n",
            "|    ent_coef_loss   | -2.25    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3766     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 394      |\n",
            "|    ep_rew_mean     | -110     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 59       |\n",
            "|    total_timesteps | 8032     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -137     |\n",
            "|    critic_loss     | 8.67     |\n",
            "|    ent_coef        | 0.678    |\n",
            "|    ent_coef_loss   | -2.33    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3964     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 341      |\n",
            "|    ep_rew_mean     | -112     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 63       |\n",
            "|    total_timesteps | 8540     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -131     |\n",
            "|    critic_loss     | 58.9     |\n",
            "|    ent_coef        | 0.661    |\n",
            "|    ent_coef_loss   | -2.52    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4218     |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -34.31 ± 3.51\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 520      |\n",
            "|    ep_rew_mean     | -114     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 16400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -97.6    |\n",
            "|    critic_loss     | 5.49     |\n",
            "|    ent_coef        | 0.446    |\n",
            "|    ent_coef_loss   | -4.71    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 8148     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 464      |\n",
            "|    ep_rew_mean     | -113     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 16688    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -96.7    |\n",
            "|    critic_loss     | 5.53     |\n",
            "|    ent_coef        | 0.44     |\n",
            "|    ent_coef_loss   | -4.7     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 8292     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 421      |\n",
            "|    ep_rew_mean     | -113     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 52       |\n",
            "|    total_timesteps | 17072    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -95.1    |\n",
            "|    critic_loss     | 6        |\n",
            "|    ent_coef        | 0.432    |\n",
            "|    ent_coef_loss   | -4.75    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 8484     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 388      |\n",
            "|    ep_rew_mean     | -112     |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 56       |\n",
            "|    total_timesteps | 17524    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -86.5    |\n",
            "|    critic_loss     | 6.36     |\n",
            "|    ent_coef        | 0.423    |\n",
            "|    ent_coef_loss   | -4.65    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 8710     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 361      |\n",
            "|    ep_rew_mean     | -112     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 59       |\n",
            "|    total_timesteps | 17980    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -87.2    |\n",
            "|    critic_loss     | 10.4     |\n",
            "|    ent_coef        | 0.414    |\n",
            "|    ent_coef_loss   | -4.67    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 8938     |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -76.06 ± 9.66\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 337      |\n",
            "|    ep_rew_mean     | -111     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 20288    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -88.1    |\n",
            "|    critic_loss     | 5.85     |\n",
            "|    ent_coef        | 0.372    |\n",
            "|    ent_coef_loss   | -5.01    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 10092    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 405      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 26436    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -52.6    |\n",
            "|    critic_loss     | 8.28     |\n",
            "|    ent_coef        | 0.274    |\n",
            "|    ent_coef_loss   | -7.03    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 13166    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -126.54 ± 42.69\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 426      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 139      |\n",
            "|    time_elapsed    | 4        |\n",
            "|    total_timesteps | 30644    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.6    |\n",
            "|    critic_loss     | 3.5      |\n",
            "|    ent_coef        | 0.221    |\n",
            "|    ent_coef_loss   | -7.62    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 15270    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 429      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 132      |\n",
            "|    time_elapsed    | 36       |\n",
            "|    total_timesteps | 34808    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -23.4    |\n",
            "|    critic_loss     | 2.15     |\n",
            "|    ent_coef        | 0.18     |\n",
            "|    ent_coef_loss   | -9.4     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 17352    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 478      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 57       |\n",
            "|    total_timesteps | 37720    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.3    |\n",
            "|    critic_loss     | 1.45     |\n",
            "|    ent_coef        | 0.156    |\n",
            "|    ent_coef_loss   | -9.33    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 18808    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -61.48 ± 0.29\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 544      |\n",
            "|    ep_rew_mean     | -115     |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 46400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -15.4    |\n",
            "|    critic_loss     | 1.51     |\n",
            "|    ent_coef        | 0.101    |\n",
            "|    ent_coef_loss   | -11.9    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 23148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -46.10 ± 1.31\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 603      |\n",
            "|    ep_rew_mean     | -114     |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 56400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.3     |\n",
            "|    critic_loss     | 0.535    |\n",
            "|    ent_coef        | 0.0613   |\n",
            "|    ent_coef_loss   | -14.9    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 28148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -58.38 ± 5.36\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 656      |\n",
            "|    ep_rew_mean     | -113     |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 127      |\n",
            "|    time_elapsed    | 50       |\n",
            "|    total_timesteps | 66400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.991    |\n",
            "|    critic_loss     | 0.185    |\n",
            "|    ent_coef        | 0.0373   |\n",
            "|    ent_coef_loss   | -16.4    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 33148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -37.73 ± 1.74\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 703      |\n",
            "|    ep_rew_mean     | -112     |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 130      |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 76400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.52     |\n",
            "|    critic_loss     | 0.115    |\n",
            "|    ent_coef        | 0.0228   |\n",
            "|    ent_coef_loss   | -19.2    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 38148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -75.92 ± 21.69\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 745      |\n",
            "|    ep_rew_mean     | -111     |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 130      |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 86400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.54     |\n",
            "|    critic_loss     | 0.0605   |\n",
            "|    ent_coef        | 0.0139   |\n",
            "|    ent_coef_loss   | -20.7    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 43148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -56.64 ± 2.34\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 784      |\n",
            "|    ep_rew_mean     | -109     |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 131      |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 96400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.04     |\n",
            "|    critic_loss     | 0.0412   |\n",
            "|    ent_coef        | 0.00858  |\n",
            "|    ent_coef_loss   | -19.2    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 48148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: -82.05 ± 0.12\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 820      |\n",
            "|    ep_rew_mean     | -108     |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 132      |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 106400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.98     |\n",
            "|    critic_loss     | 0.301    |\n",
            "|    ent_coef        | 0.00536  |\n",
            "|    ent_coef_loss   | -11.1    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 53148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -67.80 ± 6.51\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 852      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 126      |\n",
            "|    time_elapsed    | 50       |\n",
            "|    total_timesteps | 116400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.4      |\n",
            "|    critic_loss     | 0.172    |\n",
            "|    ent_coef        | 0.00337  |\n",
            "|    ent_coef_loss   | -16.9    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 58148    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 822      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 126      |\n",
            "|    time_elapsed    | 55       |\n",
            "|    total_timesteps | 117008   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.82     |\n",
            "|    critic_loss     | 0.0174   |\n",
            "|    ent_coef        | 0.00327  |\n",
            "|    ent_coef_loss   | -13.8    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 58452    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 822      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 126      |\n",
            "|    time_elapsed    | 60       |\n",
            "|    total_timesteps | 117604   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.81     |\n",
            "|    critic_loss     | 0.128    |\n",
            "|    ent_coef        | 0.0032   |\n",
            "|    ent_coef_loss   | -7.26    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 58750    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 823      |\n",
            "|    ep_rew_mean     | -105     |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 126      |\n",
            "|    time_elapsed    | 64       |\n",
            "|    total_timesteps | 118196   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.4      |\n",
            "|    critic_loss     | 0.195    |\n",
            "|    ent_coef        | 0.00314  |\n",
            "|    ent_coef_loss   | -14.1    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 59046    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 824      |\n",
            "|    ep_rew_mean     | -105     |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 126      |\n",
            "|    time_elapsed    | 69       |\n",
            "|    total_timesteps | 118812   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.03     |\n",
            "|    critic_loss     | 0.136    |\n",
            "|    ent_coef        | 0.0031   |\n",
            "|    ent_coef_loss   | 4.32     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 59354    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -95.65 ± 0.46\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 870      |\n",
            "|    ep_rew_mean     | -105     |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 131      |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 126400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.04     |\n",
            "|    critic_loss     | 0.288    |\n",
            "|    ent_coef        | 0.00242  |\n",
            "|    ent_coef_loss   | -0.317   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 63148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -72.45 ± 32.54\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 885      |\n",
            "|    ep_rew_mean     | -103     |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 130      |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 136400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.28     |\n",
            "|    critic_loss     | 0.138    |\n",
            "|    ent_coef        | 0.00176  |\n",
            "|    ent_coef_loss   | -4.32    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 68148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -75.25 ± 2.44\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 946      |\n",
            "|    ep_rew_mean     | -102     |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 128      |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 146400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.72     |\n",
            "|    critic_loss     | 0.058    |\n",
            "|    ent_coef        | 0.0015   |\n",
            "|    ent_coef_loss   | -2.51    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 73148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: -46.59 ± 0.52\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 946      |\n",
            "|    ep_rew_mean     | -98.7    |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 128      |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 156400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.68     |\n",
            "|    critic_loss     | 0.129    |\n",
            "|    ent_coef        | 0.00127  |\n",
            "|    ent_coef_loss   | 6.33     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 78148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -57.45 ± 6.65\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.01e+03 |\n",
            "|    ep_rew_mean     | -96.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 127      |\n",
            "|    time_elapsed    | 50       |\n",
            "|    total_timesteps | 166400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.85     |\n",
            "|    critic_loss     | 0.935    |\n",
            "|    ent_coef        | 0.0012   |\n",
            "|    ent_coef_loss   | 6.52     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 83148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -52.42 ± 4.78\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.07e+03 |\n",
            "|    ep_rew_mean     | -93.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 125      |\n",
            "|    time_elapsed    | 50       |\n",
            "|    total_timesteps | 176400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.55     |\n",
            "|    critic_loss     | 0.0426   |\n",
            "|    ent_coef        | 0.00127  |\n",
            "|    ent_coef_loss   | -2.46    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 88148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -52.49 ± 5.40\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.13e+03 |\n",
            "|    ep_rew_mean     | -91.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 129      |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 186400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.82     |\n",
            "|    critic_loss     | 0.0364   |\n",
            "|    ent_coef        | 0.00129  |\n",
            "|    ent_coef_loss   | 2.41     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 93148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: -97.88 ± 28.26\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.17e+03 |\n",
            "|    ep_rew_mean     | -90.3    |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 128      |\n",
            "|    time_elapsed    | 20       |\n",
            "|    total_timesteps | 192632   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.14     |\n",
            "|    critic_loss     | 0.0601   |\n",
            "|    ent_coef        | 0.00128  |\n",
            "|    ent_coef_loss   | -3.36    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 96264    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.2e+03  |\n",
            "|    ep_rew_mean     | -89.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 128      |\n",
            "|    time_elapsed    | 59       |\n",
            "|    total_timesteps | 197628   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.31     |\n",
            "|    critic_loss     | 0.119    |\n",
            "|    ent_coef        | 0.00128  |\n",
            "|    ent_coef_loss   | 0.805    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 98762    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: -74.53 ± 1.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=4, batch size= 64, lr= 3e-4"
      ],
      "metadata": {
        "id": "tyP_scUayzA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker7():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=4)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/\",\n",
        "                learning_rate=3e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64\")"
      ],
      "metadata": {
        "id": "Zliw82kW0QhI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker7()"
      ],
      "metadata": {
        "id": "F45QMaRa0ayM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9a5ff7-8114-491f-97ee-32fbaf60f6e7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | -117     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 186      |\n",
            "|    time_elapsed    | 4        |\n",
            "|    total_timesteps | 912      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -89.6    |\n",
            "|    critic_loss     | 3.6      |\n",
            "|    ent_coef        | 0.888    |\n",
            "|    ent_coef_loss   | -0.742   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 404      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 110      |\n",
            "|    ep_rew_mean     | -112     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 183      |\n",
            "|    time_elapsed    | 6        |\n",
            "|    total_timesteps | 1256     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -109     |\n",
            "|    critic_loss     | 3.97     |\n",
            "|    ent_coef        | 0.845    |\n",
            "|    ent_coef_loss   | -1.09    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 576      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | -112     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 181      |\n",
            "|    time_elapsed    | 8        |\n",
            "|    total_timesteps | 1596     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -106     |\n",
            "|    critic_loss     | 11.5     |\n",
            "|    ent_coef        | 0.803    |\n",
            "|    ent_coef_loss   | -1.43    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 746      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 123      |\n",
            "|    ep_rew_mean     | -112     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 174      |\n",
            "|    time_elapsed    | 12       |\n",
            "|    total_timesteps | 2100     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -110     |\n",
            "|    critic_loss     | 467      |\n",
            "|    ent_coef        | 0.746    |\n",
            "|    ent_coef_loss   | -1.82    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 998      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 108      |\n",
            "|    ep_rew_mean     | -111     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 170      |\n",
            "|    time_elapsed    | 14       |\n",
            "|    total_timesteps | 2436     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -89.6    |\n",
            "|    critic_loss     | 175      |\n",
            "|    ent_coef        | 0.71     |\n",
            "|    ent_coef_loss   | -2.14    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1166     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 125      |\n",
            "|    ep_rew_mean     | -113     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 169      |\n",
            "|    time_elapsed    | 29       |\n",
            "|    total_timesteps | 5072     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -68.2    |\n",
            "|    critic_loss     | 45.2     |\n",
            "|    ent_coef        | 0.494    |\n",
            "|    ent_coef_loss   | -3.48    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2484     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 138      |\n",
            "|    ep_rew_mean     | -114     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 170      |\n",
            "|    time_elapsed    | 34       |\n",
            "|    total_timesteps | 5812     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -69      |\n",
            "|    critic_loss     | 46.8     |\n",
            "|    ent_coef        | 0.449    |\n",
            "|    ent_coef_loss   | -4.07    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2854     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 189      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 167      |\n",
            "|    time_elapsed    | 37       |\n",
            "|    total_timesteps | 6236     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -63.6    |\n",
            "|    critic_loss     | 31.9     |\n",
            "|    ent_coef        | 0.425    |\n",
            "|    ent_coef_loss   | -3.75    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3066     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 178      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 168      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 6596     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -54.6    |\n",
            "|    critic_loss     | 29.4     |\n",
            "|    ent_coef        | 0.405    |\n",
            "|    ent_coef_loss   | -4.18    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3246     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 174      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 168      |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 7056     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -44      |\n",
            "|    critic_loss     | 40.6     |\n",
            "|    ent_coef        | 0.38     |\n",
            "|    ent_coef_loss   | -4.12    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3476     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 165      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 168      |\n",
            "|    time_elapsed    | 43       |\n",
            "|    total_timesteps | 7308     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.1    |\n",
            "|    critic_loss     | 70       |\n",
            "|    ent_coef        | 0.368    |\n",
            "|    ent_coef_loss   | -4.23    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3602     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 159      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 169      |\n",
            "|    time_elapsed    | 46       |\n",
            "|    total_timesteps | 7900     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -21.7    |\n",
            "|    critic_loss     | 24.4     |\n",
            "|    ent_coef        | 0.339    |\n",
            "|    ent_coef_loss   | -4.86    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3898     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 170      |\n",
            "|    ep_rew_mean     | -117     |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 167      |\n",
            "|    time_elapsed    | 59       |\n",
            "|    total_timesteps | 9984     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.5    |\n",
            "|    critic_loss     | 30.5     |\n",
            "|    ent_coef        | 0.254    |\n",
            "|    ent_coef_loss   | -5.13    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4940     |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -101.41 ± 20.77\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 168      |\n",
            "|    ep_rew_mean     | -117     |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 158      |\n",
            "|    time_elapsed    | 9        |\n",
            "|    total_timesteps | 11492    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -50      |\n",
            "|    critic_loss     | 27       |\n",
            "|    ent_coef        | 0.208    |\n",
            "|    ent_coef_loss   | -5.97    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5694     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 248      |\n",
            "|    ep_rew_mean     | -119     |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 164      |\n",
            "|    time_elapsed    | 40       |\n",
            "|    total_timesteps | 16612    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -48.7    |\n",
            "|    critic_loss     | 14.8     |\n",
            "|    ent_coef        | 0.11     |\n",
            "|    ent_coef_loss   | -2.22    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8254     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 274      |\n",
            "|    ep_rew_mean     | -119     |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 163      |\n",
            "|    time_elapsed    | 46       |\n",
            "|    total_timesteps | 17604    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.1    |\n",
            "|    critic_loss     | 8.63     |\n",
            "|    ent_coef        | 0.0963   |\n",
            "|    ent_coef_loss   | -3.34    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8750     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 279      |\n",
            "|    ep_rew_mean     | -120     |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 163      |\n",
            "|    time_elapsed    | 57       |\n",
            "|    total_timesteps | 19440    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.3    |\n",
            "|    critic_loss     | 9.56     |\n",
            "|    ent_coef        | 0.077    |\n",
            "|    ent_coef_loss   | -4.01    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9668     |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -57.74 ± 4.40\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 347      |\n",
            "|    ep_rew_mean     | -120     |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 163      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 26400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.46    |\n",
            "|    critic_loss     | 5.33     |\n",
            "|    ent_coef        | 0.0334   |\n",
            "|    ent_coef_loss   | -5.97    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 13148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -72.52 ± 15.89\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 366      |\n",
            "|    ep_rew_mean     | -121     |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 162      |\n",
            "|    time_elapsed    | 20       |\n",
            "|    total_timesteps | 33392    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.05     |\n",
            "|    critic_loss     | 3.81     |\n",
            "|    ent_coef        | 0.0159   |\n",
            "|    ent_coef_loss   | 1.8      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 16644    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 401      |\n",
            "|    ep_rew_mean     | -120     |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 163      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 36400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.09     |\n",
            "|    critic_loss     | 2.77     |\n",
            "|    ent_coef        | 0.0132   |\n",
            "|    ent_coef_loss   | -1.75    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 18148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -127.84 ± 0.75\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 416      |\n",
            "|    ep_rew_mean     | -121     |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 159      |\n",
            "|    time_elapsed    | 29       |\n",
            "|    total_timesteps | 44772    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.59     |\n",
            "|    critic_loss     | 2.68     |\n",
            "|    ent_coef        | 0.00862  |\n",
            "|    ent_coef_loss   | -6.21    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 22334    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -94.40 ± 10.67\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 459      |\n",
            "|    ep_rew_mean     | -121     |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 162      |\n",
            "|    time_elapsed    | 26       |\n",
            "|    total_timesteps | 54260    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.2      |\n",
            "|    critic_loss     | 1.66     |\n",
            "|    ent_coef        | 0.00722  |\n",
            "|    ent_coef_loss   | -1.32    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 27078    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 498      |\n",
            "|    ep_rew_mean     | -120     |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 161      |\n",
            "|    time_elapsed    | 54       |\n",
            "|    total_timesteps | 58752    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.18     |\n",
            "|    critic_loss     | 1.08     |\n",
            "|    ent_coef        | 0.00586  |\n",
            "|    ent_coef_loss   | -1.49    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 29324    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -156.91 ± 3.44\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 529      |\n",
            "|    ep_rew_mean     | -120     |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 162      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 66400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.68     |\n",
            "|    critic_loss     | 0.509    |\n",
            "|    ent_coef        | 0.00544  |\n",
            "|    ent_coef_loss   | -3.45    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 33148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -85.60 ± 28.69\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 554      |\n",
            "|    ep_rew_mean     | -119     |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 158      |\n",
            "|    time_elapsed    | 15       |\n",
            "|    total_timesteps | 72464    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.08     |\n",
            "|    critic_loss     | 0.293    |\n",
            "|    ent_coef        | 0.00494  |\n",
            "|    ent_coef_loss   | 4.14     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 36180    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 613      |\n",
            "|    ep_rew_mean     | -117     |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 159      |\n",
            "|    time_elapsed    | 55       |\n",
            "|    total_timesteps | 78864    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.78     |\n",
            "|    critic_loss     | 0.593    |\n",
            "|    ent_coef        | 0.00438  |\n",
            "|    ent_coef_loss   | -6.37    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 39380    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -86.88 ± 11.17\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 673      |\n",
            "|    ep_rew_mean     | -115     |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 153      |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 86400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6        |\n",
            "|    critic_loss     | 0.783    |\n",
            "|    ent_coef        | 0.00343  |\n",
            "|    ent_coef_loss   | -4.64    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 43148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -47.01 ± 8.97\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 717      |\n",
            "|    ep_rew_mean     | -114     |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 163      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 96400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.1      |\n",
            "|    critic_loss     | 0.127    |\n",
            "|    ent_coef        | 0.00355  |\n",
            "|    ent_coef_loss   | 1.47     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 48148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: -39.62 ± 9.76\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 791      |\n",
            "|    ep_rew_mean     | -111     |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 166      |\n",
            "|    time_elapsed    | 38       |\n",
            "|    total_timesteps | 106400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.79     |\n",
            "|    critic_loss     | 0.606    |\n",
            "|    ent_coef        | 0.00319  |\n",
            "|    ent_coef_loss   | 5.62     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 53148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -49.43 ± 10.51\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 853      |\n",
            "|    ep_rew_mean     | -109     |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 161      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 116400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.32     |\n",
            "|    critic_loss     | 0.897    |\n",
            "|    ent_coef        | 0.00301  |\n",
            "|    ent_coef_loss   | -0.398   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 58148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -77.35 ± 29.79\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 886      |\n",
            "|    ep_rew_mean     | -108     |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 161      |\n",
            "|    time_elapsed    | 35       |\n",
            "|    total_timesteps | 125776   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.33     |\n",
            "|    critic_loss     | 0.977    |\n",
            "|    ent_coef        | 0.00266  |\n",
            "|    ent_coef_loss   | 4.8      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 62836    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -50.72 ± 20.11\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 910      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 172      |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 130252   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.96     |\n",
            "|    critic_loss     | 0.171    |\n",
            "|    ent_coef        | 0.00265  |\n",
            "|    ent_coef_loss   | -0.384   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 65074    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 947      |\n",
            "|    ep_rew_mean     | -103     |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 159      |\n",
            "|    time_elapsed    | 40       |\n",
            "|    total_timesteps | 136400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.24     |\n",
            "|    critic_loss     | 1.11     |\n",
            "|    ent_coef        | 0.00294  |\n",
            "|    ent_coef_loss   | -2.05    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 68148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -55.82 ± 15.04\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.01e+03 |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 154      |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 146400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.41     |\n",
            "|    critic_loss     | 0.271    |\n",
            "|    ent_coef        | 0.00259  |\n",
            "|    ent_coef_loss   | 9.96     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 73148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: -81.11 ± 2.21\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.07e+03 |\n",
            "|    ep_rew_mean     | -97.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 154      |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 156400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.4      |\n",
            "|    critic_loss     | 0.119    |\n",
            "|    ent_coef        | 0.00225  |\n",
            "|    ent_coef_loss   | -4.05    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 78148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -60.57 ± 0.50\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.12e+03 |\n",
            "|    ep_rew_mean     | -95.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 150      |\n",
            "|    time_elapsed    | 42       |\n",
            "|    total_timesteps | 166400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.32     |\n",
            "|    critic_loss     | 0.113    |\n",
            "|    ent_coef        | 0.00226  |\n",
            "|    ent_coef_loss   | -5.21    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 83148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -45.27 ± 12.17\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.19e+03 |\n",
            "|    ep_rew_mean     | -91.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 149      |\n",
            "|    time_elapsed    | 42       |\n",
            "|    total_timesteps | 176400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.59     |\n",
            "|    critic_loss     | 0.104    |\n",
            "|    ent_coef        | 0.00239  |\n",
            "|    ent_coef_loss   | -4.57    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 88148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -39.70 ± 15.72\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.24e+03 |\n",
            "|    ep_rew_mean     | -88.2    |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 148      |\n",
            "|    time_elapsed    | 43       |\n",
            "|    total_timesteps | 186400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.69     |\n",
            "|    critic_loss     | 0.63     |\n",
            "|    ent_coef        | 0.00223  |\n",
            "|    ent_coef_loss   | 3.84     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 93148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: -51.44 ± 49.85\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.27e+03 |\n",
            "|    ep_rew_mean     | -86.8    |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 151      |\n",
            "|    time_elapsed    | 36       |\n",
            "|    total_timesteps | 195564   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.14     |\n",
            "|    critic_loss     | 0.137    |\n",
            "|    ent_coef        | 0.002    |\n",
            "|    ent_coef_loss   | 1.69     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 97730    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: -41.22 ± 18.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=4, batch size= 128, lr= 3e-4"
      ],
      "metadata": {
        "id": "E3M98SlOy4c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker8():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=4)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/\",\n",
        "                learning_rate=3e-4, buffer_size=500000, batch_size=128, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128\")"
      ],
      "metadata": {
        "id": "5IOF8ZMs0foG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker8()"
      ],
      "metadata": {
        "id": "GSw85KrX035n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee407f1-0393-4270-fb8b-e4d6040ca4ee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 75       |\n",
            "|    ep_rew_mean     | -108     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 164      |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 616      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -67.1    |\n",
            "|    critic_loss     | 9.54     |\n",
            "|    ent_coef        | 0.928    |\n",
            "|    ent_coef_loss   | -0.439   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 256      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 91.9     |\n",
            "|    ep_rew_mean     | -109     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 150      |\n",
            "|    time_elapsed    | 9        |\n",
            "|    total_timesteps | 1388     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -90.8    |\n",
            "|    critic_loss     | 75.4     |\n",
            "|    ent_coef        | 0.83     |\n",
            "|    ent_coef_loss   | -1.09    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 642      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 126      |\n",
            "|    ep_rew_mean     | -110     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 140      |\n",
            "|    time_elapsed    | 14       |\n",
            "|    total_timesteps | 1972     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -93.7    |\n",
            "|    critic_loss     | 10.2     |\n",
            "|    ent_coef        | 0.762    |\n",
            "|    ent_coef_loss   | -1.68    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 934      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 130      |\n",
            "|    ep_rew_mean     | -109     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 139      |\n",
            "|    time_elapsed    | 19       |\n",
            "|    total_timesteps | 2740     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -98.1    |\n",
            "|    critic_loss     | 42.4     |\n",
            "|    ent_coef        | 0.682    |\n",
            "|    ent_coef_loss   | -2.17    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1318     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 140      |\n",
            "|    ep_rew_mean     | -110     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 139      |\n",
            "|    time_elapsed    | 21       |\n",
            "|    total_timesteps | 3060     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -90.1    |\n",
            "|    critic_loss     | 27.6     |\n",
            "|    ent_coef        | 0.652    |\n",
            "|    ent_coef_loss   | -2.48    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1478     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 137      |\n",
            "|    ep_rew_mean     | -111     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 25       |\n",
            "|    total_timesteps | 3500     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -97.1    |\n",
            "|    critic_loss     | 33.1     |\n",
            "|    ent_coef        | 0.614    |\n",
            "|    ent_coef_loss   | -2.32    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1698     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 132      |\n",
            "|    ep_rew_mean     | -112     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 28       |\n",
            "|    total_timesteps | 3924     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -86      |\n",
            "|    critic_loss     | 77.2     |\n",
            "|    ent_coef        | 0.58     |\n",
            "|    ent_coef_loss   | -2.7     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1910     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 128      |\n",
            "|    ep_rew_mean     | -111     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 30       |\n",
            "|    total_timesteps | 4200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -74.6    |\n",
            "|    critic_loss     | 53.9     |\n",
            "|    ent_coef        | 0.559    |\n",
            "|    ent_coef_loss   | -3.17    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2048     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 131      |\n",
            "|    ep_rew_mean     | -113     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 38       |\n",
            "|    total_timesteps | 5196     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.9    |\n",
            "|    critic_loss     | 35.4     |\n",
            "|    ent_coef        | 0.486    |\n",
            "|    ent_coef_loss   | -3.49    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2546     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 138      |\n",
            "|    ep_rew_mean     | -112     |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 44       |\n",
            "|    total_timesteps | 6112     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -27      |\n",
            "|    critic_loss     | 22       |\n",
            "|    ent_coef        | 0.428    |\n",
            "|    ent_coef_loss   | -3.91    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3004     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 205      |\n",
            "|    ep_rew_mean     | -118     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 68       |\n",
            "|    total_timesteps | 9328     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -24.3    |\n",
            "|    critic_loss     | 10.1     |\n",
            "|    ent_coef        | 0.275    |\n",
            "|    ent_coef_loss   | -5.91    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4612     |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -95.31 ± 41.92\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 251      |\n",
            "|    ep_rew_mean     | -121     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 25       |\n",
            "|    total_timesteps | 13452    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17      |\n",
            "|    critic_loss     | 6.72     |\n",
            "|    ent_coef        | 0.152    |\n",
            "|    ent_coef_loss   | -6.97    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6674     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 331      |\n",
            "|    ep_rew_mean     | -123     |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 71       |\n",
            "|    total_timesteps | 19532    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.1    |\n",
            "|    critic_loss     | 3.23     |\n",
            "|    ent_coef        | 0.073    |\n",
            "|    ent_coef_loss   | -6.48    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9714     |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -68.91 ± 16.19\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 375      |\n",
            "|    ep_rew_mean     | -123     |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 131      |\n",
            "|    time_elapsed    | 23       |\n",
            "|    total_timesteps | 23128    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.27    |\n",
            "|    critic_loss     | 1.34     |\n",
            "|    ent_coef        | 0.0435   |\n",
            "|    ent_coef_loss   | -9.28    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11512    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 369      |\n",
            "|    ep_rew_mean     | -122     |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 28       |\n",
            "|    total_timesteps | 23812    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.94    |\n",
            "|    critic_loss     | 2.41     |\n",
            "|    ent_coef        | 0.0395   |\n",
            "|    ent_coef_loss   | -6.32    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11854    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 355      |\n",
            "|    ep_rew_mean     | -121     |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 30       |\n",
            "|    total_timesteps | 24100    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.5      |\n",
            "|    critic_loss     | 4.88     |\n",
            "|    ent_coef        | 0.038    |\n",
            "|    ent_coef_loss   | -6.31    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11998    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 340      |\n",
            "|    ep_rew_mean     | -120     |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 131      |\n",
            "|    time_elapsed    | 35       |\n",
            "|    total_timesteps | 24704    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.68     |\n",
            "|    critic_loss     | 2.89     |\n",
            "|    ent_coef        | 0.0354   |\n",
            "|    ent_coef_loss   | -6.34    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 12300    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 328      |\n",
            "|    ep_rew_mean     | -120     |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 132      |\n",
            "|    time_elapsed    | 40       |\n",
            "|    total_timesteps | 25348    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.16     |\n",
            "|    critic_loss     | 5.15     |\n",
            "|    ent_coef        | 0.0326   |\n",
            "|    ent_coef_loss   | -6       |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 12622    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 325      |\n",
            "|    ep_rew_mean     | -120     |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 132      |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 26256    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.61     |\n",
            "|    critic_loss     | 1.34     |\n",
            "|    ent_coef        | 0.0295   |\n",
            "|    ent_coef_loss   | -4.93    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 13076    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 348      |\n",
            "|    ep_rew_mean     | -121     |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 132      |\n",
            "|    time_elapsed    | 74       |\n",
            "|    total_timesteps | 29836    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.48     |\n",
            "|    critic_loss     | 1.82     |\n",
            "|    ent_coef        | 0.019    |\n",
            "|    ent_coef_loss   | -5.52    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 14866    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -102.93 ± 19.17\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 350      |\n",
            "|    ep_rew_mean     | -121     |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 130      |\n",
            "|    time_elapsed    | 44       |\n",
            "|    total_timesteps | 35796    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.92     |\n",
            "|    critic_loss     | 1.29     |\n",
            "|    ent_coef        | 0.0107   |\n",
            "|    ent_coef_loss   | -3       |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 17846    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 390      |\n",
            "|    ep_rew_mean     | -121     |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 130      |\n",
            "|    time_elapsed    | 58       |\n",
            "|    total_timesteps | 37552    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.32     |\n",
            "|    critic_loss     | 1.56     |\n",
            "|    ent_coef        | 0.01     |\n",
            "|    ent_coef_loss   | -2.02    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 18724    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -5.53 ± 8.37\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 443      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 130      |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 46400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.63     |\n",
            "|    critic_loss     | 0.797    |\n",
            "|    ent_coef        | 0.00833  |\n",
            "|    ent_coef_loss   | -4.22    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 23148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -57.33 ± 22.48\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 444      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 50512    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.28     |\n",
            "|    critic_loss     | 0.714    |\n",
            "|    ent_coef        | 0.00716  |\n",
            "|    ent_coef_loss   | -5.14    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 25204    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 491      |\n",
            "|    ep_rew_mean     | -110     |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 131      |\n",
            "|    time_elapsed    | 52       |\n",
            "|    total_timesteps | 56912    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.93     |\n",
            "|    critic_loss     | 0.753    |\n",
            "|    ent_coef        | 0.00639  |\n",
            "|    ent_coef_loss   | 1.58     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 28404    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: 46.22 ± 43.80\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 531      |\n",
            "|    ep_rew_mean     | -107     |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 126      |\n",
            "|    time_elapsed    | 50       |\n",
            "|    total_timesteps | 66400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.806    |\n",
            "|    critic_loss     | 0.522    |\n",
            "|    ent_coef        | 0.00608  |\n",
            "|    ent_coef_loss   | -1.51    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 33148    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 559      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 128      |\n",
            "|    time_elapsed    | 71       |\n",
            "|    total_timesteps | 69184    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.797    |\n",
            "|    critic_loss     | 0.712    |\n",
            "|    ent_coef        | 0.00573  |\n",
            "|    ent_coef_loss   | 2.6      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 34540    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -71.72 ± 7.93\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 615      |\n",
            "|    ep_rew_mean     | -99.2    |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 76400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.467   |\n",
            "|    critic_loss     | 0.488    |\n",
            "|    ent_coef        | 0.00561  |\n",
            "|    ent_coef_loss   | -0.144   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 38148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -26.25 ± 73.64\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 672      |\n",
            "|    ep_rew_mean     | -88.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 46       |\n",
            "|    total_timesteps | 86400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.33    |\n",
            "|    critic_loss     | 0.245    |\n",
            "|    ent_coef        | 0.00523  |\n",
            "|    ent_coef_loss   | -1.21    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 43148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: 139.22 ± 59.06\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 723      |\n",
            "|    ep_rew_mean     | -78.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 130      |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 96400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.84    |\n",
            "|    critic_loss     | 0.301    |\n",
            "|    ent_coef        | 0.00635  |\n",
            "|    ent_coef_loss   | -0.942   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 48148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: 182.37 ± 86.18\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 738      |\n",
            "|    ep_rew_mean     | -77.3    |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 100424   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.19    |\n",
            "|    critic_loss     | 0.191    |\n",
            "|    ent_coef        | 0.00552  |\n",
            "|    ent_coef_loss   | -1.95    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 50160    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 798      |\n",
            "|    ep_rew_mean     | -65.2    |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 132      |\n",
            "|    time_elapsed    | 51       |\n",
            "|    total_timesteps | 106824   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.09    |\n",
            "|    critic_loss     | 0.305    |\n",
            "|    ent_coef        | 0.00629  |\n",
            "|    ent_coef_loss   | 0.738    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 53360    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: 224.24 ± 6.32\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 875      |\n",
            "|    ep_rew_mean     | -50.3    |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 132      |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 116400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.68    |\n",
            "|    critic_loss     | 0.444    |\n",
            "|    ent_coef        | 0.00545  |\n",
            "|    ent_coef_loss   | -0.958   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 58148    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 881      |\n",
            "|    ep_rew_mean     | -48.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 132      |\n",
            "|    time_elapsed    | 62       |\n",
            "|    total_timesteps | 118304   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.38    |\n",
            "|    critic_loss     | 0.423    |\n",
            "|    ent_coef        | 0.00578  |\n",
            "|    ent_coef_loss   | -2.36    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 59100    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: 227.09 ± 12.62\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 937      |\n",
            "|    ep_rew_mean     | -37.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 131      |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 126400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.95    |\n",
            "|    critic_loss     | 0.383    |\n",
            "|    ent_coef        | 0.00591  |\n",
            "|    ent_coef_loss   | -0.483   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 63148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: 200.47 ± 11.92\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 966      |\n",
            "|    ep_rew_mean     | -22.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 128      |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 136400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.26    |\n",
            "|    critic_loss     | 0.497    |\n",
            "|    ent_coef        | 0.00574  |\n",
            "|    ent_coef_loss   | 2.87     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 68148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: 243.54 ± 13.16\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 985      |\n",
            "|    ep_rew_mean     | -6.19    |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 124      |\n",
            "|    time_elapsed    | 51       |\n",
            "|    total_timesteps | 146400   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.37    |\n",
            "|    critic_loss     | 0.388    |\n",
            "|    ent_coef        | 0.00589  |\n",
            "|    ent_coef_loss   | 0.18     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 73148    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: 231.20 ± 12.84\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 976      |\n",
            "|    ep_rew_mean     | -1.46    |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 123      |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 155908   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.82    |\n",
            "|    critic_loss     | 0.35     |\n",
            "|    ent_coef        | 0.00552  |\n",
            "|    ent_coef_loss   | -0.395   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 77902    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: 201.93 ± 121.08\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 997      |\n",
            "|    ep_rew_mean     | 12.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 105      |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 160416   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.87    |\n",
            "|    critic_loss     | 0.406    |\n",
            "|    ent_coef        | 0.00604  |\n",
            "|    ent_coef_loss   | 0.365    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 80156    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.05e+03 |\n",
            "|    ep_rew_mean     | 27.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 120      |\n",
            "|    time_elapsed    | 51       |\n",
            "|    total_timesteps | 166248   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.6    |\n",
            "|    critic_loss     | 0.242    |\n",
            "|    ent_coef        | 0.00598  |\n",
            "|    ent_coef_loss   | 0.592    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 83072    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: 284.19 ± 1.90\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.09e+03 |\n",
            "|    ep_rew_mean     | 38.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 121      |\n",
            "|    time_elapsed    | 44       |\n",
            "|    total_timesteps | 175436   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.5    |\n",
            "|    critic_loss     | 0.315    |\n",
            "|    ent_coef        | 0.00578  |\n",
            "|    ent_coef_loss   | 3.67     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 87666    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: 289.14 ± 1.42\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.14e+03 |\n",
            "|    ep_rew_mean     | 54.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 119      |\n",
            "|    time_elapsed    | 44       |\n",
            "|    total_timesteps | 185284   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12.2    |\n",
            "|    critic_loss     | 0.21     |\n",
            "|    ent_coef        | 0.00637  |\n",
            "|    ent_coef_loss   | -2.15    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 92590    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: 289.98 ± 2.10\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.19e+03 |\n",
            "|    ep_rew_mean     | 69       |\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 118      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 194740   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.2    |\n",
            "|    critic_loss     | 0.328    |\n",
            "|    ent_coef        | 0.00719  |\n",
            "|    ent_coef_loss   | 1.81     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 97318    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.21e+03 |\n",
            "|    ep_rew_mean     | 80.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 176      |\n",
            "|    fps             | 119      |\n",
            "|    time_elapsed    | 45       |\n",
            "|    total_timesteps | 195428   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12.3    |\n",
            "|    critic_loss     | 0.527    |\n",
            "|    ent_coef        | 0.00714  |\n",
            "|    ent_coef_loss   | -1.11    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 97662    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: 46.87 ± 175.96\n"
          ]
        }
      ]
    }
  ]
}