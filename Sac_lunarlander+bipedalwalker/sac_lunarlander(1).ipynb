{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I08ysbNCpSI7","outputId":"24766768-4b00-421f-d126-19bbcd9d6b02"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stable_baselines3\n","  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n","Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.0.0)\n","Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n","Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n","Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.5.0\n"]}],"source":["pip install stable_baselines3"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-K5hh_2rwIzf","outputId":"67d6967a-8f65-4107-e304-2950a0368be7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["pip install box2d"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECjjcZ-opzYL","outputId":"d748cd61-3928-4da5-c2e2-35d503134c60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting box2d\n","  Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (573 bytes)\n","Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: box2d\n","Successfully installed box2d-2.3.10\n"]}]},{"cell_type":"code","source":["import multiprocessing\n","from stable_baselines3 import SAC\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.env_util import make_vec_env"],"metadata":{"id":"EOJbyToUp4Zx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, env, n_eval_episodes=10):\n","    \"\"\"Evaluate the model on a given environment and return mean and std rewards.\"\"\"\n","    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes)\n","    return mean_reward, std_reward"],"metadata":{"id":"cwiNPKwzp8Xb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SAC Lunar"],"metadata":{"id":"0_W45wJuuRZK"}},{"cell_type":"markdown","source":["env=1, batch size= 64, lr= 1e-4"],"metadata":{"id":"F35T9vmOuZlR"}},{"cell_type":"code","source":["def train_lunarlander1():\n","    # Create environment and model for LunarLander (continuous version for SAC)\n","    env_lunar = make_vec_env(\"LunarLanderContinuous-v3\", n_envs=1)\n","    model = SAC(\"MlpPolicy\", env_lunar, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/\",\n","                learning_rate=1e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n","                gamma=0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n","\n","    eval_freq = 10000  # Evaluate every 10,000 steps\n","    n_eval_episodes = 10  # Number of episodes per evaluation\n","\n","    for step in range(1, 200001, eval_freq):\n","        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n","        mean_reward, std_reward = evaluate_model(model, env_lunar, n_eval_episodes)\n","        print(f\"LunarLander - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n","\n","    model.save(\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64\")"],"metadata":{"id":"EylnIb_kp-mk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    train_lunarlander1()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Noyb706JqCMn","outputId":"f43ea9b5-0523-4a09-bbe8-daf1d1dc13c7"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n","<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n","<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n","/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n","  from pkg_resources import resource_stream, resource_exists\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n"]},{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 160      |\n","|    ep_rew_mean     | -263     |\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 30       |\n","|    time_elapsed    | 20       |\n","|    total_timesteps | 641      |\n","| train/             |          |\n","|    actor_loss      | -10.8    |\n","|    critic_loss     | 3.5      |\n","|    ent_coef        | 0.899    |\n","|    ent_coef_loss   | -0.34    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 1080     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 137      |\n","|    ep_rew_mean     | -181     |\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 30       |\n","|    time_elapsed    | 36       |\n","|    total_timesteps | 1098     |\n","| train/             |          |\n","|    actor_loss      | 7.12     |\n","|    critic_loss     | 40       |\n","|    ent_coef        | 0.822    |\n","|    ent_coef_loss   | -0.591   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 1994     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 184      |\n","|    ep_rew_mean     | -219     |\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 29       |\n","|    time_elapsed    | 75       |\n","|    total_timesteps | 2206     |\n","| train/             |          |\n","|    actor_loss      | 41.9     |\n","|    critic_loss     | 4.41     |\n","|    ent_coef        | 0.669    |\n","|    ent_coef_loss   | -1.1     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 4210     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 184      |\n","|    ep_rew_mean     | -214     |\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 29       |\n","|    time_elapsed    | 99       |\n","|    total_timesteps | 2941     |\n","| train/             |          |\n","|    actor_loss      | 41.8     |\n","|    critic_loss     | 17.5     |\n","|    ent_coef        | 0.581    |\n","|    ent_coef_loss   | -1.47    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 5680     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 191      |\n","|    ep_rew_mean     | -226     |\n","| time/              |          |\n","|    episodes        | 20       |\n","|    fps             | 29       |\n","|    time_elapsed    | 129      |\n","|    total_timesteps | 3826     |\n","| train/             |          |\n","|    actor_loss      | 29.7     |\n","|    critic_loss     | 6.15     |\n","|    ent_coef        | 0.491    |\n","|    ent_coef_loss   | -1.38    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 7450     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 189      |\n","|    ep_rew_mean     | -220     |\n","| time/              |          |\n","|    episodes        | 24       |\n","|    fps             | 29       |\n","|    time_elapsed    | 153      |\n","|    total_timesteps | 4544     |\n","| train/             |          |\n","|    actor_loss      | 31.2     |\n","|    critic_loss     | 11.2     |\n","|    ent_coef        | 0.428    |\n","|    ent_coef_loss   | -1.72    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 8886     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 197      |\n","|    ep_rew_mean     | -211     |\n","| time/              |          |\n","|    episodes        | 28       |\n","|    fps             | 29       |\n","|    time_elapsed    | 188      |\n","|    total_timesteps | 5514     |\n","| train/             |          |\n","|    actor_loss      | 21.8     |\n","|    critic_loss     | 7.26     |\n","|    ent_coef        | 0.355    |\n","|    ent_coef_loss   | -1.75    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 10826    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 283      |\n","|    ep_rew_mean     | -203     |\n","| time/              |          |\n","|    episodes        | 32       |\n","|    fps             | 28       |\n","|    time_elapsed    | 320      |\n","|    total_timesteps | 9065     |\n","| train/             |          |\n","|    actor_loss      | -3       |\n","|    critic_loss     | 5.35     |\n","|    ent_coef        | 0.183    |\n","|    ent_coef_loss   | -2.3     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 17928    |\n","---------------------------------\n","LunarLander - Step: 1 | Mean Reward: -83.58 ± 27.37\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 363      |\n","|    ep_rew_mean     | -185     |\n","| time/              |          |\n","|    episodes        | 36       |\n","|    fps             | 27       |\n","|    time_elapsed    | 143      |\n","|    total_timesteps | 14000    |\n","| train/             |          |\n","|    actor_loss      | -5.23    |\n","|    critic_loss     | 55.5     |\n","|    ent_coef        | 0.0746   |\n","|    ent_coef_loss   | -1.27    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 27798    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 427      |\n","|    ep_rew_mean     | -173     |\n","| time/              |          |\n","|    episodes        | 40       |\n","|    fps             | 27       |\n","|    time_elapsed    | 289      |\n","|    total_timesteps | 18000    |\n","| train/             |          |\n","|    actor_loss      | -16.3    |\n","|    critic_loss     | 2.52     |\n","|    ent_coef        | 0.0513   |\n","|    ent_coef_loss   | -0.923   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 35798    |\n","---------------------------------\n","LunarLander - Step: 10001 | Mean Reward: -53.60 ± 16.12\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 479      |\n","|    ep_rew_mean     | -163     |\n","| time/              |          |\n","|    episodes        | 44       |\n","|    fps             | 27       |\n","|    time_elapsed    | 72       |\n","|    total_timesteps | 22000    |\n","| train/             |          |\n","|    actor_loss      | -7.82    |\n","|    critic_loss     | 28.5     |\n","|    ent_coef        | 0.0521   |\n","|    ent_coef_loss   | -1.96    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 43798    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 512      |\n","|    ep_rew_mean     | -159     |\n","| time/              |          |\n","|    episodes        | 48       |\n","|    fps             | 27       |\n","|    time_elapsed    | 202      |\n","|    total_timesteps | 25510    |\n","| train/             |          |\n","|    actor_loss      | -6.05    |\n","|    critic_loss     | 2.17     |\n","|    ent_coef        | 0.0508   |\n","|    ent_coef_loss   | -0.716   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 50818    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 537      |\n","|    ep_rew_mean     | -158     |\n","| time/              |          |\n","|    episodes        | 52       |\n","|    fps             | 27       |\n","|    time_elapsed    | 326      |\n","|    total_timesteps | 28844    |\n","| train/             |          |\n","|    actor_loss      | -4.19    |\n","|    critic_loss     | 3.93     |\n","|    ent_coef        | 0.0473   |\n","|    ent_coef_loss   | 0.178    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 57486    |\n","---------------------------------\n","LunarLander - Step: 20001 | Mean Reward: -36.54 ± 34.60\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 570      |\n","|    ep_rew_mean     | -151     |\n","| time/              |          |\n","|    episodes        | 56       |\n","|    fps             | 27       |\n","|    time_elapsed    | 107      |\n","|    total_timesteps | 33000    |\n","| train/             |          |\n","|    actor_loss      | 0.526    |\n","|    critic_loss     | 9.59     |\n","|    ent_coef        | 0.0604   |\n","|    ent_coef_loss   | -2.02    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 65798    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 572      |\n","|    ep_rew_mean     | -145     |\n","| time/              |          |\n","|    episodes        | 60       |\n","|    fps             | 27       |\n","|    time_elapsed    | 196      |\n","|    total_timesteps | 35390    |\n","| train/             |          |\n","|    actor_loss      | -4.92    |\n","|    critic_loss     | 2.39     |\n","|    ent_coef        | 0.0568   |\n","|    ent_coef_loss   | 1.11     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 70578    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 570      |\n","|    ep_rew_mean     | -142     |\n","| time/              |          |\n","|    episodes        | 64       |\n","|    fps             | 27       |\n","|    time_elapsed    | 280      |\n","|    total_timesteps | 37602    |\n","| train/             |          |\n","|    actor_loss      | -3.52    |\n","|    critic_loss     | 1.97     |\n","|    ent_coef        | 0.061    |\n","|    ent_coef_loss   | 1.5      |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 75002    |\n","---------------------------------\n","LunarLander - Step: 30001 | Mean Reward: -67.24 ± 30.58\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 580      |\n","|    ep_rew_mean     | -137     |\n","| time/              |          |\n","|    episodes        | 68       |\n","|    fps             | 26       |\n","|    time_elapsed    | 42       |\n","|    total_timesteps | 41130    |\n","| train/             |          |\n","|    actor_loss      | 2.19     |\n","|    critic_loss     | 1.65     |\n","|    ent_coef        | 0.0526   |\n","|    ent_coef_loss   | -1.03    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 82058    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 598      |\n","|    ep_rew_mean     | -135     |\n","| time/              |          |\n","|    episodes        | 72       |\n","|    fps             | 26       |\n","|    time_elapsed    | 180      |\n","|    total_timesteps | 44760    |\n","| train/             |          |\n","|    actor_loss      | -3.29    |\n","|    critic_loss     | 1.69     |\n","|    ent_coef        | 0.0455   |\n","|    ent_coef_loss   | -0.215   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 89318    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 619      |\n","|    ep_rew_mean     | -131     |\n","| time/              |          |\n","|    episodes        | 76       |\n","|    fps             | 26       |\n","|    time_elapsed    | 331      |\n","|    total_timesteps | 48760    |\n","| train/             |          |\n","|    actor_loss      | 1.02     |\n","|    critic_loss     | 4.96     |\n","|    ent_coef        | 0.0409   |\n","|    ent_coef_loss   | 0.534    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 97318    |\n","---------------------------------\n","LunarLander - Step: 40001 | Mean Reward: -95.26 ± 78.63\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 638      |\n","|    ep_rew_mean     | -127     |\n","| time/              |          |\n","|    episodes        | 80       |\n","|    fps             | 26       |\n","|    time_elapsed    | 114      |\n","|    total_timesteps | 53000    |\n","| train/             |          |\n","|    actor_loss      | 0.4      |\n","|    critic_loss     | 6.98     |\n","|    ent_coef        | 0.0384   |\n","|    ent_coef_loss   | 0.494    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 105798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 654      |\n","|    ep_rew_mean     | -125     |\n","| time/              |          |\n","|    episodes        | 84       |\n","|    fps             | 25       |\n","|    time_elapsed    | 266      |\n","|    total_timesteps | 56869    |\n","| train/             |          |\n","|    actor_loss      | 1.02     |\n","|    critic_loss     | 2.12     |\n","|    ent_coef        | 0.0291   |\n","|    ent_coef_loss   | 0.91     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 113536   |\n","---------------------------------\n","LunarLander - Step: 50001 | Mean Reward: -104.27 ± 34.54\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 670      |\n","|    ep_rew_mean     | -122     |\n","| time/              |          |\n","|    episodes        | 88       |\n","|    fps             | 27       |\n","|    time_elapsed    | 36       |\n","|    total_timesteps | 61000    |\n","| train/             |          |\n","|    actor_loss      | 1.78     |\n","|    critic_loss     | 1.61     |\n","|    ent_coef        | 0.0284   |\n","|    ent_coef_loss   | 0.886    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 121798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 675      |\n","|    ep_rew_mean     | -122     |\n","| time/              |          |\n","|    episodes        | 92       |\n","|    fps             | 26       |\n","|    time_elapsed    | 157      |\n","|    total_timesteps | 64162    |\n","| train/             |          |\n","|    actor_loss      | -1.51    |\n","|    critic_loss     | 3        |\n","|    ent_coef        | 0.0325   |\n","|    ent_coef_loss   | 2.19     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 128122   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 674      |\n","|    ep_rew_mean     | -125     |\n","| time/              |          |\n","|    episodes        | 96       |\n","|    fps             | 26       |\n","|    time_elapsed    | 253      |\n","|    total_timesteps | 66745    |\n","| train/             |          |\n","|    actor_loss      | 4.51     |\n","|    critic_loss     | 1.61     |\n","|    ent_coef        | 0.0386   |\n","|    ent_coef_loss   | 0.865    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 133288   |\n","---------------------------------\n","LunarLander - Step: 60001 | Mean Reward: -91.22 ± 78.96\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 682      |\n","|    ep_rew_mean     | -124     |\n","| time/              |          |\n","|    episodes        | 100      |\n","|    fps             | 26       |\n","|    time_elapsed    | 30       |\n","|    total_timesteps | 70790    |\n","| train/             |          |\n","|    actor_loss      | -2.59    |\n","|    critic_loss     | 1.12     |\n","|    ent_coef        | 0.0463   |\n","|    ent_coef_loss   | -2.31    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 141378   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 706      |\n","|    ep_rew_mean     | -116     |\n","| time/              |          |\n","|    episodes        | 104      |\n","|    fps             | 26       |\n","|    time_elapsed    | 147      |\n","|    total_timesteps | 73880    |\n","| train/             |          |\n","|    actor_loss      | 0.0331   |\n","|    critic_loss     | 1.57     |\n","|    ent_coef        | 0.0372   |\n","|    ent_coef_loss   | -0.343   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 147558   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 742      |\n","|    ep_rew_mean     | -114     |\n","| time/              |          |\n","|    episodes        | 108      |\n","|    fps             | 26       |\n","|    time_elapsed    | 299      |\n","|    total_timesteps | 77880    |\n","| train/             |          |\n","|    actor_loss      | 0.949    |\n","|    critic_loss     | 1.21     |\n","|    ent_coef        | 0.0336   |\n","|    ent_coef_loss   | -1.62    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 155558   |\n","---------------------------------\n","LunarLander - Step: 70001 | Mean Reward: -45.76 ± 25.25\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 771      |\n","|    ep_rew_mean     | -106     |\n","| time/              |          |\n","|    episodes        | 112      |\n","|    fps             | 25       |\n","|    time_elapsed    | 77       |\n","|    total_timesteps | 82000    |\n","| train/             |          |\n","|    actor_loss      | -1.42    |\n","|    critic_loss     | 0.793    |\n","|    ent_coef        | 0.0282   |\n","|    ent_coef_loss   | -0.771   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 163798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 803      |\n","|    ep_rew_mean     | -100     |\n","| time/              |          |\n","|    episodes        | 116      |\n","|    fps             | 26       |\n","|    time_elapsed    | 229      |\n","|    total_timesteps | 86000    |\n","| train/             |          |\n","|    actor_loss      | 4.76     |\n","|    critic_loss     | 0.87     |\n","|    ent_coef        | 0.0257   |\n","|    ent_coef_loss   | -0.484   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 171798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 835      |\n","|    ep_rew_mean     | -90.4    |\n","| time/              |          |\n","|    episodes        | 120      |\n","|    fps             | 26       |\n","|    time_elapsed    | 377      |\n","|    total_timesteps | 90000    |\n","| train/             |          |\n","|    actor_loss      | 3.76     |\n","|    critic_loss     | 0.671    |\n","|    ent_coef        | 0.0262   |\n","|    ent_coef_loss   | -1.39    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 179798   |\n","---------------------------------\n","LunarLander - Step: 80001 | Mean Reward: -29.96 ± 22.37\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 867      |\n","|    ep_rew_mean     | -85.1    |\n","| time/              |          |\n","|    episodes        | 124      |\n","|    fps             | 26       |\n","|    time_elapsed    | 148      |\n","|    total_timesteps | 94000    |\n","| train/             |          |\n","|    actor_loss      | 0.268    |\n","|    critic_loss     | 17       |\n","|    ent_coef        | 0.0217   |\n","|    ent_coef_loss   | 0.875    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 187798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 898      |\n","|    ep_rew_mean     | -82      |\n","| time/              |          |\n","|    episodes        | 128      |\n","|    fps             | 27       |\n","|    time_elapsed    | 294      |\n","|    total_timesteps | 98000    |\n","| train/             |          |\n","|    actor_loss      | 1.5      |\n","|    critic_loss     | 1.27     |\n","|    ent_coef        | 0.0258   |\n","|    ent_coef_loss   | -1.22    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 195798   |\n","---------------------------------\n","LunarLander - Step: 90001 | Mean Reward: -55.06 ± 22.58\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 900      |\n","|    ep_rew_mean     | -80      |\n","| time/              |          |\n","|    episodes        | 132      |\n","|    fps             | 26       |\n","|    time_elapsed    | 76       |\n","|    total_timesteps | 102000   |\n","| train/             |          |\n","|    actor_loss      | 5.48     |\n","|    critic_loss     | 0.773    |\n","|    ent_coef        | 0.0234   |\n","|    ent_coef_loss   | -1.55    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 203798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 900      |\n","|    ep_rew_mean     | -79.5    |\n","| time/              |          |\n","|    episodes        | 136      |\n","|    fps             | 26       |\n","|    time_elapsed    | 223      |\n","|    total_timesteps | 106000   |\n","| train/             |          |\n","|    actor_loss      | 6.92     |\n","|    critic_loss     | 0.683    |\n","|    ent_coef        | 0.0211   |\n","|    ent_coef_loss   | -0.212   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 211798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 900      |\n","|    ep_rew_mean     | -78.3    |\n","| time/              |          |\n","|    episodes        | 140      |\n","|    fps             | 26       |\n","|    time_elapsed    | 370      |\n","|    total_timesteps | 110000   |\n","| train/             |          |\n","|    actor_loss      | 0.492    |\n","|    critic_loss     | 0.697    |\n","|    ent_coef        | 0.0215   |\n","|    ent_coef_loss   | 1.41     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 219798   |\n","---------------------------------\n","LunarLander - Step: 100001 | Mean Reward: -37.64 ± 18.47\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 900      |\n","|    ep_rew_mean     | -76.7    |\n","| time/              |          |\n","|    episodes        | 144      |\n","|    fps             | 26       |\n","|    time_elapsed    | 151      |\n","|    total_timesteps | 114000   |\n","| train/             |          |\n","|    actor_loss      | 4.25     |\n","|    critic_loss     | 0.801    |\n","|    ent_coef        | 0.0224   |\n","|    ent_coef_loss   | -0.235   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 227798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 905      |\n","|    ep_rew_mean     | -73.6    |\n","| time/              |          |\n","|    episodes        | 148      |\n","|    fps             | 26       |\n","|    time_elapsed    | 302      |\n","|    total_timesteps | 118000   |\n","| train/             |          |\n","|    actor_loss      | 3.55     |\n","|    critic_loss     | 0.499    |\n","|    ent_coef        | 0.0227   |\n","|    ent_coef_loss   | -2.05    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 235798   |\n","---------------------------------\n","LunarLander - Step: 110001 | Mean Reward: -39.21 ± 15.19\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 911      |\n","|    ep_rew_mean     | -68.1    |\n","| time/              |          |\n","|    episodes        | 152      |\n","|    fps             | 26       |\n","|    time_elapsed    | 76       |\n","|    total_timesteps | 122000   |\n","| train/             |          |\n","|    actor_loss      | 5.48     |\n","|    critic_loss     | 1.02     |\n","|    ent_coef        | 0.0222   |\n","|    ent_coef_loss   | 2.2      |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 243798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 911      |\n","|    ep_rew_mean     | -67      |\n","| time/              |          |\n","|    episodes        | 156      |\n","|    fps             | 27       |\n","|    time_elapsed    | 221      |\n","|    total_timesteps | 126000   |\n","| train/             |          |\n","|    actor_loss      | 4.67     |\n","|    critic_loss     | 2.87     |\n","|    ent_coef        | 0.0229   |\n","|    ent_coef_loss   | -1.1     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 251798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 928      |\n","|    ep_rew_mean     | -65.7    |\n","| time/              |          |\n","|    episodes        | 160      |\n","|    fps             | 26       |\n","|    time_elapsed    | 374      |\n","|    total_timesteps | 130000   |\n","| train/             |          |\n","|    actor_loss      | 5.88     |\n","|    critic_loss     | 0.596    |\n","|    ent_coef        | 0.0212   |\n","|    ent_coef_loss   | -0.214   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 259798   |\n","---------------------------------\n","LunarLander - Step: 120001 | Mean Reward: -33.01 ± 23.35\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 945      |\n","|    ep_rew_mean     | -62.6    |\n","| time/              |          |\n","|    episodes        | 164      |\n","|    fps             | 27       |\n","|    time_elapsed    | 145      |\n","|    total_timesteps | 134000   |\n","| train/             |          |\n","|    actor_loss      | 7.11     |\n","|    critic_loss     | 0.526    |\n","|    ent_coef        | 0.0178   |\n","|    ent_coef_loss   | -0.93    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 267798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 956      |\n","|    ep_rew_mean     | -61.6    |\n","| time/              |          |\n","|    episodes        | 168      |\n","|    fps             | 26       |\n","|    time_elapsed    | 296      |\n","|    total_timesteps | 138000   |\n","| train/             |          |\n","|    actor_loss      | 1.92     |\n","|    critic_loss     | 1.05     |\n","|    ent_coef        | 0.017    |\n","|    ent_coef_loss   | -0.707   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 275798   |\n","---------------------------------\n","LunarLander - Step: 130001 | Mean Reward: -24.20 ± 21.34\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 960      |\n","|    ep_rew_mean     | -59.7    |\n","| time/              |          |\n","|    episodes        | 172      |\n","|    fps             | 26       |\n","|    time_elapsed    | 75       |\n","|    total_timesteps | 142000   |\n","| train/             |          |\n","|    actor_loss      | 2.82     |\n","|    critic_loss     | 0.573    |\n","|    ent_coef        | 0.0171   |\n","|    ent_coef_loss   | -0.681   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 283798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 960      |\n","|    ep_rew_mean     | -59.5    |\n","| time/              |          |\n","|    episodes        | 176      |\n","|    fps             | 27       |\n","|    time_elapsed    | 221      |\n","|    total_timesteps | 146000   |\n","| train/             |          |\n","|    actor_loss      | 5.49     |\n","|    critic_loss     | 1.22     |\n","|    ent_coef        | 0.0175   |\n","|    ent_coef_loss   | 0.00272  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 291798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 960      |\n","|    ep_rew_mean     | -58.8    |\n","| time/              |          |\n","|    episodes        | 180      |\n","|    fps             | 26       |\n","|    time_elapsed    | 373      |\n","|    total_timesteps | 150000   |\n","| train/             |          |\n","|    actor_loss      | 5.58     |\n","|    critic_loss     | 3.4      |\n","|    ent_coef        | 0.0171   |\n","|    ent_coef_loss   | 0.602    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 299798   |\n","---------------------------------\n","LunarLander - Step: 140001 | Mean Reward: -53.49 ± 28.23\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 961      |\n","|    ep_rew_mean     | -58.2    |\n","| time/              |          |\n","|    episodes        | 184      |\n","|    fps             | 26       |\n","|    time_elapsed    | 150      |\n","|    total_timesteps | 154000   |\n","| train/             |          |\n","|    actor_loss      | 6.09     |\n","|    critic_loss     | 0.54     |\n","|    ent_coef        | 0.0153   |\n","|    ent_coef_loss   | -0.349   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 307798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 961      |\n","|    ep_rew_mean     | -58.6    |\n","| time/              |          |\n","|    episodes        | 188      |\n","|    fps             | 26       |\n","|    time_elapsed    | 303      |\n","|    total_timesteps | 158000   |\n","| train/             |          |\n","|    actor_loss      | 6.34     |\n","|    critic_loss     | 0.682    |\n","|    ent_coef        | 0.0153   |\n","|    ent_coef_loss   | 0.447    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 315798   |\n","---------------------------------\n","LunarLander - Step: 150001 | Mean Reward: -39.21 ± 41.49\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 970      |\n","|    ep_rew_mean     | -54.1    |\n","| time/              |          |\n","|    episodes        | 192      |\n","|    fps             | 26       |\n","|    time_elapsed    | 74       |\n","|    total_timesteps | 162000   |\n","| train/             |          |\n","|    actor_loss      | 8.2      |\n","|    critic_loss     | 0.441    |\n","|    ent_coef        | 0.0166   |\n","|    ent_coef_loss   | -1.69    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 323798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 984      |\n","|    ep_rew_mean     | -47.6    |\n","| time/              |          |\n","|    episodes        | 196      |\n","|    fps             | 26       |\n","|    time_elapsed    | 225      |\n","|    total_timesteps | 166000   |\n","| train/             |          |\n","|    actor_loss      | 4.42     |\n","|    critic_loss     | 0.763    |\n","|    ent_coef        | 0.0174   |\n","|    ent_coef_loss   | -0.26    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 331798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 989      |\n","|    ep_rew_mean     | -44.2    |\n","| time/              |          |\n","|    episodes        | 200      |\n","|    fps             | 26       |\n","|    time_elapsed    | 380      |\n","|    total_timesteps | 170000   |\n","| train/             |          |\n","|    actor_loss      | 3.89     |\n","|    critic_loss     | 0.884    |\n","|    ent_coef        | 0.0188   |\n","|    ent_coef_loss   | -0.0907  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 339798   |\n","---------------------------------\n","LunarLander - Step: 160001 | Mean Reward: -14.78 ± 17.02\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -42.3    |\n","| time/              |          |\n","|    episodes        | 204      |\n","|    fps             | 26       |\n","|    time_elapsed    | 152      |\n","|    total_timesteps | 174000   |\n","| train/             |          |\n","|    actor_loss      | 0.836    |\n","|    critic_loss     | 0.66     |\n","|    ent_coef        | 0.0182   |\n","|    ent_coef_loss   | 0.591    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 347798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -41.6    |\n","| time/              |          |\n","|    episodes        | 208      |\n","|    fps             | 26       |\n","|    time_elapsed    | 303      |\n","|    total_timesteps | 178000   |\n","| train/             |          |\n","|    actor_loss      | -3.1     |\n","|    critic_loss     | 0.565    |\n","|    ent_coef        | 0.0172   |\n","|    ent_coef_loss   | -0.422   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 355798   |\n","---------------------------------\n","LunarLander - Step: 170001 | Mean Reward: -27.29 ± 22.60\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -39.2    |\n","| time/              |          |\n","|    episodes        | 212      |\n","|    fps             | 26       |\n","|    time_elapsed    | 74       |\n","|    total_timesteps | 182000   |\n","| train/             |          |\n","|    actor_loss      | 7.58     |\n","|    critic_loss     | 8.64     |\n","|    ent_coef        | 0.0185   |\n","|    ent_coef_loss   | -0.3     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 363798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -37.2    |\n","| time/              |          |\n","|    episodes        | 216      |\n","|    fps             | 26       |\n","|    time_elapsed    | 225      |\n","|    total_timesteps | 186000   |\n","| train/             |          |\n","|    actor_loss      | 1.67     |\n","|    critic_loss     | 0.465    |\n","|    ent_coef        | 0.0169   |\n","|    ent_coef_loss   | 0.689    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 371798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -37.5    |\n","| time/              |          |\n","|    episodes        | 220      |\n","|    fps             | 26       |\n","|    time_elapsed    | 380      |\n","|    total_timesteps | 190000   |\n","| train/             |          |\n","|    actor_loss      | 1.24     |\n","|    critic_loss     | 0.653    |\n","|    ent_coef        | 0.0161   |\n","|    ent_coef_loss   | 1.33     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 379798   |\n","---------------------------------\n","LunarLander - Step: 180001 | Mean Reward: -7.99 ± 23.45\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -35.4    |\n","| time/              |          |\n","|    episodes        | 224      |\n","|    fps             | 25       |\n","|    time_elapsed    | 154      |\n","|    total_timesteps | 194000   |\n","| train/             |          |\n","|    actor_loss      | 8.34     |\n","|    critic_loss     | 0.514    |\n","|    ent_coef        | 0.0158   |\n","|    ent_coef_loss   | -1.11    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 387798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -32.2    |\n","| time/              |          |\n","|    episodes        | 228      |\n","|    fps             | 26       |\n","|    time_elapsed    | 303      |\n","|    total_timesteps | 198000   |\n","| train/             |          |\n","|    actor_loss      | 2.36     |\n","|    critic_loss     | 0.406    |\n","|    ent_coef        | 0.0163   |\n","|    ent_coef_loss   | 0.585    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 395798   |\n","---------------------------------\n","LunarLander - Step: 190001 | Mean Reward: -21.80 ± 21.96\n"]}]},{"cell_type":"markdown","source":["env=4, batch size= 64, lr= 1e-4"],"metadata":{"id":"yEGbaPd53_Ww"}},{"cell_type":"code","source":["def train_lunarlander5():\n","    # Create environment and model for LunarLander (continuous version for SAC)\n","    env_lunar = make_vec_env(\"LunarLanderContinuous-v3\", n_envs=4)\n","    model = SAC(\"MlpPolicy\", env_lunar, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/\",\n","                learning_rate=1e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n","                gamma=0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n","\n","    eval_freq = 10000  # Evaluate every 10,000 steps\n","    n_eval_episodes = 10  # Number of episodes per evaluation\n","\n","    for step in range(1, 200001, eval_freq):\n","        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n","        mean_reward, std_reward = evaluate_model(model, env_lunar, n_eval_episodes)\n","        print(f\"LunarLander - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n","\n","    model.save(\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64\")"],"metadata":{"id":"Iug0t7JQ5XH4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    train_lunarlander5()"],"metadata":{"id":"dXr6c11L6FtD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["env=4, batch size= 128, lr= 1e-4"],"metadata":{"id":"9F3WCmGp4CSh"}},{"cell_type":"code","source":["def train_lunarlander6():\n","    # Create environment and model for LunarLander (continuous version for SAC)\n","    env_lunar = make_vec_env(\"LunarLanderContinuous-v3\", n_envs=4)\n","    model = SAC(\"MlpPolicy\", env_lunar, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/\",\n","                learning_rate=1e-4, buffer_size=500000, batch_size=128, tau=1.68e-1,\n","                gamma=0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n","\n","    eval_freq = 10000  # Evaluate every 10,000 steps\n","    n_eval_episodes = 10  # Number of episodes per evaluation\n","\n","    for step in range(1, 200001, eval_freq):\n","        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n","        mean_reward, std_reward = evaluate_model(model, env_lunar, n_eval_episodes)\n","        print(f\"LunarLander - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n","\n","    model.save(\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128\")"],"metadata":{"id":"aGobQN2f5ief"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    train_lunarlander6()"],"metadata":{"id":"7JLTs_zg6H15"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["env=4, batch size= 64, lr= 3e-4"],"metadata":{"id":"K85FksMq4FsJ"}},{"cell_type":"code","source":["def train_lunarlander7():\n","    # Create environment and model for LunarLander (continuous version for SAC)\n","    env_lunar = make_vec_env(\"LunarLanderContinuous-v3\", n_envs=4)\n","    model = SAC(\"MlpPolicy\", env_lunar, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/\",\n","                learning_rate=3e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n","                gamma=0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n","\n","    eval_freq = 10000  # Evaluate every 10,000 steps\n","    n_eval_episodes = 10  # Number of episodes per evaluation\n","\n","    for step in range(1, 200001, eval_freq):\n","        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n","        mean_reward, std_reward = evaluate_model(model, env_lunar, n_eval_episodes)\n","        print(f\"LunarLander - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n","\n","    model.save(\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64\")"],"metadata":{"id":"X-EDXLAF5szZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    train_lunarlander7()"],"metadata":{"id":"KoCDWzFH6Jpd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"24a5fe0b-4e91-439e-af67-5eabd41fb393"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n","<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n","<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n","/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n","  from pkg_resources import resource_stream, resource_exists\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n"]},{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 104      |\n","|    ep_rew_mean     | -295     |\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 78       |\n","|    time_elapsed    | 7        |\n","|    total_timesteps | 604      |\n","| train/             |          |\n","|    actor_loss      | -7.16    |\n","|    critic_loss     | 22.5     |\n","|    ent_coef        | 0.932    |\n","|    ent_coef_loss   | -0.197   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 250      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 120      |\n","|    ep_rew_mean     | -290     |\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 84       |\n","|    time_elapsed    | 13       |\n","|    total_timesteps | 1144     |\n","| train/             |          |\n","|    actor_loss      | 11.3     |\n","|    critic_loss     | 139      |\n","|    ent_coef        | 0.862    |\n","|    ent_coef_loss   | -0.364   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 520      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 128      |\n","|    ep_rew_mean     | -213     |\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 95       |\n","|    time_elapsed    | 22       |\n","|    total_timesteps | 2112     |\n","| train/             |          |\n","|    actor_loss      | -7.17    |\n","|    critic_loss     | 12.3     |\n","|    ent_coef        | 0.759    |\n","|    ent_coef_loss   | -0.695   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 1004     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 275      |\n","|    ep_rew_mean     | -178     |\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 85       |\n","|    time_elapsed    | 71       |\n","|    total_timesteps | 6112     |\n","| train/             |          |\n","|    actor_loss      | -32.4    |\n","|    critic_loss     | 2.95     |\n","|    ent_coef        | 0.431    |\n","|    ent_coef_loss   | -2.17    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 3004     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 352      |\n","|    ep_rew_mean     | -176     |\n","| time/              |          |\n","|    episodes        | 20       |\n","|    fps             | 85       |\n","|    time_elapsed    | 94       |\n","|    total_timesteps | 8048     |\n","| train/             |          |\n","|    actor_loss      | -23.6    |\n","|    critic_loss     | 4.29     |\n","|    ent_coef        | 0.322    |\n","|    ent_coef_loss   | -2.46    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 3972     |\n","---------------------------------\n","LunarLander - Step: 1 | Mean Reward: -38.14 ± 22.26\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 481      |\n","|    ep_rew_mean     | -145     |\n","| time/              |          |\n","|    episodes        | 24       |\n","|    fps             | 81       |\n","|    time_elapsed    | 49       |\n","|    total_timesteps | 14000    |\n","| train/             |          |\n","|    actor_loss      | -16.4    |\n","|    critic_loss     | 3.05     |\n","|    ent_coef        | 0.14     |\n","|    ent_coef_loss   | -3.61    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 6948     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 548      |\n","|    ep_rew_mean     | -140     |\n","| time/              |          |\n","|    episodes        | 28       |\n","|    fps             | 82       |\n","|    time_elapsed    | 96       |\n","|    total_timesteps | 18000    |\n","| train/             |          |\n","|    actor_loss      | -13.7    |\n","|    critic_loss     | 2.72     |\n","|    ent_coef        | 0.0809   |\n","|    ent_coef_loss   | -4.72    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 8948     |\n","---------------------------------\n","LunarLander - Step: 10001 | Mean Reward: -46.88 ± 58.70\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 591      |\n","|    ep_rew_mean     | -129     |\n","| time/              |          |\n","|    episodes        | 32       |\n","|    fps             | 86       |\n","|    time_elapsed    | 30       |\n","|    total_timesteps | 22664    |\n","| train/             |          |\n","|    actor_loss      | -11.7    |\n","|    critic_loss     | 1.76     |\n","|    ent_coef        | 0.0453   |\n","|    ent_coef_loss   | -3.69    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 11280    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 594      |\n","|    ep_rew_mean     | -131     |\n","| time/              |          |\n","|    episodes        | 36       |\n","|    fps             | 88       |\n","|    time_elapsed    | 63       |\n","|    total_timesteps | 25636    |\n","| train/             |          |\n","|    actor_loss      | -17.1    |\n","|    critic_loss     | 3.29     |\n","|    ent_coef        | 0.0371   |\n","|    ent_coef_loss   | 7.69     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 12766    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 634      |\n","|    ep_rew_mean     | -119     |\n","| time/              |          |\n","|    episodes        | 40       |\n","|    fps             | 88       |\n","|    time_elapsed    | 108      |\n","|    total_timesteps | 29636    |\n","| train/             |          |\n","|    actor_loss      | -13.7    |\n","|    critic_loss     | 4.63     |\n","|    ent_coef        | 0.037    |\n","|    ent_coef_loss   | -1.34    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 14766    |\n","---------------------------------\n","LunarLander - Step: 20001 | Mean Reward: -64.12 ± 29.30\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 647      |\n","|    ep_rew_mean     | -111     |\n","| time/              |          |\n","|    episodes        | 44       |\n","|    fps             | 84       |\n","|    time_elapsed    | 47       |\n","|    total_timesteps | 34000    |\n","| train/             |          |\n","|    actor_loss      | -5.78    |\n","|    critic_loss     | 4.96     |\n","|    ent_coef        | 0.025    |\n","|    ent_coef_loss   | -1.91    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 16948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 666      |\n","|    ep_rew_mean     | -107     |\n","| time/              |          |\n","|    episodes        | 48       |\n","|    fps             | 84       |\n","|    time_elapsed    | 94       |\n","|    total_timesteps | 38000    |\n","| train/             |          |\n","|    actor_loss      | -8.37    |\n","|    critic_loss     | 1.27     |\n","|    ent_coef        | 0.0199   |\n","|    ent_coef_loss   | -0.792   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 18948    |\n","---------------------------------\n","LunarLander - Step: 30001 | Mean Reward: -31.14 ± 29.75\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 675      |\n","|    ep_rew_mean     | -110     |\n","| time/              |          |\n","|    episodes        | 52       |\n","|    fps             | 83       |\n","|    time_elapsed    | 43       |\n","|    total_timesteps | 43588    |\n","| train/             |          |\n","|    actor_loss      | -9.54    |\n","|    critic_loss     | 1.13     |\n","|    ent_coef        | 0.021    |\n","|    ent_coef_loss   | -0.602   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 21742    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 698      |\n","|    ep_rew_mean     | -103     |\n","| time/              |          |\n","|    episodes        | 56       |\n","|    fps             | 80       |\n","|    time_elapsed    | 93       |\n","|    total_timesteps | 47588    |\n","| train/             |          |\n","|    actor_loss      | -6.47    |\n","|    critic_loss     | 0.701    |\n","|    ent_coef        | 0.0228   |\n","|    ent_coef_loss   | -2.85    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 23742    |\n","---------------------------------\n","LunarLander - Step: 40001 | Mean Reward: -11.48 ± 20.80\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 732      |\n","|    ep_rew_mean     | -94.3    |\n","| time/              |          |\n","|    episodes        | 60       |\n","|    fps             | 86       |\n","|    time_elapsed    | 46       |\n","|    total_timesteps | 54000    |\n","| train/             |          |\n","|    actor_loss      | -6.79    |\n","|    critic_loss     | 0.803    |\n","|    ent_coef        | 0.0205   |\n","|    ent_coef_loss   | -1.27    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 26948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 748      |\n","|    ep_rew_mean     | -89.6    |\n","| time/              |          |\n","|    episodes        | 64       |\n","|    fps             | 85       |\n","|    time_elapsed    | 93       |\n","|    total_timesteps | 58000    |\n","| train/             |          |\n","|    actor_loss      | -6.93    |\n","|    critic_loss     | 0.595    |\n","|    ent_coef        | 0.0232   |\n","|    ent_coef_loss   | -0.267   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 28948    |\n","---------------------------------\n","LunarLander - Step: 50001 | Mean Reward: -10.05 ± 18.82\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 762      |\n","|    ep_rew_mean     | -86.7    |\n","| time/              |          |\n","|    episodes        | 68       |\n","|    fps             | 84       |\n","|    time_elapsed    | 47       |\n","|    total_timesteps | 64000    |\n","| train/             |          |\n","|    actor_loss      | -8.96    |\n","|    critic_loss     | 1.24     |\n","|    ent_coef        | 0.0211   |\n","|    ent_coef_loss   | -0.933   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 31948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 775      |\n","|    ep_rew_mean     | -82.5    |\n","| time/              |          |\n","|    episodes        | 72       |\n","|    fps             | 84       |\n","|    time_elapsed    | 94       |\n","|    total_timesteps | 68000    |\n","| train/             |          |\n","|    actor_loss      | -6.59    |\n","|    critic_loss     | 0.946    |\n","|    ent_coef        | 0.0209   |\n","|    ent_coef_loss   | 1.88     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 33948    |\n","---------------------------------\n","LunarLander - Step: 60001 | Mean Reward: -29.80 ± 22.00\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 786      |\n","|    ep_rew_mean     | -80      |\n","| time/              |          |\n","|    episodes        | 76       |\n","|    fps             | 83       |\n","|    time_elapsed    | 47       |\n","|    total_timesteps | 74000    |\n","| train/             |          |\n","|    actor_loss      | -6.89    |\n","|    critic_loss     | 9.53     |\n","|    ent_coef        | 0.0219   |\n","|    ent_coef_loss   | -1.03    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 36948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 796      |\n","|    ep_rew_mean     | -77.9    |\n","| time/              |          |\n","|    episodes        | 80       |\n","|    fps             | 79       |\n","|    time_elapsed    | 100      |\n","|    total_timesteps | 78000    |\n","| train/             |          |\n","|    actor_loss      | -6.7     |\n","|    critic_loss     | 1.8      |\n","|    ent_coef        | 0.0194   |\n","|    ent_coef_loss   | 1.85     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 38948    |\n","---------------------------------\n","LunarLander - Step: 70001 | Mean Reward: -21.02 ± 17.11\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 806      |\n","|    ep_rew_mean     | -75.5    |\n","| time/              |          |\n","|    episodes        | 84       |\n","|    fps             | 82       |\n","|    time_elapsed    | 48       |\n","|    total_timesteps | 84000    |\n","| train/             |          |\n","|    actor_loss      | -6.14    |\n","|    critic_loss     | 0.762    |\n","|    ent_coef        | 0.0216   |\n","|    ent_coef_loss   | -2.01    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 41948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 814      |\n","|    ep_rew_mean     | -72.9    |\n","| time/              |          |\n","|    episodes        | 88       |\n","|    fps             | 84       |\n","|    time_elapsed    | 95       |\n","|    total_timesteps | 88000    |\n","| train/             |          |\n","|    actor_loss      | -9.73    |\n","|    critic_loss     | 0.618    |\n","|    ent_coef        | 0.0208   |\n","|    ent_coef_loss   | -0.44    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 43948    |\n","---------------------------------\n","LunarLander - Step: 80001 | Mean Reward: -44.33 ± 22.26\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 822      |\n","|    ep_rew_mean     | -71.2    |\n","| time/              |          |\n","|    episodes        | 92       |\n","|    fps             | 77       |\n","|    time_elapsed    | 51       |\n","|    total_timesteps | 94000    |\n","| train/             |          |\n","|    actor_loss      | -5.93    |\n","|    critic_loss     | 0.755    |\n","|    ent_coef        | 0.0212   |\n","|    ent_coef_loss   | 0.138    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 46948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 829      |\n","|    ep_rew_mean     | -69.9    |\n","| time/              |          |\n","|    episodes        | 96       |\n","|    fps             | 75       |\n","|    time_elapsed    | 105      |\n","|    total_timesteps | 98000    |\n","| train/             |          |\n","|    actor_loss      | -6.48    |\n","|    critic_loss     | 1.25     |\n","|    ent_coef        | 0.019    |\n","|    ent_coef_loss   | -0.832   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 48948    |\n","---------------------------------\n","LunarLander - Step: 90001 | Mean Reward: -33.37 ± 15.81\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 858      |\n","|    ep_rew_mean     | -63.6    |\n","| time/              |          |\n","|    episodes        | 100      |\n","|    fps             | 86       |\n","|    time_elapsed    | 46       |\n","|    total_timesteps | 104000   |\n","| train/             |          |\n","|    actor_loss      | -0.331   |\n","|    critic_loss     | 1.37     |\n","|    ent_coef        | 0.0203   |\n","|    ent_coef_loss   | -0.825   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 51948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 893      |\n","|    ep_rew_mean     | -50.6    |\n","| time/              |          |\n","|    episodes        | 104      |\n","|    fps             | 81       |\n","|    time_elapsed    | 98       |\n","|    total_timesteps | 108000   |\n","| train/             |          |\n","|    actor_loss      | -6.59    |\n","|    critic_loss     | 0.562    |\n","|    ent_coef        | 0.0178   |\n","|    ent_coef_loss   | 2.03     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 53948    |\n","---------------------------------\n","LunarLander - Step: 100001 | Mean Reward: -19.67 ± 18.16\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 928      |\n","|    ep_rew_mean     | -47.9    |\n","| time/              |          |\n","|    episodes        | 108      |\n","|    fps             | 82       |\n","|    time_elapsed    | 48       |\n","|    total_timesteps | 114000   |\n","| train/             |          |\n","|    actor_loss      | -1.44    |\n","|    critic_loss     | 0.599    |\n","|    ent_coef        | 0.0164   |\n","|    ent_coef_loss   | 0.745    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 56948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 947      |\n","|    ep_rew_mean     | -45.7    |\n","| time/              |          |\n","|    episodes        | 112      |\n","|    fps             | 81       |\n","|    time_elapsed    | 97       |\n","|    total_timesteps | 118000   |\n","| train/             |          |\n","|    actor_loss      | -6.85    |\n","|    critic_loss     | 0.672    |\n","|    ent_coef        | 0.0234   |\n","|    ent_coef_loss   | -1.94    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 58948    |\n","---------------------------------\n","LunarLander - Step: 110001 | Mean Reward: -26.89 ± 15.45\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 959      |\n","|    ep_rew_mean     | -43.5    |\n","| time/              |          |\n","|    episodes        | 116      |\n","|    fps             | 79       |\n","|    time_elapsed    | 50       |\n","|    total_timesteps | 124000   |\n","| train/             |          |\n","|    actor_loss      | 0.398    |\n","|    critic_loss     | 0.619    |\n","|    ent_coef        | 0.0171   |\n","|    ent_coef_loss   | -2.06    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 61948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 954      |\n","|    ep_rew_mean     | -41.6    |\n","| time/              |          |\n","|    episodes        | 120      |\n","|    fps             | 83       |\n","|    time_elapsed    | 62       |\n","|    total_timesteps | 125208   |\n","| train/             |          |\n","|    actor_loss      | -2.54    |\n","|    critic_loss     | 0.843    |\n","|    ent_coef        | 0.0162   |\n","|    ent_coef_loss   | -0.912   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 62552    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 954      |\n","|    ep_rew_mean     | -42.9    |\n","| time/              |          |\n","|    episodes        | 124      |\n","|    fps             | 82       |\n","|    time_elapsed    | 111      |\n","|    total_timesteps | 129208   |\n","| train/             |          |\n","|    actor_loss      | -3.28    |\n","|    critic_loss     | 0.701    |\n","|    ent_coef        | 0.0165   |\n","|    ent_coef_loss   | -1.42    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 64552    |\n","---------------------------------\n","LunarLander - Step: 120001 | Mean Reward: -45.08 ± 54.14\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 955      |\n","|    ep_rew_mean     | -40.8    |\n","| time/              |          |\n","|    episodes        | 128      |\n","|    fps             | 76       |\n","|    time_elapsed    | 52       |\n","|    total_timesteps | 134000   |\n","| train/             |          |\n","|    actor_loss      | -0.454   |\n","|    critic_loss     | 1.69     |\n","|    ent_coef        | 0.0155   |\n","|    ent_coef_loss   | 0.519    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 66948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 951      |\n","|    ep_rew_mean     | -43.7    |\n","| time/              |          |\n","|    episodes        | 132      |\n","|    fps             | 79       |\n","|    time_elapsed    | 100      |\n","|    total_timesteps | 138000   |\n","| train/             |          |\n","|    actor_loss      | 2.09     |\n","|    critic_loss     | 0.6      |\n","|    ent_coef        | 0.0168   |\n","|    ent_coef_loss   | -2.47    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 68948    |\n","---------------------------------\n","LunarLander - Step: 130001 | Mean Reward: -12.89 ± 27.69\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 966      |\n","|    ep_rew_mean     | -39.7    |\n","| time/              |          |\n","|    episodes        | 136      |\n","|    fps             | 80       |\n","|    time_elapsed    | 49       |\n","|    total_timesteps | 144000   |\n","| train/             |          |\n","|    actor_loss      | -5.31    |\n","|    critic_loss     | 0.526    |\n","|    ent_coef        | 0.0142   |\n","|    ent_coef_loss   | 1.66     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 71948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 966      |\n","|    ep_rew_mean     | -40.8    |\n","| time/              |          |\n","|    episodes        | 140      |\n","|    fps             | 79       |\n","|    time_elapsed    | 100      |\n","|    total_timesteps | 148000   |\n","| train/             |          |\n","|    actor_loss      | -3.44    |\n","|    critic_loss     | 7.64     |\n","|    ent_coef        | 0.015    |\n","|    ent_coef_loss   | 0.273    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 73948    |\n","---------------------------------\n","LunarLander - Step: 140001 | Mean Reward: -19.94 ± 16.72\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 969      |\n","|    ep_rew_mean     | -41.7    |\n","| time/              |          |\n","|    episodes        | 144      |\n","|    fps             | 84       |\n","|    time_elapsed    | 47       |\n","|    total_timesteps | 154000   |\n","| train/             |          |\n","|    actor_loss      | -1.19    |\n","|    critic_loss     | 0.638    |\n","|    ent_coef        | 0.0163   |\n","|    ent_coef_loss   | -2.13    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 76948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 974      |\n","|    ep_rew_mean     | -41.5    |\n","| time/              |          |\n","|    episodes        | 148      |\n","|    fps             | 82       |\n","|    time_elapsed    | 97       |\n","|    total_timesteps | 158000   |\n","| train/             |          |\n","|    actor_loss      | -8.94    |\n","|    critic_loss     | 0.481    |\n","|    ent_coef        | 0.0178   |\n","|    ent_coef_loss   | -1.01    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 78948    |\n","---------------------------------\n","LunarLander - Step: 150001 | Mean Reward: -20.77 ± 28.15\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 983      |\n","|    ep_rew_mean     | -36.6    |\n","| time/              |          |\n","|    episodes        | 152      |\n","|    fps             | 80       |\n","|    time_elapsed    | 49       |\n","|    total_timesteps | 164000   |\n","| train/             |          |\n","|    actor_loss      | -4.77    |\n","|    critic_loss     | 0.409    |\n","|    ent_coef        | 0.0155   |\n","|    ent_coef_loss   | -0.015   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 81948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 983      |\n","|    ep_rew_mean     | -38.1    |\n","| time/              |          |\n","|    episodes        | 156      |\n","|    fps             | 83       |\n","|    time_elapsed    | 96       |\n","|    total_timesteps | 168000   |\n","| train/             |          |\n","|    actor_loss      | -0.0692  |\n","|    critic_loss     | 0.905    |\n","|    ent_coef        | 0.0168   |\n","|    ent_coef_loss   | -1.63    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 83948    |\n","---------------------------------\n","LunarLander - Step: 160001 | Mean Reward: -37.23 ± 19.90\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 983      |\n","|    ep_rew_mean     | -38.1    |\n","| time/              |          |\n","|    episodes        | 160      |\n","|    fps             | 80       |\n","|    time_elapsed    | 49       |\n","|    total_timesteps | 174000   |\n","| train/             |          |\n","|    actor_loss      | 0.624    |\n","|    critic_loss     | 0.522    |\n","|    ent_coef        | 0.014    |\n","|    ent_coef_loss   | -1.47    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 86948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 983      |\n","|    ep_rew_mean     | -38.7    |\n","| time/              |          |\n","|    episodes        | 164      |\n","|    fps             | 85       |\n","|    time_elapsed    | 93       |\n","|    total_timesteps | 178000   |\n","| train/             |          |\n","|    actor_loss      | -0.704   |\n","|    critic_loss     | 0.83     |\n","|    ent_coef        | 0.0121   |\n","|    ent_coef_loss   | 0.162    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 88948    |\n","---------------------------------\n","LunarLander - Step: 170001 | Mean Reward: -29.53 ± 14.72\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 983      |\n","|    ep_rew_mean     | -39.6    |\n","| time/              |          |\n","|    episodes        | 168      |\n","|    fps             | 80       |\n","|    time_elapsed    | 49       |\n","|    total_timesteps | 184000   |\n","| train/             |          |\n","|    actor_loss      | -2.02    |\n","|    critic_loss     | 0.355    |\n","|    ent_coef        | 0.0135   |\n","|    ent_coef_loss   | 1.06     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 91948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 983      |\n","|    ep_rew_mean     | -39.4    |\n","| time/              |          |\n","|    episodes        | 172      |\n","|    fps             | 81       |\n","|    time_elapsed    | 97       |\n","|    total_timesteps | 188000   |\n","| train/             |          |\n","|    actor_loss      | 2.03     |\n","|    critic_loss     | 0.58     |\n","|    ent_coef        | 0.0125   |\n","|    ent_coef_loss   | -0.259   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 93948    |\n","---------------------------------\n","LunarLander - Step: 180001 | Mean Reward: -35.00 ± 25.94\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 983      |\n","|    ep_rew_mean     | -40      |\n","| time/              |          |\n","|    episodes        | 176      |\n","|    fps             | 73       |\n","|    time_elapsed    | 54       |\n","|    total_timesteps | 194000   |\n","| train/             |          |\n","|    actor_loss      | 1.16     |\n","|    critic_loss     | 0.609    |\n","|    ent_coef        | 0.0129   |\n","|    ent_coef_loss   | 2.14     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 96948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 983      |\n","|    ep_rew_mean     | -39.5    |\n","| time/              |          |\n","|    episodes        | 180      |\n","|    fps             | 74       |\n","|    time_elapsed    | 106      |\n","|    total_timesteps | 198000   |\n","| train/             |          |\n","|    actor_loss      | -8.6     |\n","|    critic_loss     | 0.45     |\n","|    ent_coef        | 0.0153   |\n","|    ent_coef_loss   | 0.798    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 98948    |\n","---------------------------------\n","LunarLander - Step: 190001 | Mean Reward: -22.51 ± 17.20\n"]}]}]}