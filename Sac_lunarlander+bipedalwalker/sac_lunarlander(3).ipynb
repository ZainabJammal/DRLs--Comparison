{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I08ysbNCpSI7","outputId":"555422d7-7d84-4502-8b21-72a162badf9f","executionInfo":{"status":"ok","timestamp":1740521664227,"user_tz":-120,"elapsed":101304,"user":{"displayName":"Rana Choker","userId":"13341093079406228038"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stable_baselines3\n","  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n","Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.0.0)\n","Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n","Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n","Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.5.0\n"]}],"source":["!pip install stable_baselines3"]},{"cell_type":"code","source":["!pip install box2d"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECjjcZ-opzYL","outputId":"93231781-8aab-46d0-da8f-52d79d833c19","executionInfo":{"status":"ok","timestamp":1740521966438,"user_tz":-120,"elapsed":3478,"user":{"displayName":"Rana Choker","userId":"13341093079406228038"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting box2d\n","  Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (573 bytes)\n","Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: box2d\n","Successfully installed box2d-2.3.10\n"]}]},{"cell_type":"code","source":["import multiprocessing\n","from stable_baselines3 import SAC\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.env_util import make_vec_env"],"metadata":{"id":"EOJbyToUp4Zx","executionInfo":{"status":"ok","timestamp":1740521698253,"user_tz":-120,"elapsed":13665,"user":{"displayName":"Rana Choker","userId":"13341093079406228038"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, env, n_eval_episodes=10):\n","    \"\"\"Evaluate the model on a given environment and return mean and std rewards.\"\"\"\n","    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes)\n","    return mean_reward, std_reward"],"metadata":{"id":"cwiNPKwzp8Xb","executionInfo":{"status":"ok","timestamp":1740521702297,"user_tz":-120,"elapsed":12,"user":{"displayName":"Rana Choker","userId":"13341093079406228038"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"igtSZhJMLg23","executionInfo":{"status":"ok","timestamp":1740521833285,"user_tz":-120,"elapsed":67366,"user":{"displayName":"Rana Choker","userId":"13341093079406228038"}},"outputId":"1f215314-ceee-404a-e1c2-7327c39d02f2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## SAC Lunar"],"metadata":{"id":"0_W45wJuuRZK"}},{"cell_type":"markdown","source":["env=1, batch size= 64, lr= 1e-4"],"metadata":{"id":"F35T9vmOuZlR"}},{"cell_type":"code","source":["def train_lunarlander1():\n","    # Create environment and model for LunarLander (continuous version for SAC)\n","    env_lunar = make_vec_env(\"LunarLanderContinuous-v3\", n_envs=1)\n","    model = SAC(\"MlpPolicy\", env_lunar, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/\",\n","                learning_rate=1e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n","                gamma=0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n","\n","    eval_freq = 10000  # Evaluate every 10,000 steps\n","    n_eval_episodes = 10  # Number of episodes per evaluation\n","\n","    for step in range(1, 200001, eval_freq):\n","        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n","        mean_reward, std_reward = evaluate_model(model, env_lunar, n_eval_episodes)\n","        print(f\"LunarLander - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n","\n","    model.save(\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64\")"],"metadata":{"id":"EylnIb_kp-mk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    train_lunarlander1()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Noyb706JqCMn","outputId":"f43ea9b5-0523-4a09-bbe8-daf1d1dc13c7"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n","<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n","<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n","/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n","  from pkg_resources import resource_stream, resource_exists\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n"]},{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 160      |\n","|    ep_rew_mean     | -263     |\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 30       |\n","|    time_elapsed    | 20       |\n","|    total_timesteps | 641      |\n","| train/             |          |\n","|    actor_loss      | -10.8    |\n","|    critic_loss     | 3.5      |\n","|    ent_coef        | 0.899    |\n","|    ent_coef_loss   | -0.34    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 1080     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 137      |\n","|    ep_rew_mean     | -181     |\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 30       |\n","|    time_elapsed    | 36       |\n","|    total_timesteps | 1098     |\n","| train/             |          |\n","|    actor_loss      | 7.12     |\n","|    critic_loss     | 40       |\n","|    ent_coef        | 0.822    |\n","|    ent_coef_loss   | -0.591   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 1994     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 184      |\n","|    ep_rew_mean     | -219     |\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 29       |\n","|    time_elapsed    | 75       |\n","|    total_timesteps | 2206     |\n","| train/             |          |\n","|    actor_loss      | 41.9     |\n","|    critic_loss     | 4.41     |\n","|    ent_coef        | 0.669    |\n","|    ent_coef_loss   | -1.1     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 4210     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 184      |\n","|    ep_rew_mean     | -214     |\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 29       |\n","|    time_elapsed    | 99       |\n","|    total_timesteps | 2941     |\n","| train/             |          |\n","|    actor_loss      | 41.8     |\n","|    critic_loss     | 17.5     |\n","|    ent_coef        | 0.581    |\n","|    ent_coef_loss   | -1.47    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 5680     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 191      |\n","|    ep_rew_mean     | -226     |\n","| time/              |          |\n","|    episodes        | 20       |\n","|    fps             | 29       |\n","|    time_elapsed    | 129      |\n","|    total_timesteps | 3826     |\n","| train/             |          |\n","|    actor_loss      | 29.7     |\n","|    critic_loss     | 6.15     |\n","|    ent_coef        | 0.491    |\n","|    ent_coef_loss   | -1.38    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 7450     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 189      |\n","|    ep_rew_mean     | -220     |\n","| time/              |          |\n","|    episodes        | 24       |\n","|    fps             | 29       |\n","|    time_elapsed    | 153      |\n","|    total_timesteps | 4544     |\n","| train/             |          |\n","|    actor_loss      | 31.2     |\n","|    critic_loss     | 11.2     |\n","|    ent_coef        | 0.428    |\n","|    ent_coef_loss   | -1.72    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 8886     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 197      |\n","|    ep_rew_mean     | -211     |\n","| time/              |          |\n","|    episodes        | 28       |\n","|    fps             | 29       |\n","|    time_elapsed    | 188      |\n","|    total_timesteps | 5514     |\n","| train/             |          |\n","|    actor_loss      | 21.8     |\n","|    critic_loss     | 7.26     |\n","|    ent_coef        | 0.355    |\n","|    ent_coef_loss   | -1.75    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 10826    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 283      |\n","|    ep_rew_mean     | -203     |\n","| time/              |          |\n","|    episodes        | 32       |\n","|    fps             | 28       |\n","|    time_elapsed    | 320      |\n","|    total_timesteps | 9065     |\n","| train/             |          |\n","|    actor_loss      | -3       |\n","|    critic_loss     | 5.35     |\n","|    ent_coef        | 0.183    |\n","|    ent_coef_loss   | -2.3     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 17928    |\n","---------------------------------\n","LunarLander - Step: 1 | Mean Reward: -83.58 ± 27.37\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 363      |\n","|    ep_rew_mean     | -185     |\n","| time/              |          |\n","|    episodes        | 36       |\n","|    fps             | 27       |\n","|    time_elapsed    | 143      |\n","|    total_timesteps | 14000    |\n","| train/             |          |\n","|    actor_loss      | -5.23    |\n","|    critic_loss     | 55.5     |\n","|    ent_coef        | 0.0746   |\n","|    ent_coef_loss   | -1.27    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 27798    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 427      |\n","|    ep_rew_mean     | -173     |\n","| time/              |          |\n","|    episodes        | 40       |\n","|    fps             | 27       |\n","|    time_elapsed    | 289      |\n","|    total_timesteps | 18000    |\n","| train/             |          |\n","|    actor_loss      | -16.3    |\n","|    critic_loss     | 2.52     |\n","|    ent_coef        | 0.0513   |\n","|    ent_coef_loss   | -0.923   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 35798    |\n","---------------------------------\n","LunarLander - Step: 10001 | Mean Reward: -53.60 ± 16.12\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 479      |\n","|    ep_rew_mean     | -163     |\n","| time/              |          |\n","|    episodes        | 44       |\n","|    fps             | 27       |\n","|    time_elapsed    | 72       |\n","|    total_timesteps | 22000    |\n","| train/             |          |\n","|    actor_loss      | -7.82    |\n","|    critic_loss     | 28.5     |\n","|    ent_coef        | 0.0521   |\n","|    ent_coef_loss   | -1.96    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 43798    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 512      |\n","|    ep_rew_mean     | -159     |\n","| time/              |          |\n","|    episodes        | 48       |\n","|    fps             | 27       |\n","|    time_elapsed    | 202      |\n","|    total_timesteps | 25510    |\n","| train/             |          |\n","|    actor_loss      | -6.05    |\n","|    critic_loss     | 2.17     |\n","|    ent_coef        | 0.0508   |\n","|    ent_coef_loss   | -0.716   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 50818    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 537      |\n","|    ep_rew_mean     | -158     |\n","| time/              |          |\n","|    episodes        | 52       |\n","|    fps             | 27       |\n","|    time_elapsed    | 326      |\n","|    total_timesteps | 28844    |\n","| train/             |          |\n","|    actor_loss      | -4.19    |\n","|    critic_loss     | 3.93     |\n","|    ent_coef        | 0.0473   |\n","|    ent_coef_loss   | 0.178    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 57486    |\n","---------------------------------\n","LunarLander - Step: 20001 | Mean Reward: -36.54 ± 34.60\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 570      |\n","|    ep_rew_mean     | -151     |\n","| time/              |          |\n","|    episodes        | 56       |\n","|    fps             | 27       |\n","|    time_elapsed    | 107      |\n","|    total_timesteps | 33000    |\n","| train/             |          |\n","|    actor_loss      | 0.526    |\n","|    critic_loss     | 9.59     |\n","|    ent_coef        | 0.0604   |\n","|    ent_coef_loss   | -2.02    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 65798    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 572      |\n","|    ep_rew_mean     | -145     |\n","| time/              |          |\n","|    episodes        | 60       |\n","|    fps             | 27       |\n","|    time_elapsed    | 196      |\n","|    total_timesteps | 35390    |\n","| train/             |          |\n","|    actor_loss      | -4.92    |\n","|    critic_loss     | 2.39     |\n","|    ent_coef        | 0.0568   |\n","|    ent_coef_loss   | 1.11     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 70578    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 570      |\n","|    ep_rew_mean     | -142     |\n","| time/              |          |\n","|    episodes        | 64       |\n","|    fps             | 27       |\n","|    time_elapsed    | 280      |\n","|    total_timesteps | 37602    |\n","| train/             |          |\n","|    actor_loss      | -3.52    |\n","|    critic_loss     | 1.97     |\n","|    ent_coef        | 0.061    |\n","|    ent_coef_loss   | 1.5      |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 75002    |\n","---------------------------------\n","LunarLander - Step: 30001 | Mean Reward: -67.24 ± 30.58\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 580      |\n","|    ep_rew_mean     | -137     |\n","| time/              |          |\n","|    episodes        | 68       |\n","|    fps             | 26       |\n","|    time_elapsed    | 42       |\n","|    total_timesteps | 41130    |\n","| train/             |          |\n","|    actor_loss      | 2.19     |\n","|    critic_loss     | 1.65     |\n","|    ent_coef        | 0.0526   |\n","|    ent_coef_loss   | -1.03    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 82058    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 598      |\n","|    ep_rew_mean     | -135     |\n","| time/              |          |\n","|    episodes        | 72       |\n","|    fps             | 26       |\n","|    time_elapsed    | 180      |\n","|    total_timesteps | 44760    |\n","| train/             |          |\n","|    actor_loss      | -3.29    |\n","|    critic_loss     | 1.69     |\n","|    ent_coef        | 0.0455   |\n","|    ent_coef_loss   | -0.215   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 89318    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 619      |\n","|    ep_rew_mean     | -131     |\n","| time/              |          |\n","|    episodes        | 76       |\n","|    fps             | 26       |\n","|    time_elapsed    | 331      |\n","|    total_timesteps | 48760    |\n","| train/             |          |\n","|    actor_loss      | 1.02     |\n","|    critic_loss     | 4.96     |\n","|    ent_coef        | 0.0409   |\n","|    ent_coef_loss   | 0.534    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 97318    |\n","---------------------------------\n","LunarLander - Step: 40001 | Mean Reward: -95.26 ± 78.63\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 638      |\n","|    ep_rew_mean     | -127     |\n","| time/              |          |\n","|    episodes        | 80       |\n","|    fps             | 26       |\n","|    time_elapsed    | 114      |\n","|    total_timesteps | 53000    |\n","| train/             |          |\n","|    actor_loss      | 0.4      |\n","|    critic_loss     | 6.98     |\n","|    ent_coef        | 0.0384   |\n","|    ent_coef_loss   | 0.494    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 105798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 654      |\n","|    ep_rew_mean     | -125     |\n","| time/              |          |\n","|    episodes        | 84       |\n","|    fps             | 25       |\n","|    time_elapsed    | 266      |\n","|    total_timesteps | 56869    |\n","| train/             |          |\n","|    actor_loss      | 1.02     |\n","|    critic_loss     | 2.12     |\n","|    ent_coef        | 0.0291   |\n","|    ent_coef_loss   | 0.91     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 113536   |\n","---------------------------------\n","LunarLander - Step: 50001 | Mean Reward: -104.27 ± 34.54\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 670      |\n","|    ep_rew_mean     | -122     |\n","| time/              |          |\n","|    episodes        | 88       |\n","|    fps             | 27       |\n","|    time_elapsed    | 36       |\n","|    total_timesteps | 61000    |\n","| train/             |          |\n","|    actor_loss      | 1.78     |\n","|    critic_loss     | 1.61     |\n","|    ent_coef        | 0.0284   |\n","|    ent_coef_loss   | 0.886    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 121798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 675      |\n","|    ep_rew_mean     | -122     |\n","| time/              |          |\n","|    episodes        | 92       |\n","|    fps             | 26       |\n","|    time_elapsed    | 157      |\n","|    total_timesteps | 64162    |\n","| train/             |          |\n","|    actor_loss      | -1.51    |\n","|    critic_loss     | 3        |\n","|    ent_coef        | 0.0325   |\n","|    ent_coef_loss   | 2.19     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 128122   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 674      |\n","|    ep_rew_mean     | -125     |\n","| time/              |          |\n","|    episodes        | 96       |\n","|    fps             | 26       |\n","|    time_elapsed    | 253      |\n","|    total_timesteps | 66745    |\n","| train/             |          |\n","|    actor_loss      | 4.51     |\n","|    critic_loss     | 1.61     |\n","|    ent_coef        | 0.0386   |\n","|    ent_coef_loss   | 0.865    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 133288   |\n","---------------------------------\n","LunarLander - Step: 60001 | Mean Reward: -91.22 ± 78.96\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 682      |\n","|    ep_rew_mean     | -124     |\n","| time/              |          |\n","|    episodes        | 100      |\n","|    fps             | 26       |\n","|    time_elapsed    | 30       |\n","|    total_timesteps | 70790    |\n","| train/             |          |\n","|    actor_loss      | -2.59    |\n","|    critic_loss     | 1.12     |\n","|    ent_coef        | 0.0463   |\n","|    ent_coef_loss   | -2.31    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 141378   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 706      |\n","|    ep_rew_mean     | -116     |\n","| time/              |          |\n","|    episodes        | 104      |\n","|    fps             | 26       |\n","|    time_elapsed    | 147      |\n","|    total_timesteps | 73880    |\n","| train/             |          |\n","|    actor_loss      | 0.0331   |\n","|    critic_loss     | 1.57     |\n","|    ent_coef        | 0.0372   |\n","|    ent_coef_loss   | -0.343   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 147558   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 742      |\n","|    ep_rew_mean     | -114     |\n","| time/              |          |\n","|    episodes        | 108      |\n","|    fps             | 26       |\n","|    time_elapsed    | 299      |\n","|    total_timesteps | 77880    |\n","| train/             |          |\n","|    actor_loss      | 0.949    |\n","|    critic_loss     | 1.21     |\n","|    ent_coef        | 0.0336   |\n","|    ent_coef_loss   | -1.62    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 155558   |\n","---------------------------------\n","LunarLander - Step: 70001 | Mean Reward: -45.76 ± 25.25\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 771      |\n","|    ep_rew_mean     | -106     |\n","| time/              |          |\n","|    episodes        | 112      |\n","|    fps             | 25       |\n","|    time_elapsed    | 77       |\n","|    total_timesteps | 82000    |\n","| train/             |          |\n","|    actor_loss      | -1.42    |\n","|    critic_loss     | 0.793    |\n","|    ent_coef        | 0.0282   |\n","|    ent_coef_loss   | -0.771   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 163798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 803      |\n","|    ep_rew_mean     | -100     |\n","| time/              |          |\n","|    episodes        | 116      |\n","|    fps             | 26       |\n","|    time_elapsed    | 229      |\n","|    total_timesteps | 86000    |\n","| train/             |          |\n","|    actor_loss      | 4.76     |\n","|    critic_loss     | 0.87     |\n","|    ent_coef        | 0.0257   |\n","|    ent_coef_loss   | -0.484   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 171798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 835      |\n","|    ep_rew_mean     | -90.4    |\n","| time/              |          |\n","|    episodes        | 120      |\n","|    fps             | 26       |\n","|    time_elapsed    | 377      |\n","|    total_timesteps | 90000    |\n","| train/             |          |\n","|    actor_loss      | 3.76     |\n","|    critic_loss     | 0.671    |\n","|    ent_coef        | 0.0262   |\n","|    ent_coef_loss   | -1.39    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 179798   |\n","---------------------------------\n","LunarLander - Step: 80001 | Mean Reward: -29.96 ± 22.37\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 867      |\n","|    ep_rew_mean     | -85.1    |\n","| time/              |          |\n","|    episodes        | 124      |\n","|    fps             | 26       |\n","|    time_elapsed    | 148      |\n","|    total_timesteps | 94000    |\n","| train/             |          |\n","|    actor_loss      | 0.268    |\n","|    critic_loss     | 17       |\n","|    ent_coef        | 0.0217   |\n","|    ent_coef_loss   | 0.875    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 187798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 898      |\n","|    ep_rew_mean     | -82      |\n","| time/              |          |\n","|    episodes        | 128      |\n","|    fps             | 27       |\n","|    time_elapsed    | 294      |\n","|    total_timesteps | 98000    |\n","| train/             |          |\n","|    actor_loss      | 1.5      |\n","|    critic_loss     | 1.27     |\n","|    ent_coef        | 0.0258   |\n","|    ent_coef_loss   | -1.22    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 195798   |\n","---------------------------------\n","LunarLander - Step: 90001 | Mean Reward: -55.06 ± 22.58\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 900      |\n","|    ep_rew_mean     | -80      |\n","| time/              |          |\n","|    episodes        | 132      |\n","|    fps             | 26       |\n","|    time_elapsed    | 76       |\n","|    total_timesteps | 102000   |\n","| train/             |          |\n","|    actor_loss      | 5.48     |\n","|    critic_loss     | 0.773    |\n","|    ent_coef        | 0.0234   |\n","|    ent_coef_loss   | -1.55    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 203798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 900      |\n","|    ep_rew_mean     | -79.5    |\n","| time/              |          |\n","|    episodes        | 136      |\n","|    fps             | 26       |\n","|    time_elapsed    | 223      |\n","|    total_timesteps | 106000   |\n","| train/             |          |\n","|    actor_loss      | 6.92     |\n","|    critic_loss     | 0.683    |\n","|    ent_coef        | 0.0211   |\n","|    ent_coef_loss   | -0.212   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 211798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 900      |\n","|    ep_rew_mean     | -78.3    |\n","| time/              |          |\n","|    episodes        | 140      |\n","|    fps             | 26       |\n","|    time_elapsed    | 370      |\n","|    total_timesteps | 110000   |\n","| train/             |          |\n","|    actor_loss      | 0.492    |\n","|    critic_loss     | 0.697    |\n","|    ent_coef        | 0.0215   |\n","|    ent_coef_loss   | 1.41     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 219798   |\n","---------------------------------\n","LunarLander - Step: 100001 | Mean Reward: -37.64 ± 18.47\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 900      |\n","|    ep_rew_mean     | -76.7    |\n","| time/              |          |\n","|    episodes        | 144      |\n","|    fps             | 26       |\n","|    time_elapsed    | 151      |\n","|    total_timesteps | 114000   |\n","| train/             |          |\n","|    actor_loss      | 4.25     |\n","|    critic_loss     | 0.801    |\n","|    ent_coef        | 0.0224   |\n","|    ent_coef_loss   | -0.235   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 227798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 905      |\n","|    ep_rew_mean     | -73.6    |\n","| time/              |          |\n","|    episodes        | 148      |\n","|    fps             | 26       |\n","|    time_elapsed    | 302      |\n","|    total_timesteps | 118000   |\n","| train/             |          |\n","|    actor_loss      | 3.55     |\n","|    critic_loss     | 0.499    |\n","|    ent_coef        | 0.0227   |\n","|    ent_coef_loss   | -2.05    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 235798   |\n","---------------------------------\n","LunarLander - Step: 110001 | Mean Reward: -39.21 ± 15.19\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 911      |\n","|    ep_rew_mean     | -68.1    |\n","| time/              |          |\n","|    episodes        | 152      |\n","|    fps             | 26       |\n","|    time_elapsed    | 76       |\n","|    total_timesteps | 122000   |\n","| train/             |          |\n","|    actor_loss      | 5.48     |\n","|    critic_loss     | 1.02     |\n","|    ent_coef        | 0.0222   |\n","|    ent_coef_loss   | 2.2      |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 243798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 911      |\n","|    ep_rew_mean     | -67      |\n","| time/              |          |\n","|    episodes        | 156      |\n","|    fps             | 27       |\n","|    time_elapsed    | 221      |\n","|    total_timesteps | 126000   |\n","| train/             |          |\n","|    actor_loss      | 4.67     |\n","|    critic_loss     | 2.87     |\n","|    ent_coef        | 0.0229   |\n","|    ent_coef_loss   | -1.1     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 251798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 928      |\n","|    ep_rew_mean     | -65.7    |\n","| time/              |          |\n","|    episodes        | 160      |\n","|    fps             | 26       |\n","|    time_elapsed    | 374      |\n","|    total_timesteps | 130000   |\n","| train/             |          |\n","|    actor_loss      | 5.88     |\n","|    critic_loss     | 0.596    |\n","|    ent_coef        | 0.0212   |\n","|    ent_coef_loss   | -0.214   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 259798   |\n","---------------------------------\n","LunarLander - Step: 120001 | Mean Reward: -33.01 ± 23.35\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 945      |\n","|    ep_rew_mean     | -62.6    |\n","| time/              |          |\n","|    episodes        | 164      |\n","|    fps             | 27       |\n","|    time_elapsed    | 145      |\n","|    total_timesteps | 134000   |\n","| train/             |          |\n","|    actor_loss      | 7.11     |\n","|    critic_loss     | 0.526    |\n","|    ent_coef        | 0.0178   |\n","|    ent_coef_loss   | -0.93    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 267798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 956      |\n","|    ep_rew_mean     | -61.6    |\n","| time/              |          |\n","|    episodes        | 168      |\n","|    fps             | 26       |\n","|    time_elapsed    | 296      |\n","|    total_timesteps | 138000   |\n","| train/             |          |\n","|    actor_loss      | 1.92     |\n","|    critic_loss     | 1.05     |\n","|    ent_coef        | 0.017    |\n","|    ent_coef_loss   | -0.707   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 275798   |\n","---------------------------------\n","LunarLander - Step: 130001 | Mean Reward: -24.20 ± 21.34\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 960      |\n","|    ep_rew_mean     | -59.7    |\n","| time/              |          |\n","|    episodes        | 172      |\n","|    fps             | 26       |\n","|    time_elapsed    | 75       |\n","|    total_timesteps | 142000   |\n","| train/             |          |\n","|    actor_loss      | 2.82     |\n","|    critic_loss     | 0.573    |\n","|    ent_coef        | 0.0171   |\n","|    ent_coef_loss   | -0.681   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 283798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 960      |\n","|    ep_rew_mean     | -59.5    |\n","| time/              |          |\n","|    episodes        | 176      |\n","|    fps             | 27       |\n","|    time_elapsed    | 221      |\n","|    total_timesteps | 146000   |\n","| train/             |          |\n","|    actor_loss      | 5.49     |\n","|    critic_loss     | 1.22     |\n","|    ent_coef        | 0.0175   |\n","|    ent_coef_loss   | 0.00272  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 291798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 960      |\n","|    ep_rew_mean     | -58.8    |\n","| time/              |          |\n","|    episodes        | 180      |\n","|    fps             | 26       |\n","|    time_elapsed    | 373      |\n","|    total_timesteps | 150000   |\n","| train/             |          |\n","|    actor_loss      | 5.58     |\n","|    critic_loss     | 3.4      |\n","|    ent_coef        | 0.0171   |\n","|    ent_coef_loss   | 0.602    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 299798   |\n","---------------------------------\n","LunarLander - Step: 140001 | Mean Reward: -53.49 ± 28.23\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 961      |\n","|    ep_rew_mean     | -58.2    |\n","| time/              |          |\n","|    episodes        | 184      |\n","|    fps             | 26       |\n","|    time_elapsed    | 150      |\n","|    total_timesteps | 154000   |\n","| train/             |          |\n","|    actor_loss      | 6.09     |\n","|    critic_loss     | 0.54     |\n","|    ent_coef        | 0.0153   |\n","|    ent_coef_loss   | -0.349   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 307798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 961      |\n","|    ep_rew_mean     | -58.6    |\n","| time/              |          |\n","|    episodes        | 188      |\n","|    fps             | 26       |\n","|    time_elapsed    | 303      |\n","|    total_timesteps | 158000   |\n","| train/             |          |\n","|    actor_loss      | 6.34     |\n","|    critic_loss     | 0.682    |\n","|    ent_coef        | 0.0153   |\n","|    ent_coef_loss   | 0.447    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 315798   |\n","---------------------------------\n","LunarLander - Step: 150001 | Mean Reward: -39.21 ± 41.49\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 970      |\n","|    ep_rew_mean     | -54.1    |\n","| time/              |          |\n","|    episodes        | 192      |\n","|    fps             | 26       |\n","|    time_elapsed    | 74       |\n","|    total_timesteps | 162000   |\n","| train/             |          |\n","|    actor_loss      | 8.2      |\n","|    critic_loss     | 0.441    |\n","|    ent_coef        | 0.0166   |\n","|    ent_coef_loss   | -1.69    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 323798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 984      |\n","|    ep_rew_mean     | -47.6    |\n","| time/              |          |\n","|    episodes        | 196      |\n","|    fps             | 26       |\n","|    time_elapsed    | 225      |\n","|    total_timesteps | 166000   |\n","| train/             |          |\n","|    actor_loss      | 4.42     |\n","|    critic_loss     | 0.763    |\n","|    ent_coef        | 0.0174   |\n","|    ent_coef_loss   | -0.26    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 331798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 989      |\n","|    ep_rew_mean     | -44.2    |\n","| time/              |          |\n","|    episodes        | 200      |\n","|    fps             | 26       |\n","|    time_elapsed    | 380      |\n","|    total_timesteps | 170000   |\n","| train/             |          |\n","|    actor_loss      | 3.89     |\n","|    critic_loss     | 0.884    |\n","|    ent_coef        | 0.0188   |\n","|    ent_coef_loss   | -0.0907  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 339798   |\n","---------------------------------\n","LunarLander - Step: 160001 | Mean Reward: -14.78 ± 17.02\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -42.3    |\n","| time/              |          |\n","|    episodes        | 204      |\n","|    fps             | 26       |\n","|    time_elapsed    | 152      |\n","|    total_timesteps | 174000   |\n","| train/             |          |\n","|    actor_loss      | 0.836    |\n","|    critic_loss     | 0.66     |\n","|    ent_coef        | 0.0182   |\n","|    ent_coef_loss   | 0.591    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 347798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -41.6    |\n","| time/              |          |\n","|    episodes        | 208      |\n","|    fps             | 26       |\n","|    time_elapsed    | 303      |\n","|    total_timesteps | 178000   |\n","| train/             |          |\n","|    actor_loss      | -3.1     |\n","|    critic_loss     | 0.565    |\n","|    ent_coef        | 0.0172   |\n","|    ent_coef_loss   | -0.422   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 355798   |\n","---------------------------------\n","LunarLander - Step: 170001 | Mean Reward: -27.29 ± 22.60\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -39.2    |\n","| time/              |          |\n","|    episodes        | 212      |\n","|    fps             | 26       |\n","|    time_elapsed    | 74       |\n","|    total_timesteps | 182000   |\n","| train/             |          |\n","|    actor_loss      | 7.58     |\n","|    critic_loss     | 8.64     |\n","|    ent_coef        | 0.0185   |\n","|    ent_coef_loss   | -0.3     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 363798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -37.2    |\n","| time/              |          |\n","|    episodes        | 216      |\n","|    fps             | 26       |\n","|    time_elapsed    | 225      |\n","|    total_timesteps | 186000   |\n","| train/             |          |\n","|    actor_loss      | 1.67     |\n","|    critic_loss     | 0.465    |\n","|    ent_coef        | 0.0169   |\n","|    ent_coef_loss   | 0.689    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 371798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -37.5    |\n","| time/              |          |\n","|    episodes        | 220      |\n","|    fps             | 26       |\n","|    time_elapsed    | 380      |\n","|    total_timesteps | 190000   |\n","| train/             |          |\n","|    actor_loss      | 1.24     |\n","|    critic_loss     | 0.653    |\n","|    ent_coef        | 0.0161   |\n","|    ent_coef_loss   | 1.33     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 379798   |\n","---------------------------------\n","LunarLander - Step: 180001 | Mean Reward: -7.99 ± 23.45\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -35.4    |\n","| time/              |          |\n","|    episodes        | 224      |\n","|    fps             | 25       |\n","|    time_elapsed    | 154      |\n","|    total_timesteps | 194000   |\n","| train/             |          |\n","|    actor_loss      | 8.34     |\n","|    critic_loss     | 0.514    |\n","|    ent_coef        | 0.0158   |\n","|    ent_coef_loss   | -1.11    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 387798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 998      |\n","|    ep_rew_mean     | -32.2    |\n","| time/              |          |\n","|    episodes        | 228      |\n","|    fps             | 26       |\n","|    time_elapsed    | 303      |\n","|    total_timesteps | 198000   |\n","| train/             |          |\n","|    actor_loss      | 2.36     |\n","|    critic_loss     | 0.406    |\n","|    ent_coef        | 0.0163   |\n","|    ent_coef_loss   | 0.585    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 395798   |\n","---------------------------------\n","LunarLander - Step: 190001 | Mean Reward: -21.80 ± 21.96\n"]}]},{"cell_type":"markdown","source":["env=1, batch size= 128, lr= 1e-4"],"metadata":{"id":"jesypoG63yz9"}},{"cell_type":"code","source":["def train_lunarlander2():\n","    # Create environment and model for LunarLander (continuous version for SAC)\n","    env_lunar = make_vec_env(\"LunarLanderContinuous-v3\", n_envs=1)\n","    model = SAC(\"MlpPolicy\", env_lunar, verbose=1, tensorboard_log=\"/content/tb_logs/sac_lunarlanderenv1lr1eb128/\",\n","                learning_rate=1e-4, buffer_size=100000, batch_size=128, tau=1.68e-1,\n","                gamma=0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n","\n","    eval_freq = 10000  # Evaluate every 10,000 steps\n","    n_eval_episodes = 10  # Number of episodes per evaluation\n","\n","    for step in range(1, 200001, eval_freq):\n","        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n","        mean_reward, std_reward = evaluate_model(model, env_lunar, n_eval_episodes)\n","        print(f\"LunarLander - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n","\n","    model.replay_buffer = None  # This removes the buffer before saving\n","    temp_path = \"/content/sac_lunarlanderenv1lr1eb128\"\n","    model.save(temp_path)\n","\n","    #model.save(\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr1eb128\")\n"],"metadata":{"id":"tvi38wFu4NM5","executionInfo":{"status":"ok","timestamp":1740523890274,"user_tz":-120,"elapsed":47,"user":{"displayName":"Rana Choker","userId":"13341093079406228038"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    train_lunarlander2()"],"metadata":{"id":"zglzfv0h59CC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d0d46f4b-af43-4a98-e3ba-05d46c9d98e2","executionInfo":{"status":"ok","timestamp":1740532162577,"user_tz":-120,"elapsed":653033,"user":{"displayName":"Rana Choker","userId":"13341093079406228038"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 132      |\n","|    ep_rew_mean     | -341     |\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 33       |\n","|    time_elapsed    | 15       |\n","|    total_timesteps | 527      |\n","| train/             |          |\n","|    actor_loss      | -1.36    |\n","|    critic_loss     | 8.82     |\n","|    ent_coef        | 0.922    |\n","|    ent_coef_loss   | -0.244   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 852      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 134      |\n","|    ep_rew_mean     | -267     |\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 30       |\n","|    time_elapsed    | 35       |\n","|    total_timesteps | 1075     |\n","| train/             |          |\n","|    actor_loss      | 28.3     |\n","|    critic_loss     | 25.3     |\n","|    ent_coef        | 0.831    |\n","|    ent_coef_loss   | -0.454   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 1948     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 140      |\n","|    ep_rew_mean     | -233     |\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 28       |\n","|    time_elapsed    | 59       |\n","|    total_timesteps | 1680     |\n","| train/             |          |\n","|    actor_loss      | 17.3     |\n","|    critic_loss     | 8.49     |\n","|    ent_coef        | 0.746    |\n","|    ent_coef_loss   | -0.736   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 3158     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 305      |\n","|    ep_rew_mean     | -187     |\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 26       |\n","|    time_elapsed    | 186      |\n","|    total_timesteps | 4882     |\n","| train/             |          |\n","|    actor_loss      | -16.7    |\n","|    critic_loss     | 6.73     |\n","|    ent_coef        | 0.397    |\n","|    ent_coef_loss   | -1.94    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 9562     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 418      |\n","|    ep_rew_mean     | -150     |\n","| time/              |          |\n","|    episodes        | 20       |\n","|    fps             | 25       |\n","|    time_elapsed    | 325      |\n","|    total_timesteps | 8355     |\n","| train/             |          |\n","|    actor_loss      | -17.6    |\n","|    critic_loss     | 23.1     |\n","|    ent_coef        | 0.203    |\n","|    ent_coef_loss   | -2.58    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 16508    |\n","---------------------------------\n","LunarLander - Step: 1 | Mean Reward: -40.23 ± 25.09\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 515      |\n","|    ep_rew_mean     | -136     |\n","| time/              |          |\n","|    episodes        | 24       |\n","|    fps             | 24       |\n","|    time_elapsed    | 122      |\n","|    total_timesteps | 13000    |\n","| train/             |          |\n","|    actor_loss      | -18.8    |\n","|    critic_loss     | 11.3     |\n","|    ent_coef        | 0.0834   |\n","|    ent_coef_loss   | -2.84    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 25798    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 584      |\n","|    ep_rew_mean     | -124     |\n","| time/              |          |\n","|    episodes        | 28       |\n","|    fps             | 24       |\n","|    time_elapsed    | 282      |\n","|    total_timesteps | 17000    |\n","| train/             |          |\n","|    actor_loss      | -15.1    |\n","|    critic_loss     | 1.5      |\n","|    ent_coef        | 0.0436   |\n","|    ent_coef_loss   | -1.74    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 33798    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 603      |\n","|    ep_rew_mean     | -125     |\n","| time/              |          |\n","|    episodes        | 32       |\n","|    fps             | 24       |\n","|    time_elapsed    | 398      |\n","|    total_timesteps | 19946    |\n","| train/             |          |\n","|    actor_loss      | -17.1    |\n","|    critic_loss     | 2.11     |\n","|    ent_coef        | 0.0406   |\n","|    ent_coef_loss   | 1.86     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 39690    |\n","---------------------------------\n","LunarLander - Step: 10001 | Mean Reward: -95.39 ± 49.42\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 644      |\n","|    ep_rew_mean     | -123     |\n","| time/              |          |\n","|    episodes        | 36       |\n","|    fps             | 25       |\n","|    time_elapsed    | 153      |\n","|    total_timesteps | 23898    |\n","| train/             |          |\n","|    actor_loss      | -21.2    |\n","|    critic_loss     | 2.2      |\n","|    ent_coef        | 0.0528   |\n","|    ent_coef_loss   | -0.552   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 47594    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 654      |\n","|    ep_rew_mean     | -128     |\n","| time/              |          |\n","|    episodes        | 40       |\n","|    fps             | 25       |\n","|    time_elapsed    | 273      |\n","|    total_timesteps | 26853    |\n","| train/             |          |\n","|    actor_loss      | -18.5    |\n","|    critic_loss     | 2.72     |\n","|    ent_coef        | 0.0661   |\n","|    ent_coef_loss   | 0.0882   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 53504    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 662      |\n","|    ep_rew_mean     | -115     |\n","| time/              |          |\n","|    episodes        | 44       |\n","|    fps             | 25       |\n","|    time_elapsed    | 392      |\n","|    total_timesteps | 29849    |\n","| train/             |          |\n","|    actor_loss      | -14.8    |\n","|    critic_loss     | 1.79     |\n","|    ent_coef        | 0.072    |\n","|    ent_coef_loss   | -1.31    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 59496    |\n","---------------------------------\n","LunarLander - Step: 20001 | Mean Reward: -56.80 ± 93.86\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 655      |\n","|    ep_rew_mean     | -104     |\n","| time/              |          |\n","|    episodes        | 48       |\n","|    fps             | 25       |\n","|    time_elapsed    | 88       |\n","|    total_timesteps | 32285    |\n","| train/             |          |\n","|    actor_loss      | -12.8    |\n","|    critic_loss     | 2.39     |\n","|    ent_coef        | 0.0653   |\n","|    ent_coef_loss   | -1.82    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 64368    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 641      |\n","|    ep_rew_mean     | -100     |\n","| time/              |          |\n","|    episodes        | 52       |\n","|    fps             | 25       |\n","|    time_elapsed    | 164      |\n","|    total_timesteps | 34180    |\n","| train/             |          |\n","|    actor_loss      | -9.08    |\n","|    critic_loss     | 11.2     |\n","|    ent_coef        | 0.0545   |\n","|    ent_coef_loss   | 0.00723  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 68158    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 650      |\n","|    ep_rew_mean     | -95.2    |\n","| time/              |          |\n","|    episodes        | 56       |\n","|    fps             | 25       |\n","|    time_elapsed    | 285      |\n","|    total_timesteps | 37238    |\n","| train/             |          |\n","|    actor_loss      | -18.1    |\n","|    critic_loss     | 2.52     |\n","|    ent_coef        | 0.0588   |\n","|    ent_coef_loss   | -0.25    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 74274    |\n","---------------------------------\n","LunarLander - Step: 30001 | Mean Reward: -44.75 ± 73.76\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 668      |\n","|    ep_rew_mean     | -92.6    |\n","| time/              |          |\n","|    episodes        | 60       |\n","|    fps             | 25       |\n","|    time_elapsed    | 39       |\n","|    total_timesteps | 41000    |\n","| train/             |          |\n","|    actor_loss      | -15.7    |\n","|    critic_loss     | 2.28     |\n","|    ent_coef        | 0.0571   |\n","|    ent_coef_loss   | -0.402   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 81798    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 686      |\n","|    ep_rew_mean     | -88.9    |\n","| time/              |          |\n","|    episodes        | 64       |\n","|    fps             | 25       |\n","|    time_elapsed    | 193      |\n","|    total_timesteps | 44852    |\n","| train/             |          |\n","|    actor_loss      | -17.3    |\n","|    critic_loss     | 2.44     |\n","|    ent_coef        | 0.0495   |\n","|    ent_coef_loss   | -1.45    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 89502    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 701      |\n","|    ep_rew_mean     | -85.6    |\n","| time/              |          |\n","|    episodes        | 68       |\n","|    fps             | 25       |\n","|    time_elapsed    | 343      |\n","|    total_timesteps | 48607    |\n","| train/             |          |\n","|    actor_loss      | -11.9    |\n","|    critic_loss     | 1.22     |\n","|    ent_coef        | 0.0422   |\n","|    ent_coef_loss   | -0.442   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 97012    |\n","---------------------------------\n","LunarLander - Step: 40001 | Mean Reward: 18.10 ± 85.11\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 693      |\n","|    ep_rew_mean     | -81.8    |\n","| time/              |          |\n","|    episodes        | 72       |\n","|    fps             | 26       |\n","|    time_elapsed    | 42       |\n","|    total_timesteps | 51128    |\n","| train/             |          |\n","|    actor_loss      | -11.8    |\n","|    critic_loss     | 3.39     |\n","|    ent_coef        | 0.0376   |\n","|    ent_coef_loss   | -0.232   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 102054   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 698      |\n","|    ep_rew_mean     | -79.9    |\n","| time/              |          |\n","|    episodes        | 76       |\n","|    fps             | 25       |\n","|    time_elapsed    | 165      |\n","|    total_timesteps | 54254    |\n","| train/             |          |\n","|    actor_loss      | -14.8    |\n","|    critic_loss     | 1.06     |\n","|    ent_coef        | 0.0354   |\n","|    ent_coef_loss   | -0.0449  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 108306   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 713      |\n","|    ep_rew_mean     | -76.5    |\n","| time/              |          |\n","|    episodes        | 80       |\n","|    fps             | 25       |\n","|    time_elapsed    | 324      |\n","|    total_timesteps | 58254    |\n","| train/             |          |\n","|    actor_loss      | -11.2    |\n","|    critic_loss     | 4.24     |\n","|    ent_coef        | 0.0358   |\n","|    ent_coef_loss   | 0.107    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 116306   |\n","---------------------------------\n","LunarLander - Step: 50001 | Mean Reward: -3.94 ± 62.36\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 726      |\n","|    ep_rew_mean     | -73.3    |\n","| time/              |          |\n","|    episodes        | 84       |\n","|    fps             | 25       |\n","|    time_elapsed    | 117      |\n","|    total_timesteps | 62979    |\n","| train/             |          |\n","|    actor_loss      | -16      |\n","|    critic_loss     | 80.1     |\n","|    ent_coef        | 0.0374   |\n","|    ent_coef_loss   | -0.101   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 125756   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 739      |\n","|    ep_rew_mean     | -71      |\n","| time/              |          |\n","|    episodes        | 88       |\n","|    fps             | 25       |\n","|    time_elapsed    | 277      |\n","|    total_timesteps | 66979    |\n","| train/             |          |\n","|    actor_loss      | -7.57    |\n","|    critic_loss     | 1.59     |\n","|    ent_coef        | 0.034    |\n","|    ent_coef_loss   | -0.0338  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 133756   |\n","---------------------------------\n","LunarLander - Step: 60001 | Mean Reward: -41.62 ± 59.31\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 750      |\n","|    ep_rew_mean     | -69.2    |\n","| time/              |          |\n","|    episodes        | 92       |\n","|    fps             | 24       |\n","|    time_elapsed    | 40       |\n","|    total_timesteps | 71000    |\n","| train/             |          |\n","|    actor_loss      | -9.49    |\n","|    critic_loss     | 1.54     |\n","|    ent_coef        | 0.0292   |\n","|    ent_coef_loss   | 0.0256   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 141798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 754      |\n","|    ep_rew_mean     | -59.7    |\n","| time/              |          |\n","|    episodes        | 96       |\n","|    fps             | 25       |\n","|    time_elapsed    | 171      |\n","|    total_timesteps | 74343    |\n","| train/             |          |\n","|    actor_loss      | -8.67    |\n","|    critic_loss     | 2.5      |\n","|    ent_coef        | 0.0306   |\n","|    ent_coef_loss   | 1.13     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 148484   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 756      |\n","|    ep_rew_mean     | -55.2    |\n","| time/              |          |\n","|    episodes        | 100      |\n","|    fps             | 25       |\n","|    time_elapsed    | 299      |\n","|    total_timesteps | 77618    |\n","| train/             |          |\n","|    actor_loss      | -12.8    |\n","|    critic_loss     | 1.2      |\n","|    ent_coef        | 0.0341   |\n","|    ent_coef_loss   | -0.739   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 155034   |\n","---------------------------------\n","LunarLander - Step: 70001 | Mean Reward: -54.73 ± 106.18\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 779      |\n","|    ep_rew_mean     | -41.2    |\n","| time/              |          |\n","|    episodes        | 104      |\n","|    fps             | 24       |\n","|    time_elapsed    | 40       |\n","|    total_timesteps | 81000    |\n","| train/             |          |\n","|    actor_loss      | -6.07    |\n","|    critic_loss     | 1.05     |\n","|    ent_coef        | 0.0323   |\n","|    ent_coef_loss   | 0.666    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 161798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 812      |\n","|    ep_rew_mean     | -31.4    |\n","| time/              |          |\n","|    episodes        | 108      |\n","|    fps             | 24       |\n","|    time_elapsed    | 191      |\n","|    total_timesteps | 84759    |\n","| train/             |          |\n","|    actor_loss      | -15      |\n","|    critic_loss     | 1.82     |\n","|    ent_coef        | 0.0344   |\n","|    ent_coef_loss   | 0.437    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 169316   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 838      |\n","|    ep_rew_mean     | -22.6    |\n","| time/              |          |\n","|    episodes        | 112      |\n","|    fps             | 25       |\n","|    time_elapsed    | 319      |\n","|    total_timesteps | 88004    |\n","| train/             |          |\n","|    actor_loss      | -12.7    |\n","|    critic_loss     | 1.49     |\n","|    ent_coef        | 0.0355   |\n","|    ent_coef_loss   | 0.38     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 175806   |\n","---------------------------------\n","LunarLander - Step: 80001 | Mean Reward: -122.70 ± 88.60\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 841      |\n","|    ep_rew_mean     | -20.4    |\n","| time/              |          |\n","|    episodes        | 116      |\n","|    fps             | 25       |\n","|    time_elapsed    | 101      |\n","|    total_timesteps | 92554    |\n","| train/             |          |\n","|    actor_loss      | -13.4    |\n","|    critic_loss     | 1.49     |\n","|    ent_coef        | 0.0354   |\n","|    ent_coef_loss   | 0.222    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 184906   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 834      |\n","|    ep_rew_mean     | -24.7    |\n","| time/              |          |\n","|    episodes        | 120      |\n","|    fps             | 25       |\n","|    time_elapsed    | 202      |\n","|    total_timesteps | 95246    |\n","| train/             |          |\n","|    actor_loss      | -15.6    |\n","|    critic_loss     | 2.46     |\n","|    ent_coef        | 0.0382   |\n","|    ent_coef_loss   | 0.571    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 190290   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 822      |\n","|    ep_rew_mean     | -24.1    |\n","| time/              |          |\n","|    episodes        | 124      |\n","|    fps             | 25       |\n","|    time_elapsed    | 312      |\n","|    total_timesteps | 98064    |\n","| train/             |          |\n","|    actor_loss      | -12.7    |\n","|    critic_loss     | 2.17     |\n","|    ent_coef        | 0.0339   |\n","|    ent_coef_loss   | -0.0443  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 195926   |\n","---------------------------------\n","LunarLander - Step: 90001 | Mean Reward: -52.12 ± 122.78\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 811      |\n","|    ep_rew_mean     | -27.2    |\n","| time/              |          |\n","|    episodes        | 128      |\n","|    fps             | 25       |\n","|    time_elapsed    | 38       |\n","|    total_timesteps | 101000   |\n","| train/             |          |\n","|    actor_loss      | -12.2    |\n","|    critic_loss     | 2.32     |\n","|    ent_coef        | 0.0316   |\n","|    ent_coef_loss   | 0.0607   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 201798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 816      |\n","|    ep_rew_mean     | -22.4    |\n","| time/              |          |\n","|    episodes        | 132      |\n","|    fps             | 25       |\n","|    time_elapsed    | 174      |\n","|    total_timesteps | 104466   |\n","| train/             |          |\n","|    actor_loss      | -11.8    |\n","|    critic_loss     | 1.52     |\n","|    ent_coef        | 0.0321   |\n","|    ent_coef_loss   | -0.411   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 208730   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 810      |\n","|    ep_rew_mean     | -16.8    |\n","| time/              |          |\n","|    episodes        | 136      |\n","|    fps             | 25       |\n","|    time_elapsed    | 303      |\n","|    total_timesteps | 107750   |\n","| train/             |          |\n","|    actor_loss      | -15.2    |\n","|    critic_loss     | 1.13     |\n","|    ent_coef        | 0.0341   |\n","|    ent_coef_loss   | 0.462    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 215298   |\n","---------------------------------\n","LunarLander - Step: 100001 | Mean Reward: 19.37 ± 115.39\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 815      |\n","|    ep_rew_mean     | -12.9    |\n","| time/              |          |\n","|    episodes        | 140      |\n","|    fps             | 25       |\n","|    time_elapsed    | 57       |\n","|    total_timesteps | 111475   |\n","| train/             |          |\n","|    actor_loss      | -14.7    |\n","|    critic_loss     | 2.24     |\n","|    ent_coef        | 0.0351   |\n","|    ent_coef_loss   | -0.151   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 222748   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 799      |\n","|    ep_rew_mean     | -11.9    |\n","| time/              |          |\n","|    episodes        | 144      |\n","|    fps             | 25       |\n","|    time_elapsed    | 112      |\n","|    total_timesteps | 112895   |\n","| train/             |          |\n","|    actor_loss      | -12.8    |\n","|    critic_loss     | 53.1     |\n","|    ent_coef        | 0.0379   |\n","|    ent_coef_loss   | -0.0155  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 225588   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 806      |\n","|    ep_rew_mean     | -7.36    |\n","| time/              |          |\n","|    episodes        | 148      |\n","|    fps             | 25       |\n","|    time_elapsed    | 224      |\n","|    total_timesteps | 115826   |\n","| train/             |          |\n","|    actor_loss      | -10.8    |\n","|    critic_loss     | 5.99     |\n","|    ent_coef        | 0.0376   |\n","|    ent_coef_loss   | -0.265   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 231450   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 822      |\n","|    ep_rew_mean     | -3.89    |\n","| time/              |          |\n","|    episodes        | 152      |\n","|    fps             | 25       |\n","|    time_elapsed    | 360      |\n","|    total_timesteps | 119313   |\n","| train/             |          |\n","|    actor_loss      | -12.4    |\n","|    critic_loss     | 1.94     |\n","|    ent_coef        | 0.0379   |\n","|    ent_coef_loss   | -0.44    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 238424   |\n","---------------------------------\n","LunarLander - Step: 110001 | Mean Reward: 88.18 ± 126.84\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 825      |\n","|    ep_rew_mean     | -2.96    |\n","| time/              |          |\n","|    episodes        | 156      |\n","|    fps             | 26       |\n","|    time_elapsed    | 132      |\n","|    total_timesteps | 123456   |\n","| train/             |          |\n","|    actor_loss      | -9.69    |\n","|    critic_loss     | 1.52     |\n","|    ent_coef        | 0.0334   |\n","|    ent_coef_loss   | -0.0539  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 246710   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 812      |\n","|    ep_rew_mean     | 6.4      |\n","| time/              |          |\n","|    episodes        | 160      |\n","|    fps             | 25       |\n","|    time_elapsed    | 224      |\n","|    total_timesteps | 125797   |\n","| train/             |          |\n","|    actor_loss      | -14.5    |\n","|    critic_loss     | 1.3      |\n","|    ent_coef        | 0.0335   |\n","|    ent_coef_loss   | -0.498   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 251392   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 790      |\n","|    ep_rew_mean     | 16.6     |\n","| time/              |          |\n","|    episodes        | 164      |\n","|    fps             | 26       |\n","|    time_elapsed    | 285      |\n","|    total_timesteps | 127440   |\n","| train/             |          |\n","|    actor_loss      | -16.1    |\n","|    critic_loss     | 1.54     |\n","|    ent_coef        | 0.0349   |\n","|    ent_coef_loss   | 0.202    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 254678   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 776      |\n","|    ep_rew_mean     | 23.9     |\n","| time/              |          |\n","|    episodes        | 168      |\n","|    fps             | 25       |\n","|    time_elapsed    | 378      |\n","|    total_timesteps | 129824   |\n","| train/             |          |\n","|    actor_loss      | -15.6    |\n","|    critic_loss     | 62.5     |\n","|    ent_coef        | 0.033    |\n","|    ent_coef_loss   | 1.07     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 259446   |\n","---------------------------------\n","LunarLander - Step: 120001 | Mean Reward: 165.67 ± 137.56\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 783      |\n","|    ep_rew_mean     | 27.9     |\n","| time/              |          |\n","|    episodes        | 172      |\n","|    fps             | 25       |\n","|    time_elapsed    | 111      |\n","|    total_timesteps | 132871   |\n","| train/             |          |\n","|    actor_loss      | -13.4    |\n","|    critic_loss     | 3.87     |\n","|    ent_coef        | 0.0327   |\n","|    ent_coef_loss   | 0.609    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 265540   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 780      |\n","|    ep_rew_mean     | 32.6     |\n","| time/              |          |\n","|    episodes        | 176      |\n","|    fps             | 26       |\n","|    time_elapsed    | 217      |\n","|    total_timesteps | 135690   |\n","| train/             |          |\n","|    actor_loss      | -12.3    |\n","|    critic_loss     | 1.44     |\n","|    ent_coef        | 0.0302   |\n","|    ent_coef_loss   | -0.295   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 271178   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 763      |\n","|    ep_rew_mean     | 39.3     |\n","| time/              |          |\n","|    episodes        | 180      |\n","|    fps             | 26       |\n","|    time_elapsed    | 307      |\n","|    total_timesteps | 138047   |\n","| train/             |          |\n","|    actor_loss      | -13.2    |\n","|    critic_loss     | 10.5     |\n","|    ent_coef        | 0.029    |\n","|    ent_coef_loss   | 0.213    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 275892   |\n","---------------------------------\n","LunarLander - Step: 130001 | Mean Reward: 99.89 ± 149.80\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 753      |\n","|    ep_rew_mean     | 43.4     |\n","| time/              |          |\n","|    episodes        | 184      |\n","|    fps             | 25       |\n","|    time_elapsed    | 55       |\n","|    total_timesteps | 141439   |\n","| train/             |          |\n","|    actor_loss      | -14.1    |\n","|    critic_loss     | 0.993    |\n","|    ent_coef        | 0.0303   |\n","|    ent_coef_loss   | -0.043   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 282676   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 741      |\n","|    ep_rew_mean     | 48.6     |\n","| time/              |          |\n","|    episodes        | 188      |\n","|    fps             | 25       |\n","|    time_elapsed    | 164      |\n","|    total_timesteps | 144231   |\n","| train/             |          |\n","|    actor_loss      | -9.86    |\n","|    critic_loss     | 0.845    |\n","|    ent_coef        | 0.0304   |\n","|    ent_coef_loss   | -0.171   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 288260   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 725      |\n","|    ep_rew_mean     | 56.2     |\n","| time/              |          |\n","|    episodes        | 192      |\n","|    fps             | 25       |\n","|    time_elapsed    | 261      |\n","|    total_timesteps | 146703   |\n","| train/             |          |\n","|    actor_loss      | -15.3    |\n","|    critic_loss     | 0.928    |\n","|    ent_coef        | 0.0326   |\n","|    ent_coef_loss   | 0.176    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 293204   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 715      |\n","|    ep_rew_mean     | 54.7     |\n","| time/              |          |\n","|    episodes        | 196      |\n","|    fps             | 25       |\n","|    time_elapsed    | 351      |\n","|    total_timesteps | 149051   |\n","| train/             |          |\n","|    actor_loss      | -17.5    |\n","|    critic_loss     | 1.07     |\n","|    ent_coef        | 0.0323   |\n","|    ent_coef_loss   | 0.227    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 297900   |\n","---------------------------------\n","LunarLander - Step: 140001 | Mean Reward: 4.05 ± 110.47\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 703      |\n","|    ep_rew_mean     | 61       |\n","| time/              |          |\n","|    episodes        | 200      |\n","|    fps             | 26       |\n","|    time_elapsed    | 46       |\n","|    total_timesteps | 151204   |\n","| train/             |          |\n","|    actor_loss      | -13.6    |\n","|    critic_loss     | 4.13     |\n","|    ent_coef        | 0.031    |\n","|    ent_coef_loss   | -0.395   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 302206   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 703      |\n","|    ep_rew_mean     | 65.9     |\n","| time/              |          |\n","|    episodes        | 204      |\n","|    fps             | 25       |\n","|    time_elapsed    | 154      |\n","|    total_timesteps | 153960   |\n","| train/             |          |\n","|    actor_loss      | -10.9    |\n","|    critic_loss     | 8.96     |\n","|    ent_coef        | 0.0305   |\n","|    ent_coef_loss   | -0.705   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 307718   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 682      |\n","|    ep_rew_mean     | 74.1     |\n","| time/              |          |\n","|    episodes        | 208      |\n","|    fps             | 25       |\n","|    time_elapsed    | 217      |\n","|    total_timesteps | 155614   |\n","| train/             |          |\n","|    actor_loss      | -11.9    |\n","|    critic_loss     | 1.9      |\n","|    ent_coef        | 0.0296   |\n","|    ent_coef_loss   | 0.329    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 311026   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 676      |\n","|    ep_rew_mean     | 74.7     |\n","| time/              |          |\n","|    episodes        | 212      |\n","|    fps             | 25       |\n","|    time_elapsed    | 325      |\n","|    total_timesteps | 158348   |\n","| train/             |          |\n","|    actor_loss      | -15.8    |\n","|    critic_loss     | 2.7      |\n","|    ent_coef        | 0.0296   |\n","|    ent_coef_loss   | -0.113   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 316494   |\n","---------------------------------\n","LunarLander - Step: 150001 | Mean Reward: 17.31 ± 137.88\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 669      |\n","|    ep_rew_mean     | 79       |\n","| time/              |          |\n","|    episodes        | 216      |\n","|    fps             | 25       |\n","|    time_elapsed    | 52       |\n","|    total_timesteps | 161319   |\n","| train/             |          |\n","|    actor_loss      | -16.2    |\n","|    critic_loss     | 1.41     |\n","|    ent_coef        | 0.0293   |\n","|    ent_coef_loss   | 0.581    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 322436   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 662      |\n","|    ep_rew_mean     | 89.9     |\n","| time/              |          |\n","|    episodes        | 220      |\n","|    fps             | 25       |\n","|    time_elapsed    | 128      |\n","|    total_timesteps | 163307   |\n","| train/             |          |\n","|    actor_loss      | -19.1    |\n","|    critic_loss     | 5.31     |\n","|    ent_coef        | 0.0299   |\n","|    ent_coef_loss   | 0.64     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 326412   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 652      |\n","|    ep_rew_mean     | 95.8     |\n","| time/              |          |\n","|    episodes        | 224      |\n","|    fps             | 25       |\n","|    time_elapsed    | 199      |\n","|    total_timesteps | 165183   |\n","| train/             |          |\n","|    actor_loss      | -17.7    |\n","|    critic_loss     | 1.08     |\n","|    ent_coef        | 0.0329   |\n","|    ent_coef_loss   | -0.81    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 330164   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 643      |\n","|    ep_rew_mean     | 108      |\n","| time/              |          |\n","|    episodes        | 228      |\n","|    fps             | 25       |\n","|    time_elapsed    | 275      |\n","|    total_timesteps | 167134   |\n","| train/             |          |\n","|    actor_loss      | -14      |\n","|    critic_loss     | 3.93     |\n","|    ent_coef        | 0.031    |\n","|    ent_coef_loss   | 0.431    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 334066   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 637      |\n","|    ep_rew_mean     | 112      |\n","| time/              |          |\n","|    episodes        | 232      |\n","|    fps             | 26       |\n","|    time_elapsed    | 384      |\n","|    total_timesteps | 170000   |\n","| train/             |          |\n","|    actor_loss      | -12.6    |\n","|    critic_loss     | 1.24     |\n","|    ent_coef        | 0.0311   |\n","|    ent_coef_loss   | 0.337    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 339798   |\n","---------------------------------\n","LunarLander - Step: 160001 | Mean Reward: 238.15 ± 20.61\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 617      |\n","|    ep_rew_mean     | 119      |\n","| time/              |          |\n","|    episodes        | 236      |\n","|    fps             | 26       |\n","|    time_elapsed    | 47       |\n","|    total_timesteps | 171262   |\n","| train/             |          |\n","|    actor_loss      | -17      |\n","|    critic_loss     | 2.56     |\n","|    ent_coef        | 0.0311   |\n","|    ent_coef_loss   | 0.248    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 342322   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 608      |\n","|    ep_rew_mean     | 126      |\n","| time/              |          |\n","|    episodes        | 240      |\n","|    fps             | 26       |\n","|    time_elapsed    | 149      |\n","|    total_timesteps | 173899   |\n","| train/             |          |\n","|    actor_loss      | -14.5    |\n","|    critic_loss     | 1.44     |\n","|    ent_coef        | 0.0304   |\n","|    ent_coef_loss   | 0.245    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 347596   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 609      |\n","|    ep_rew_mean     | 134      |\n","| time/              |          |\n","|    episodes        | 244      |\n","|    fps             | 26       |\n","|    time_elapsed    | 206      |\n","|    total_timesteps | 175430   |\n","| train/             |          |\n","|    actor_loss      | -15.5    |\n","|    critic_loss     | 0.671    |\n","|    ent_coef        | 0.0308   |\n","|    ent_coef_loss   | -0.14    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 350658   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 598      |\n","|    ep_rew_mean     | 139      |\n","| time/              |          |\n","|    episodes        | 248      |\n","|    fps             | 26       |\n","|    time_elapsed    | 272      |\n","|    total_timesteps | 177184   |\n","| train/             |          |\n","|    actor_loss      | -19      |\n","|    critic_loss     | 1.46     |\n","|    ent_coef        | 0.0348   |\n","|    ent_coef_loss   | 0.0412   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 354166   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 578      |\n","|    ep_rew_mean     | 139      |\n","| time/              |          |\n","|    episodes        | 252      |\n","|    fps             | 26       |\n","|    time_elapsed    | 328      |\n","|    total_timesteps | 178707   |\n","| train/             |          |\n","|    actor_loss      | -16      |\n","|    critic_loss     | 2.16     |\n","|    ent_coef        | 0.0318   |\n","|    ent_coef_loss   | 0.117    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 357212   |\n","---------------------------------\n","LunarLander - Step: 170001 | Mean Reward: 144.59 ± 111.62\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 556      |\n","|    ep_rew_mean     | 149      |\n","| time/              |          |\n","|    episodes        | 256      |\n","|    fps             | 26       |\n","|    time_elapsed    | 32       |\n","|    total_timesteps | 180859   |\n","| train/             |          |\n","|    actor_loss      | -15.1    |\n","|    critic_loss     | 35.1     |\n","|    ent_coef        | 0.0313   |\n","|    ent_coef_loss   | 0.173    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 361516   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 551      |\n","|    ep_rew_mean     | 151      |\n","| time/              |          |\n","|    episodes        | 260      |\n","|    fps             | 26       |\n","|    time_elapsed    | 101      |\n","|    total_timesteps | 182737   |\n","| train/             |          |\n","|    actor_loss      | -15.9    |\n","|    critic_loss     | 1.39     |\n","|    ent_coef        | 0.0338   |\n","|    ent_coef_loss   | 0.00944  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 365272   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 555      |\n","|    ep_rew_mean     | 149      |\n","| time/              |          |\n","|    episodes        | 264      |\n","|    fps             | 26       |\n","|    time_elapsed    | 177      |\n","|    total_timesteps | 184737   |\n","| train/             |          |\n","|    actor_loss      | -15.3    |\n","|    critic_loss     | 9.92     |\n","|    ent_coef        | 0.0348   |\n","|    ent_coef_loss   | -0.323   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 369272   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 546      |\n","|    ep_rew_mean     | 148      |\n","| time/              |          |\n","|    episodes        | 268      |\n","|    fps             | 26       |\n","|    time_elapsed    | 236      |\n","|    total_timesteps | 186263   |\n","| train/             |          |\n","|    actor_loss      | -16.4    |\n","|    critic_loss     | 3.65     |\n","|    ent_coef        | 0.0378   |\n","|    ent_coef_loss   | 0.608    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 372324   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 535      |\n","|    ep_rew_mean     | 150      |\n","| time/              |          |\n","|    episodes        | 272      |\n","|    fps             | 26       |\n","|    time_elapsed    | 302      |\n","|    total_timesteps | 188033   |\n","| train/             |          |\n","|    actor_loss      | -18.7    |\n","|    critic_loss     | 2.4      |\n","|    ent_coef        | 0.0413   |\n","|    ent_coef_loss   | 0.379    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 375864   |\n","---------------------------------\n","LunarLander - Step: 180001 | Mean Reward: 167.91 ± 90.50\n","Logging to /content/tb_logs/sac_lunarlanderenv1lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 531      |\n","|    ep_rew_mean     | 150      |\n","| time/              |          |\n","|    episodes        | 276      |\n","|    fps             | 26       |\n","|    time_elapsed    | 38       |\n","|    total_timesteps | 191000   |\n","| train/             |          |\n","|    actor_loss      | -17.3    |\n","|    critic_loss     | 8.73     |\n","|    ent_coef        | 0.0413   |\n","|    ent_coef_loss   | 0.0498   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 381798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 519      |\n","|    ep_rew_mean     | 154      |\n","| time/              |          |\n","|    episodes        | 280      |\n","|    fps             | 26       |\n","|    time_elapsed    | 81       |\n","|    total_timesteps | 192142   |\n","| train/             |          |\n","|    actor_loss      | -19.3    |\n","|    critic_loss     | 5.45     |\n","|    ent_coef        | 0.0409   |\n","|    ent_coef_loss   | -0.144   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 384082   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 528      |\n","|    ep_rew_mean     | 147      |\n","| time/              |          |\n","|    episodes        | 284      |\n","|    fps             | 25       |\n","|    time_elapsed    | 230      |\n","|    total_timesteps | 195981   |\n","| train/             |          |\n","|    actor_loss      | -19.1    |\n","|    critic_loss     | 1.48     |\n","|    ent_coef        | 0.0409   |\n","|    ent_coef_loss   | 0.388    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 391760   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 510      |\n","|    ep_rew_mean     | 148      |\n","| time/              |          |\n","|    episodes        | 288      |\n","|    fps             | 25       |\n","|    time_elapsed    | 266      |\n","|    total_timesteps | 196926   |\n","| train/             |          |\n","|    actor_loss      | -23.6    |\n","|    critic_loss     | 6.05     |\n","|    ent_coef        | 0.0401   |\n","|    ent_coef_loss   | 0.155    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 393650   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 493      |\n","|    ep_rew_mean     | 144      |\n","| time/              |          |\n","|    episodes        | 292      |\n","|    fps             | 25       |\n","|    time_elapsed    | 296      |\n","|    total_timesteps | 197681   |\n","| train/             |          |\n","|    actor_loss      | -20.8    |\n","|    critic_loss     | 45.4     |\n","|    ent_coef        | 0.0406   |\n","|    ent_coef_loss   | -0.578   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 395160   |\n","---------------------------------\n","LunarLander - Step: 190001 | Mean Reward: 91.82 ± 138.01\n"]}]},{"cell_type":"code","source":["!mv /content/tb_logs /content/drive/MyDrive/RLmodels/"],"metadata":{"id":"JdEa1uYBTrB7","executionInfo":{"status":"ok","timestamp":1740532183680,"user_tz":-120,"elapsed":305,"user":{"displayName":"Rana Choker","userId":"13341093079406228038"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Move to Google Drive after saving\n","!mv {temp_path} /content/drive/MyDrive/RLmodels/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlf31JnuSft_","executionInfo":{"status":"ok","timestamp":1740532186058,"user_tz":-120,"elapsed":127,"user":{"displayName":"Rana Choker","userId":"13341093079406228038"}},"outputId":"db74ef54-dd92-43d1-c43e-75ea102ea9c4"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["mv: cannot stat '{temp_path}': No such file or directory\n"]}]},{"cell_type":"markdown","source":["env=1, batch size= 128, lr= 3e-4"],"metadata":{"id":"JzY0j02536kS"}},{"cell_type":"code","source":["def train_lunarlander4():\n","    # Create environment and model for LunarLander (continuous version for SAC)\n","    env_lunar = make_vec_env(\"LunarLanderContinuous-v3\", n_envs=1)\n","    model = SAC(\"MlpPolicy\", env_lunar, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/\",\n","                learning_rate=3e-4, buffer_size=500000, batch_size=128, tau=1.68e-1,\n","                gamma=0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n","\n","    eval_freq = 10000  # Evaluate every 10,000 steps\n","    n_eval_episodes = 10  # Number of episodes per evaluation\n","\n","    for step in range(1, 200001, eval_freq):\n","        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n","        mean_reward, std_reward = evaluate_model(model, env_lunar, n_eval_episodes)\n","        print(f\"LunarLander - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n","\n","    model.save(\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128\")"],"metadata":{"id":"et7zPL4h4-Gv","executionInfo":{"status":"ok","timestamp":1740532310327,"user_tz":-120,"elapsed":31,"user":{"displayName":"Rana Choker","userId":"13341093079406228038"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["train_lunarlander4()"],"metadata":{"id":"jBuCdMdu6Dnq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740540511952,"user_tz":-120,"elapsed":8184520,"user":{"displayName":"Rana Choker","userId":"13341093079406228038"}},"outputId":"8d97d51b-408b-452d-f35a-3c14fe59b1bf"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 112      |\n","|    ep_rew_mean     | -248     |\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 34       |\n","|    time_elapsed    | 12       |\n","|    total_timesteps | 448      |\n","| train/             |          |\n","|    actor_loss      | -21.5    |\n","|    critic_loss     | 6.52     |\n","|    ent_coef        | 0.829    |\n","|    ent_coef_loss   | -0.387   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 694      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 156      |\n","|    ep_rew_mean     | -225     |\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 28       |\n","|    time_elapsed    | 43       |\n","|    total_timesteps | 1249     |\n","| train/             |          |\n","|    actor_loss      | -17.7    |\n","|    critic_loss     | 11       |\n","|    ent_coef        | 0.564    |\n","|    ent_coef_loss   | -0.929   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 2296     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 323      |\n","|    ep_rew_mean     | -204     |\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 26       |\n","|    time_elapsed    | 148      |\n","|    total_timesteps | 3875     |\n","| train/             |          |\n","|    actor_loss      | -102     |\n","|    critic_loss     | 136      |\n","|    ent_coef        | 0.25     |\n","|    ent_coef_loss   | 0.00301  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 7548     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 380      |\n","|    ep_rew_mean     | -171     |\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 25       |\n","|    time_elapsed    | 234      |\n","|    total_timesteps | 6086     |\n","| train/             |          |\n","|    actor_loss      | -59.3    |\n","|    critic_loss     | 45.2     |\n","|    ent_coef        | 0.185    |\n","|    ent_coef_loss   | -0.116   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 11970    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 396      |\n","|    ep_rew_mean     | -148     |\n","| time/              |          |\n","|    episodes        | 20       |\n","|    fps             | 25       |\n","|    time_elapsed    | 308      |\n","|    total_timesteps | 7926     |\n","| train/             |          |\n","|    actor_loss      | -70.7    |\n","|    critic_loss     | 27.3     |\n","|    ent_coef        | 0.172    |\n","|    ent_coef_loss   | 0.269    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 15650    |\n","---------------------------------\n","LunarLander - Step: 1 | Mean Reward: 10.23 ± 161.42\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 472      |\n","|    ep_rew_mean     | -127     |\n","| time/              |          |\n","|    episodes        | 24       |\n","|    fps             | 25       |\n","|    time_elapsed    | 55       |\n","|    total_timesteps | 11412    |\n","| train/             |          |\n","|    actor_loss      | -44.8    |\n","|    critic_loss     | 7.54     |\n","|    ent_coef        | 0.14     |\n","|    ent_coef_loss   | -0.00515 |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 22622    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 482      |\n","|    ep_rew_mean     | -121     |\n","| time/              |          |\n","|    episodes        | 28       |\n","|    fps             | 25       |\n","|    time_elapsed    | 141      |\n","|    total_timesteps | 13575    |\n","| train/             |          |\n","|    actor_loss      | -45      |\n","|    critic_loss     | 8.46     |\n","|    ent_coef        | 0.125    |\n","|    ent_coef_loss   | -0.533   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 26948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 432      |\n","|    ep_rew_mean     | -129     |\n","| time/              |          |\n","|    episodes        | 32       |\n","|    fps             | 25       |\n","|    time_elapsed    | 153      |\n","|    total_timesteps | 13896    |\n","| train/             |          |\n","|    actor_loss      | -36.9    |\n","|    critic_loss     | 14.6     |\n","|    ent_coef        | 0.114    |\n","|    ent_coef_loss   | 0.0761   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 27590    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 469      |\n","|    ep_rew_mean     | -119     |\n","| time/              |          |\n","|    episodes        | 36       |\n","|    fps             | 25       |\n","|    time_elapsed    | 275      |\n","|    total_timesteps | 16967    |\n","| train/             |          |\n","|    actor_loss      | -36      |\n","|    critic_loss     | 9.76     |\n","|    ent_coef        | 0.11     |\n","|    ent_coef_loss   | -0.437   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 33732    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 486      |\n","|    ep_rew_mean     | -103     |\n","| time/              |          |\n","|    episodes        | 40       |\n","|    fps             | 25       |\n","|    time_elapsed    | 376      |\n","|    total_timesteps | 19496    |\n","| train/             |          |\n","|    actor_loss      | -35.8    |\n","|    critic_loss     | 5.42     |\n","|    ent_coef        | 0.121    |\n","|    ent_coef_loss   | 0.413    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 38790    |\n","---------------------------------\n","LunarLander - Step: 10001 | Mean Reward: -27.54 ± 104.52\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 505      |\n","|    ep_rew_mean     | -88.6    |\n","| time/              |          |\n","|    episodes        | 44       |\n","|    fps             | 25       |\n","|    time_elapsed    | 109      |\n","|    total_timesteps | 22818    |\n","| train/             |          |\n","|    actor_loss      | -25.2    |\n","|    critic_loss     | 6.21     |\n","|    ent_coef        | 0.111    |\n","|    ent_coef_loss   | 0.116    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 45434    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 523      |\n","|    ep_rew_mean     | -89.2    |\n","| time/              |          |\n","|    episodes        | 48       |\n","|    fps             | 25       |\n","|    time_elapsed    | 227      |\n","|    total_timesteps | 25699    |\n","| train/             |          |\n","|    actor_loss      | -18.5    |\n","|    critic_loss     | 4.44     |\n","|    ent_coef        | 0.101    |\n","|    ent_coef_loss   | -0.539   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 51196    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 548      |\n","|    ep_rew_mean     | -84.2    |\n","| time/              |          |\n","|    episodes        | 52       |\n","|    fps             | 24       |\n","|    time_elapsed    | 366      |\n","|    total_timesteps | 29051    |\n","| train/             |          |\n","|    actor_loss      | -21.3    |\n","|    critic_loss     | 4.19     |\n","|    ent_coef        | 0.103    |\n","|    ent_coef_loss   | -0.0117  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 57900    |\n","---------------------------------\n","LunarLander - Step: 20001 | Mean Reward: -14.15 ± 18.91\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 561      |\n","|    ep_rew_mean     | -81.6    |\n","| time/              |          |\n","|    episodes        | 56       |\n","|    fps             | 24       |\n","|    time_elapsed    | 123      |\n","|    total_timesteps | 32965    |\n","| train/             |          |\n","|    actor_loss      | -29.1    |\n","|    critic_loss     | 2.71     |\n","|    ent_coef        | 0.091    |\n","|    ent_coef_loss   | -0.121   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 65728    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 563      |\n","|    ep_rew_mean     | -80.5    |\n","| time/              |          |\n","|    episodes        | 60       |\n","|    fps             | 24       |\n","|    time_elapsed    | 221      |\n","|    total_timesteps | 35334    |\n","| train/             |          |\n","|    actor_loss      | -17.3    |\n","|    critic_loss     | 20       |\n","|    ent_coef        | 0.0718   |\n","|    ent_coef_loss   | 0.0268   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 70466    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 556      |\n","|    ep_rew_mean     | -80.5    |\n","| time/              |          |\n","|    episodes        | 64       |\n","|    fps             | 23       |\n","|    time_elapsed    | 298      |\n","|    total_timesteps | 37130    |\n","| train/             |          |\n","|    actor_loss      | -11.8    |\n","|    critic_loss     | 5.12     |\n","|    ent_coef        | 0.0608   |\n","|    ent_coef_loss   | 0.412    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 74058    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 561      |\n","|    ep_rew_mean     | -73.6    |\n","| time/              |          |\n","|    episodes        | 68       |\n","|    fps             | 24       |\n","|    time_elapsed    | 401      |\n","|    total_timesteps | 39666    |\n","| train/             |          |\n","|    actor_loss      | -12.2    |\n","|    critic_loss     | 4.34     |\n","|    ent_coef        | 0.065    |\n","|    ent_coef_loss   | 0.422    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 79130    |\n","---------------------------------\n","LunarLander - Step: 30001 | Mean Reward: 174.43 ± 84.44\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 579      |\n","|    ep_rew_mean     | -62.2    |\n","| time/              |          |\n","|    episodes        | 72       |\n","|    fps             | 23       |\n","|    time_elapsed    | 150      |\n","|    total_timesteps | 43563    |\n","| train/             |          |\n","|    actor_loss      | -22.5    |\n","|    critic_loss     | 8.52     |\n","|    ent_coef        | 0.0708   |\n","|    ent_coef_loss   | -0.34    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 86924    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 586      |\n","|    ep_rew_mean     | -49.8    |\n","| time/              |          |\n","|    episodes        | 76       |\n","|    fps             | 23       |\n","|    time_elapsed    | 266      |\n","|    total_timesteps | 46362    |\n","| train/             |          |\n","|    actor_loss      | -18      |\n","|    critic_loss     | 8.02     |\n","|    ent_coef        | 0.0667   |\n","|    ent_coef_loss   | -0.299   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 92522    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 592      |\n","|    ep_rew_mean     | -38.2    |\n","| time/              |          |\n","|    episodes        | 80       |\n","|    fps             | 24       |\n","|    time_elapsed    | 381      |\n","|    total_timesteps | 49189    |\n","| train/             |          |\n","|    actor_loss      | -25.2    |\n","|    critic_loss     | 2.68     |\n","|    ent_coef        | 0.0732   |\n","|    ent_coef_loss   | 0.478    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 98176    |\n","---------------------------------\n","LunarLander - Step: 40001 | Mean Reward: 181.53 ± 83.48\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 576      |\n","|    ep_rew_mean     | -28.4    |\n","| time/              |          |\n","|    episodes        | 84       |\n","|    fps             | 24       |\n","|    time_elapsed    | 15       |\n","|    total_timesteps | 50372    |\n","| train/             |          |\n","|    actor_loss      | -29.2    |\n","|    critic_loss     | 6.69     |\n","|    ent_coef        | 0.0786   |\n","|    ent_coef_loss   | -0.0412  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 100542   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 567      |\n","|    ep_rew_mean     | -16      |\n","| time/              |          |\n","|    episodes        | 88       |\n","|    fps             | 24       |\n","|    time_elapsed    | 74       |\n","|    total_timesteps | 51860    |\n","| train/             |          |\n","|    actor_loss      | -35.3    |\n","|    critic_loss     | 3.89     |\n","|    ent_coef        | 0.0773   |\n","|    ent_coef_loss   | 0.103    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 103518   |\n","---------------------------------\n","----------------------------------\n","| rollout/           |           |\n","|    ep_len_mean     | 554       |\n","|    ep_rew_mean     | -6.76     |\n","| time/              |           |\n","|    episodes        | 92        |\n","|    fps             | 25        |\n","|    time_elapsed    | 118       |\n","|    total_timesteps | 52985     |\n","| train/             |           |\n","|    actor_loss      | -31.8     |\n","|    critic_loss     | 6.42      |\n","|    ent_coef        | 0.0784    |\n","|    ent_coef_loss   | -0.000759 |\n","|    learning_rate   | 0.0003    |\n","|    n_updates       | 105768    |\n","----------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 538      |\n","|    ep_rew_mean     | -1.92    |\n","| time/              |          |\n","|    episodes        | 96       |\n","|    fps             | 25       |\n","|    time_elapsed    | 144      |\n","|    total_timesteps | 53616    |\n","| train/             |          |\n","|    actor_loss      | -29.4    |\n","|    critic_loss     | 4.82     |\n","|    ent_coef        | 0.0744   |\n","|    ent_coef_loss   | 1.1      |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 107030   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 524      |\n","|    ep_rew_mean     | 6.14     |\n","| time/              |          |\n","|    episodes        | 100      |\n","|    fps             | 25       |\n","|    time_elapsed    | 175      |\n","|    total_timesteps | 54407    |\n","| train/             |          |\n","|    actor_loss      | -28.2    |\n","|    critic_loss     | 5.64     |\n","|    ent_coef        | 0.0774   |\n","|    ent_coef_loss   | -0.547   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 108612   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 534      |\n","|    ep_rew_mean     | 25.4     |\n","| time/              |          |\n","|    episodes        | 104      |\n","|    fps             | 25       |\n","|    time_elapsed    | 231      |\n","|    total_timesteps | 55789    |\n","| train/             |          |\n","|    actor_loss      | -38.3    |\n","|    critic_loss     | 4.03     |\n","|    ent_coef        | 0.0838   |\n","|    ent_coef_loss   | -0.321   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 111376   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 538      |\n","|    ep_rew_mean     | 42.9     |\n","| time/              |          |\n","|    episodes        | 108      |\n","|    fps             | 25       |\n","|    time_elapsed    | 280      |\n","|    total_timesteps | 57023    |\n","| train/             |          |\n","|    actor_loss      | -42.6    |\n","|    critic_loss     | 4.99     |\n","|    ent_coef        | 0.0803   |\n","|    ent_coef_loss   | 0.31     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 113844   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 523      |\n","|    ep_rew_mean     | 59.4     |\n","| time/              |          |\n","|    episodes        | 112      |\n","|    fps             | 24       |\n","|    time_elapsed    | 326      |\n","|    total_timesteps | 58133    |\n","| train/             |          |\n","|    actor_loss      | -42.5    |\n","|    critic_loss     | 3.63     |\n","|    ent_coef        | 0.0783   |\n","|    ent_coef_loss   | -0.368   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 116064   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 512      |\n","|    ep_rew_mean     | 72.7     |\n","| time/              |          |\n","|    episodes        | 116      |\n","|    fps             | 24       |\n","|    time_elapsed    | 372      |\n","|    total_timesteps | 59297    |\n","| train/             |          |\n","|    actor_loss      | -43.4    |\n","|    critic_loss     | 2.99     |\n","|    ent_coef        | 0.0825   |\n","|    ent_coef_loss   | 0.569    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 118392   |\n","---------------------------------\n","LunarLander - Step: 50001 | Mean Reward: 237.61 ± 28.67\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 510      |\n","|    ep_rew_mean     | 85.6     |\n","| time/              |          |\n","|    episodes        | 120      |\n","|    fps             | 24       |\n","|    time_elapsed    | 42       |\n","|    total_timesteps | 61044    |\n","| train/             |          |\n","|    actor_loss      | -43.3    |\n","|    critic_loss     | 4.69     |\n","|    ent_coef        | 0.0834   |\n","|    ent_coef_loss   | -0.31    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 121886   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 492      |\n","|    ep_rew_mean     | 96.7     |\n","| time/              |          |\n","|    episodes        | 124      |\n","|    fps             | 25       |\n","|    time_elapsed    | 104      |\n","|    total_timesteps | 62615    |\n","| train/             |          |\n","|    actor_loss      | -44.7    |\n","|    critic_loss     | 7.62     |\n","|    ent_coef        | 0.0837   |\n","|    ent_coef_loss   | 0.0299   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 125028   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 487      |\n","|    ep_rew_mean     | 107      |\n","| time/              |          |\n","|    episodes        | 128      |\n","|    fps             | 24       |\n","|    time_elapsed    | 172      |\n","|    total_timesteps | 64313    |\n","| train/             |          |\n","|    actor_loss      | -42.8    |\n","|    critic_loss     | 17.9     |\n","|    ent_coef        | 0.0845   |\n","|    ent_coef_loss   | -0.0698  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 128424   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 498      |\n","|    ep_rew_mean     | 125      |\n","| time/              |          |\n","|    episodes        | 132      |\n","|    fps             | 24       |\n","|    time_elapsed    | 227      |\n","|    total_timesteps | 65681    |\n","| train/             |          |\n","|    actor_loss      | -46.1    |\n","|    critic_loss     | 8.32     |\n","|    ent_coef        | 0.0888   |\n","|    ent_coef_loss   | 0.00257  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 131160   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 478      |\n","|    ep_rew_mean     | 137      |\n","| time/              |          |\n","|    episodes        | 136      |\n","|    fps             | 24       |\n","|    time_elapsed    | 272      |\n","|    total_timesteps | 66802    |\n","| train/             |          |\n","|    actor_loss      | -48.2    |\n","|    critic_loss     | 2.83     |\n","|    ent_coef        | 0.0919   |\n","|    ent_coef_loss   | -0.0855  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 133402   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 466      |\n","|    ep_rew_mean     | 146      |\n","| time/              |          |\n","|    episodes        | 140      |\n","|    fps             | 25       |\n","|    time_elapsed    | 323      |\n","|    total_timesteps | 68104    |\n","| train/             |          |\n","|    actor_loss      | -48.5    |\n","|    critic_loss     | 4.68     |\n","|    ent_coef        | 0.0876   |\n","|    ent_coef_loss   | -0.651   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 136006   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 447      |\n","|    ep_rew_mean     | 154      |\n","| time/              |          |\n","|    episodes        | 144      |\n","|    fps             | 24       |\n","|    time_elapsed    | 361      |\n","|    total_timesteps | 69029    |\n","| train/             |          |\n","|    actor_loss      | -49.4    |\n","|    critic_loss     | 2.95     |\n","|    ent_coef        | 0.085    |\n","|    ent_coef_loss   | -0.294   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 137856   |\n","---------------------------------\n","LunarLander - Step: 60001 | Mean Reward: 267.90 ± 20.42\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 430      |\n","|    ep_rew_mean     | 168      |\n","| time/              |          |\n","|    episodes        | 148      |\n","|    fps             | 24       |\n","|    time_elapsed    | 18       |\n","|    total_timesteps | 70448    |\n","| train/             |          |\n","|    actor_loss      | -50.5    |\n","|    critic_loss     | 4.08     |\n","|    ent_coef        | 0.0839   |\n","|    ent_coef_loss   | -0.539   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 140694   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 412      |\n","|    ep_rew_mean     | 176      |\n","| time/              |          |\n","|    episodes        | 152      |\n","|    fps             | 24       |\n","|    time_elapsed    | 78       |\n","|    total_timesteps | 71939    |\n","| train/             |          |\n","|    actor_loss      | -51.1    |\n","|    critic_loss     | 7.65     |\n","|    ent_coef        | 0.085    |\n","|    ent_coef_loss   | 0.181    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 143676   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 394      |\n","|    ep_rew_mean     | 189      |\n","| time/              |          |\n","|    episodes        | 156      |\n","|    fps             | 24       |\n","|    time_elapsed    | 124      |\n","|    total_timesteps | 73109    |\n","| train/             |          |\n","|    actor_loss      | -51      |\n","|    critic_loss     | 4.4      |\n","|    ent_coef        | 0.0879   |\n","|    ent_coef_loss   | 0.411    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 146016   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 381      |\n","|    ep_rew_mean     | 201      |\n","| time/              |          |\n","|    episodes        | 160      |\n","|    fps             | 24       |\n","|    time_elapsed    | 168      |\n","|    total_timesteps | 74210    |\n","| train/             |          |\n","|    actor_loss      | -49.7    |\n","|    critic_loss     | 11.7     |\n","|    ent_coef        | 0.0876   |\n","|    ent_coef_loss   | 0.0675   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 148218   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 374      |\n","|    ep_rew_mean     | 214      |\n","| time/              |          |\n","|    episodes        | 164      |\n","|    fps             | 24       |\n","|    time_elapsed    | 212      |\n","|    total_timesteps | 75306    |\n","| train/             |          |\n","|    actor_loss      | -51.1    |\n","|    critic_loss     | 6.86     |\n","|    ent_coef        | 0.0869   |\n","|    ent_coef_loss   | -0.347   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 150410   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 359      |\n","|    ep_rew_mean     | 223      |\n","| time/              |          |\n","|    episodes        | 168      |\n","|    fps             | 24       |\n","|    time_elapsed    | 253      |\n","|    total_timesteps | 76328    |\n","| train/             |          |\n","|    actor_loss      | -54.4    |\n","|    critic_loss     | 30.1     |\n","|    ent_coef        | 0.0859   |\n","|    ent_coef_loss   | 0.972    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 152454   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 339      |\n","|    ep_rew_mean     | 229      |\n","| time/              |          |\n","|    episodes        | 172      |\n","|    fps             | 24       |\n","|    time_elapsed    | 314      |\n","|    total_timesteps | 77867    |\n","| train/             |          |\n","|    actor_loss      | -50.5    |\n","|    critic_loss     | 9.91     |\n","|    ent_coef        | 0.0872   |\n","|    ent_coef_loss   | -0.0835  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 155532   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 324      |\n","|    ep_rew_mean     | 231      |\n","| time/              |          |\n","|    episodes        | 176      |\n","|    fps             | 25       |\n","|    time_elapsed    | 366      |\n","|    total_timesteps | 79160    |\n","| train/             |          |\n","|    actor_loss      | -53      |\n","|    critic_loss     | 9.03     |\n","|    ent_coef        | 0.0928   |\n","|    ent_coef_loss   | 0.13     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 158118   |\n","---------------------------------\n","LunarLander - Step: 70001 | Mean Reward: 238.68 ± 31.88\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 313      |\n","|    ep_rew_mean     | 233      |\n","| time/              |          |\n","|    episodes        | 180      |\n","|    fps             | 24       |\n","|    time_elapsed    | 54       |\n","|    total_timesteps | 81322    |\n","| train/             |          |\n","|    actor_loss      | -56.7    |\n","|    critic_loss     | 6.11     |\n","|    ent_coef        | 0.0869   |\n","|    ent_coef_loss   | -0.521   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 162442   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 316      |\n","|    ep_rew_mean     | 235      |\n","| time/              |          |\n","|    episodes        | 184      |\n","|    fps             | 24       |\n","|    time_elapsed    | 108      |\n","|    total_timesteps | 82650    |\n","| train/             |          |\n","|    actor_loss      | -54.1    |\n","|    critic_loss     | 30.8     |\n","|    ent_coef        | 0.0931   |\n","|    ent_coef_loss   | -0.264   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 165098   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 312      |\n","|    ep_rew_mean     | 235      |\n","| time/              |          |\n","|    episodes        | 188      |\n","|    fps             | 24       |\n","|    time_elapsed    | 152      |\n","|    total_timesteps | 83705    |\n","| train/             |          |\n","|    actor_loss      | -51.3    |\n","|    critic_loss     | 9.83     |\n","|    ent_coef        | 0.0906   |\n","|    ent_coef_loss   | -0.295   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 167208   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 312      |\n","|    ep_rew_mean     | 238      |\n","| time/              |          |\n","|    episodes        | 192      |\n","|    fps             | 24       |\n","|    time_elapsed    | 197      |\n","|    total_timesteps | 84819    |\n","| train/             |          |\n","|    actor_loss      | -48      |\n","|    critic_loss     | 5.42     |\n","|    ent_coef        | 0.0888   |\n","|    ent_coef_loss   | 0.219    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 169436   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 317      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 196      |\n","|    fps             | 24       |\n","|    time_elapsed    | 246      |\n","|    total_timesteps | 86030    |\n","| train/             |          |\n","|    actor_loss      | -51.4    |\n","|    critic_loss     | 3.84     |\n","|    ent_coef        | 0.0891   |\n","|    ent_coef_loss   | -0.17    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 171858   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 324      |\n","|    ep_rew_mean     | 246      |\n","| time/              |          |\n","|    episodes        | 200      |\n","|    fps             | 24       |\n","|    time_elapsed    | 306      |\n","|    total_timesteps | 87492    |\n","| train/             |          |\n","|    actor_loss      | -55.7    |\n","|    critic_loss     | 14.3     |\n","|    ent_coef        | 0.0906   |\n","|    ent_coef_loss   | -0.281   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 174782   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 324      |\n","|    ep_rew_mean     | 247      |\n","| time/              |          |\n","|    episodes        | 204      |\n","|    fps             | 24       |\n","|    time_elapsed    | 362      |\n","|    total_timesteps | 88878    |\n","| train/             |          |\n","|    actor_loss      | -47.8    |\n","|    critic_loss     | 3.35     |\n","|    ent_coef        | 0.0914   |\n","|    ent_coef_loss   | 0.0788   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 177554   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 322      |\n","|    ep_rew_mean     | 248      |\n","| time/              |          |\n","|    episodes        | 208      |\n","|    fps             | 24       |\n","|    time_elapsed    | 401      |\n","|    total_timesteps | 89876    |\n","| train/             |          |\n","|    actor_loss      | -52.3    |\n","|    critic_loss     | 20.1     |\n","|    ent_coef        | 0.0932   |\n","|    ent_coef_loss   | 0.158    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 179550   |\n","---------------------------------\n","LunarLander - Step: 80001 | Mean Reward: 256.12 ± 14.12\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 327      |\n","|    ep_rew_mean     | 248      |\n","| time/              |          |\n","|    episodes        | 212      |\n","|    fps             | 25       |\n","|    time_elapsed    | 64       |\n","|    total_timesteps | 91606    |\n","| train/             |          |\n","|    actor_loss      | -50.5    |\n","|    critic_loss     | 3.75     |\n","|    ent_coef        | 0.092    |\n","|    ent_coef_loss   | -0.397   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 183010   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 326      |\n","|    ep_rew_mean     | 246      |\n","| time/              |          |\n","|    episodes        | 216      |\n","|    fps             | 25       |\n","|    time_elapsed    | 108      |\n","|    total_timesteps | 92721    |\n","| train/             |          |\n","|    actor_loss      | -52.6    |\n","|    critic_loss     | 5.23     |\n","|    ent_coef        | 0.0901   |\n","|    ent_coef_loss   | -0.268   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 185240   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 323      |\n","|    ep_rew_mean     | 246      |\n","| time/              |          |\n","|    episodes        | 220      |\n","|    fps             | 24       |\n","|    time_elapsed    | 162      |\n","|    total_timesteps | 94045    |\n","| train/             |          |\n","|    actor_loss      | -49.4    |\n","|    critic_loss     | 7.39     |\n","|    ent_coef        | 0.0906   |\n","|    ent_coef_loss   | -0.0333  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 187888   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 325      |\n","|    ep_rew_mean     | 245      |\n","| time/              |          |\n","|    episodes        | 224      |\n","|    fps             | 24       |\n","|    time_elapsed    | 234      |\n","|    total_timesteps | 95829    |\n","| train/             |          |\n","|    actor_loss      | -48.7    |\n","|    critic_loss     | 90       |\n","|    ent_coef        | 0.0912   |\n","|    ent_coef_loss   | 0.226    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 191456   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 323      |\n","|    ep_rew_mean     | 246      |\n","| time/              |          |\n","|    episodes        | 228      |\n","|    fps             | 24       |\n","|    time_elapsed    | 293      |\n","|    total_timesteps | 97290    |\n","| train/             |          |\n","|    actor_loss      | -51.5    |\n","|    critic_loss     | 8.54     |\n","|    ent_coef        | 0.0934   |\n","|    ent_coef_loss   | -0.525   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 194378   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 321      |\n","|    ep_rew_mean     | 246      |\n","| time/              |          |\n","|    episodes        | 232      |\n","|    fps             | 24       |\n","|    time_elapsed    | 341      |\n","|    total_timesteps | 98518    |\n","| train/             |          |\n","|    actor_loss      | -54.1    |\n","|    critic_loss     | 3.85     |\n","|    ent_coef        | 0.0949   |\n","|    ent_coef_loss   | 0.1      |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 196834   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 322      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 236      |\n","|    fps             | 24       |\n","|    time_elapsed    | 390      |\n","|    total_timesteps | 99709    |\n","| train/             |          |\n","|    actor_loss      | -48      |\n","|    critic_loss     | 3.66     |\n","|    ent_coef        | 0.0852   |\n","|    ent_coef_loss   | -0.0941  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 199216   |\n","---------------------------------\n","LunarLander - Step: 90001 | Mean Reward: 240.54 ± 40.10\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 322      |\n","|    ep_rew_mean     | 245      |\n","| time/              |          |\n","|    episodes        | 240      |\n","|    fps             | 25       |\n","|    time_elapsed    | 50       |\n","|    total_timesteps | 101257   |\n","| train/             |          |\n","|    actor_loss      | -53.5    |\n","|    critic_loss     | 3.96     |\n","|    ent_coef        | 0.082    |\n","|    ent_coef_loss   | 0.323    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 202312   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 327      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 244      |\n","|    fps             | 24       |\n","|    time_elapsed    | 110      |\n","|    total_timesteps | 102743   |\n","| train/             |          |\n","|    actor_loss      | -49.1    |\n","|    critic_loss     | 2.18     |\n","|    ent_coef        | 0.0863   |\n","|    ent_coef_loss   | 0.682    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 205284   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 327      |\n","|    ep_rew_mean     | 243      |\n","| time/              |          |\n","|    episodes        | 248      |\n","|    fps             | 24       |\n","|    time_elapsed    | 155      |\n","|    total_timesteps | 103890   |\n","| train/             |          |\n","|    actor_loss      | -43.1    |\n","|    critic_loss     | 3.11     |\n","|    ent_coef        | 0.0794   |\n","|    ent_coef_loss   | -0.161   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 207578   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 323      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 252      |\n","|    fps             | 25       |\n","|    time_elapsed    | 201      |\n","|    total_timesteps | 105040   |\n","| train/             |          |\n","|    actor_loss      | -53.8    |\n","|    critic_loss     | 7.67     |\n","|    ent_coef        | 0.0845   |\n","|    ent_coef_loss   | 0.106    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 209878   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 330      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 256      |\n","|    fps             | 24       |\n","|    time_elapsed    | 277      |\n","|    total_timesteps | 106862   |\n","| train/             |          |\n","|    actor_loss      | -42.3    |\n","|    critic_loss     | 5.06     |\n","|    ent_coef        | 0.0779   |\n","|    ent_coef_loss   | -0.529   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 213522   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 329      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 260      |\n","|    fps             | 24       |\n","|    time_elapsed    | 317      |\n","|    total_timesteps | 107884   |\n","| train/             |          |\n","|    actor_loss      | -45.1    |\n","|    critic_loss     | 6.6      |\n","|    ent_coef        | 0.0837   |\n","|    ent_coef_loss   | 0.419    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 215566   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 328      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 264      |\n","|    fps             | 24       |\n","|    time_elapsed    | 354      |\n","|    total_timesteps | 108851   |\n","| train/             |          |\n","|    actor_loss      | -46.8    |\n","|    critic_loss     | 3.73     |\n","|    ent_coef        | 0.0774   |\n","|    ent_coef_loss   | 0.287    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 217500   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 326      |\n","|    ep_rew_mean     | 245      |\n","| time/              |          |\n","|    episodes        | 268      |\n","|    fps             | 24       |\n","|    time_elapsed    | 388      |\n","|    total_timesteps | 109692   |\n","| train/             |          |\n","|    actor_loss      | -47.7    |\n","|    critic_loss     | 4.57     |\n","|    ent_coef        | 0.0743   |\n","|    ent_coef_loss   | -0.105   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 219182   |\n","---------------------------------\n","LunarLander - Step: 100001 | Mean Reward: 259.40 ± 27.46\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 320      |\n","|    ep_rew_mean     | 245      |\n","| time/              |          |\n","|    episodes        | 272      |\n","|    fps             | 25       |\n","|    time_elapsed    | 27       |\n","|    total_timesteps | 110712   |\n","| train/             |          |\n","|    actor_loss      | -45.7    |\n","|    critic_loss     | 4.24     |\n","|    ent_coef        | 0.0734   |\n","|    ent_coef_loss   | 0.414    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 221222   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 316      |\n","|    ep_rew_mean     | 247      |\n","| time/              |          |\n","|    episodes        | 276      |\n","|    fps             | 25       |\n","|    time_elapsed    | 63       |\n","|    total_timesteps | 111605   |\n","| train/             |          |\n","|    actor_loss      | -51      |\n","|    critic_loss     | 2.74     |\n","|    ent_coef        | 0.078    |\n","|    ent_coef_loss   | -0.0474  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 223008   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 311      |\n","|    ep_rew_mean     | 247      |\n","| time/              |          |\n","|    episodes        | 280      |\n","|    fps             | 24       |\n","|    time_elapsed    | 116      |\n","|    total_timesteps | 112895   |\n","| train/             |          |\n","|    actor_loss      | -47.5    |\n","|    critic_loss     | 14.4     |\n","|    ent_coef        | 0.0744   |\n","|    ent_coef_loss   | -0.492   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 225588   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 308      |\n","|    ep_rew_mean     | 248      |\n","| time/              |          |\n","|    episodes        | 284      |\n","|    fps             | 25       |\n","|    time_elapsed    | 155      |\n","|    total_timesteps | 113898   |\n","| train/             |          |\n","|    actor_loss      | -51.9    |\n","|    critic_loss     | 3.88     |\n","|    ent_coef        | 0.0729   |\n","|    ent_coef_loss   | -0.202   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 227594   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 309      |\n","|    ep_rew_mean     | 247      |\n","| time/              |          |\n","|    episodes        | 288      |\n","|    fps             | 25       |\n","|    time_elapsed    | 204      |\n","|    total_timesteps | 115145   |\n","| train/             |          |\n","|    actor_loss      | -50.4    |\n","|    critic_loss     | 3.87     |\n","|    ent_coef        | 0.0762   |\n","|    ent_coef_loss   | -0.383   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 230088   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 308      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 292      |\n","|    fps             | 25       |\n","|    time_elapsed    | 243      |\n","|    total_timesteps | 116130   |\n","| train/             |          |\n","|    actor_loss      | -45.4    |\n","|    critic_loss     | 3.76     |\n","|    ent_coef        | 0.0729   |\n","|    ent_coef_loss   | -0.125   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 232058   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 310      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 296      |\n","|    fps             | 25       |\n","|    time_elapsed    | 299      |\n","|    total_timesteps | 117537   |\n","| train/             |          |\n","|    actor_loss      | -49      |\n","|    critic_loss     | 5.6      |\n","|    ent_coef        | 0.0715   |\n","|    ent_coef_loss   | -0.242   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 234872   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 302      |\n","|    ep_rew_mean     | 239      |\n","| time/              |          |\n","|    episodes        | 300      |\n","|    fps             | 25       |\n","|    time_elapsed    | 327      |\n","|    total_timesteps | 118223   |\n","| train/             |          |\n","|    actor_loss      | -48.5    |\n","|    critic_loss     | 18.1     |\n","|    ent_coef        | 0.0747   |\n","|    ent_coef_loss   | -0.615   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 236244   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 297      |\n","|    ep_rew_mean     | 237      |\n","| time/              |          |\n","|    episodes        | 304      |\n","|    fps             | 25       |\n","|    time_elapsed    | 362      |\n","|    total_timesteps | 119092   |\n","| train/             |          |\n","|    actor_loss      | -47.5    |\n","|    critic_loss     | 3.23     |\n","|    ent_coef        | 0.0749   |\n","|    ent_coef_loss   | 0.799    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 237982   |\n","---------------------------------\n","LunarLander - Step: 110001 | Mean Reward: 232.69 ± 73.68\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 303      |\n","|    ep_rew_mean     | 233      |\n","| time/              |          |\n","|    episodes        | 308      |\n","|    fps             | 25       |\n","|    time_elapsed    | 30       |\n","|    total_timesteps | 120767   |\n","| train/             |          |\n","|    actor_loss      | -48.4    |\n","|    critic_loss     | 3.03     |\n","|    ent_coef        | 0.0721   |\n","|    ent_coef_loss   | 0.548    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 241332   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 297      |\n","|    ep_rew_mean     | 231      |\n","| time/              |          |\n","|    episodes        | 312      |\n","|    fps             | 25       |\n","|    time_elapsed    | 68       |\n","|    total_timesteps | 121731   |\n","| train/             |          |\n","|    actor_loss      | -45.3    |\n","|    critic_loss     | 22.7     |\n","|    ent_coef        | 0.0729   |\n","|    ent_coef_loss   | -0.495   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 243260   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 302      |\n","|    ep_rew_mean     | 231      |\n","| time/              |          |\n","|    episodes        | 316      |\n","|    fps             | 25       |\n","|    time_elapsed    | 132      |\n","|    total_timesteps | 123337   |\n","| train/             |          |\n","|    actor_loss      | -47.9    |\n","|    critic_loss     | 10.6     |\n","|    ent_coef        | 0.073    |\n","|    ent_coef_loss   | 0.0155   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 246472   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 300      |\n","|    ep_rew_mean     | 231      |\n","| time/              |          |\n","|    episodes        | 320      |\n","|    fps             | 24       |\n","|    time_elapsed    | 178      |\n","|    total_timesteps | 124446   |\n","| train/             |          |\n","|    actor_loss      | -44.9    |\n","|    critic_loss     | 3.54     |\n","|    ent_coef        | 0.0727   |\n","|    ent_coef_loss   | 0.599    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 248690   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 293      |\n","|    ep_rew_mean     | 230      |\n","| time/              |          |\n","|    episodes        | 324      |\n","|    fps             | 25       |\n","|    time_elapsed    | 223      |\n","|    total_timesteps | 125601   |\n","| train/             |          |\n","|    actor_loss      | -49.7    |\n","|    critic_loss     | 25.8     |\n","|    ent_coef        | 0.0727   |\n","|    ent_coef_loss   | -0.0723  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 251000   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 291      |\n","|    ep_rew_mean     | 231      |\n","| time/              |          |\n","|    episodes        | 328      |\n","|    fps             | 25       |\n","|    time_elapsed    | 270      |\n","|    total_timesteps | 126783   |\n","| train/             |          |\n","|    actor_loss      | -48.1    |\n","|    critic_loss     | 34.2     |\n","|    ent_coef        | 0.0757   |\n","|    ent_coef_loss   | -0.14    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 253364   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 290      |\n","|    ep_rew_mean     | 228      |\n","| time/              |          |\n","|    episodes        | 332      |\n","|    fps             | 25       |\n","|    time_elapsed    | 315      |\n","|    total_timesteps | 127911   |\n","| train/             |          |\n","|    actor_loss      | -50.6    |\n","|    critic_loss     | 5.62     |\n","|    ent_coef        | 0.0731   |\n","|    ent_coef_loss   | -0.217   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 255620   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 290      |\n","|    ep_rew_mean     | 229      |\n","| time/              |          |\n","|    episodes        | 336      |\n","|    fps             | 25       |\n","|    time_elapsed    | 366      |\n","|    total_timesteps | 129187   |\n","| train/             |          |\n","|    actor_loss      | -48.6    |\n","|    critic_loss     | 5.06     |\n","|    ent_coef        | 0.0689   |\n","|    ent_coef_loss   | -0.263   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 258172   |\n","---------------------------------\n","LunarLander - Step: 120001 | Mean Reward: 234.43 ± 70.91\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 289      |\n","|    ep_rew_mean     | 228      |\n","| time/              |          |\n","|    episodes        | 340      |\n","|    fps             | 23       |\n","|    time_elapsed    | 26       |\n","|    total_timesteps | 130630   |\n","| train/             |          |\n","|    actor_loss      | -48.4    |\n","|    critic_loss     | 20.6     |\n","|    ent_coef        | 0.0642   |\n","|    ent_coef_loss   | 0.344    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 261058   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 292      |\n","|    ep_rew_mean     | 228      |\n","| time/              |          |\n","|    episodes        | 344      |\n","|    fps             | 24       |\n","|    time_elapsed    | 98       |\n","|    total_timesteps | 132409   |\n","| train/             |          |\n","|    actor_loss      | -51.3    |\n","|    critic_loss     | 2.9      |\n","|    ent_coef        | 0.0655   |\n","|    ent_coef_loss   | -0.142   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 264616   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 293      |\n","|    ep_rew_mean     | 228      |\n","| time/              |          |\n","|    episodes        | 348      |\n","|    fps             | 24       |\n","|    time_elapsed    | 146      |\n","|    total_timesteps | 133628   |\n","| train/             |          |\n","|    actor_loss      | -46      |\n","|    critic_loss     | 14.3     |\n","|    ent_coef        | 0.0661   |\n","|    ent_coef_loss   | -0.234   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 267054   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 296      |\n","|    ep_rew_mean     | 229      |\n","| time/              |          |\n","|    episodes        | 352      |\n","|    fps             | 24       |\n","|    time_elapsed    | 201      |\n","|    total_timesteps | 135041   |\n","| train/             |          |\n","|    actor_loss      | -44.7    |\n","|    critic_loss     | 3.79     |\n","|    ent_coef        | 0.0656   |\n","|    ent_coef_loss   | 0.0517   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 269880   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 289      |\n","|    ep_rew_mean     | 229      |\n","| time/              |          |\n","|    episodes        | 356      |\n","|    fps             | 24       |\n","|    time_elapsed    | 249      |\n","|    total_timesteps | 136237   |\n","| train/             |          |\n","|    actor_loss      | -47.1    |\n","|    critic_loss     | 4.43     |\n","|    ent_coef        | 0.0639   |\n","|    ent_coef_loss   | 0.244    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 272272   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 292      |\n","|    ep_rew_mean     | 228      |\n","| time/              |          |\n","|    episodes        | 360      |\n","|    fps             | 24       |\n","|    time_elapsed    | 301      |\n","|    total_timesteps | 137524   |\n","| train/             |          |\n","|    actor_loss      | -47.3    |\n","|    critic_loss     | 3.13     |\n","|    ent_coef        | 0.0578   |\n","|    ent_coef_loss   | -0.541   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 274846   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 295      |\n","|    ep_rew_mean     | 228      |\n","| time/              |          |\n","|    episodes        | 364      |\n","|    fps             | 25       |\n","|    time_elapsed    | 352      |\n","|    total_timesteps | 138827   |\n","| train/             |          |\n","|    actor_loss      | -47.9    |\n","|    critic_loss     | 25.4     |\n","|    ent_coef        | 0.0637   |\n","|    ent_coef_loss   | -0.546   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 277452   |\n","---------------------------------\n","LunarLander - Step: 130001 | Mean Reward: 221.15 ± 74.48\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 300      |\n","|    ep_rew_mean     | 228      |\n","| time/              |          |\n","|    episodes        | 368      |\n","|    fps             | 25       |\n","|    time_elapsed    | 12       |\n","|    total_timesteps | 140313   |\n","| train/             |          |\n","|    actor_loss      | -47.9    |\n","|    critic_loss     | 3.34     |\n","|    ent_coef        | 0.0596   |\n","|    ent_coef_loss   | 0.31     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 280424   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 307      |\n","|    ep_rew_mean     | 226      |\n","| time/              |          |\n","|    episodes        | 372      |\n","|    fps             | 25       |\n","|    time_elapsed    | 77       |\n","|    total_timesteps | 141941   |\n","| train/             |          |\n","|    actor_loss      | -51.9    |\n","|    critic_loss     | 3.46     |\n","|    ent_coef        | 0.0589   |\n","|    ent_coef_loss   | -0.403   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 283680   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 315      |\n","|    ep_rew_mean     | 224      |\n","| time/              |          |\n","|    episodes        | 376      |\n","|    fps             | 24       |\n","|    time_elapsed    | 146      |\n","|    total_timesteps | 143633   |\n","| train/             |          |\n","|    actor_loss      | -49.6    |\n","|    critic_loss     | 2.39     |\n","|    ent_coef        | 0.0613   |\n","|    ent_coef_loss   | -0.304   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 287064   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 313      |\n","|    ep_rew_mean     | 226      |\n","| time/              |          |\n","|    episodes        | 380      |\n","|    fps             | 24       |\n","|    time_elapsed    | 189      |\n","|    total_timesteps | 144728   |\n","| train/             |          |\n","|    actor_loss      | -52.7    |\n","|    critic_loss     | 3.4      |\n","|    ent_coef        | 0.0626   |\n","|    ent_coef_loss   | 0.489    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 289254   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 312      |\n","|    ep_rew_mean     | 227      |\n","| time/              |          |\n","|    episodes        | 384      |\n","|    fps             | 25       |\n","|    time_elapsed    | 225      |\n","|    total_timesteps | 145651   |\n","| train/             |          |\n","|    actor_loss      | -54.2    |\n","|    critic_loss     | 24.1     |\n","|    ent_coef        | 0.0616   |\n","|    ent_coef_loss   | -0.256   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 291100   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 310      |\n","|    ep_rew_mean     | 228      |\n","| time/              |          |\n","|    episodes        | 388      |\n","|    fps             | 25       |\n","|    time_elapsed    | 267      |\n","|    total_timesteps | 146697   |\n","| train/             |          |\n","|    actor_loss      | -51.4    |\n","|    critic_loss     | 6.4      |\n","|    ent_coef        | 0.064    |\n","|    ent_coef_loss   | -0.484   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 293192   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 310      |\n","|    ep_rew_mean     | 231      |\n","| time/              |          |\n","|    episodes        | 392      |\n","|    fps             | 25       |\n","|    time_elapsed    | 304      |\n","|    total_timesteps | 147655   |\n","| train/             |          |\n","|    actor_loss      | -52.8    |\n","|    critic_loss     | 2.66     |\n","|    ent_coef        | 0.0642   |\n","|    ent_coef_loss   | -0.107   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 295108   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 306      |\n","|    ep_rew_mean     | 230      |\n","| time/              |          |\n","|    episodes        | 396      |\n","|    fps             | 25       |\n","|    time_elapsed    | 346      |\n","|    total_timesteps | 148715   |\n","| train/             |          |\n","|    actor_loss      | -49.5    |\n","|    critic_loss     | 7.51     |\n","|    ent_coef        | 0.0613   |\n","|    ent_coef_loss   | -0.0337  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 297228   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 309      |\n","|    ep_rew_mean     | 236      |\n","| time/              |          |\n","|    episodes        | 400      |\n","|    fps             | 25       |\n","|    time_elapsed    | 385      |\n","|    total_timesteps | 149708   |\n","| train/             |          |\n","|    actor_loss      | -55.9    |\n","|    critic_loss     | 2.83     |\n","|    ent_coef        | 0.0624   |\n","|    ent_coef_loss   | 0.291    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 299214   |\n","---------------------------------\n","LunarLander - Step: 140001 | Mean Reward: 212.66 ± 100.49\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 310      |\n","|    ep_rew_mean     | 237      |\n","| time/              |          |\n","|    episodes        | 404      |\n","|    fps             | 25       |\n","|    time_elapsed    | 27       |\n","|    total_timesteps | 150702   |\n","| train/             |          |\n","|    actor_loss      | -58.3    |\n","|    critic_loss     | 8.77     |\n","|    ent_coef        | 0.0663   |\n","|    ent_coef_loss   | 0.124    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 301202   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 302      |\n","|    ep_rew_mean     | 241      |\n","| time/              |          |\n","|    episodes        | 408      |\n","|    fps             | 25       |\n","|    time_elapsed    | 59       |\n","|    total_timesteps | 151511   |\n","| train/             |          |\n","|    actor_loss      | -54.7    |\n","|    critic_loss     | 2.37     |\n","|    ent_coef        | 0.0611   |\n","|    ent_coef_loss   | 0.346    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 302820   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 302      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 412      |\n","|    fps             | 25       |\n","|    time_elapsed    | 97       |\n","|    total_timesteps | 152498   |\n","| train/             |          |\n","|    actor_loss      | -55.9    |\n","|    critic_loss     | 2.95     |\n","|    ent_coef        | 0.0595   |\n","|    ent_coef_loss   | 0.936    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 304794   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 294      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 416      |\n","|    fps             | 25       |\n","|    time_elapsed    | 130      |\n","|    total_timesteps | 153298   |\n","| train/             |          |\n","|    actor_loss      | -51.6    |\n","|    critic_loss     | 24.6     |\n","|    ent_coef        | 0.0597   |\n","|    ent_coef_loss   | 0.244    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 306394   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 296      |\n","|    ep_rew_mean     | 243      |\n","| time/              |          |\n","|    episodes        | 420      |\n","|    fps             | 25       |\n","|    time_elapsed    | 181      |\n","|    total_timesteps | 154583   |\n","| train/             |          |\n","|    actor_loss      | -52.7    |\n","|    critic_loss     | 2.08     |\n","|    ent_coef        | 0.0609   |\n","|    ent_coef_loss   | 0.117    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 308964   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 295      |\n","|    ep_rew_mean     | 247      |\n","| time/              |          |\n","|    episodes        | 424      |\n","|    fps             | 25       |\n","|    time_elapsed    | 221      |\n","|    total_timesteps | 155607   |\n","| train/             |          |\n","|    actor_loss      | -52.1    |\n","|    critic_loss     | 2.38     |\n","|    ent_coef        | 0.0653   |\n","|    ent_coef_loss   | -0.321   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 311012   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 290      |\n","|    ep_rew_mean     | 248      |\n","| time/              |          |\n","|    episodes        | 428      |\n","|    fps             | 25       |\n","|    time_elapsed    | 252      |\n","|    total_timesteps | 156363   |\n","| train/             |          |\n","|    actor_loss      | -53.1    |\n","|    critic_loss     | 3.65     |\n","|    ent_coef        | 0.0632   |\n","|    ent_coef_loss   | -0.673   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 312524   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 287      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 432      |\n","|    fps             | 25       |\n","|    time_elapsed    | 284      |\n","|    total_timesteps | 157182   |\n","| train/             |          |\n","|    actor_loss      | -47.8    |\n","|    critic_loss     | 5.83     |\n","|    ent_coef        | 0.0619   |\n","|    ent_coef_loss   | -0.0984  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 314162   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 282      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 436      |\n","|    fps             | 25       |\n","|    time_elapsed    | 315      |\n","|    total_timesteps | 157978   |\n","| train/             |          |\n","|    actor_loss      | -49.5    |\n","|    critic_loss     | 2.28     |\n","|    ent_coef        | 0.0584   |\n","|    ent_coef_loss   | -0.184   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 315754   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 282      |\n","|    ep_rew_mean     | 242      |\n","| time/              |          |\n","|    episodes        | 440      |\n","|    fps             | 25       |\n","|    time_elapsed    | 359      |\n","|    total_timesteps | 159089   |\n","| train/             |          |\n","|    actor_loss      | -57.9    |\n","|    critic_loss     | 12.4     |\n","|    ent_coef        | 0.0661   |\n","|    ent_coef_loss   | 0.459    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 317976   |\n","---------------------------------\n","LunarLander - Step: 150001 | Mean Reward: 183.60 ± 107.68\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 276      |\n","|    ep_rew_mean     | 243      |\n","| time/              |          |\n","|    episodes        | 444      |\n","|    fps             | 25       |\n","|    time_elapsed    | 32       |\n","|    total_timesteps | 160836   |\n","| train/             |          |\n","|    actor_loss      | -55.6    |\n","|    critic_loss     | 2.25     |\n","|    ent_coef        | 0.0561   |\n","|    ent_coef_loss   | -0.0629  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 321470   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 273      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 448      |\n","|    fps             | 25       |\n","|    time_elapsed    | 71       |\n","|    total_timesteps | 161835   |\n","| train/             |          |\n","|    actor_loss      | -49.7    |\n","|    critic_loss     | 4.74     |\n","|    ent_coef        | 0.0592   |\n","|    ent_coef_loss   | -0.169   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 323468   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 266      |\n","|    ep_rew_mean     | 243      |\n","| time/              |          |\n","|    episodes        | 452      |\n","|    fps             | 25       |\n","|    time_elapsed    | 99       |\n","|    total_timesteps | 162562   |\n","| train/             |          |\n","|    actor_loss      | -55.7    |\n","|    critic_loss     | 5.14     |\n","|    ent_coef        | 0.0582   |\n","|    ent_coef_loss   | 0.236    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 324922   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 263      |\n","|    ep_rew_mean     | 244      |\n","| time/              |          |\n","|    episodes        | 456      |\n","|    fps             | 25       |\n","|    time_elapsed    | 134      |\n","|    total_timesteps | 163407   |\n","| train/             |          |\n","|    actor_loss      | -53.9    |\n","|    critic_loss     | 25.4     |\n","|    ent_coef        | 0.0583   |\n","|    ent_coef_loss   | 0.895    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 326612   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 256      |\n","|    ep_rew_mean     | 243      |\n","| time/              |          |\n","|    episodes        | 460      |\n","|    fps             | 25       |\n","|    time_elapsed    | 157      |\n","|    total_timesteps | 164023   |\n","| train/             |          |\n","|    actor_loss      | -55.6    |\n","|    critic_loss     | 2.98     |\n","|    ent_coef        | 0.0611   |\n","|    ent_coef_loss   | -0.214   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 327844   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 252      |\n","|    ep_rew_mean     | 240      |\n","| time/              |          |\n","|    episodes        | 464      |\n","|    fps             | 25       |\n","|    time_elapsed    | 194      |\n","|    total_timesteps | 164936   |\n","| train/             |          |\n","|    actor_loss      | -51.2    |\n","|    critic_loss     | 4.05     |\n","|    ent_coef        | 0.0537   |\n","|    ent_coef_loss   | 0.52     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 329670   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 245      |\n","|    ep_rew_mean     | 235      |\n","| time/              |          |\n","|    episodes        | 468      |\n","|    fps             | 25       |\n","|    time_elapsed    | 214      |\n","|    total_timesteps | 165452   |\n","| train/             |          |\n","|    actor_loss      | -58.3    |\n","|    critic_loss     | 9.1      |\n","|    ent_coef        | 0.0588   |\n","|    ent_coef_loss   | 0.0477   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 330702   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 239      |\n","|    ep_rew_mean     | 235      |\n","| time/              |          |\n","|    episodes        | 472      |\n","|    fps             | 25       |\n","|    time_elapsed    | 255      |\n","|    total_timesteps | 166484   |\n","| train/             |          |\n","|    actor_loss      | -54.2    |\n","|    critic_loss     | 4.66     |\n","|    ent_coef        | 0.0578   |\n","|    ent_coef_loss   | 0.504    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 332766   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 232      |\n","|    ep_rew_mean     | 237      |\n","| time/              |          |\n","|    episodes        | 476      |\n","|    fps             | 25       |\n","|    time_elapsed    | 292      |\n","|    total_timesteps | 167453   |\n","| train/             |          |\n","|    actor_loss      | -52.4    |\n","|    critic_loss     | 2.38     |\n","|    ent_coef        | 0.0557   |\n","|    ent_coef_loss   | 0.12     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 334704   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 229      |\n","|    ep_rew_mean     | 237      |\n","| time/              |          |\n","|    episodes        | 480      |\n","|    fps             | 25       |\n","|    time_elapsed    | 325      |\n","|    total_timesteps | 168269   |\n","| train/             |          |\n","|    actor_loss      | -63.3    |\n","|    critic_loss     | 12.2     |\n","|    ent_coef        | 0.0598   |\n","|    ent_coef_loss   | -0.629   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 336336   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 231      |\n","|    ep_rew_mean     | 238      |\n","| time/              |          |\n","|    episodes        | 484      |\n","|    fps             | 25       |\n","|    time_elapsed    | 373      |\n","|    total_timesteps | 169455   |\n","| train/             |          |\n","|    actor_loss      | -60      |\n","|    critic_loss     | 6.94     |\n","|    ent_coef        | 0.0632   |\n","|    ent_coef_loss   | 0.399    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 338708   |\n","---------------------------------\n","LunarLander - Step: 160001 | Mean Reward: 259.12 ± 50.72\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 228      |\n","|    ep_rew_mean     | 236      |\n","| time/              |          |\n","|    episodes        | 488      |\n","|    fps             | 25       |\n","|    time_elapsed    | 12       |\n","|    total_timesteps | 170308   |\n","| train/             |          |\n","|    actor_loss      | -61.7    |\n","|    critic_loss     | 40.4     |\n","|    ent_coef        | 0.0575   |\n","|    ent_coef_loss   | -0.317   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 340414   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 229      |\n","|    ep_rew_mean     | 236      |\n","| time/              |          |\n","|    episodes        | 492      |\n","|    fps             | 25       |\n","|    time_elapsed    | 51       |\n","|    total_timesteps | 171313   |\n","| train/             |          |\n","|    actor_loss      | -57.2    |\n","|    critic_loss     | 2.25     |\n","|    ent_coef        | 0.0592   |\n","|    ent_coef_loss   | -0.06    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 342424   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 229      |\n","|    ep_rew_mean     | 237      |\n","| time/              |          |\n","|    episodes        | 496      |\n","|    fps             | 25       |\n","|    time_elapsed    | 93       |\n","|    total_timesteps | 172386   |\n","| train/             |          |\n","|    actor_loss      | -54.2    |\n","|    critic_loss     | 3.16     |\n","|    ent_coef        | 0.0608   |\n","|    ent_coef_loss   | -0.637   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 344570   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 227      |\n","|    ep_rew_mean     | 238      |\n","| time/              |          |\n","|    episodes        | 500      |\n","|    fps             | 25       |\n","|    time_elapsed    | 125      |\n","|    total_timesteps | 173187   |\n","| train/             |          |\n","|    actor_loss      | -56.4    |\n","|    critic_loss     | 66       |\n","|    ent_coef        | 0.0587   |\n","|    ent_coef_loss   | -0.402   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 346172   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 227      |\n","|    ep_rew_mean     | 239      |\n","| time/              |          |\n","|    episodes        | 504      |\n","|    fps             | 25       |\n","|    time_elapsed    | 162      |\n","|    total_timesteps | 174139   |\n","| train/             |          |\n","|    actor_loss      | -60.6    |\n","|    critic_loss     | 16.7     |\n","|    ent_coef        | 0.0596   |\n","|    ent_coef_loss   | -0.358   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 348076   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 229      |\n","|    ep_rew_mean     | 240      |\n","| time/              |          |\n","|    episodes        | 508      |\n","|    fps             | 25       |\n","|    time_elapsed    | 204      |\n","|    total_timesteps | 175203   |\n","| train/             |          |\n","|    actor_loss      | -56.7    |\n","|    critic_loss     | 20.1     |\n","|    ent_coef        | 0.0582   |\n","|    ent_coef_loss   | -0.387   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 350204   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 230      |\n","|    ep_rew_mean     | 237      |\n","| time/              |          |\n","|    episodes        | 512      |\n","|    fps             | 25       |\n","|    time_elapsed    | 246      |\n","|    total_timesteps | 176219   |\n","| train/             |          |\n","|    actor_loss      | -56.7    |\n","|    critic_loss     | 13.5     |\n","|    ent_coef        | 0.0563   |\n","|    ent_coef_loss   | 0.452    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 352236   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 231      |\n","|    ep_rew_mean     | 239      |\n","| time/              |          |\n","|    episodes        | 516      |\n","|    fps             | 25       |\n","|    time_elapsed    | 281      |\n","|    total_timesteps | 177097   |\n","| train/             |          |\n","|    actor_loss      | -59.1    |\n","|    critic_loss     | 9.09     |\n","|    ent_coef        | 0.061    |\n","|    ent_coef_loss   | 0.259    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 353992   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 225      |\n","|    ep_rew_mean     | 240      |\n","| time/              |          |\n","|    episodes        | 520      |\n","|    fps             | 25       |\n","|    time_elapsed    | 309      |\n","|    total_timesteps | 177832   |\n","| train/             |          |\n","|    actor_loss      | -61      |\n","|    critic_loss     | 4.23     |\n","|    ent_coef        | 0.0618   |\n","|    ent_coef_loss   | -0.0934  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 355462   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 222      |\n","|    ep_rew_mean     | 240      |\n","| time/              |          |\n","|    episodes        | 524      |\n","|    fps             | 25       |\n","|    time_elapsed    | 337      |\n","|    total_timesteps | 178554   |\n","| train/             |          |\n","|    actor_loss      | -58.1    |\n","|    critic_loss     | 20.5     |\n","|    ent_coef        | 0.0636   |\n","|    ent_coef_loss   | -0.546   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 356906   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 223      |\n","|    ep_rew_mean     | 240      |\n","| time/              |          |\n","|    episodes        | 528      |\n","|    fps             | 25       |\n","|    time_elapsed    | 370      |\n","|    total_timesteps | 179372   |\n","| train/             |          |\n","|    actor_loss      | -55.9    |\n","|    critic_loss     | 2.46     |\n","|    ent_coef        | 0.0605   |\n","|    ent_coef_loss   | 0.988    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 358542   |\n","---------------------------------\n","LunarLander - Step: 170001 | Mean Reward: 266.41 ± 17.32\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 222      |\n","|    ep_rew_mean     | 246      |\n","| time/              |          |\n","|    episodes        | 532      |\n","|    fps             | 28       |\n","|    time_elapsed    | 6        |\n","|    total_timesteps | 180187   |\n","| train/             |          |\n","|    actor_loss      | -59.7    |\n","|    critic_loss     | 21.5     |\n","|    ent_coef        | 0.0652   |\n","|    ent_coef_loss   | -0.221   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 360172   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 222      |\n","|    ep_rew_mean     | 246      |\n","| time/              |          |\n","|    episodes        | 536      |\n","|    fps             | 26       |\n","|    time_elapsed    | 38       |\n","|    total_timesteps | 180996   |\n","| train/             |          |\n","|    actor_loss      | -56.9    |\n","|    critic_loss     | 5.9      |\n","|    ent_coef        | 0.0633   |\n","|    ent_coef_loss   | -0.227   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 361790   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 220      |\n","|    ep_rew_mean     | 251      |\n","| time/              |          |\n","|    episodes        | 540      |\n","|    fps             | 25       |\n","|    time_elapsed    | 72       |\n","|    total_timesteps | 181845   |\n","| train/             |          |\n","|    actor_loss      | -63.2    |\n","|    critic_loss     | 21.4     |\n","|    ent_coef        | 0.0632   |\n","|    ent_coef_loss   | 0.34     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 363488   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 218      |\n","|    ep_rew_mean     | 252      |\n","| time/              |          |\n","|    episodes        | 544      |\n","|    fps             | 25       |\n","|    time_elapsed    | 110      |\n","|    total_timesteps | 182808   |\n","| train/             |          |\n","|    actor_loss      | -59.3    |\n","|    critic_loss     | 8.27     |\n","|    ent_coef        | 0.0599   |\n","|    ent_coef_loss   | -0.0159  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 365414   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 215      |\n","|    ep_rew_mean     | 251      |\n","| time/              |          |\n","|    episodes        | 548      |\n","|    fps             | 25       |\n","|    time_elapsed    | 136      |\n","|    total_timesteps | 183477   |\n","| train/             |          |\n","|    actor_loss      | -51      |\n","|    critic_loss     | 2.56     |\n","|    ent_coef        | 0.0583   |\n","|    ent_coef_loss   | 0.381    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 366752   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 215      |\n","|    ep_rew_mean     | 254      |\n","| time/              |          |\n","|    episodes        | 552      |\n","|    fps             | 25       |\n","|    time_elapsed    | 165      |\n","|    total_timesteps | 184234   |\n","| train/             |          |\n","|    actor_loss      | -58.8    |\n","|    critic_loss     | 14.2     |\n","|    ent_coef        | 0.0602   |\n","|    ent_coef_loss   | -0.456   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 368266   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 214      |\n","|    ep_rew_mean     | 253      |\n","| time/              |          |\n","|    episodes        | 556      |\n","|    fps             | 25       |\n","|    time_elapsed    | 195      |\n","|    total_timesteps | 184995   |\n","| train/             |          |\n","|    actor_loss      | -59      |\n","|    critic_loss     | 5.13     |\n","|    ent_coef        | 0.0589   |\n","|    ent_coef_loss   | 0.14     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 369788   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 217      |\n","|    ep_rew_mean     | 257      |\n","| time/              |          |\n","|    episodes        | 560      |\n","|    fps             | 25       |\n","|    time_elapsed    | 233      |\n","|    total_timesteps | 185958   |\n","| train/             |          |\n","|    actor_loss      | -61      |\n","|    critic_loss     | 13.7     |\n","|    ent_coef        | 0.0606   |\n","|    ent_coef_loss   | 0.267    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 371714   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 217      |\n","|    ep_rew_mean     | 260      |\n","| time/              |          |\n","|    episodes        | 564      |\n","|    fps             | 25       |\n","|    time_elapsed    | 264      |\n","|    total_timesteps | 186786   |\n","| train/             |          |\n","|    actor_loss      | -58.4    |\n","|    critic_loss     | 4.1      |\n","|    ent_coef        | 0.0588   |\n","|    ent_coef_loss   | 0.619    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 373370   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 219      |\n","|    ep_rew_mean     | 266      |\n","| time/              |          |\n","|    episodes        | 568      |\n","|    fps             | 25       |\n","|    time_elapsed    | 294      |\n","|    total_timesteps | 187550   |\n","| train/             |          |\n","|    actor_loss      | -65.6    |\n","|    critic_loss     | 1.89     |\n","|    ent_coef        | 0.0646   |\n","|    ent_coef_loss   | -0.226   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 374898   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 217      |\n","|    ep_rew_mean     | 266      |\n","| time/              |          |\n","|    episodes        | 572      |\n","|    fps             | 25       |\n","|    time_elapsed    | 327      |\n","|    total_timesteps | 188375   |\n","| train/             |          |\n","|    actor_loss      | -58.8    |\n","|    critic_loss     | 15.1     |\n","|    ent_coef        | 0.0611   |\n","|    ent_coef_loss   | 0.169    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 376548   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 216      |\n","|    ep_rew_mean     | 264      |\n","| time/              |          |\n","|    episodes        | 576      |\n","|    fps             | 25       |\n","|    time_elapsed    | 363      |\n","|    total_timesteps | 189273   |\n","| train/             |          |\n","|    actor_loss      | -55.9    |\n","|    critic_loss     | 5.02     |\n","|    ent_coef        | 0.0578   |\n","|    ent_coef_loss   | -0.0939  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 378344   |\n","---------------------------------\n","LunarLander - Step: 180001 | Mean Reward: 254.08 ± 13.33\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 216      |\n","|    ep_rew_mean     | 264      |\n","| time/              |          |\n","|    episodes        | 580      |\n","|    fps             | 28       |\n","|    time_elapsed    | 5        |\n","|    total_timesteps | 190158   |\n","| train/             |          |\n","|    actor_loss      | -62.4    |\n","|    critic_loss     | 2.92     |\n","|    ent_coef        | 0.0636   |\n","|    ent_coef_loss   | 1.05     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 380114   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 212      |\n","|    ep_rew_mean     | 264      |\n","| time/              |          |\n","|    episodes        | 584      |\n","|    fps             | 25       |\n","|    time_elapsed    | 39       |\n","|    total_timesteps | 191007   |\n","| train/             |          |\n","|    actor_loss      | -60.1    |\n","|    critic_loss     | 2.09     |\n","|    ent_coef        | 0.0557   |\n","|    ent_coef_loss   | 0.52     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 381812   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 214      |\n","|    ep_rew_mean     | 267      |\n","| time/              |          |\n","|    episodes        | 588      |\n","|    fps             | 25       |\n","|    time_elapsed    | 74       |\n","|    total_timesteps | 191923   |\n","| train/             |          |\n","|    actor_loss      | -62.4    |\n","|    critic_loss     | 2.72     |\n","|    ent_coef        | 0.0614   |\n","|    ent_coef_loss   | 0.892    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 383644   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 213      |\n","|    ep_rew_mean     | 267      |\n","| time/              |          |\n","|    episodes        | 592      |\n","|    fps             | 25       |\n","|    time_elapsed    | 107      |\n","|    total_timesteps | 192767   |\n","| train/             |          |\n","|    actor_loss      | -57.8    |\n","|    critic_loss     | 19.3     |\n","|    ent_coef        | 0.0567   |\n","|    ent_coef_loss   | 0.08     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 385332   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 210      |\n","|    ep_rew_mean     | 268      |\n","| time/              |          |\n","|    episodes        | 596      |\n","|    fps             | 25       |\n","|    time_elapsed    | 139      |\n","|    total_timesteps | 193612   |\n","| train/             |          |\n","|    actor_loss      | -63.7    |\n","|    critic_loss     | 3.85     |\n","|    ent_coef        | 0.0633   |\n","|    ent_coef_loss   | 0.0644   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 387022   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 211      |\n","|    ep_rew_mean     | 268      |\n","| time/              |          |\n","|    episodes        | 600      |\n","|    fps             | 25       |\n","|    time_elapsed    | 174      |\n","|    total_timesteps | 194493   |\n","| train/             |          |\n","|    actor_loss      | -67.1    |\n","|    critic_loss     | 9.67     |\n","|    ent_coef        | 0.0613   |\n","|    ent_coef_loss   | -0.212   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 388784   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 210      |\n","|    ep_rew_mean     | 267      |\n","| time/              |          |\n","|    episodes        | 604      |\n","|    fps             | 25       |\n","|    time_elapsed    | 208      |\n","|    total_timesteps | 195358   |\n","| train/             |          |\n","|    actor_loss      | -58.5    |\n","|    critic_loss     | 11.2     |\n","|    ent_coef        | 0.0584   |\n","|    ent_coef_loss   | -0.223   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 390514   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 207      |\n","|    ep_rew_mean     | 268      |\n","| time/              |          |\n","|    episodes        | 608      |\n","|    fps             | 25       |\n","|    time_elapsed    | 237      |\n","|    total_timesteps | 196104   |\n","| train/             |          |\n","|    actor_loss      | -61.7    |\n","|    critic_loss     | 3.94     |\n","|    ent_coef        | 0.0599   |\n","|    ent_coef_loss   | -0.374   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 392006   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 206      |\n","|    ep_rew_mean     | 272      |\n","| time/              |          |\n","|    episodes        | 612      |\n","|    fps             | 25       |\n","|    time_elapsed    | 274      |\n","|    total_timesteps | 197039   |\n","| train/             |          |\n","|    actor_loss      | -63.7    |\n","|    critic_loss     | 15       |\n","|    ent_coef        | 0.0585   |\n","|    ent_coef_loss   | 0.0427   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 393876   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 205      |\n","|    ep_rew_mean     | 272      |\n","| time/              |          |\n","|    episodes        | 616      |\n","|    fps             | 25       |\n","|    time_elapsed    | 304      |\n","|    total_timesteps | 197817   |\n","| train/             |          |\n","|    actor_loss      | -67.8    |\n","|    critic_loss     | 3.14     |\n","|    ent_coef        | 0.0603   |\n","|    ent_coef_loss   | -0.0995  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 395432   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 208      |\n","|    ep_rew_mean     | 270      |\n","| time/              |          |\n","|    episodes        | 620      |\n","|    fps             | 25       |\n","|    time_elapsed    | 344      |\n","|    total_timesteps | 198823   |\n","| train/             |          |\n","|    actor_loss      | -64.1    |\n","|    critic_loss     | 10.3     |\n","|    ent_coef        | 0.0586   |\n","|    ent_coef_loss   | 0.333    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 397444   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 208      |\n","|    ep_rew_mean     | 268      |\n","| time/              |          |\n","|    episodes        | 624      |\n","|    fps             | 25       |\n","|    time_elapsed    | 374      |\n","|    total_timesteps | 199572   |\n","| train/             |          |\n","|    actor_loss      | -64.6    |\n","|    critic_loss     | 9.72     |\n","|    ent_coef        | 0.0612   |\n","|    ent_coef_loss   | -0.65    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 398942   |\n","---------------------------------\n","LunarLander - Step: 190001 | Mean Reward: 250.90 ± 86.22\n"]}]}]}