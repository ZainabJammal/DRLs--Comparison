{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I08ysbNCpSI7","outputId":"e91b1ae0-761a-4a52-f6b6-3f61d4ff8b1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stable_baselines3\n","  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n","Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.0.0)\n","Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n","Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n","Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.5.0\n"]}],"source":["pip install stable_baselines3"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7TnsTBRCjNhu","outputId":"16e805ac-0152-4d93-c5e5-b6d31f875a82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["pip install box2d"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECjjcZ-opzYL","outputId":"4185f56c-e882-456e-8063-902de6770103"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting box2d\n","  Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (573 bytes)\n","Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: box2d\n","Successfully installed box2d-2.3.10\n"]}]},{"cell_type":"code","source":["import multiprocessing\n","from stable_baselines3 import SAC\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.env_util import make_vec_env"],"metadata":{"id":"EOJbyToUp4Zx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, env, n_eval_episodes=10):\n","    \"\"\"Evaluate the model on a given environment and return mean and std rewards.\"\"\"\n","    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes)\n","    return mean_reward, std_reward"],"metadata":{"id":"cwiNPKwzp8Xb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SAC Lunar"],"metadata":{"id":"0_W45wJuuRZK"}},{"cell_type":"markdown","source":["env=4, batch size= 64, lr= 1e-4"],"metadata":{"id":"yEGbaPd53_Ww"}},{"cell_type":"code","source":["def train_lunarlander5():\n","    # Create environment and model for LunarLander (continuous version for SAC)\n","    env_lunar = make_vec_env(\"LunarLanderContinuous-v3\", n_envs=4)\n","    model = SAC(\"MlpPolicy\", env_lunar, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/\",\n","                learning_rate=1e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n","                gamma=0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n","\n","    eval_freq = 10000  # Evaluate every 10,000 steps\n","    n_eval_episodes = 10  # Number of episodes per evaluation\n","\n","    for step in range(1, 200001, eval_freq):\n","        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n","        mean_reward, std_reward = evaluate_model(model, env_lunar, n_eval_episodes)\n","        print(f\"LunarLander - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n","\n","    model.save(\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64\")"],"metadata":{"id":"Iug0t7JQ5XH4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    train_lunarlander5()"],"metadata":{"id":"dXr6c11L6FtD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d617daa8-72fa-42c2-9324-1264a30c8100"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n","<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n","<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n","/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n","  from pkg_resources import resource_stream, resource_exists\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n"]},{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 115      |\n","|    ep_rew_mean     | -197     |\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 134      |\n","|    time_elapsed    | 4        |\n","|    total_timesteps | 568      |\n","| train/             |          |\n","|    actor_loss      | -3.35    |\n","|    critic_loss     | 8.6      |\n","|    ent_coef        | 0.977    |\n","|    ent_coef_loss   | -0.0752  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 232      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 103      |\n","|    ep_rew_mean     | -198     |\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 111      |\n","|    time_elapsed    | 8        |\n","|    total_timesteps | 916      |\n","| train/             |          |\n","|    actor_loss      | -2.18    |\n","|    critic_loss     | 4.08     |\n","|    ent_coef        | 0.961    |\n","|    ent_coef_loss   | -0.133   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 406      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 107      |\n","|    ep_rew_mean     | -167     |\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 110      |\n","|    time_elapsed    | 12       |\n","|    total_timesteps | 1368     |\n","| train/             |          |\n","|    actor_loss      | -4.04    |\n","|    critic_loss     | 66.1     |\n","|    ent_coef        | 0.94     |\n","|    ent_coef_loss   | -0.196   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 632      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 112      |\n","|    ep_rew_mean     | -200     |\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 112      |\n","|    time_elapsed    | 16       |\n","|    total_timesteps | 1900     |\n","| train/             |          |\n","|    actor_loss      | -0.651   |\n","|    critic_loss     | 82       |\n","|    ent_coef        | 0.917    |\n","|    ent_coef_loss   | -0.26    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 898      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 112      |\n","|    ep_rew_mean     | -173     |\n","| time/              |          |\n","|    episodes        | 20       |\n","|    fps             | 107      |\n","|    time_elapsed    | 24       |\n","|    total_timesteps | 2660     |\n","| train/             |          |\n","|    actor_loss      | 6.69     |\n","|    critic_loss     | 28.2     |\n","|    ent_coef        | 0.885    |\n","|    ent_coef_loss   | -0.322   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 1278     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 121      |\n","|    ep_rew_mean     | -157     |\n","| time/              |          |\n","|    episodes        | 24       |\n","|    fps             | 109      |\n","|    time_elapsed    | 29       |\n","|    total_timesteps | 3264     |\n","| train/             |          |\n","|    actor_loss      | 11.5     |\n","|    critic_loss     | 67.2     |\n","|    ent_coef        | 0.862    |\n","|    ent_coef_loss   | -0.386   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 1580     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 124      |\n","|    ep_rew_mean     | -170     |\n","| time/              |          |\n","|    episodes        | 28       |\n","|    fps             | 107      |\n","|    time_elapsed    | 35       |\n","|    total_timesteps | 3784     |\n","| train/             |          |\n","|    actor_loss      | 15.7     |\n","|    critic_loss     | 32.5     |\n","|    ent_coef        | 0.842    |\n","|    ent_coef_loss   | -0.451   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 1840     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 125      |\n","|    ep_rew_mean     | -178     |\n","| time/              |          |\n","|    episodes        | 32       |\n","|    fps             | 106      |\n","|    time_elapsed    | 39       |\n","|    total_timesteps | 4224     |\n","| train/             |          |\n","|    actor_loss      | 17.4     |\n","|    critic_loss     | 37.8     |\n","|    ent_coef        | 0.825    |\n","|    ent_coef_loss   | -0.504   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 2060     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 131      |\n","|    ep_rew_mean     | -180     |\n","| time/              |          |\n","|    episodes        | 36       |\n","|    fps             | 108      |\n","|    time_elapsed    | 45       |\n","|    total_timesteps | 4904     |\n","| train/             |          |\n","|    actor_loss      | 19.8     |\n","|    critic_loss     | 43.5     |\n","|    ent_coef        | 0.798    |\n","|    ent_coef_loss   | -0.57    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 2400     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 137      |\n","|    ep_rew_mean     | -180     |\n","| time/              |          |\n","|    episodes        | 40       |\n","|    fps             | 106      |\n","|    time_elapsed    | 54       |\n","|    total_timesteps | 5812     |\n","| train/             |          |\n","|    actor_loss      | 23.2     |\n","|    critic_loss     | 8.02     |\n","|    ent_coef        | 0.764    |\n","|    ent_coef_loss   | -0.693   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 2854     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 146      |\n","|    ep_rew_mean     | -179     |\n","| time/              |          |\n","|    episodes        | 44       |\n","|    fps             | 106      |\n","|    time_elapsed    | 62       |\n","|    total_timesteps | 6632     |\n","| train/             |          |\n","|    actor_loss      | 17       |\n","|    critic_loss     | 4.36     |\n","|    ent_coef        | 0.735    |\n","|    ent_coef_loss   | -0.747   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 3264     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 149      |\n","|    ep_rew_mean     | -179     |\n","| time/              |          |\n","|    episodes        | 48       |\n","|    fps             | 104      |\n","|    time_elapsed    | 71       |\n","|    total_timesteps | 7488     |\n","| train/             |          |\n","|    actor_loss      | 29.4     |\n","|    critic_loss     | 11.9     |\n","|    ent_coef        | 0.705    |\n","|    ent_coef_loss   | -0.854   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 3692     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 153      |\n","|    ep_rew_mean     | -172     |\n","| time/              |          |\n","|    episodes        | 52       |\n","|    fps             | 103      |\n","|    time_elapsed    | 79       |\n","|    total_timesteps | 8304     |\n","| train/             |          |\n","|    actor_loss      | 28.5     |\n","|    critic_loss     | 22.4     |\n","|    ent_coef        | 0.678    |\n","|    ent_coef_loss   | -0.831   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 4100     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 155      |\n","|    ep_rew_mean     | -169     |\n","| time/              |          |\n","|    episodes        | 56       |\n","|    fps             | 104      |\n","|    time_elapsed    | 85       |\n","|    total_timesteps | 8860     |\n","| train/             |          |\n","|    actor_loss      | 22.8     |\n","|    critic_loss     | 5.26     |\n","|    ent_coef        | 0.661    |\n","|    ent_coef_loss   | -0.978   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 4378     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 155      |\n","|    ep_rew_mean     | -161     |\n","| time/              |          |\n","|    episodes        | 60       |\n","|    fps             | 103      |\n","|    time_elapsed    | 94       |\n","|    total_timesteps | 9724     |\n","| train/             |          |\n","|    actor_loss      | 23.9     |\n","|    critic_loss     | 7.19     |\n","|    ent_coef        | 0.634    |\n","|    ent_coef_loss   | -1.22    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 4810     |\n","---------------------------------\n","LunarLander - Step: 1 | Mean Reward: -139.35 ± 85.53\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 161      |\n","|    ep_rew_mean     | -163     |\n","| time/              |          |\n","|    episodes        | 64       |\n","|    fps             | 110      |\n","|    time_elapsed    | 3        |\n","|    total_timesteps | 10408    |\n","| train/             |          |\n","|    actor_loss      | 30.3     |\n","|    critic_loss     | 6.71     |\n","|    ent_coef        | 0.613    |\n","|    ent_coef_loss   | -1.15    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 5152     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 167      |\n","|    ep_rew_mean     | -155     |\n","| time/              |          |\n","|    episodes        | 68       |\n","|    fps             | 106      |\n","|    time_elapsed    | 16       |\n","|    total_timesteps | 11764    |\n","| train/             |          |\n","|    actor_loss      | 13.9     |\n","|    critic_loss     | 4.36     |\n","|    ent_coef        | 0.574    |\n","|    ent_coef_loss   | -1.29    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 5830     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 174      |\n","|    ep_rew_mean     | -151     |\n","| time/              |          |\n","|    episodes        | 72       |\n","|    fps             | 103      |\n","|    time_elapsed    | 27       |\n","|    total_timesteps | 12896    |\n","| train/             |          |\n","|    actor_loss      | 7.22     |\n","|    critic_loss     | 8.99     |\n","|    ent_coef        | 0.545    |\n","|    ent_coef_loss   | -1.15    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 6396     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 181      |\n","|    ep_rew_mean     | -147     |\n","| time/              |          |\n","|    episodes        | 76       |\n","|    fps             | 90       |\n","|    time_elapsed    | 65       |\n","|    total_timesteps | 15888    |\n","| train/             |          |\n","|    actor_loss      | -4.02    |\n","|    critic_loss     | 120      |\n","|    ent_coef        | 0.473    |\n","|    ent_coef_loss   | -1.42    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 7892     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 203      |\n","|    ep_rew_mean     | -143     |\n","| time/              |          |\n","|    episodes        | 80       |\n","|    fps             | 89       |\n","|    time_elapsed    | 79       |\n","|    total_timesteps | 17136    |\n","| train/             |          |\n","|    actor_loss      | -14.8    |\n","|    critic_loss     | 5.21     |\n","|    ent_coef        | 0.446    |\n","|    ent_coef_loss   | -1.65    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 8516     |\n","---------------------------------\n","LunarLander - Step: 10001 | Mean Reward: -73.17 ± 77.66\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 220      |\n","|    ep_rew_mean     | -146     |\n","| time/              |          |\n","|    episodes        | 84       |\n","|    fps             | 79       |\n","|    time_elapsed    | 7        |\n","|    total_timesteps | 20596    |\n","| train/             |          |\n","|    actor_loss      | 2.71     |\n","|    critic_loss     | 21.7     |\n","|    ent_coef        | 0.376    |\n","|    ent_coef_loss   | -2.05    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 10246    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 239      |\n","|    ep_rew_mean     | -140     |\n","| time/              |          |\n","|    episodes        | 88       |\n","|    fps             | 91       |\n","|    time_elapsed    | 29       |\n","|    total_timesteps | 22668    |\n","| train/             |          |\n","|    actor_loss      | -5.32    |\n","|    critic_loss     | 2.66     |\n","|    ent_coef        | 0.339    |\n","|    ent_coef_loss   | -2.05    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 11282    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 271      |\n","|    ep_rew_mean     | -130     |\n","| time/              |          |\n","|    episodes        | 92       |\n","|    fps             | 85       |\n","|    time_elapsed    | 77       |\n","|    total_timesteps | 26668    |\n","| train/             |          |\n","|    actor_loss      | 3.97     |\n","|    critic_loss     | 14.6     |\n","|    ent_coef        | 0.281    |\n","|    ent_coef_loss   | -2.17    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 13282    |\n","---------------------------------\n","LunarLander - Step: 20001 | Mean Reward: -14.59 ± 38.54\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 316      |\n","|    ep_rew_mean     | -119     |\n","| time/              |          |\n","|    episodes        | 96       |\n","|    fps             | 81       |\n","|    time_elapsed    | 49       |\n","|    total_timesteps | 34000    |\n","| train/             |          |\n","|    actor_loss      | -14.5    |\n","|    critic_loss     | 114      |\n","|    ent_coef        | 0.199    |\n","|    ent_coef_loss   | -2.51    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 16948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 323      |\n","|    ep_rew_mean     | -115     |\n","| time/              |          |\n","|    episodes        | 100      |\n","|    fps             | 84       |\n","|    time_elapsed    | 82       |\n","|    total_timesteps | 36936    |\n","| train/             |          |\n","|    actor_loss      | -16.8    |\n","|    critic_loss     | 5.06     |\n","|    ent_coef        | 0.173    |\n","|    ent_coef_loss   | -2.51    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 18416    |\n","---------------------------------\n","LunarLander - Step: 30001 | Mean Reward: 4.61 ± 18.04\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 375      |\n","|    ep_rew_mean     | -101     |\n","| time/              |          |\n","|    episodes        | 104      |\n","|    fps             | 79       |\n","|    time_elapsed    | 50       |\n","|    total_timesteps | 44000    |\n","| train/             |          |\n","|    actor_loss      | -21.9    |\n","|    critic_loss     | 6.44     |\n","|    ent_coef        | 0.124    |\n","|    ent_coef_loss   | -2.32    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 21948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 411      |\n","|    ep_rew_mean     | -95.8    |\n","| time/              |          |\n","|    episodes        | 108      |\n","|    fps             | 82       |\n","|    time_elapsed    | 97       |\n","|    total_timesteps | 48000    |\n","| train/             |          |\n","|    actor_loss      | -21.8    |\n","|    critic_loss     | 4.39     |\n","|    ent_coef        | 0.104    |\n","|    ent_coef_loss   | -2.41    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 23948    |\n","---------------------------------\n","LunarLander - Step: 40001 | Mean Reward: -52.61 ± 23.47\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 446      |\n","|    ep_rew_mean     | -90.5    |\n","| time/              |          |\n","|    episodes        | 112      |\n","|    fps             | 81       |\n","|    time_elapsed    | 49       |\n","|    total_timesteps | 54000    |\n","| train/             |          |\n","|    actor_loss      | -24.2    |\n","|    critic_loss     | 2.13     |\n","|    ent_coef        | 0.0797   |\n","|    ent_coef_loss   | -2.68    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 26948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 482      |\n","|    ep_rew_mean     | -82.7    |\n","| time/              |          |\n","|    episodes        | 116      |\n","|    fps             | 80       |\n","|    time_elapsed    | 99       |\n","|    total_timesteps | 58000    |\n","| train/             |          |\n","|    actor_loss      | -19.1    |\n","|    critic_loss     | 1.71     |\n","|    ent_coef        | 0.0665   |\n","|    ent_coef_loss   | -2.51    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 28948    |\n","---------------------------------\n","LunarLander - Step: 50001 | Mean Reward: -107.93 ± 100.79\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 517      |\n","|    ep_rew_mean     | -81      |\n","| time/              |          |\n","|    episodes        | 120      |\n","|    fps             | 81       |\n","|    time_elapsed    | 48       |\n","|    total_timesteps | 64000    |\n","| train/             |          |\n","|    actor_loss      | -21.3    |\n","|    critic_loss     | 3.11     |\n","|    ent_coef        | 0.0522   |\n","|    ent_coef_loss   | -2.28    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 31948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 549      |\n","|    ep_rew_mean     | -74.2    |\n","| time/              |          |\n","|    episodes        | 124      |\n","|    fps             | 82       |\n","|    time_elapsed    | 97       |\n","|    total_timesteps | 68000    |\n","| train/             |          |\n","|    actor_loss      | -17.5    |\n","|    critic_loss     | 6.69     |\n","|    ent_coef        | 0.0462   |\n","|    ent_coef_loss   | -1.3     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 33948    |\n","---------------------------------\n","LunarLander - Step: 60001 | Mean Reward: -13.34 ± 13.23\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 584      |\n","|    ep_rew_mean     | -67.8    |\n","| time/              |          |\n","|    episodes        | 128      |\n","|    fps             | 86       |\n","|    time_elapsed    | 46       |\n","|    total_timesteps | 74000    |\n","| train/             |          |\n","|    actor_loss      | -17.9    |\n","|    critic_loss     | 12.2     |\n","|    ent_coef        | 0.0396   |\n","|    ent_coef_loss   | -1.53    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 36948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 618      |\n","|    ep_rew_mean     | -60      |\n","| time/              |          |\n","|    episodes        | 132      |\n","|    fps             | 84       |\n","|    time_elapsed    | 94       |\n","|    total_timesteps | 78000    |\n","| train/             |          |\n","|    actor_loss      | -16.5    |\n","|    critic_loss     | 143      |\n","|    ent_coef        | 0.035    |\n","|    ent_coef_loss   | 1.07     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 38948    |\n","---------------------------------\n","LunarLander - Step: 70001 | Mean Reward: -7.04 ± 16.96\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 650      |\n","|    ep_rew_mean     | -55.5    |\n","| time/              |          |\n","|    episodes        | 136      |\n","|    fps             | 87       |\n","|    time_elapsed    | 45       |\n","|    total_timesteps | 84000    |\n","| train/             |          |\n","|    actor_loss      | -16.6    |\n","|    critic_loss     | 2.32     |\n","|    ent_coef        | 0.0356   |\n","|    ent_coef_loss   | 1.21     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 41948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 681      |\n","|    ep_rew_mean     | -49.8    |\n","| time/              |          |\n","|    episodes        | 140      |\n","|    fps             | 85       |\n","|    time_elapsed    | 93       |\n","|    total_timesteps | 88000    |\n","| train/             |          |\n","|    actor_loss      | -18.4    |\n","|    critic_loss     | 2.55     |\n","|    ent_coef        | 0.0377   |\n","|    ent_coef_loss   | 1.1      |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 43948    |\n","---------------------------------\n","LunarLander - Step: 80001 | Mean Reward: -128.18 ± 100.17\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 697      |\n","|    ep_rew_mean     | -47.7    |\n","| time/              |          |\n","|    episodes        | 144      |\n","|    fps             | 80       |\n","|    time_elapsed    | 47       |\n","|    total_timesteps | 93808    |\n","| train/             |          |\n","|    actor_loss      | -17.7    |\n","|    critic_loss     | 4.47     |\n","|    ent_coef        | 0.0362   |\n","|    ent_coef_loss   | 0.905    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 46852    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 730      |\n","|    ep_rew_mean     | -44      |\n","| time/              |          |\n","|    episodes        | 148      |\n","|    fps             | 82       |\n","|    time_elapsed    | 94       |\n","|    total_timesteps | 97808    |\n","| train/             |          |\n","|    actor_loss      | -18      |\n","|    critic_loss     | 5.43     |\n","|    ent_coef        | 0.0411   |\n","|    ent_coef_loss   | 0.8      |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 48852    |\n","---------------------------------\n","LunarLander - Step: 90001 | Mean Reward: -85.53 ± 26.41\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 779      |\n","|    ep_rew_mean     | -41.9    |\n","| time/              |          |\n","|    episodes        | 152      |\n","|    fps             | 84       |\n","|    time_elapsed    | 47       |\n","|    total_timesteps | 104000   |\n","| train/             |          |\n","|    actor_loss      | -19.5    |\n","|    critic_loss     | 4.31     |\n","|    ent_coef        | 0.0423   |\n","|    ent_coef_loss   | 0.507    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 51948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 811      |\n","|    ep_rew_mean     | -40.8    |\n","| time/              |          |\n","|    episodes        | 156      |\n","|    fps             | 80       |\n","|    time_elapsed    | 98       |\n","|    total_timesteps | 108000   |\n","| train/             |          |\n","|    actor_loss      | -19.1    |\n","|    critic_loss     | 1.36     |\n","|    ent_coef        | 0.0404   |\n","|    ent_coef_loss   | 0.304    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 53948    |\n","---------------------------------\n","LunarLander - Step: 100001 | Mean Reward: -48.78 ± 26.22\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 843      |\n","|    ep_rew_mean     | -35.5    |\n","| time/              |          |\n","|    episodes        | 160      |\n","|    fps             | 81       |\n","|    time_elapsed    | 48       |\n","|    total_timesteps | 114000   |\n","| train/             |          |\n","|    actor_loss      | -16.2    |\n","|    critic_loss     | 1.13     |\n","|    ent_coef        | 0.0398   |\n","|    ent_coef_loss   | 1.2      |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 56948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 872      |\n","|    ep_rew_mean     | -35.1    |\n","| time/              |          |\n","|    episodes        | 164      |\n","|    fps             | 80       |\n","|    time_elapsed    | 98       |\n","|    total_timesteps | 118000   |\n","| train/             |          |\n","|    actor_loss      | -11.8    |\n","|    critic_loss     | 21.1     |\n","|    ent_coef        | 0.0396   |\n","|    ent_coef_loss   | -0.38    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 58948    |\n","---------------------------------\n","LunarLander - Step: 110001 | Mean Reward: -57.91 ± 16.91\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 906      |\n","|    ep_rew_mean     | -36.7    |\n","| time/              |          |\n","|    episodes        | 168      |\n","|    fps             | 82       |\n","|    time_elapsed    | 48       |\n","|    total_timesteps | 124000   |\n","| train/             |          |\n","|    actor_loss      | -11.5    |\n","|    critic_loss     | 1.28     |\n","|    ent_coef        | 0.0419   |\n","|    ent_coef_loss   | -0.206   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 61948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 931      |\n","|    ep_rew_mean     | -37.7    |\n","| time/              |          |\n","|    episodes        | 172      |\n","|    fps             | 84       |\n","|    time_elapsed    | 94       |\n","|    total_timesteps | 128000   |\n","| train/             |          |\n","|    actor_loss      | -8.37    |\n","|    critic_loss     | 2.6      |\n","|    ent_coef        | 0.0382   |\n","|    ent_coef_loss   | -0.876   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 63948    |\n","---------------------------------\n","LunarLander - Step: 120001 | Mean Reward: -55.61 ± 32.70\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 945      |\n","|    ep_rew_mean     | -36.1    |\n","| time/              |          |\n","|    episodes        | 176      |\n","|    fps             | 84       |\n","|    time_elapsed    | 47       |\n","|    total_timesteps | 134000   |\n","| train/             |          |\n","|    actor_loss      | -6.09    |\n","|    critic_loss     | 2.09     |\n","|    ent_coef        | 0.0349   |\n","|    ent_coef_loss   | -1.18    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 66948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 949      |\n","|    ep_rew_mean     | -33.3    |\n","| time/              |          |\n","|    episodes        | 180      |\n","|    fps             | 86       |\n","|    time_elapsed    | 75       |\n","|    total_timesteps | 136452   |\n","| train/             |          |\n","|    actor_loss      | -9.75    |\n","|    critic_loss     | 1.04     |\n","|    ent_coef        | 0.0328   |\n","|    ent_coef_loss   | -0.694   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 68174    |\n","---------------------------------\n","LunarLander - Step: 130001 | Mean Reward: -9.45 ± 105.26\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 967      |\n","|    ep_rew_mean     | -26.2    |\n","| time/              |          |\n","|    episodes        | 184      |\n","|    fps             | 85       |\n","|    time_elapsed    | 4        |\n","|    total_timesteps | 140420   |\n","| train/             |          |\n","|    actor_loss      | -5.14    |\n","|    critic_loss     | 7.02     |\n","|    ent_coef        | 0.0333   |\n","|    ent_coef_loss   | 0.827    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 70158    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 977      |\n","|    ep_rew_mean     | -23.6    |\n","| time/              |          |\n","|    episodes        | 188      |\n","|    fps             | 82       |\n","|    time_elapsed    | 53       |\n","|    total_timesteps | 144420   |\n","| train/             |          |\n","|    actor_loss      | -3.45    |\n","|    critic_loss     | 1.26     |\n","|    ent_coef        | 0.0323   |\n","|    ent_coef_loss   | -2.23    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 72158    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 978      |\n","|    ep_rew_mean     | -29      |\n","| time/              |          |\n","|    episodes        | 192      |\n","|    fps             | 82       |\n","|    time_elapsed    | 102      |\n","|    total_timesteps | 148420   |\n","| train/             |          |\n","|    actor_loss      | -7.31    |\n","|    critic_loss     | 3.8      |\n","|    ent_coef        | 0.0331   |\n","|    ent_coef_loss   | 1.38     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 74158    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 965      |\n","|    ep_rew_mean     | -32.4    |\n","| time/              |          |\n","|    episodes        | 196      |\n","|    fps             | 83       |\n","|    time_elapsed    | 120      |\n","|    total_timesteps | 149976   |\n","| train/             |          |\n","|    actor_loss      | -5.97    |\n","|    critic_loss     | 57.3     |\n","|    ent_coef        | 0.0327   |\n","|    ent_coef_loss   | 0.562    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 74936    |\n","---------------------------------\n","LunarLander - Step: 140001 | Mean Reward: -21.13 ± 33.51\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 970      |\n","|    ep_rew_mean     | -34.5    |\n","| time/              |          |\n","|    episodes        | 200      |\n","|    fps             | 75       |\n","|    time_elapsed    | 52       |\n","|    total_timesteps | 154000   |\n","| train/             |          |\n","|    actor_loss      | -6.59    |\n","|    critic_loss     | 1.5      |\n","|    ent_coef        | 0.0296   |\n","|    ent_coef_loss   | -0.195   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 76948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 970      |\n","|    ep_rew_mean     | -33.3    |\n","| time/              |          |\n","|    episodes        | 204      |\n","|    fps             | 82       |\n","|    time_elapsed    | 96       |\n","|    total_timesteps | 158000   |\n","| train/             |          |\n","|    actor_loss      | -9.47    |\n","|    critic_loss     | 1.06     |\n","|    ent_coef        | 0.0295   |\n","|    ent_coef_loss   | -1.14    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 78948    |\n","---------------------------------\n","LunarLander - Step: 150001 | Mean Reward: 47.45 ± 94.82\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 970      |\n","|    ep_rew_mean     | -34.1    |\n","| time/              |          |\n","|    episodes        | 208      |\n","|    fps             | 75       |\n","|    time_elapsed    | 53       |\n","|    total_timesteps | 164000   |\n","| train/             |          |\n","|    actor_loss      | -6.07    |\n","|    critic_loss     | 0.862    |\n","|    ent_coef        | 0.027    |\n","|    ent_coef_loss   | -1.58    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 81948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 970      |\n","|    ep_rew_mean     | -32.4    |\n","| time/              |          |\n","|    episodes        | 212      |\n","|    fps             | 75       |\n","|    time_elapsed    | 105      |\n","|    total_timesteps | 168000   |\n","| train/             |          |\n","|    actor_loss      | -7.21    |\n","|    critic_loss     | 0.807    |\n","|    ent_coef        | 0.0258   |\n","|    ent_coef_loss   | -0.73    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 83948    |\n","---------------------------------\n","LunarLander - Step: 160001 | Mean Reward: 21.89 ± 117.06\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 970      |\n","|    ep_rew_mean     | -32.5    |\n","| time/              |          |\n","|    episodes        | 216      |\n","|    fps             | 77       |\n","|    time_elapsed    | 18       |\n","|    total_timesteps | 171400   |\n","| train/             |          |\n","|    actor_loss      | -11.6    |\n","|    critic_loss     | 1.13     |\n","|    ent_coef        | 0.0265   |\n","|    ent_coef_loss   | -0.0427  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 85648    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 963      |\n","|    ep_rew_mean     | -27.5    |\n","| time/              |          |\n","|    episodes        | 220      |\n","|    fps             | 80       |\n","|    time_elapsed    | 66       |\n","|    total_timesteps | 175400   |\n","| train/             |          |\n","|    actor_loss      | -6.15    |\n","|    critic_loss     | 1.24     |\n","|    ent_coef        | 0.0244   |\n","|    ent_coef_loss   | -0.126   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 87648    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 957      |\n","|    ep_rew_mean     | -21.4    |\n","| time/              |          |\n","|    episodes        | 224      |\n","|    fps             | 81       |\n","|    time_elapsed    | 100      |\n","|    total_timesteps | 178196   |\n","| train/             |          |\n","|    actor_loss      | -5.39    |\n","|    critic_loss     | 1.29     |\n","|    ent_coef        | 0.0236   |\n","|    ent_coef_loss   | -0.607   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 89046    |\n","---------------------------------\n","LunarLander - Step: 170001 | Mean Reward: 30.14 ± 105.58\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 949      |\n","|    ep_rew_mean     | -20.2    |\n","| time/              |          |\n","|    episodes        | 228      |\n","|    fps             | 80       |\n","|    time_elapsed    | 22       |\n","|    total_timesteps | 181824   |\n","| train/             |          |\n","|    actor_loss      | -8.67    |\n","|    critic_loss     | 7.26     |\n","|    ent_coef        | 0.0231   |\n","|    ent_coef_loss   | 0.8      |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 90860    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 940      |\n","|    ep_rew_mean     | -13.6    |\n","| time/              |          |\n","|    episodes        | 232      |\n","|    fps             | 83       |\n","|    time_elapsed    | 66       |\n","|    total_timesteps | 185580   |\n","| train/             |          |\n","|    actor_loss      | -6.18    |\n","|    critic_loss     | 4.12     |\n","|    ent_coef        | 0.0241   |\n","|    ent_coef_loss   | 0.0666   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 92738    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 937      |\n","|    ep_rew_mean     | -10.5    |\n","| time/              |          |\n","|    episodes        | 236      |\n","|    fps             | 81       |\n","|    time_elapsed    | 117      |\n","|    total_timesteps | 189580   |\n","| train/             |          |\n","|    actor_loss      | -8.16    |\n","|    critic_loss     | 3.25     |\n","|    ent_coef        | 0.0244   |\n","|    ent_coef_loss   | 0.701    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 94738    |\n","---------------------------------\n","LunarLander - Step: 180001 | Mean Reward: 48.71 ± 74.51\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 925      |\n","|    ep_rew_mean     | -8.19    |\n","| time/              |          |\n","|    episodes        | 240      |\n","|    fps             | 91       |\n","|    time_elapsed    | 43       |\n","|    total_timesteps | 194000   |\n","| train/             |          |\n","|    actor_loss      | -8.97    |\n","|    critic_loss     | 2.25     |\n","|    ent_coef        | 0.0242   |\n","|    ent_coef_loss   | -0.379   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 96948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 907      |\n","|    ep_rew_mean     | -8.22    |\n","| time/              |          |\n","|    episodes        | 244      |\n","|    fps             | 93       |\n","|    time_elapsed    | 58       |\n","|    total_timesteps | 195456   |\n","| train/             |          |\n","|    actor_loss      | -6.85    |\n","|    critic_loss     | 7.17     |\n","|    ent_coef        | 0.0237   |\n","|    ent_coef_loss   | -0.916   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 97676    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 896      |\n","|    ep_rew_mean     | -1.38    |\n","| time/              |          |\n","|    episodes        | 248      |\n","|    fps             | 90       |\n","|    time_elapsed    | 98       |\n","|    total_timesteps | 198932   |\n","| train/             |          |\n","|    actor_loss      | -10.1    |\n","|    critic_loss     | 1.78     |\n","|    ent_coef        | 0.0227   |\n","|    ent_coef_loss   | 0.987    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 99414    |\n","---------------------------------\n","LunarLander - Step: 190001 | Mean Reward: -26.97 ± 54.15\n"]}]},{"cell_type":"markdown","source":["env=4, batch size= 128, lr= 1e-4"],"metadata":{"id":"9F3WCmGp4CSh"}},{"cell_type":"code","source":["def train_lunarlander6():\n","    # Create environment and model for LunarLander (continuous version for SAC)\n","    env_lunar = make_vec_env(\"LunarLanderContinuous-v3\", n_envs=4)\n","    model = SAC(\"MlpPolicy\", env_lunar, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/\",\n","                learning_rate=1e-4, buffer_size=500000, batch_size=128, tau=1.68e-1,\n","                gamma=0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n","\n","    eval_freq = 10000  # Evaluate every 10,000 steps\n","    n_eval_episodes = 10  # Number of episodes per evaluation\n","\n","    for step in range(1, 200001, eval_freq):\n","        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n","        mean_reward, std_reward = evaluate_model(model, env_lunar, n_eval_episodes)\n","        print(f\"LunarLander - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n","\n","    model.save(\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128\")"],"metadata":{"id":"aGobQN2f5ief"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    train_lunarlander6()"],"metadata":{"id":"7JLTs_zg6H15","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5fed73f0-4b22-4c0e-cd0d-ad3f68238bc9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 120      |\n","|    ep_rew_mean     | -249     |\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 115      |\n","|    time_elapsed    | 5        |\n","|    total_timesteps | 600      |\n","| train/             |          |\n","|    actor_loss      | -2.56    |\n","|    critic_loss     | 75.5     |\n","|    ent_coef        | 0.976    |\n","|    ent_coef_loss   | -0.0792  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 248      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 119      |\n","|    ep_rew_mean     | -316     |\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 96       |\n","|    time_elapsed    | 11       |\n","|    total_timesteps | 1076     |\n","| train/             |          |\n","|    actor_loss      | 3.08     |\n","|    critic_loss     | 33.4     |\n","|    ent_coef        | 0.953    |\n","|    ent_coef_loss   | -0.16    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 486      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 119      |\n","|    ep_rew_mean     | -276     |\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 96       |\n","|    time_elapsed    | 17       |\n","|    total_timesteps | 1660     |\n","| train/             |          |\n","|    actor_loss      | 19.3     |\n","|    critic_loss     | 15.8     |\n","|    ent_coef        | 0.927    |\n","|    ent_coef_loss   | -0.22    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 778      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 130      |\n","|    ep_rew_mean     | -238     |\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 94       |\n","|    time_elapsed    | 22       |\n","|    total_timesteps | 2160     |\n","| train/             |          |\n","|    actor_loss      | 26.3     |\n","|    critic_loss     | 14.2     |\n","|    ent_coef        | 0.907    |\n","|    ent_coef_loss   | -0.259   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 1028     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 176      |\n","|    ep_rew_mean     | -243     |\n","| time/              |          |\n","|    episodes        | 20       |\n","|    fps             | 87       |\n","|    time_elapsed    | 44       |\n","|    total_timesteps | 3876     |\n","| train/             |          |\n","|    actor_loss      | 14.7     |\n","|    critic_loss     | 4.9      |\n","|    ent_coef        | 0.839    |\n","|    ent_coef_loss   | -0.486   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 1886     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 181      |\n","|    ep_rew_mean     | -236     |\n","| time/              |          |\n","|    episodes        | 24       |\n","|    fps             | 82       |\n","|    time_elapsed    | 55       |\n","|    total_timesteps | 4580     |\n","| train/             |          |\n","|    actor_loss      | 23.2     |\n","|    critic_loss     | 17.8     |\n","|    ent_coef        | 0.811    |\n","|    ent_coef_loss   | -0.567   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 2238     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 187      |\n","|    ep_rew_mean     | -238     |\n","| time/              |          |\n","|    episodes        | 28       |\n","|    fps             | 82       |\n","|    time_elapsed    | 65       |\n","|    total_timesteps | 5408     |\n","| train/             |          |\n","|    actor_loss      | 29.6     |\n","|    critic_loss     | 11.8     |\n","|    ent_coef        | 0.779    |\n","|    ent_coef_loss   | -0.641   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 2652     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 192      |\n","|    ep_rew_mean     | -233     |\n","| time/              |          |\n","|    episodes        | 32       |\n","|    fps             | 82       |\n","|    time_elapsed    | 81       |\n","|    total_timesteps | 6712     |\n","| train/             |          |\n","|    actor_loss      | 17.7     |\n","|    critic_loss     | 13.9     |\n","|    ent_coef        | 0.733    |\n","|    ent_coef_loss   | -0.71    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 3304     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 200      |\n","|    ep_rew_mean     | -218     |\n","| time/              |          |\n","|    episodes        | 36       |\n","|    fps             | 81       |\n","|    time_elapsed    | 99       |\n","|    total_timesteps | 8168     |\n","| train/             |          |\n","|    actor_loss      | -3.4     |\n","|    critic_loss     | 5.87     |\n","|    ent_coef        | 0.686    |\n","|    ent_coef_loss   | -0.767   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 4032     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 225      |\n","|    ep_rew_mean     | -216     |\n","| time/              |          |\n","|    episodes        | 40       |\n","|    fps             | 80       |\n","|    time_elapsed    | 118      |\n","|    total_timesteps | 9528     |\n","| train/             |          |\n","|    actor_loss      | -20.6    |\n","|    critic_loss     | 3.32     |\n","|    ent_coef        | 0.644    |\n","|    ent_coef_loss   | -0.962   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 4712     |\n","---------------------------------\n","LunarLander - Step: 1 | Mean Reward: -232.93 ± 52.93\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 231      |\n","|    ep_rew_mean     | -215     |\n","| time/              |          |\n","|    episodes        | 44       |\n","|    fps             | 79       |\n","|    time_elapsed    | 18       |\n","|    total_timesteps | 11436    |\n","| train/             |          |\n","|    actor_loss      | -17.6    |\n","|    critic_loss     | 6.8      |\n","|    ent_coef        | 0.586    |\n","|    ent_coef_loss   | -1.31    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 5666     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 250      |\n","|    ep_rew_mean     | -211     |\n","| time/              |          |\n","|    episodes        | 48       |\n","|    fps             | 80       |\n","|    time_elapsed    | 35       |\n","|    total_timesteps | 12856    |\n","| train/             |          |\n","|    actor_loss      | -12.9    |\n","|    critic_loss     | 25.5     |\n","|    ent_coef        | 0.545    |\n","|    ent_coef_loss   | -1.41    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 6376     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 299      |\n","|    ep_rew_mean     | -202     |\n","| time/              |          |\n","|    episodes        | 52       |\n","|    fps             | 72       |\n","|    time_elapsed    | 94       |\n","|    total_timesteps | 16856    |\n","| train/             |          |\n","|    actor_loss      | -6.38    |\n","|    critic_loss     | 4.66     |\n","|    ent_coef        | 0.445    |\n","|    ent_coef_loss   | -1.84    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 8376     |\n","---------------------------------\n","LunarLander - Step: 10001 | Mean Reward: -108.05 ± 17.83\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 359      |\n","|    ep_rew_mean     | -185     |\n","| time/              |          |\n","|    episodes        | 56       |\n","|    fps             | 71       |\n","|    time_elapsed    | 55       |\n","|    total_timesteps | 24000    |\n","| train/             |          |\n","|    actor_loss      | -13.5    |\n","|    critic_loss     | 3.02     |\n","|    ent_coef        | 0.312    |\n","|    ent_coef_loss   | -2.57    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 11948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 400      |\n","|    ep_rew_mean     | -179     |\n","| time/              |          |\n","|    episodes        | 60       |\n","|    fps             | 70       |\n","|    time_elapsed    | 112      |\n","|    total_timesteps | 28000    |\n","| train/             |          |\n","|    actor_loss      | -12.5    |\n","|    critic_loss     | 7.51     |\n","|    ent_coef        | 0.257    |\n","|    ent_coef_loss   | -3.06    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 13948    |\n","---------------------------------\n","LunarLander - Step: 20001 | Mean Reward: -76.87 ± 26.56\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 437      |\n","|    ep_rew_mean     | -172     |\n","| time/              |          |\n","|    episodes        | 64       |\n","|    fps             | 68       |\n","|    time_elapsed    | 58       |\n","|    total_timesteps | 34000    |\n","| train/             |          |\n","|    actor_loss      | -9.76    |\n","|    critic_loss     | 5.71     |\n","|    ent_coef        | 0.191    |\n","|    ent_coef_loss   | -3.46    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 16948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 469      |\n","|    ep_rew_mean     | -166     |\n","| time/              |          |\n","|    episodes        | 68       |\n","|    fps             | 69       |\n","|    time_elapsed    | 115      |\n","|    total_timesteps | 38000    |\n","| train/             |          |\n","|    actor_loss      | -11.1    |\n","|    critic_loss     | 7.79     |\n","|    ent_coef        | 0.158    |\n","|    ent_coef_loss   | -3.23    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 18948    |\n","---------------------------------\n","LunarLander - Step: 30001 | Mean Reward: -119.39 ± 21.53\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 498      |\n","|    ep_rew_mean     | -161     |\n","| time/              |          |\n","|    episodes        | 72       |\n","|    fps             | 67       |\n","|    time_elapsed    | 58       |\n","|    total_timesteps | 44000    |\n","| train/             |          |\n","|    actor_loss      | -11.2    |\n","|    critic_loss     | 6.6      |\n","|    ent_coef        | 0.119    |\n","|    ent_coef_loss   | -3.6     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 21948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 523      |\n","|    ep_rew_mean     | -155     |\n","| time/              |          |\n","|    episodes        | 76       |\n","|    fps             | 67       |\n","|    time_elapsed    | 118      |\n","|    total_timesteps | 48000    |\n","| train/             |          |\n","|    actor_loss      | -10.9    |\n","|    critic_loss     | 1.82     |\n","|    ent_coef        | 0.0987   |\n","|    ent_coef_loss   | -3.67    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 23948    |\n","---------------------------------\n","LunarLander - Step: 40001 | Mean Reward: -248.62 ± 443.17\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 547      |\n","|    ep_rew_mean     | -152     |\n","| time/              |          |\n","|    episodes        | 80       |\n","|    fps             | 69       |\n","|    time_elapsed    | 57       |\n","|    total_timesteps | 54000    |\n","| train/             |          |\n","|    actor_loss      | -9.19    |\n","|    critic_loss     | 1.59     |\n","|    ent_coef        | 0.0744   |\n","|    ent_coef_loss   | -3.3     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 26948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 568      |\n","|    ep_rew_mean     | -149     |\n","| time/              |          |\n","|    episodes        | 84       |\n","|    fps             | 68       |\n","|    time_elapsed    | 117      |\n","|    total_timesteps | 58000    |\n","| train/             |          |\n","|    actor_loss      | -7.81    |\n","|    critic_loss     | 1.42     |\n","|    ent_coef        | 0.0619   |\n","|    ent_coef_loss   | -2.14    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 28948    |\n","---------------------------------\n","LunarLander - Step: 50001 | Mean Reward: -24.73 ± 21.59\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 580      |\n","|    ep_rew_mean     | -150     |\n","| time/              |          |\n","|    episodes        | 88       |\n","|    fps             | 71       |\n","|    time_elapsed    | 55       |\n","|    total_timesteps | 64000    |\n","| train/             |          |\n","|    actor_loss      | -9.4     |\n","|    critic_loss     | 1.91     |\n","|    ent_coef        | 0.0493   |\n","|    ent_coef_loss   | -2.41    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 31948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 598      |\n","|    ep_rew_mean     | -146     |\n","| time/              |          |\n","|    episodes        | 92       |\n","|    fps             | 71       |\n","|    time_elapsed    | 112      |\n","|    total_timesteps | 68000    |\n","| train/             |          |\n","|    actor_loss      | -13.8    |\n","|    critic_loss     | 1.75     |\n","|    ent_coef        | 0.0431   |\n","|    ent_coef_loss   | 0.119    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 33948    |\n","---------------------------------\n","LunarLander - Step: 60001 | Mean Reward: -111.73 ± 62.08\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 600      |\n","|    ep_rew_mean     | -146     |\n","| time/              |          |\n","|    episodes        | 96       |\n","|    fps             | 72       |\n","|    time_elapsed    | 14       |\n","|    total_timesteps | 71068    |\n","| train/             |          |\n","|    actor_loss      | -9.24    |\n","|    critic_loss     | 0.967    |\n","|    ent_coef        | 0.0384   |\n","|    ent_coef_loss   | 0.0851   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 35482    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 605      |\n","|    ep_rew_mean     | -143     |\n","| time/              |          |\n","|    episodes        | 100      |\n","|    fps             | 73       |\n","|    time_elapsed    | 48       |\n","|    total_timesteps | 73544    |\n","| train/             |          |\n","|    actor_loss      | -4.88    |\n","|    critic_loss     | 1.47     |\n","|    ent_coef        | 0.0351   |\n","|    ent_coef_loss   | -0.658   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 36720    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 626      |\n","|    ep_rew_mean     | -137     |\n","| time/              |          |\n","|    episodes        | 104      |\n","|    fps             | 73       |\n","|    time_elapsed    | 75       |\n","|    total_timesteps | 75544    |\n","| train/             |          |\n","|    actor_loss      | -4.69    |\n","|    critic_loss     | 1.67     |\n","|    ent_coef        | 0.0336   |\n","|    ent_coef_loss   | -0.485   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 37720    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 652      |\n","|    ep_rew_mean     | -124     |\n","| time/              |          |\n","|    episodes        | 108      |\n","|    fps             | 72       |\n","|    time_elapsed    | 129      |\n","|    total_timesteps | 79452    |\n","| train/             |          |\n","|    actor_loss      | -7.4     |\n","|    critic_loss     | 1.3      |\n","|    ent_coef        | 0.0361   |\n","|    ent_coef_loss   | 0.313    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 39674    |\n","---------------------------------\n","LunarLander - Step: 70001 | Mean Reward: -40.83 ± 20.74\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 695      |\n","|    ep_rew_mean     | -120     |\n","| time/              |          |\n","|    episodes        | 112      |\n","|    fps             | 77       |\n","|    time_elapsed    | 51       |\n","|    total_timesteps | 84000    |\n","| train/             |          |\n","|    actor_loss      | -6.78    |\n","|    critic_loss     | 1.09     |\n","|    ent_coef        | 0.032    |\n","|    ent_coef_loss   | -0.68    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 41948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 728      |\n","|    ep_rew_mean     | -115     |\n","| time/              |          |\n","|    episodes        | 116      |\n","|    fps             | 74       |\n","|    time_elapsed    | 107      |\n","|    total_timesteps | 88000    |\n","| train/             |          |\n","|    actor_loss      | -10.3    |\n","|    critic_loss     | 1.28     |\n","|    ent_coef        | 0.0312   |\n","|    ent_coef_loss   | -1.98    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 43948    |\n","---------------------------------\n","LunarLander - Step: 80001 | Mean Reward: -43.84 ± 27.41\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 736      |\n","|    ep_rew_mean     | -105     |\n","| time/              |          |\n","|    episodes        | 120      |\n","|    fps             | 74       |\n","|    time_elapsed    | 53       |\n","|    total_timesteps | 94000    |\n","| train/             |          |\n","|    actor_loss      | -11      |\n","|    critic_loss     | 1.41     |\n","|    ent_coef        | 0.0319   |\n","|    ent_coef_loss   | 0.541    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 46948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 768      |\n","|    ep_rew_mean     | -99.8    |\n","| time/              |          |\n","|    episodes        | 124      |\n","|    fps             | 71       |\n","|    time_elapsed    | 112      |\n","|    total_timesteps | 98000    |\n","| train/             |          |\n","|    actor_loss      | -6.77    |\n","|    critic_loss     | 1.22     |\n","|    ent_coef        | 0.03     |\n","|    ent_coef_loss   | -0.379   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 48948    |\n","---------------------------------\n","LunarLander - Step: 90001 | Mean Reward: -33.69 ± 21.42\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 815      |\n","|    ep_rew_mean     | -89      |\n","| time/              |          |\n","|    episodes        | 128      |\n","|    fps             | 71       |\n","|    time_elapsed    | 56       |\n","|    total_timesteps | 104000   |\n","| train/             |          |\n","|    actor_loss      | -10      |\n","|    critic_loss     | 1.16     |\n","|    ent_coef        | 0.0269   |\n","|    ent_coef_loss   | -1.13    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 51948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 845      |\n","|    ep_rew_mean     | -84.8    |\n","| time/              |          |\n","|    episodes        | 132      |\n","|    fps             | 70       |\n","|    time_elapsed    | 114      |\n","|    total_timesteps | 108000   |\n","| train/             |          |\n","|    actor_loss      | -4.51    |\n","|    critic_loss     | 1.22     |\n","|    ent_coef        | 0.0251   |\n","|    ent_coef_loss   | 0.136    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 53948    |\n","---------------------------------\n","LunarLander - Step: 100001 | Mean Reward: -26.78 ± 23.59\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 870      |\n","|    ep_rew_mean     | -77.5    |\n","| time/              |          |\n","|    episodes        | 136      |\n","|    fps             | 65       |\n","|    time_elapsed    | 60       |\n","|    total_timesteps | 114000   |\n","| train/             |          |\n","|    actor_loss      | -11.5    |\n","|    critic_loss     | 1.28     |\n","|    ent_coef        | 0.0238   |\n","|    ent_coef_loss   | 0.693    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 56948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 895      |\n","|    ep_rew_mean     | -70.8    |\n","| time/              |          |\n","|    episodes        | 140      |\n","|    fps             | 65       |\n","|    time_elapsed    | 122      |\n","|    total_timesteps | 118000   |\n","| train/             |          |\n","|    actor_loss      | -5.21    |\n","|    critic_loss     | 1.34     |\n","|    ent_coef        | 0.0224   |\n","|    ent_coef_loss   | -1.27    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 58948    |\n","---------------------------------\n","LunarLander - Step: 110001 | Mean Reward: -17.93 ± 23.48\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 901      |\n","|    ep_rew_mean     | -68.6    |\n","| time/              |          |\n","|    episodes        | 144      |\n","|    fps             | 75       |\n","|    time_elapsed    | 8        |\n","|    total_timesteps | 120680   |\n","| train/             |          |\n","|    actor_loss      | -7.98    |\n","|    critic_loss     | 1.11     |\n","|    ent_coef        | 0.0218   |\n","|    ent_coef_loss   | 1.11     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 60288    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 923      |\n","|    ep_rew_mean     | -62.5    |\n","| time/              |          |\n","|    episodes        | 148      |\n","|    fps             | 68       |\n","|    time_elapsed    | 68       |\n","|    total_timesteps | 124680   |\n","| train/             |          |\n","|    actor_loss      | -9.68    |\n","|    critic_loss     | 4.28     |\n","|    ent_coef        | 0.0237   |\n","|    ent_coef_loss   | -0.73    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 62288    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 928      |\n","|    ep_rew_mean     | -60      |\n","| time/              |          |\n","|    episodes        | 152      |\n","|    fps             | 69       |\n","|    time_elapsed    | 124      |\n","|    total_timesteps | 128680   |\n","| train/             |          |\n","|    actor_loss      | -7.68    |\n","|    critic_loss     | 1.05     |\n","|    ent_coef        | 0.0217   |\n","|    ent_coef_loss   | -1.02    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 64288    |\n","---------------------------------\n","LunarLander - Step: 120001 | Mean Reward: -37.56 ± 35.32\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 935      |\n","|    ep_rew_mean     | -59.4    |\n","| time/              |          |\n","|    episodes        | 156      |\n","|    fps             | 70       |\n","|    time_elapsed    | 56       |\n","|    total_timesteps | 134000   |\n","| train/             |          |\n","|    actor_loss      | -6.14    |\n","|    critic_loss     | 1.28     |\n","|    ent_coef        | 0.0207   |\n","|    ent_coef_loss   | 0.35     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 66948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 919      |\n","|    ep_rew_mean     | -58.7    |\n","| time/              |          |\n","|    episodes        | 160      |\n","|    fps             | 70       |\n","|    time_elapsed    | 113      |\n","|    total_timesteps | 138000   |\n","| train/             |          |\n","|    actor_loss      | 1.98     |\n","|    critic_loss     | 0.965    |\n","|    ent_coef        | 0.0195   |\n","|    ent_coef_loss   | -1.49    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 68948    |\n","---------------------------------\n","LunarLander - Step: 130001 | Mean Reward: -32.76 ± 14.91\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 919      |\n","|    ep_rew_mean     | -56.3    |\n","| time/              |          |\n","|    episodes        | 164      |\n","|    fps             | 74       |\n","|    time_elapsed    | 53       |\n","|    total_timesteps | 144000   |\n","| train/             |          |\n","|    actor_loss      | -3.25    |\n","|    critic_loss     | 0.995    |\n","|    ent_coef        | 0.0179   |\n","|    ent_coef_loss   | -0.335   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 71948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 919      |\n","|    ep_rew_mean     | -55.5    |\n","| time/              |          |\n","|    episodes        | 168      |\n","|    fps             | 69       |\n","|    time_elapsed    | 115      |\n","|    total_timesteps | 148000   |\n","| train/             |          |\n","|    actor_loss      | -1.9     |\n","|    critic_loss     | 0.761    |\n","|    ent_coef        | 0.018    |\n","|    ent_coef_loss   | 0.75     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 73948    |\n","---------------------------------\n","LunarLander - Step: 140001 | Mean Reward: -42.55 ± 19.52\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 919      |\n","|    ep_rew_mean     | -53.1    |\n","| time/              |          |\n","|    episodes        | 172      |\n","|    fps             | 68       |\n","|    time_elapsed    | 58       |\n","|    total_timesteps | 154000   |\n","| train/             |          |\n","|    actor_loss      | 0.33     |\n","|    critic_loss     | 0.986    |\n","|    ent_coef        | 0.0192   |\n","|    ent_coef_loss   | -0.375   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 76948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 919      |\n","|    ep_rew_mean     | -53.5    |\n","| time/              |          |\n","|    episodes        | 176      |\n","|    fps             | 68       |\n","|    time_elapsed    | 117      |\n","|    total_timesteps | 158000   |\n","| train/             |          |\n","|    actor_loss      | -2.51    |\n","|    critic_loss     | 0.741    |\n","|    ent_coef        | 0.0178   |\n","|    ent_coef_loss   | -1.02    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 78948    |\n","---------------------------------\n","LunarLander - Step: 150001 | Mean Reward: -34.95 ± 17.60\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 919      |\n","|    ep_rew_mean     | -51.4    |\n","| time/              |          |\n","|    episodes        | 180      |\n","|    fps             | 67       |\n","|    time_elapsed    | 59       |\n","|    total_timesteps | 164000   |\n","| train/             |          |\n","|    actor_loss      | -2.81    |\n","|    critic_loss     | 0.755    |\n","|    ent_coef        | 0.0177   |\n","|    ent_coef_loss   | -0.88    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 81948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 911      |\n","|    ep_rew_mean     | -51.2    |\n","| time/              |          |\n","|    episodes        | 184      |\n","|    fps             | 70       |\n","|    time_elapsed    | 68       |\n","|    total_timesteps | 164828   |\n","| train/             |          |\n","|    actor_loss      | -1.94    |\n","|    critic_loss     | 0.816    |\n","|    ent_coef        | 0.0177   |\n","|    ent_coef_loss   | -0.327   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 82362    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 909      |\n","|    ep_rew_mean     | -44.6    |\n","| time/              |          |\n","|    episodes        | 188      |\n","|    fps             | 70       |\n","|    time_elapsed    | 123      |\n","|    total_timesteps | 168708   |\n","| train/             |          |\n","|    actor_loss      | 0.0531   |\n","|    critic_loss     | 0.908    |\n","|    ent_coef        | 0.017    |\n","|    ent_coef_loss   | -1.23    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 84302    |\n","---------------------------------\n","LunarLander - Step: 160001 | Mean Reward: -17.06 ± 15.04\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 901      |\n","|    ep_rew_mean     | -44.1    |\n","| time/              |          |\n","|    episodes        | 192      |\n","|    fps             | 69       |\n","|    time_elapsed    | 57       |\n","|    total_timesteps | 174000   |\n","| train/             |          |\n","|    actor_loss      | 0.389    |\n","|    critic_loss     | 0.711    |\n","|    ent_coef        | 0.0165   |\n","|    ent_coef_loss   | -0.459   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 86948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 912      |\n","|    ep_rew_mean     | -38.9    |\n","| time/              |          |\n","|    episodes        | 196      |\n","|    fps             | 69       |\n","|    time_elapsed    | 114      |\n","|    total_timesteps | 178000   |\n","| train/             |          |\n","|    actor_loss      | -5.48    |\n","|    critic_loss     | 0.85     |\n","|    ent_coef        | 0.0175   |\n","|    ent_coef_loss   | -0.0683  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 88948    |\n","---------------------------------\n","LunarLander - Step: 170001 | Mean Reward: -39.69 ± 17.12\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 927      |\n","|    ep_rew_mean     | -37.2    |\n","| time/              |          |\n","|    episodes        | 200      |\n","|    fps             | 67       |\n","|    time_elapsed    | 59       |\n","|    total_timesteps | 184000   |\n","| train/             |          |\n","|    actor_loss      | -9.25    |\n","|    critic_loss     | 1.16     |\n","|    ent_coef        | 0.0184   |\n","|    ent_coef_loss   | 0.164    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 91948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 942      |\n","|    ep_rew_mean     | -35.9    |\n","| time/              |          |\n","|    episodes        | 204      |\n","|    fps             | 66       |\n","|    time_elapsed    | 120      |\n","|    total_timesteps | 188000   |\n","| train/             |          |\n","|    actor_loss      | -0.144   |\n","|    critic_loss     | 0.797    |\n","|    ent_coef        | 0.0172   |\n","|    ent_coef_loss   | 0.917    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 93948    |\n","---------------------------------\n","LunarLander - Step: 180001 | Mean Reward: -15.44 ± 20.72\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr1eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 942      |\n","|    ep_rew_mean     | -34.6    |\n","| time/              |          |\n","|    episodes        | 208      |\n","|    fps             | 66       |\n","|    time_elapsed    | 60       |\n","|    total_timesteps | 194000   |\n","| train/             |          |\n","|    actor_loss      | -5.21    |\n","|    critic_loss     | 1.26     |\n","|    ent_coef        | 0.0174   |\n","|    ent_coef_loss   | -0.0871  |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 96948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 942      |\n","|    ep_rew_mean     | -32.4    |\n","| time/              |          |\n","|    episodes        | 212      |\n","|    fps             | 67       |\n","|    time_elapsed    | 118      |\n","|    total_timesteps | 198000   |\n","| train/             |          |\n","|    actor_loss      | 1.13     |\n","|    critic_loss     | 0.713    |\n","|    ent_coef        | 0.0161   |\n","|    ent_coef_loss   | -0.639   |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 98948    |\n","---------------------------------\n","LunarLander - Step: 190001 | Mean Reward: -5.48 ± 20.86\n"]}]}]}