{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I08ysbNCpSI7","outputId":"37ff53c2-7196-49da-b8fb-292c407d8422"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting stable_baselines3\n","  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n","Collecting gymnasium<1.1.0,>=0.29.1 (from stable_baselines3)\n","  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n","Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu121)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n","Collecting farama-notifications>=0.0.1 (from gymnasium<1.1.0,>=0.29.1->stable_baselines3)\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0,>=2.3->stable_baselines3) (12.8.61)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.55.6)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n","Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Installing collected packages: farama-notifications, gymnasium, stable_baselines3\n","Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 stable_baselines3-2.5.0\n"]}],"source":["!pip install stable_baselines3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECjjcZ-opzYL","outputId":"d3cd5aff-17e1-46f8-ab5a-59d758a14641"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting box2d\n","  Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (573 bytes)\n","Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: box2d\n","Successfully installed box2d-2.3.10\n"]}],"source":["!pip install box2d"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOJbyToUp4Zx"},"outputs":[],"source":["import multiprocessing\n","from stable_baselines3 import SAC\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.env_util import make_vec_env"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cwiNPKwzp8Xb"},"outputs":[],"source":["def evaluate_model(model, env, n_eval_episodes=10):\n","    \"\"\"Evaluate the model on a given environment and return mean and std rewards.\"\"\"\n","    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes)\n","    return mean_reward, std_reward"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gK1dDPHp6_pn","outputId":"43a8415f-fb52-4fd9-9727-090f64e540e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"0_W45wJuuRZK"},"source":["## SAC Lunar"]},{"cell_type":"markdown","metadata":{"id":"6b0EuoDH4HyG"},"source":["env=4, batch size= 128, lr= 3e-4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nJCseAQH4Iy7"},"outputs":[],"source":["def train_lunarlander8():\n","    # Create environment and model for LunarLander (continuous version for SAC)\n","    env_lunar = make_vec_env(\"LunarLanderContinuous-v3\", n_envs=4)\n","    model = SAC(\"MlpPolicy\", env_lunar, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/\",\n","                learning_rate=3e-4, buffer_size=500000, batch_size=128, tau=1.68e-1,\n","                gamma=0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n","\n","    eval_freq = 10000  # Evaluate every 10,000 steps\n","    n_eval_episodes = 10  # Number of episodes per evaluation\n","\n","    for step in range(1, 200001, eval_freq):\n","        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n","        mean_reward, std_reward = evaluate_model(model, env_lunar, n_eval_episodes)\n","        print(f\"LunarLander - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n","\n","    model.save(\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"fG273WYf6LrE","outputId":"77b82bbe-1762-401c-a9c2-4c63a598664e"},"outputs":[{"name":"stderr","output_type":"stream","text":["<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n","<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n","<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n","/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n","  from pkg_resources import resource_stream, resource_exists\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n"]},{"name":"stdout","output_type":"stream","text":["Using cpu device\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 125      |\n","|    ep_rew_mean     | -209     |\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 102      |\n","|    time_elapsed    | 6        |\n","|    total_timesteps | 640      |\n","| train/             |          |\n","|    actor_loss      | -22.5    |\n","|    critic_loss     | 5.17     |\n","|    ent_coef        | 0.925    |\n","|    ent_coef_loss   | -0.258   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 268      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 130      |\n","|    ep_rew_mean     | -261     |\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 109      |\n","|    time_elapsed    | 12       |\n","|    total_timesteps | 1324     |\n","| train/             |          |\n","|    actor_loss      | -7.26    |\n","|    critic_loss     | 18.3     |\n","|    ent_coef        | 0.838    |\n","|    ent_coef_loss   | -0.445   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 610      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 148      |\n","|    ep_rew_mean     | -189     |\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 103      |\n","|    time_elapsed    | 20       |\n","|    total_timesteps | 2080     |\n","| train/             |          |\n","|    actor_loss      | -13.1    |\n","|    critic_loss     | 15.6     |\n","|    ent_coef        | 0.763    |\n","|    ent_coef_loss   | -0.612   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 988      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 166      |\n","|    ep_rew_mean     | -149     |\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 105      |\n","|    time_elapsed    | 28       |\n","|    total_timesteps | 3020     |\n","| train/             |          |\n","|    actor_loss      | -27.8    |\n","|    critic_loss     | 10.4     |\n","|    ent_coef        | 0.676    |\n","|    ent_coef_loss   | -0.819   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 1458     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 193      |\n","|    ep_rew_mean     | -141     |\n","| time/              |          |\n","|    episodes        | 20       |\n","|    fps             | 102      |\n","|    time_elapsed    | 41       |\n","|    total_timesteps | 4316     |\n","| train/             |          |\n","|    actor_loss      | -19.2    |\n","|    critic_loss     | 5.82     |\n","|    ent_coef        | 0.563    |\n","|    ent_coef_loss   | -1.36    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 2106     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 212      |\n","|    ep_rew_mean     | -140     |\n","| time/              |          |\n","|    episodes        | 24       |\n","|    fps             | 99       |\n","|    time_elapsed    | 63       |\n","|    total_timesteps | 6264     |\n","| train/             |          |\n","|    actor_loss      | -6.94    |\n","|    critic_loss     | 2.45     |\n","|    ent_coef        | 0.423    |\n","|    ent_coef_loss   | -2.08    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 3080     |\n","---------------------------------\n","LunarLander - Step: 1 | Mean Reward: -147.12 ± 144.79\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 270      |\n","|    ep_rew_mean     | -142     |\n","| time/              |          |\n","|    episodes        | 28       |\n","|    fps             | 89       |\n","|    time_elapsed    | 8        |\n","|    total_timesteps | 10768    |\n","| train/             |          |\n","|    actor_loss      | 6.69     |\n","|    critic_loss     | 3.1      |\n","|    ent_coef        | 0.219    |\n","|    ent_coef_loss   | -3.17    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 5332     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 348      |\n","|    ep_rew_mean     | -130     |\n","| time/              |          |\n","|    episodes        | 32       |\n","|    fps             | 82       |\n","|    time_elapsed    | 57       |\n","|    total_timesteps | 14768    |\n","| train/             |          |\n","|    actor_loss      | 1.82     |\n","|    critic_loss     | 2.37     |\n","|    ent_coef        | 0.129    |\n","|    ent_coef_loss   | -2.97    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 7332     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 421      |\n","|    ep_rew_mean     | -124     |\n","| time/              |          |\n","|    episodes        | 36       |\n","|    fps             | 81       |\n","|    time_elapsed    | 107      |\n","|    total_timesteps | 18768    |\n","| train/             |          |\n","|    actor_loss      | -4.09    |\n","|    critic_loss     | 7.24     |\n","|    ent_coef        | 0.0755   |\n","|    ent_coef_loss   | -2.74    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 9332     |\n","---------------------------------\n","LunarLander - Step: 10001 | Mean Reward: -24.78 ± 24.26\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 492      |\n","|    ep_rew_mean     | -112     |\n","| time/              |          |\n","|    episodes        | 40       |\n","|    fps             | 88       |\n","|    time_elapsed    | 45       |\n","|    total_timesteps | 24000    |\n","| train/             |          |\n","|    actor_loss      | -27.1    |\n","|    critic_loss     | 13.8     |\n","|    ent_coef        | 0.0526   |\n","|    ent_coef_loss   | 0.374    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 11948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 537      |\n","|    ep_rew_mean     | -105     |\n","| time/              |          |\n","|    episodes        | 44       |\n","|    fps             | 81       |\n","|    time_elapsed    | 98       |\n","|    total_timesteps | 28000    |\n","| train/             |          |\n","|    actor_loss      | -24.8    |\n","|    critic_loss     | 4.77     |\n","|    ent_coef        | 0.0524   |\n","|    ent_coef_loss   | 1.23     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 13948    |\n","---------------------------------\n","LunarLander - Step: 20001 | Mean Reward: -44.30 ± 19.00\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 575      |\n","|    ep_rew_mean     | -101     |\n","| time/              |          |\n","|    episodes        | 48       |\n","|    fps             | 78       |\n","|    time_elapsed    | 50       |\n","|    total_timesteps | 34000    |\n","| train/             |          |\n","|    actor_loss      | -9.77    |\n","|    critic_loss     | 9.51     |\n","|    ent_coef        | 0.0291   |\n","|    ent_coef_loss   | -0.826   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 16948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 607      |\n","|    ep_rew_mean     | -97.6    |\n","| time/              |          |\n","|    episodes        | 52       |\n","|    fps             | 75       |\n","|    time_elapsed    | 105      |\n","|    total_timesteps | 38000    |\n","| train/             |          |\n","|    actor_loss      | -10.7    |\n","|    critic_loss     | 17.3     |\n","|    ent_coef        | 0.0249   |\n","|    ent_coef_loss   | -0.31    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 18948    |\n","---------------------------------\n","LunarLander - Step: 30001 | Mean Reward: -24.62 ± 15.78\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 634      |\n","|    ep_rew_mean     | -92.8    |\n","| time/              |          |\n","|    episodes        | 56       |\n","|    fps             | 79       |\n","|    time_elapsed    | 50       |\n","|    total_timesteps | 44000    |\n","| train/             |          |\n","|    actor_loss      | -10.8    |\n","|    critic_loss     | 1.94     |\n","|    ent_coef        | 0.0302   |\n","|    ent_coef_loss   | 1.17     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 21948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 658      |\n","|    ep_rew_mean     | -86.3    |\n","| time/              |          |\n","|    episodes        | 60       |\n","|    fps             | 80       |\n","|    time_elapsed    | 99       |\n","|    total_timesteps | 48000    |\n","| train/             |          |\n","|    actor_loss      | -13.8    |\n","|    critic_loss     | 1.24     |\n","|    ent_coef        | 0.0343   |\n","|    ent_coef_loss   | 0.818    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 23948    |\n","---------------------------------\n","LunarLander - Step: 40001 | Mean Reward: -0.91 ± 16.10\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 679      |\n","|    ep_rew_mean     | -82.3    |\n","| time/              |          |\n","|    episodes        | 64       |\n","|    fps             | 81       |\n","|    time_elapsed    | 49       |\n","|    total_timesteps | 54000    |\n","| train/             |          |\n","|    actor_loss      | -10.5    |\n","|    critic_loss     | 1.77     |\n","|    ent_coef        | 0.0246   |\n","|    ent_coef_loss   | 0.21     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 26948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 698      |\n","|    ep_rew_mean     | -78.5    |\n","| time/              |          |\n","|    episodes        | 68       |\n","|    fps             | 79       |\n","|    time_elapsed    | 100      |\n","|    total_timesteps | 58000    |\n","| train/             |          |\n","|    actor_loss      | -8       |\n","|    critic_loss     | 0.837    |\n","|    ent_coef        | 0.0207   |\n","|    ent_coef_loss   | -1.07    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 28948    |\n","---------------------------------\n","LunarLander - Step: 50001 | Mean Reward: -31.07 ± 19.36\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 714      |\n","|    ep_rew_mean     | -76      |\n","| time/              |          |\n","|    episodes        | 72       |\n","|    fps             | 77       |\n","|    time_elapsed    | 51       |\n","|    total_timesteps | 64000    |\n","| train/             |          |\n","|    actor_loss      | -8.3     |\n","|    critic_loss     | 18.1     |\n","|    ent_coef        | 0.0202   |\n","|    ent_coef_loss   | -0.203   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 31948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 729      |\n","|    ep_rew_mean     | -75.5    |\n","| time/              |          |\n","|    episodes        | 76       |\n","|    fps             | 81       |\n","|    time_elapsed    | 97       |\n","|    total_timesteps | 68000    |\n","| train/             |          |\n","|    actor_loss      | -12      |\n","|    critic_loss     | 0.726    |\n","|    ent_coef        | 0.0194   |\n","|    ent_coef_loss   | 0.703    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 33948    |\n","---------------------------------\n","LunarLander - Step: 60001 | Mean Reward: -72.08 ± 78.45\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 739      |\n","|    ep_rew_mean     | -72.5    |\n","| time/              |          |\n","|    episodes        | 80       |\n","|    fps             | 80       |\n","|    time_elapsed    | 47       |\n","|    total_timesteps | 73864    |\n","| train/             |          |\n","|    actor_loss      | -10.8    |\n","|    critic_loss     | 0.924    |\n","|    ent_coef        | 0.018    |\n","|    ent_coef_loss   | -1.35    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 36880    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 752      |\n","|    ep_rew_mean     | -69.9    |\n","| time/              |          |\n","|    episodes        | 84       |\n","|    fps             | 80       |\n","|    time_elapsed    | 97       |\n","|    total_timesteps | 77864    |\n","| train/             |          |\n","|    actor_loss      | -10.1    |\n","|    critic_loss     | 0.662    |\n","|    ent_coef        | 0.018    |\n","|    ent_coef_loss   | 0.357    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 38880    |\n","---------------------------------\n","LunarLander - Step: 70001 | Mean Reward: -28.29 ± 21.47\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 768      |\n","|    ep_rew_mean     | -66.3    |\n","| time/              |          |\n","|    episodes        | 88       |\n","|    fps             | 79       |\n","|    time_elapsed    | 50       |\n","|    total_timesteps | 84000    |\n","| train/             |          |\n","|    actor_loss      | -11.4    |\n","|    critic_loss     | 0.592    |\n","|    ent_coef        | 0.0185   |\n","|    ent_coef_loss   | 0.805    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 41948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 774      |\n","|    ep_rew_mean     | -66.7    |\n","| time/              |          |\n","|    episodes        | 92       |\n","|    fps             | 80       |\n","|    time_elapsed    | 99       |\n","|    total_timesteps | 88000    |\n","| train/             |          |\n","|    actor_loss      | -10.1    |\n","|    critic_loss     | 0.474    |\n","|    ent_coef        | 0.0179   |\n","|    ent_coef_loss   | 0.113    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 43948    |\n","---------------------------------\n","LunarLander - Step: 80001 | Mean Reward: -64.24 ± 18.06\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 783      |\n","|    ep_rew_mean     | -64.5    |\n","| time/              |          |\n","|    episodes        | 96       |\n","|    fps             | 75       |\n","|    time_elapsed    | 52       |\n","|    total_timesteps | 94000    |\n","| train/             |          |\n","|    actor_loss      | -9.96    |\n","|    critic_loss     | 2.35     |\n","|    ent_coef        | 0.0218   |\n","|    ent_coef_loss   | -0.558   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 46948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 805      |\n","|    ep_rew_mean     | -63.1    |\n","| time/              |          |\n","|    episodes        | 100      |\n","|    fps             | 74       |\n","|    time_elapsed    | 106      |\n","|    total_timesteps | 98000    |\n","| train/             |          |\n","|    actor_loss      | -9.36    |\n","|    critic_loss     | 0.536    |\n","|    ent_coef        | 0.019    |\n","|    ent_coef_loss   | 0.753    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 48948    |\n","---------------------------------\n","LunarLander - Step: 90001 | Mean Reward: -9.33 ± 21.68\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 839      |\n","|    ep_rew_mean     | -47.4    |\n","| time/              |          |\n","|    episodes        | 104      |\n","|    fps             | 74       |\n","|    time_elapsed    | 53       |\n","|    total_timesteps | 104000   |\n","| train/             |          |\n","|    actor_loss      | -8.05    |\n","|    critic_loss     | 6.42     |\n","|    ent_coef        | 0.0177   |\n","|    ent_coef_loss   | 0.829    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 51948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 873      |\n","|    ep_rew_mean     | -42.9    |\n","| time/              |          |\n","|    episodes        | 108      |\n","|    fps             | 75       |\n","|    time_elapsed    | 105      |\n","|    total_timesteps | 108000   |\n","| train/             |          |\n","|    actor_loss      | -8.78    |\n","|    critic_loss     | 0.796    |\n","|    ent_coef        | 0.0204   |\n","|    ent_coef_loss   | 0.132    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 53948    |\n","---------------------------------\n","LunarLander - Step: 100001 | Mean Reward: -19.99 ± 41.45\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 905      |\n","|    ep_rew_mean     | -42.9    |\n","| time/              |          |\n","|    episodes        | 112      |\n","|    fps             | 82       |\n","|    time_elapsed    | 48       |\n","|    total_timesteps | 114000   |\n","| train/             |          |\n","|    actor_loss      | -14.1    |\n","|    critic_loss     | 0.681    |\n","|    ent_coef        | 0.02     |\n","|    ent_coef_loss   | 0.735    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 56948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 935      |\n","|    ep_rew_mean     | -42.7    |\n","| time/              |          |\n","|    episodes        | 116      |\n","|    fps             | 82       |\n","|    time_elapsed    | 97       |\n","|    total_timesteps | 118000   |\n","| train/             |          |\n","|    actor_loss      | -9.32    |\n","|    critic_loss     | 2.6      |\n","|    ent_coef        | 0.0173   |\n","|    ent_coef_loss   | 0.0703   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 58948    |\n","---------------------------------\n","LunarLander - Step: 110001 | Mean Reward: -26.93 ± 35.47\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 963      |\n","|    ep_rew_mean     | -37.5    |\n","| time/              |          |\n","|    episodes        | 120      |\n","|    fps             | 75       |\n","|    time_elapsed    | 53       |\n","|    total_timesteps | 124000   |\n","| train/             |          |\n","|    actor_loss      | -7.33    |\n","|    critic_loss     | 0.489    |\n","|    ent_coef        | 0.0168   |\n","|    ent_coef_loss   | 0.0576   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 61948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 985      |\n","|    ep_rew_mean     | -32.8    |\n","| time/              |          |\n","|    episodes        | 124      |\n","|    fps             | 75       |\n","|    time_elapsed    | 105      |\n","|    total_timesteps | 128000   |\n","| train/             |          |\n","|    actor_loss      | -11.8    |\n","|    critic_loss     | 1.97     |\n","|    ent_coef        | 0.0177   |\n","|    ent_coef_loss   | 0.395    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 63948    |\n","---------------------------------\n","LunarLander - Step: 120001 | Mean Reward: -13.68 ± 20.40\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 996      |\n","|    ep_rew_mean     | -28.4    |\n","| time/              |          |\n","|    episodes        | 128      |\n","|    fps             | 71       |\n","|    time_elapsed    | 55       |\n","|    total_timesteps | 134000   |\n","| train/             |          |\n","|    actor_loss      | -3.98    |\n","|    critic_loss     | 0.534    |\n","|    ent_coef        | 0.0164   |\n","|    ent_coef_loss   | -1.25    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 66948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 996      |\n","|    ep_rew_mean     | -27.6    |\n","| time/              |          |\n","|    episodes        | 132      |\n","|    fps             | 71       |\n","|    time_elapsed    | 112      |\n","|    total_timesteps | 138000   |\n","| train/             |          |\n","|    actor_loss      | -6.64    |\n","|    critic_loss     | 10.9     |\n","|    ent_coef        | 0.0172   |\n","|    ent_coef_loss   | -1.12    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 68948    |\n","---------------------------------\n","LunarLander - Step: 130001 | Mean Reward: -30.68 ± 22.53\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 996      |\n","|    ep_rew_mean     | -25.8    |\n","| time/              |          |\n","|    episodes        | 136      |\n","|    fps             | 79       |\n","|    time_elapsed    | 50       |\n","|    total_timesteps | 144000   |\n","| train/             |          |\n","|    actor_loss      | -7.98    |\n","|    critic_loss     | 0.543    |\n","|    ent_coef        | 0.0155   |\n","|    ent_coef_loss   | -0.57    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 71948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 996      |\n","|    ep_rew_mean     | -26      |\n","| time/              |          |\n","|    episodes        | 140      |\n","|    fps             | 79       |\n","|    time_elapsed    | 100      |\n","|    total_timesteps | 148000   |\n","| train/             |          |\n","|    actor_loss      | -5.51    |\n","|    critic_loss     | 0.535    |\n","|    ent_coef        | 0.0155   |\n","|    ent_coef_loss   | 0.213    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 73948    |\n","---------------------------------\n","LunarLander - Step: 140001 | Mean Reward: -15.82 ± 25.68\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 996      |\n","|    ep_rew_mean     | -25.8    |\n","| time/              |          |\n","|    episodes        | 144      |\n","|    fps             | 75       |\n","|    time_elapsed    | 52       |\n","|    total_timesteps | 154000   |\n","| train/             |          |\n","|    actor_loss      | -3.67    |\n","|    critic_loss     | 0.601    |\n","|    ent_coef        | 0.0159   |\n","|    ent_coef_loss   | 1.68     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 76948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 979      |\n","|    ep_rew_mean     | -26      |\n","| time/              |          |\n","|    episodes        | 148      |\n","|    fps             | 79       |\n","|    time_elapsed    | 67       |\n","|    total_timesteps | 155356   |\n","| train/             |          |\n","|    actor_loss      | -7.46    |\n","|    critic_loss     | 0.487    |\n","|    ent_coef        | 0.0168   |\n","|    ent_coef_loss   | 0.286    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 77626    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 979      |\n","|    ep_rew_mean     | -23.7    |\n","| time/              |          |\n","|    episodes        | 152      |\n","|    fps             | 78       |\n","|    time_elapsed    | 118      |\n","|    total_timesteps | 159356   |\n","| train/             |          |\n","|    actor_loss      | -8.42    |\n","|    critic_loss     | 0.501    |\n","|    ent_coef        | 0.0178   |\n","|    ent_coef_loss   | 1.31     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 79626    |\n","---------------------------------\n","LunarLander - Step: 150001 | Mean Reward: -16.97 ± 19.32\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 979      |\n","|    ep_rew_mean     | -23.1    |\n","| time/              |          |\n","|    episodes        | 156      |\n","|    fps             | 71       |\n","|    time_elapsed    | 55       |\n","|    total_timesteps | 164000   |\n","| train/             |          |\n","|    actor_loss      | -11.5    |\n","|    critic_loss     | 0.394    |\n","|    ent_coef        | 0.0155   |\n","|    ent_coef_loss   | -0.74    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 81948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 979      |\n","|    ep_rew_mean     | -22.4    |\n","| time/              |          |\n","|    episodes        | 160      |\n","|    fps             | 72       |\n","|    time_elapsed    | 110      |\n","|    total_timesteps | 168000   |\n","| train/             |          |\n","|    actor_loss      | -6.66    |\n","|    critic_loss     | 0.392    |\n","|    ent_coef        | 0.0154   |\n","|    ent_coef_loss   | -0.68    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 83948    |\n","---------------------------------\n","LunarLander - Step: 160001 | Mean Reward: -19.68 ± 18.35\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 979      |\n","|    ep_rew_mean     | -21.5    |\n","| time/              |          |\n","|    episodes        | 164      |\n","|    fps             | 74       |\n","|    time_elapsed    | 53       |\n","|    total_timesteps | 174000   |\n","| train/             |          |\n","|    actor_loss      | -4.45    |\n","|    critic_loss     | 0.39     |\n","|    ent_coef        | 0.0183   |\n","|    ent_coef_loss   | -0.409   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 86948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 979      |\n","|    ep_rew_mean     | -20.4    |\n","| time/              |          |\n","|    episodes        | 168      |\n","|    fps             | 75       |\n","|    time_elapsed    | 106      |\n","|    total_timesteps | 178000   |\n","| train/             |          |\n","|    actor_loss      | -8.73    |\n","|    critic_loss     | 0.596    |\n","|    ent_coef        | 0.0179   |\n","|    ent_coef_loss   | -0.931   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 88948    |\n","---------------------------------\n","LunarLander - Step: 170001 | Mean Reward: -10.71 ± 29.46\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 979      |\n","|    ep_rew_mean     | -20.1    |\n","| time/              |          |\n","|    episodes        | 172      |\n","|    fps             | 79       |\n","|    time_elapsed    | 50       |\n","|    total_timesteps | 184000   |\n","| train/             |          |\n","|    actor_loss      | -4.67    |\n","|    critic_loss     | 0.383    |\n","|    ent_coef        | 0.0167   |\n","|    ent_coef_loss   | -0.112   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 91948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 979      |\n","|    ep_rew_mean     | -18.4    |\n","| time/              |          |\n","|    episodes        | 176      |\n","|    fps             | 79       |\n","|    time_elapsed    | 100      |\n","|    total_timesteps | 188000   |\n","| train/             |          |\n","|    actor_loss      | -8.94    |\n","|    critic_loss     | 0.39     |\n","|    ent_coef        | 0.0174   |\n","|    ent_coef_loss   | -0.416   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 93948    |\n","---------------------------------\n","LunarLander - Step: 180001 | Mean Reward: -53.67 ± 82.31\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv4lr3eb128/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 979      |\n","|    ep_rew_mean     | -18.7    |\n","| time/              |          |\n","|    episodes        | 180      |\n","|    fps             | 75       |\n","|    time_elapsed    | 53       |\n","|    total_timesteps | 194000   |\n","| train/             |          |\n","|    actor_loss      | -8.39    |\n","|    critic_loss     | 0.388    |\n","|    ent_coef        | 0.0149   |\n","|    ent_coef_loss   | -0.125   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 96948    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 979      |\n","|    ep_rew_mean     | -19.5    |\n","| time/              |          |\n","|    episodes        | 184      |\n","|    fps             | 74       |\n","|    time_elapsed    | 107      |\n","|    total_timesteps | 198000   |\n","| train/             |          |\n","|    actor_loss      | -6.53    |\n","|    critic_loss     | 0.344    |\n","|    ent_coef        | 0.0153   |\n","|    ent_coef_loss   | 0.861    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 98948    |\n","---------------------------------\n","LunarLander - Step: 190001 | Mean Reward: -5.46 ± 24.53\n"]}],"source":["train_lunarlander8()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}