{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T4Y_ICQTqHNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5785813-10da-4409-e600-e91438b1775f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install box2d"
      ],
      "metadata": {
        "id": "vIFTP_VsrG94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cefcb9d-0fd1-4669-a43b-d088565adbc6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting box2d\n",
            "  Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (573 bytes)\n",
            "Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: box2d\n",
            "Successfully installed box2d-2.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.env_util import make_vec_env"
      ],
      "metadata": {
        "id": "h_bBYBThqvhV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, env, n_eval_episodes=10):\n",
        "    \"\"\"Evaluate the model on a given environment and return mean and std rewards.\"\"\"\n",
        "    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes)\n",
        "    return mean_reward, std_reward"
      ],
      "metadata": {
        "id": "uCvpaicUqvr3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAC BipedalWalker"
      ],
      "metadata": {
        "id": "5tXKQaY4wTSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=1, batch size= 64, lr= 1e-4"
      ],
      "metadata": {
        "id": "vm9KwcIZxGuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker1():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=1)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/\",\n",
        "                learning_rate=1e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64\")"
      ],
      "metadata": {
        "id": "pT8tu9eZqv4d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker1()"
      ],
      "metadata": {
        "id": "YQfNwzojqwDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb8f9b0-cdc0-4517-d489-a513b7ae6de6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
            "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n",
            "/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | -115     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 43       |\n",
            "|    time_elapsed    | 10       |\n",
            "|    total_timesteps | 458      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -112     |\n",
            "|    critic_loss     | 192      |\n",
            "|    ent_coef        | 0.938    |\n",
            "|    ent_coef_loss   | -0.285   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 714      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 857      |\n",
            "|    ep_rew_mean     | -110     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 36       |\n",
            "|    time_elapsed    | 188      |\n",
            "|    total_timesteps | 6858     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -55.7    |\n",
            "|    critic_loss     | 0.542    |\n",
            "|    ent_coef        | 0.258    |\n",
            "|    ent_coef_loss   | -8.2     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 13514    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -71.85 ± 36.21\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 734      |\n",
            "|    ep_rew_mean     | -108     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 10134    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -24.1    |\n",
            "|    critic_loss     | 0.363    |\n",
            "|    ent_coef        | 0.134    |\n",
            "|    ent_coef_loss   | -12      |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 20066    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 764      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 36       |\n",
            "|    time_elapsed    | 98       |\n",
            "|    total_timesteps | 13555    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12.6    |\n",
            "|    critic_loss     | 0.351    |\n",
            "|    ent_coef        | 0.0691   |\n",
            "|    ent_coef_loss   | -13.9    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 26908    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 708      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 36       |\n",
            "|    time_elapsed    | 151      |\n",
            "|    total_timesteps | 15490    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.68    |\n",
            "|    critic_loss     | 0.321    |\n",
            "|    ent_coef        | 0.0475   |\n",
            "|    ent_coef_loss   | -13.5    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 30778    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 675      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 36       |\n",
            "|    time_elapsed    | 208      |\n",
            "|    total_timesteps | 17537    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.197   |\n",
            "|    critic_loss     | 0.33     |\n",
            "|    ent_coef        | 0.0314   |\n",
            "|    ent_coef_loss   | -15.8    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 34872    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -113.25 ± 22.52\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 753      |\n",
            "|    ep_rew_mean     | -104     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 90       |\n",
            "|    total_timesteps | 23268    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.9     |\n",
            "|    critic_loss     | 0.36     |\n",
            "|    ent_coef        | 0.0107   |\n",
            "|    ent_coef_loss   | -11.1    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 46334    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 765      |\n",
            "|    ep_rew_mean     | -105     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 186      |\n",
            "|    total_timesteps | 26667    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0285   |\n",
            "|    critic_loss     | 0.159    |\n",
            "|    ent_coef        | 0.00591  |\n",
            "|    ent_coef_loss   | -7.02    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 53132    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 687      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 192      |\n",
            "|    total_timesteps | 26907    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.962    |\n",
            "|    critic_loss     | 0.978    |\n",
            "|    ent_coef        | 0.00569  |\n",
            "|    ent_coef_loss   | -3.82    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 53612    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -77.77 ± 9.95\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 701      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 44       |\n",
            "|    total_timesteps | 31600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.5     |\n",
            "|    critic_loss     | 0.218    |\n",
            "|    ent_coef        | 0.00756  |\n",
            "|    ent_coef_loss   | -3.41    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 62998    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 749      |\n",
            "|    ep_rew_mean     | -104     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 186      |\n",
            "|    total_timesteps | 36528    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.453    |\n",
            "|    critic_loss     | 5.09     |\n",
            "|    ent_coef        | 0.00514  |\n",
            "|    ent_coef_loss   | -1.21    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 72854    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -102.38 ± 39.03\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 781      |\n",
            "|    ep_rew_mean     | -104     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 34       |\n",
            "|    total_timesteps | 41212    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.45     |\n",
            "|    critic_loss     | 3.38     |\n",
            "|    ent_coef        | 0.00279  |\n",
            "|    ent_coef_loss   | -0.527   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 82222    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 727      |\n",
            "|    ep_rew_mean     | -105     |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 43       |\n",
            "|    total_timesteps | 41526    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.25     |\n",
            "|    critic_loss     | 0.354    |\n",
            "|    ent_coef        | 0.00283  |\n",
            "|    ent_coef_loss   | -1.22    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 82850    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 689      |\n",
            "|    ep_rew_mean     | -106     |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 67       |\n",
            "|    total_timesteps | 42340    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.824   |\n",
            "|    critic_loss     | 0.388    |\n",
            "|    ent_coef        | 0.00295  |\n",
            "|    ent_coef_loss   | 1.32     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 84478    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 668      |\n",
            "|    ep_rew_mean     | -107     |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 110      |\n",
            "|    total_timesteps | 43845    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.53     |\n",
            "|    critic_loss     | 0.189    |\n",
            "|    ent_coef        | 0.0031   |\n",
            "|    ent_coef_loss   | -1.15    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 87488    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 704      |\n",
            "|    ep_rew_mean     | -104     |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 252      |\n",
            "|    total_timesteps | 48821    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.72     |\n",
            "|    critic_loss     | 0.262    |\n",
            "|    ent_coef        | 0.00262  |\n",
            "|    ent_coef_loss   | 2.74     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 97440    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -72.15 ± 6.91\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 757      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 182      |\n",
            "|    total_timesteps | 56400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.54     |\n",
            "|    critic_loss     | 0.129    |\n",
            "|    ent_coef        | 0.00278  |\n",
            "|    ent_coef_loss   | -1.84    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 112598   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: 7.56 ± 5.38\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 804      |\n",
            "|    ep_rew_mean     | -96      |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 90       |\n",
            "|    total_timesteps | 63200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.35     |\n",
            "|    critic_loss     | 0.231    |\n",
            "|    ent_coef        | 0.00233  |\n",
            "|    ent_coef_loss   | 2.61     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 126198   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 805      |\n",
            "|    ep_rew_mean     | -93.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 184      |\n",
            "|    total_timesteps | 66501    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.24     |\n",
            "|    critic_loss     | 0.211    |\n",
            "|    ent_coef        | 0.00245  |\n",
            "|    ent_coef_loss   | -1.63    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 132800   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: 10.25 ± 4.45\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 845      |\n",
            "|    ep_rew_mean     | -89.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 92       |\n",
            "|    total_timesteps | 73200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.76     |\n",
            "|    critic_loss     | 0.0505   |\n",
            "|    ent_coef        | 0.00249  |\n",
            "|    ent_coef_loss   | 5.13     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 146198   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 881      |\n",
            "|    ep_rew_mean     | -85.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 276      |\n",
            "|    total_timesteps | 79600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.66     |\n",
            "|    critic_loss     | 0.0514   |\n",
            "|    ent_coef        | 0.00211  |\n",
            "|    ent_coef_loss   | 0.889    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 158998   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: -10.71 ± 28.41\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 910      |\n",
            "|    ep_rew_mean     | -83.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 178      |\n",
            "|    total_timesteps | 86130    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.25     |\n",
            "|    critic_loss     | 0.0351   |\n",
            "|    ent_coef        | 0.00234  |\n",
            "|    ent_coef_loss   | 0.192    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 172058   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 907      |\n",
            "|    ep_rew_mean     | -82.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 275      |\n",
            "|    total_timesteps | 89500    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.01     |\n",
            "|    critic_loss     | 0.103    |\n",
            "|    ent_coef        | 0.00233  |\n",
            "|    ent_coef_loss   | 0.518    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 178798   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: -3.24 ± 26.89\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 936      |\n",
            "|    ep_rew_mean     | -78.8    |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 184      |\n",
            "|    total_timesteps | 96400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.99     |\n",
            "|    critic_loss     | 0.0446   |\n",
            "|    ent_coef        | 0.00208  |\n",
            "|    ent_coef_loss   | -4.24    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 192598   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: 20.38 ± 5.58\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 963      |\n",
            "|    ep_rew_mean     | -74.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 93       |\n",
            "|    total_timesteps | 103200   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.57     |\n",
            "|    critic_loss     | 0.323    |\n",
            "|    ent_coef        | 0.00211  |\n",
            "|    ent_coef_loss   | -1.74    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 206198   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 977      |\n",
            "|    ep_rew_mean     | -73.2    |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 148      |\n",
            "|    total_timesteps | 105062   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.25     |\n",
            "|    critic_loss     | 0.0405   |\n",
            "|    ent_coef        | 0.00211  |\n",
            "|    ent_coef_loss   | -6.12    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 209922   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: -23.67 ± 87.05\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 977      |\n",
            "|    ep_rew_mean     | -68.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 46       |\n",
            "|    total_timesteps | 111600   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.632    |\n",
            "|    critic_loss     | 0.0354   |\n",
            "|    ent_coef        | 0.00182  |\n",
            "|    ent_coef_loss   | 2.56     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 222998   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.01e+03 |\n",
            "|    ep_rew_mean     | -65.8    |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 189      |\n",
            "|    total_timesteps | 116491   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.8      |\n",
            "|    critic_loss     | 0.328    |\n",
            "|    ent_coef        | 0.00184  |\n",
            "|    ent_coef_loss   | 3.47     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 232780   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: -17.30 ± 49.09\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.04e+03 |\n",
            "|    ep_rew_mean     | -61.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 94       |\n",
            "|    total_timesteps | 123200   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.342    |\n",
            "|    critic_loss     | 0.105    |\n",
            "|    ent_coef        | 0.00223  |\n",
            "|    ent_coef_loss   | 1.37     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 246198   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.05e+03 |\n",
            "|    ep_rew_mean     | -60.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 194      |\n",
            "|    total_timesteps | 126531   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.28     |\n",
            "|    critic_loss     | 0.0766   |\n",
            "|    ent_coef        | 0.00194  |\n",
            "|    ent_coef_loss   | 3.72     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 252860   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: -14.99 ± 47.68\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.08e+03 |\n",
            "|    ep_rew_mean     | -56.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 131698   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.72     |\n",
            "|    critic_loss     | 0.107    |\n",
            "|    ent_coef        | 0.00208  |\n",
            "|    ent_coef_loss   | -3.93    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 263194   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.09e+03 |\n",
            "|    ep_rew_mean     | -52      |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 237      |\n",
            "|    total_timesteps | 138098   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.749    |\n",
            "|    critic_loss     | 0.0364   |\n",
            "|    ent_coef        | 0.0019   |\n",
            "|    ent_coef_loss   | -5.15    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 275994   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: -15.61 ± 65.92\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.09e+03 |\n",
            "|    ep_rew_mean     | -48.8    |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 45       |\n",
            "|    total_timesteps | 141600   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.05     |\n",
            "|    critic_loss     | 0.184    |\n",
            "|    ent_coef        | 0.00186  |\n",
            "|    ent_coef_loss   | -1.92    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 282998   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.16e+03 |\n",
            "|    ep_rew_mean     | -43.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 233      |\n",
            "|    total_timesteps | 148000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.935    |\n",
            "|    critic_loss     | 0.04     |\n",
            "|    ent_coef        | 0.00174  |\n",
            "|    ent_coef_loss   | -0.996   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 295798   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: 28.55 ± 28.51\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.16e+03 |\n",
            "|    ep_rew_mean     | -40.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 46       |\n",
            "|    total_timesteps | 151600   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.75     |\n",
            "|    critic_loss     | 0.084    |\n",
            "|    ent_coef        | 0.00201  |\n",
            "|    ent_coef_loss   | 1.17     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 302998   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.17e+03 |\n",
            "|    ep_rew_mean     | -36.3    |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 232      |\n",
            "|    total_timesteps | 158000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.155   |\n",
            "|    critic_loss     | 0.0606   |\n",
            "|    ent_coef        | 0.002    |\n",
            "|    ent_coef_loss   | -0.732   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 315798   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: -43.39 ± 70.43\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.17e+03 |\n",
            "|    ep_rew_mean     | -31.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 96       |\n",
            "|    total_timesteps | 163295   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.938    |\n",
            "|    critic_loss     | 0.129    |\n",
            "|    ent_coef        | 0.00214  |\n",
            "|    ent_coef_loss   | -7.53    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 326388   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.23e+03 |\n",
            "|    ep_rew_mean     | -25.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 282      |\n",
            "|    total_timesteps | 169695   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.65    |\n",
            "|    critic_loss     | 0.0426   |\n",
            "|    ent_coef        | 0.00194  |\n",
            "|    ent_coef_loss   | -2.19    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 339188   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: -62.46 ± 41.29\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.28e+03 |\n",
            "|    ep_rew_mean     | -21.7    |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 143      |\n",
            "|    total_timesteps | 174898   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.42     |\n",
            "|    critic_loss     | 0.484    |\n",
            "|    ent_coef        | 0.00206  |\n",
            "|    ent_coef_loss   | 3.64     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 349594   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: -11.15 ± 25.47\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.32e+03 |\n",
            "|    ep_rew_mean     | -15.3    |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 46       |\n",
            "|    total_timesteps | 181600   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.545   |\n",
            "|    critic_loss     | 0.13     |\n",
            "|    ent_coef        | 0.00213  |\n",
            "|    ent_coef_loss   | 1.8      |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 362998   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.32e+03 |\n",
            "|    ep_rew_mean     | -12.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 193      |\n",
            "|    total_timesteps | 186526   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.18    |\n",
            "|    critic_loss     | 0.0527   |\n",
            "|    ent_coef        | 0.0021   |\n",
            "|    ent_coef_loss   | 1.38     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 372850   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: 47.83 ± 17.20\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.31e+03 |\n",
            "|    ep_rew_mean     | -11.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 191600   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.46    |\n",
            "|    critic_loss     | 0.0341   |\n",
            "|    ent_coef        | 0.00214  |\n",
            "|    ent_coef_loss   | -0.445   |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 382998   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.31e+03 |\n",
            "|    ep_rew_mean     | -9.32    |\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 240      |\n",
            "|    total_timesteps | 198000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.31     |\n",
            "|    critic_loss     | 0.491    |\n",
            "|    ent_coef        | 0.00215  |\n",
            "|    ent_coef_loss   | 2.9      |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 395798   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: 38.22 ± 57.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=1, batch size= 128, lr= 1e-4"
      ],
      "metadata": {
        "id": "gj3SRF7RxJ2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker2():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=1)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128/\",\n",
        "                learning_rate=1e-4, buffer_size=500000, batch_size=128, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr1eb128\")"
      ],
      "metadata": {
        "id": "xp6SruwrxOU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker2()"
      ],
      "metadata": {
        "id": "1x1DpU4Mxcky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=1, batch size= 64, lr= 3e-4"
      ],
      "metadata": {
        "id": "d__engEWxidZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker3():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=1)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/\",\n",
        "                learning_rate=3e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64\")"
      ],
      "metadata": {
        "id": "bnviimltxoZn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker3()"
      ],
      "metadata": {
        "id": "zYHpa67gxr7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c892c5-61d6-4898-9e14-0ce686b71761"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 614      |\n",
            "|    ep_rew_mean     | -110     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 72       |\n",
            "|    total_timesteps | 2457     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -68.1    |\n",
            "|    critic_loss     | 2.11     |\n",
            "|    ent_coef        | 0.258    |\n",
            "|    ent_coef_loss   | -7.75    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4712     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 423      |\n",
            "|    ep_rew_mean     | -114     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 100      |\n",
            "|    total_timesteps | 3381     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -28.4    |\n",
            "|    critic_loss     | 2.25     |\n",
            "|    ent_coef        | 0.149    |\n",
            "|    ent_coef_loss   | -10.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6560     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 411      |\n",
            "|    ep_rew_mean     | -118     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 144      |\n",
            "|    total_timesteps | 4935     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.55    |\n",
            "|    critic_loss     | 0.811    |\n",
            "|    ent_coef        | 0.0629   |\n",
            "|    ent_coef_loss   | -12      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9668     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 418      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 194      |\n",
            "|    total_timesteps | 6693     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.35     |\n",
            "|    critic_loss     | 11.8     |\n",
            "|    ent_coef        | 0.0253   |\n",
            "|    ent_coef_loss   | -7.64    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 13184    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 350      |\n",
            "|    ep_rew_mean     | -115     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 203      |\n",
            "|    total_timesteps | 7002     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.21     |\n",
            "|    critic_loss     | 3.6      |\n",
            "|    ent_coef        | 0.0224   |\n",
            "|    ent_coef_loss   | -1.67    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 13802    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 370      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 257      |\n",
            "|    total_timesteps | 8872     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.75     |\n",
            "|    critic_loss     | 0.841    |\n",
            "|    ent_coef        | 0.0129   |\n",
            "|    ent_coef_loss   | -8.31    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 17542    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -99.01 ± 16.88\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 329      |\n",
            "|    ep_rew_mean     | -115     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 10055    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.3      |\n",
            "|    critic_loss     | 0.29     |\n",
            "|    ent_coef        | 0.00838  |\n",
            "|    ent_coef_loss   | -3.64    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 19908    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 319      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 29       |\n",
            "|    total_timesteps | 11059    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.08     |\n",
            "|    critic_loss     | 0.694    |\n",
            "|    ent_coef        | 0.0116   |\n",
            "|    ent_coef_loss   | 3.42     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 21916    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 356      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 103      |\n",
            "|    total_timesteps | 13672    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.69     |\n",
            "|    critic_loss     | 1.09     |\n",
            "|    ent_coef        | 0.0109   |\n",
            "|    ent_coef_loss   | -1.8     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 27142    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 348      |\n",
            "|    ep_rew_mean     | -118     |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 135      |\n",
            "|    total_timesteps | 14771    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.89     |\n",
            "|    critic_loss     | 0.803    |\n",
            "|    ent_coef        | 0.0129   |\n",
            "|    ent_coef_loss   | 2.01     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 29340    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 427      |\n",
            "|    ep_rew_mean     | -115     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 273      |\n",
            "|    total_timesteps | 19649    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.77     |\n",
            "|    critic_loss     | 0.377    |\n",
            "|    ent_coef        | 0.00854  |\n",
            "|    ent_coef_loss   | -2.29    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 39096    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -138.66 ± 0.17\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 525      |\n",
            "|    ep_rew_mean     | -114     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 34       |\n",
            "|    time_elapsed    | 183      |\n",
            "|    total_timesteps | 26400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.35     |\n",
            "|    critic_loss     | 0.437    |\n",
            "|    ent_coef        | 0.00883  |\n",
            "|    ent_coef_loss   | -0.344   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 52598    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -56.49 ± 8.66\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 583      |\n",
            "|    ep_rew_mean     | -113     |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 56       |\n",
            "|    total_timesteps | 31907    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.86     |\n",
            "|    critic_loss     | 0.167    |\n",
            "|    ent_coef        | 0.0076   |\n",
            "|    ent_coef_loss   | -4.35    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 63612    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 656      |\n",
            "|    ep_rew_mean     | -110     |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 250      |\n",
            "|    total_timesteps | 38307    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.39     |\n",
            "|    critic_loss     | 0.134    |\n",
            "|    ent_coef        | 0.00652  |\n",
            "|    ent_coef_loss   | -2.86    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 76412    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -101.88 ± 11.78\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 695      |\n",
            "|    ep_rew_mean     | -108     |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 104      |\n",
            "|    total_timesteps | 43384    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.48     |\n",
            "|    critic_loss     | 0.468    |\n",
            "|    ent_coef        | 0.00552  |\n",
            "|    ent_coef_loss   | 3.39     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 86566    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 716      |\n",
            "|    ep_rew_mean     | -108     |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 230      |\n",
            "|    total_timesteps | 47517    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.7      |\n",
            "|    critic_loss     | 2.03     |\n",
            "|    ent_coef        | 0.00547  |\n",
            "|    ent_coef_loss   | 3.2      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 94832    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: -59.36 ± 34.08\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 754      |\n",
            "|    ep_rew_mean     | -105     |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 117      |\n",
            "|    total_timesteps | 53849    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.03     |\n",
            "|    critic_loss     | 0.216    |\n",
            "|    ent_coef        | 0.00525  |\n",
            "|    ent_coef_loss   | -0.312   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 107496   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -11.19 ± 32.15\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 783      |\n",
            "|    ep_rew_mean     | -98.8    |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 9        |\n",
            "|    total_timesteps | 60311    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.987    |\n",
            "|    critic_loss     | 0.125    |\n",
            "|    ent_coef        | 0.00478  |\n",
            "|    ent_coef_loss   | -1.64    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 120420   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 779      |\n",
            "|    ep_rew_mean     | -97      |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 95       |\n",
            "|    total_timesteps | 63110    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.559   |\n",
            "|    critic_loss     | 0.321    |\n",
            "|    ent_coef        | 0.00541  |\n",
            "|    ent_coef_loss   | 1.57     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 126018   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 769      |\n",
            "|    ep_rew_mean     | -95.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 165      |\n",
            "|    total_timesteps | 65423    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.638   |\n",
            "|    critic_loss     | 0.341    |\n",
            "|    ent_coef        | 0.0054   |\n",
            "|    ent_coef_loss   | 0.889    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 130644   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: -12.82 ± 15.13\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 797      |\n",
            "|    ep_rew_mean     | -91.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 71600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.01     |\n",
            "|    critic_loss     | 0.108    |\n",
            "|    ent_coef        | 0.00387  |\n",
            "|    ent_coef_loss   | -0.783   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 142998   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 816      |\n",
            "|    ep_rew_mean     | -86.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 198      |\n",
            "|    total_timesteps | 76439    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.503   |\n",
            "|    critic_loss     | 0.125    |\n",
            "|    ent_coef        | 0.00455  |\n",
            "|    ent_coef_loss   | -6.53    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 152676   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: 121.34 ± 50.39\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 840      |\n",
            "|    ep_rew_mean     | -81.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 68       |\n",
            "|    total_timesteps | 82225    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.224   |\n",
            "|    critic_loss     | 0.436    |\n",
            "|    ent_coef        | 0.00537  |\n",
            "|    ent_coef_loss   | -1.04    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 164248   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 856      |\n",
            "|    ep_rew_mean     | -77.2    |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 221      |\n",
            "|    total_timesteps | 87167    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.97    |\n",
            "|    critic_loss     | 0.464    |\n",
            "|    ent_coef        | 0.00554  |\n",
            "|    ent_coef_loss   | -3.32    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 174132   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: 22.68 ± 83.55\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 849      |\n",
            "|    ep_rew_mean     | -75.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 15       |\n",
            "|    total_timesteps | 90519    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.33     |\n",
            "|    critic_loss     | 0.281    |\n",
            "|    ent_coef        | 0.00556  |\n",
            "|    ent_coef_loss   | -0.146   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 180836   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 843      |\n",
            "|    ep_rew_mean     | -73.2    |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 73       |\n",
            "|    total_timesteps | 92354    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.51    |\n",
            "|    critic_loss     | 0.136    |\n",
            "|    ent_coef        | 0.00592  |\n",
            "|    ent_coef_loss   | 2.42     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 184506   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 888      |\n",
            "|    ep_rew_mean     | -65.6    |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 240      |\n",
            "|    total_timesteps | 97778    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.07    |\n",
            "|    critic_loss     | 0.409    |\n",
            "|    ent_coef        | 0.00699  |\n",
            "|    ent_coef_loss   | -3.69    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 195354   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: 141.34 ± 76.09\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 936      |\n",
            "|    ep_rew_mean     | -52.2    |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 147      |\n",
            "|    total_timesteps | 104796   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.89    |\n",
            "|    critic_loss     | 0.766    |\n",
            "|    ent_coef        | 0.00657  |\n",
            "|    ent_coef_loss   | -2.56    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 209390   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: 226.98 ± 14.44\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 977      |\n",
            "|    ep_rew_mean     | -39.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 35       |\n",
            "|    total_timesteps | 111145   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.62    |\n",
            "|    critic_loss     | 0.164    |\n",
            "|    ent_coef        | 0.00673  |\n",
            "|    ent_coef_loss   | -0.763   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 222088   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.01e+03 |\n",
            "|    ep_rew_mean     | -29.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 155      |\n",
            "|    total_timesteps | 115023   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.72    |\n",
            "|    critic_loss     | 0.234    |\n",
            "|    ent_coef        | 0.00749  |\n",
            "|    ent_coef_loss   | 1.06     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 229844   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.03e+03 |\n",
            "|    ep_rew_mean     | -20.2    |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 32       |\n",
            "|    time_elapsed    | 263      |\n",
            "|    total_timesteps | 118477   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.53    |\n",
            "|    critic_loss     | 0.789    |\n",
            "|    ent_coef        | 0.0071   |\n",
            "|    ent_coef_loss   | 2.56     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 236752   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: 289.67 ± 6.95\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.08e+03 |\n",
            "|    ep_rew_mean     | -4.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 134      |\n",
            "|    total_timesteps | 124279   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.03    |\n",
            "|    critic_loss     | 0.105    |\n",
            "|    ent_coef        | 0.00803  |\n",
            "|    ent_coef_loss   | -2.61    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 248356   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.13e+03 |\n",
            "|    ep_rew_mean     | 11.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 301      |\n",
            "|    total_timesteps | 129620   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.48    |\n",
            "|    critic_loss     | 0.302    |\n",
            "|    ent_coef        | 0.00758  |\n",
            "|    ent_coef_loss   | 2.2      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 259038   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: 287.56 ± 1.72\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.14e+03 |\n",
            "|    ep_rew_mean     | 24.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 129      |\n",
            "|    total_timesteps | 134046   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.9    |\n",
            "|    critic_loss     | 0.133    |\n",
            "|    ent_coef        | 0.00687  |\n",
            "|    ent_coef_loss   | 1.27     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 267890   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.18e+03 |\n",
            "|    ep_rew_mean     | 41.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 289      |\n",
            "|    total_timesteps | 139011   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.5     |\n",
            "|    critic_loss     | 0.142    |\n",
            "|    ent_coef        | 0.00725  |\n",
            "|    ent_coef_loss   | -1.37    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 277820   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: 197.58 ± 128.92\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.17e+03 |\n",
            "|    ep_rew_mean     | 51.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 101      |\n",
            "|    total_timesteps | 143172   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.11    |\n",
            "|    critic_loss     | 0.439    |\n",
            "|    ent_coef        | 0.00784  |\n",
            "|    ent_coef_loss   | 1.33     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 286142   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.15e+03 |\n",
            "|    ep_rew_mean     | 66.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 265      |\n",
            "|    total_timesteps | 148237   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11.5    |\n",
            "|    critic_loss     | 0.288    |\n",
            "|    ent_coef        | 0.00854  |\n",
            "|    ent_coef_loss   | 1.42     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 296272   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: 305.04 ± 0.90\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.15e+03 |\n",
            "|    ep_rew_mean     | 82.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 117      |\n",
            "|    total_timesteps | 153689   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13.5    |\n",
            "|    critic_loss     | 0.177    |\n",
            "|    ent_coef        | 0.00829  |\n",
            "|    ent_coef_loss   | 4.69     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 307176   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.14e+03 |\n",
            "|    ep_rew_mean     | 97.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 276      |\n",
            "|    total_timesteps | 158637   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13.9    |\n",
            "|    critic_loss     | 0.315    |\n",
            "|    ent_coef        | 0.00845  |\n",
            "|    ent_coef_loss   | -0.0464  |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 317072   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: 299.72 ± 0.89\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.14e+03 |\n",
            "|    ep_rew_mean     | 112      |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 116      |\n",
            "|    total_timesteps | 163640   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.7    |\n",
            "|    critic_loss     | 0.659    |\n",
            "|    ent_coef        | 0.00798  |\n",
            "|    ent_coef_loss   | -0.663   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 327078   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.14e+03 |\n",
            "|    ep_rew_mean     | 128      |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 264      |\n",
            "|    total_timesteps | 168240   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.3    |\n",
            "|    critic_loss     | 0.173    |\n",
            "|    ent_coef        | 0.00763  |\n",
            "|    ent_coef_loss   | 3.69     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 336278   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: 287.65 ± 0.83\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.13e+03 |\n",
            "|    ep_rew_mean     | 142      |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 102      |\n",
            "|    total_timesteps | 173214   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14      |\n",
            "|    critic_loss     | 0.152    |\n",
            "|    ent_coef        | 0.00798  |\n",
            "|    ent_coef_loss   | -3.38    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 346226   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.12e+03 |\n",
            "|    ep_rew_mean     | 154      |\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 31       |\n",
            "|    time_elapsed    | 235      |\n",
            "|    total_timesteps | 177323   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.8    |\n",
            "|    critic_loss     | 0.0869   |\n",
            "|    ent_coef        | 0.00837  |\n",
            "|    ent_coef_loss   | -2.58    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 354444   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: 300.61 ± 1.27\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.13e+03 |\n",
            "|    ep_rew_mean     | 168      |\n",
            "| time/              |          |\n",
            "|    episodes        | 176      |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 65       |\n",
            "|    total_timesteps | 182028   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.1    |\n",
            "|    critic_loss     | 0.187    |\n",
            "|    ent_coef        | 0.00909  |\n",
            "|    ent_coef_loss   | 0.956    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 363854   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.15e+03 |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 192      |\n",
            "|    total_timesteps | 185962   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.9    |\n",
            "|    critic_loss     | 0.109    |\n",
            "|    ent_coef        | 0.00881  |\n",
            "|    ent_coef_loss   | -2.02    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 371722   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.13e+03 |\n",
            "|    ep_rew_mean     | 195      |\n",
            "| time/              |          |\n",
            "|    episodes        | 184      |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 320      |\n",
            "|    total_timesteps | 189884   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.5    |\n",
            "|    critic_loss     | 0.092    |\n",
            "|    ent_coef        | 0.00829  |\n",
            "|    ent_coef_loss   | 0.75     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 379566   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: 296.13 ± 0.58\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb64/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.13e+03 |\n",
            "|    ep_rew_mean     | 207      |\n",
            "| time/              |          |\n",
            "|    episodes        | 188      |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 127      |\n",
            "|    total_timesteps | 193898   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17.8    |\n",
            "|    critic_loss     | 0.0718   |\n",
            "|    ent_coef        | 0.00783  |\n",
            "|    ent_coef_loss   | 0.711    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 387594   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.11e+03 |\n",
            "|    ep_rew_mean     | 218      |\n",
            "| time/              |          |\n",
            "|    episodes        | 192      |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 250      |\n",
            "|    total_timesteps | 197673   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.7    |\n",
            "|    critic_loss     | 0.188    |\n",
            "|    ent_coef        | 0.00791  |\n",
            "|    ent_coef_loss   | 0.203    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 395144   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: 300.22 ± 0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=1, batch size= 128, lr= 3e-4"
      ],
      "metadata": {
        "id": "Khw2A7o2yJcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker4():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=1)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/\",\n",
        "                learning_rate=3e-4, buffer_size=100000, batch_size=128, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128\")"
      ],
      "metadata": {
        "id": "WBgL8VbEyQ_0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker4()"
      ],
      "metadata": {
        "id": "6vXUm1sVyXAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48fc9ae1-5ab3-429f-a5e3-e7fbcc1ba843"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 37       |\n",
            "|    time_elapsed    | 12       |\n",
            "|    total_timesteps | 477      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -170     |\n",
            "|    critic_loss     | 215      |\n",
            "|    ent_coef        | 0.812    |\n",
            "|    ent_coef_loss   | -0.878   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 752      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 160      |\n",
            "|    ep_rew_mean     | -115     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 44       |\n",
            "|    total_timesteps | 1280     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -199     |\n",
            "|    critic_loss     | 81       |\n",
            "|    ent_coef        | 0.541    |\n",
            "|    ent_coef_loss   | -2.34    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2358     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 157      |\n",
            "|    ep_rew_mean     | -115     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 65       |\n",
            "|    total_timesteps | 1882     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -134     |\n",
            "|    critic_loss     | 80.4     |\n",
            "|    ent_coef        | 0.403    |\n",
            "|    ent_coef_loss   | -2.99    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3562     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 150      |\n",
            "|    ep_rew_mean     | -118     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 84       |\n",
            "|    total_timesteps | 2401     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -45      |\n",
            "|    critic_loss     | 70.3     |\n",
            "|    ent_coef        | 0.306    |\n",
            "|    ent_coef_loss   | -2.97    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4600     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 210      |\n",
            "|    ep_rew_mean     | -123     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 148      |\n",
            "|    total_timesteps | 4191     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12.8    |\n",
            "|    critic_loss     | 16.6     |\n",
            "|    ent_coef        | 0.125    |\n",
            "|    ent_coef_loss   | -1.22    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8180     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 196      |\n",
            "|    ep_rew_mean     | -121     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 167      |\n",
            "|    total_timesteps | 4714     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.15    |\n",
            "|    critic_loss     | 6.78     |\n",
            "|    ent_coef        | 0.0952   |\n",
            "|    ent_coef_loss   | -4.54    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9226     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 214      |\n",
            "|    ep_rew_mean     | -122     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 212      |\n",
            "|    total_timesteps | 5998     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.39     |\n",
            "|    critic_loss     | 4.71     |\n",
            "|    ent_coef        | 0.0538   |\n",
            "|    ent_coef_loss   | -1.01    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11794    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 258      |\n",
            "|    ep_rew_mean     | -122     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 294      |\n",
            "|    total_timesteps | 8268     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.9     |\n",
            "|    critic_loss     | 1.46     |\n",
            "|    ent_coef        | 0.0332   |\n",
            "|    ent_coef_loss   | -2.38    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 16334    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 1 | Mean Reward: -132.05 ± 36.35\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 299      |\n",
            "|    ep_rew_mean     | -123     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 81       |\n",
            "|    total_timesteps | 12282    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.27     |\n",
            "|    critic_loss     | 1.85     |\n",
            "|    ent_coef        | 0.0274   |\n",
            "|    ent_coef_loss   | 0.433    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 24362    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 306      |\n",
            "|    ep_rew_mean     | -125     |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 133      |\n",
            "|    total_timesteps | 13763    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 2.36     |\n",
            "|    ent_coef        | 0.0278   |\n",
            "|    ent_coef_loss   | 1.35     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 27324    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 305      |\n",
            "|    ep_rew_mean     | -125     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 176      |\n",
            "|    total_timesteps | 14965    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.5     |\n",
            "|    critic_loss     | 5.81     |\n",
            "|    ent_coef        | 0.0253   |\n",
            "|    ent_coef_loss   | -2.18    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 29728    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 347      |\n",
            "|    ep_rew_mean     | -124     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 290      |\n",
            "|    total_timesteps | 18194    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.1     |\n",
            "|    critic_loss     | 1.45     |\n",
            "|    ent_coef        | 0.0195   |\n",
            "|    ent_coef_loss   | 2.25     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 36186    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 10001 | Mean Reward: -140.44 ± 23.67\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 397      |\n",
            "|    ep_rew_mean     | -122     |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 77       |\n",
            "|    total_timesteps | 22217    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.18     |\n",
            "|    critic_loss     | 1.48     |\n",
            "|    ent_coef        | 0.0176   |\n",
            "|    ent_coef_loss   | 0.309    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 44232    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 415      |\n",
            "|    ep_rew_mean     | -121     |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 168      |\n",
            "|    total_timesteps | 24785    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.25     |\n",
            "|    critic_loss     | 0.787    |\n",
            "|    ent_coef        | 0.0145   |\n",
            "|    ent_coef_loss   | 0.239    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 49368    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 466      |\n",
            "|    ep_rew_mean     | -119     |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 338      |\n",
            "|    total_timesteps | 29525    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.89     |\n",
            "|    critic_loss     | 0.6      |\n",
            "|    ent_coef        | 0.00831  |\n",
            "|    ent_coef_loss   | -0.335   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 58848    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 20001 | Mean Reward: -98.40 ± 7.56\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 476      |\n",
            "|    ep_rew_mean     | -119     |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 90       |\n",
            "|    total_timesteps | 32505    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.9      |\n",
            "|    critic_loss     | 1.46     |\n",
            "|    ent_coef        | 0.00841  |\n",
            "|    ent_coef_loss   | 2.59     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 64808    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 507      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 237      |\n",
            "|    total_timesteps | 36534    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.73     |\n",
            "|    critic_loss     | 0.676    |\n",
            "|    ent_coef        | 0.00644  |\n",
            "|    ent_coef_loss   | 0.965    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 72866    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 503      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 301      |\n",
            "|    total_timesteps | 38260    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.44     |\n",
            "|    critic_loss     | 0.658    |\n",
            "|    ent_coef        | 0.00744  |\n",
            "|    ent_coef_loss   | 2.68     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 76318    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 30001 | Mean Reward: -103.98 ± 18.49\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 520      |\n",
            "|    ep_rew_mean     | -114     |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 62       |\n",
            "|    total_timesteps | 41671    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.65     |\n",
            "|    critic_loss     | 0.789    |\n",
            "|    ent_coef        | 0.0114   |\n",
            "|    ent_coef_loss   | -1.15    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 83140    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 549      |\n",
            "|    ep_rew_mean     | -114     |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 226      |\n",
            "|    total_timesteps | 46089    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.35     |\n",
            "|    critic_loss     | 2.08     |\n",
            "|    ent_coef        | 0.0071   |\n",
            "|    ent_coef_loss   | -0.909   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 91976    |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 40001 | Mean Reward: 109.38 ± 27.46\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 575      |\n",
            "|    ep_rew_mean     | -108     |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 37       |\n",
            "|    total_timesteps | 50995    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.35     |\n",
            "|    critic_loss     | 0.731    |\n",
            "|    ent_coef        | 0.00725  |\n",
            "|    ent_coef_loss   | 2.58     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 101788   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 605      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 223      |\n",
            "|    total_timesteps | 55976    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.21     |\n",
            "|    critic_loss     | 0.364    |\n",
            "|    ent_coef        | 0.00767  |\n",
            "|    ent_coef_loss   | 0.635    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 111750   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 621      |\n",
            "|    ep_rew_mean     | -94.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 368      |\n",
            "|    total_timesteps | 59837    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.267   |\n",
            "|    critic_loss     | 0.385    |\n",
            "|    ent_coef        | 0.00708  |\n",
            "|    ent_coef_loss   | -1.22    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 119472   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 50001 | Mean Reward: -26.41 ± 60.76\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 639      |\n",
            "|    ep_rew_mean     | -87.1    |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 158      |\n",
            "|    total_timesteps | 64254    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.26    |\n",
            "|    critic_loss     | 0.511    |\n",
            "|    ent_coef        | 0.00737  |\n",
            "|    ent_coef_loss   | 0.179    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 128306   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 60001 | Mean Reward: 265.53 ± 22.74\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 672      |\n",
            "|    ep_rew_mean     | -76.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 58       |\n",
            "|    total_timesteps | 71547    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.11    |\n",
            "|    critic_loss     | 0.287    |\n",
            "|    ent_coef        | 0.007    |\n",
            "|    ent_coef_loss   | 0.598    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 142892   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 719      |\n",
            "|    ep_rew_mean     | -63.7    |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 250      |\n",
            "|    total_timesteps | 76702    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.96    |\n",
            "|    critic_loss     | 0.301    |\n",
            "|    ent_coef        | 0.00785  |\n",
            "|    ent_coef_loss   | -0.639   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 153202   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 70001 | Mean Reward: 34.48 ± 131.20\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 754      |\n",
            "|    ep_rew_mean     | -54.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 81303    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.14    |\n",
            "|    critic_loss     | 0.321    |\n",
            "|    ent_coef        | 0.00796  |\n",
            "|    ent_coef_loss   | -1.49    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 162404   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 807      |\n",
            "|    ep_rew_mean     | -41.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 271      |\n",
            "|    total_timesteps | 87249    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.98    |\n",
            "|    critic_loss     | 0.425    |\n",
            "|    ent_coef        | 0.00706  |\n",
            "|    ent_coef_loss   | 1.42     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 174296   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 80001 | Mean Reward: 204.49 ± 135.91\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 853      |\n",
            "|    ep_rew_mean     | -29      |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 133      |\n",
            "|    total_timesteps | 93597    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.45    |\n",
            "|    critic_loss     | 0.441    |\n",
            "|    ent_coef        | 0.00682  |\n",
            "|    ent_coef_loss   | 1.51     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 186992   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 893      |\n",
            "|    ep_rew_mean     | -11.9    |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 349      |\n",
            "|    total_timesteps | 99365    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.25    |\n",
            "|    critic_loss     | 0.351    |\n",
            "|    ent_coef        | 0.00685  |\n",
            "|    ent_coef_loss   | 1.11     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 198528   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 90001 | Mean Reward: 267.92 ± 68.94\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 941      |\n",
            "|    ep_rew_mean     | 2.27     |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 202      |\n",
            "|    total_timesteps | 105402   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.08    |\n",
            "|    critic_loss     | 0.373    |\n",
            "|    ent_coef        | 0.00597  |\n",
            "|    ent_coef_loss   | -1.04    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 210602   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 100001 | Mean Reward: 270.95 ± 79.55\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 975      |\n",
            "|    ep_rew_mean     | 15.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 42       |\n",
            "|    total_timesteps | 111113   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11      |\n",
            "|    critic_loss     | 0.153    |\n",
            "|    ent_coef        | 0.00641  |\n",
            "|    ent_coef_loss   | -1.18    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 222024   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 29.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 222      |\n",
            "|    total_timesteps | 115900   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12.9    |\n",
            "|    critic_loss     | 0.139    |\n",
            "|    ent_coef        | 0.00608  |\n",
            "|    ent_coef_loss   | -0.302   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 231598   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 110001 | Mean Reward: 163.09 ± 122.95\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.02e+03 |\n",
            "|    ep_rew_mean     | 43.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 121266   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13.3    |\n",
            "|    critic_loss     | 0.115    |\n",
            "|    ent_coef        | 0.00573  |\n",
            "|    ent_coef_loss   | -0.897   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 242330   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.05e+03 |\n",
            "|    ep_rew_mean     | 61.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 239      |\n",
            "|    total_timesteps | 126314   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.3    |\n",
            "|    critic_loss     | 0.195    |\n",
            "|    ent_coef        | 0.00606  |\n",
            "|    ent_coef_loss   | 1.22     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 252426   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 120001 | Mean Reward: 299.59 ± 0.80\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.09e+03 |\n",
            "|    ep_rew_mean     | 77.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 89       |\n",
            "|    total_timesteps | 132360   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.2    |\n",
            "|    critic_loss     | 0.288    |\n",
            "|    ent_coef        | 0.00554  |\n",
            "|    ent_coef_loss   | -1.96    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 264518   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.09e+03 |\n",
            "|    ep_rew_mean     | 87.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 221      |\n",
            "|    total_timesteps | 135815   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17.9    |\n",
            "|    critic_loss     | 0.747    |\n",
            "|    ent_coef        | 0.00608  |\n",
            "|    ent_coef_loss   | -0.0869  |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 271428   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 130001 | Mean Reward: 294.49 ± 1.46\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.1e+03  |\n",
            "|    ep_rew_mean     | 103      |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 42       |\n",
            "|    total_timesteps | 141124   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.6    |\n",
            "|    critic_loss     | 0.125    |\n",
            "|    ent_coef        | 0.00542  |\n",
            "|    ent_coef_loss   | -0.924   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 282046   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.12e+03 |\n",
            "|    ep_rew_mean     | 120      |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 230      |\n",
            "|    total_timesteps | 146026   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.8    |\n",
            "|    critic_loss     | 0.0997   |\n",
            "|    ent_coef        | 0.00497  |\n",
            "|    ent_coef_loss   | -1.11    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 291850   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 140001 | Mean Reward: 274.23 ± 91.06\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.13e+03 |\n",
            "|    ep_rew_mean     | 135      |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 25       |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 151242   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -20.7    |\n",
            "|    critic_loss     | 0.0987   |\n",
            "|    ent_coef        | 0.00499  |\n",
            "|    ent_coef_loss   | -2.37    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 302282   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.14e+03 |\n",
            "|    ep_rew_mean     | 148      |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 25       |\n",
            "|    time_elapsed    | 191      |\n",
            "|    total_timesteps | 154962   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -21.8    |\n",
            "|    critic_loss     | 0.0953   |\n",
            "|    ent_coef        | 0.00515  |\n",
            "|    ent_coef_loss   | -0.686   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 309722   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.14e+03 |\n",
            "|    ep_rew_mean     | 163      |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 25       |\n",
            "|    time_elapsed    | 374      |\n",
            "|    total_timesteps | 159661   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -20.9    |\n",
            "|    critic_loss     | 0.19     |\n",
            "|    ent_coef        | 0.00465  |\n",
            "|    ent_coef_loss   | -0.789   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 319120   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 150001 | Mean Reward: 299.12 ± 1.10\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.17e+03 |\n",
            "|    ep_rew_mean     | 177      |\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 25       |\n",
            "|    time_elapsed    | 174      |\n",
            "|    total_timesteps | 164495   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -20.8    |\n",
            "|    critic_loss     | 0.564    |\n",
            "|    ent_coef        | 0.00494  |\n",
            "|    ent_coef_loss   | -2.47    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 328788   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.18e+03 |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 176      |\n",
            "|    fps             | 25       |\n",
            "|    time_elapsed    | 330      |\n",
            "|    total_timesteps | 168450   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -22      |\n",
            "|    critic_loss     | 0.0519   |\n",
            "|    ent_coef        | 0.00506  |\n",
            "|    ent_coef_loss   | -0.059   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 336698   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 160001 | Mean Reward: 301.00 ± 1.18\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.18e+03 |\n",
            "|    ep_rew_mean     | 207      |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 25       |\n",
            "|    time_elapsed    | 134      |\n",
            "|    total_timesteps | 173389   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -22.6    |\n",
            "|    critic_loss     | 0.14     |\n",
            "|    ent_coef        | 0.00481  |\n",
            "|    ent_coef_loss   | 0.243    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 346576   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.18e+03 |\n",
            "|    ep_rew_mean     | 219      |\n",
            "| time/              |          |\n",
            "|    episodes        | 184      |\n",
            "|    fps             | 25       |\n",
            "|    time_elapsed    | 306      |\n",
            "|    total_timesteps | 177723   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -23.3    |\n",
            "|    critic_loss     | 0.0647   |\n",
            "|    ent_coef        | 0.00498  |\n",
            "|    ent_coef_loss   | -1.18    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 355244   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 170001 | Mean Reward: 227.87 ± 122.25\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.17e+03 |\n",
            "|    ep_rew_mean     | 229      |\n",
            "| time/              |          |\n",
            "|    episodes        | 188      |\n",
            "|    fps             | 24       |\n",
            "|    time_elapsed    | 87       |\n",
            "|    total_timesteps | 182159   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -24.4    |\n",
            "|    critic_loss     | 0.0508   |\n",
            "|    ent_coef        | 0.00542  |\n",
            "|    ent_coef_loss   | -0.905   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 364116   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.17e+03 |\n",
            "|    ep_rew_mean     | 237      |\n",
            "| time/              |          |\n",
            "|    episodes        | 192      |\n",
            "|    fps             | 24       |\n",
            "|    time_elapsed    | 237      |\n",
            "|    total_timesteps | 185889   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -23      |\n",
            "|    critic_loss     | 0.158    |\n",
            "|    ent_coef        | 0.00546  |\n",
            "|    ent_coef_loss   | 2.9      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 371576   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 180001 | Mean Reward: 305.93 ± 0.71\n",
            "Logging to /content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv1lr3eb128/SAC_0\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.17e+03 |\n",
            "|    ep_rew_mean     | 245      |\n",
            "| time/              |          |\n",
            "|    episodes        | 196      |\n",
            "|    fps             | 24       |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 191027   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -24.1    |\n",
            "|    critic_loss     | 0.126    |\n",
            "|    ent_coef        | 0.00573  |\n",
            "|    ent_coef_loss   | 2.1      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 381852   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.16e+03 |\n",
            "|    ep_rew_mean     | 250      |\n",
            "| time/              |          |\n",
            "|    episodes        | 200      |\n",
            "|    fps             | 24       |\n",
            "|    time_elapsed    | 213      |\n",
            "|    total_timesteps | 195314   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -25.1    |\n",
            "|    critic_loss     | 0.0718   |\n",
            "|    ent_coef        | 0.00582  |\n",
            "|    ent_coef_loss   | 0.811    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 390426   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.15e+03 |\n",
            "|    ep_rew_mean     | 254      |\n",
            "| time/              |          |\n",
            "|    episodes        | 204      |\n",
            "|    fps             | 24       |\n",
            "|    time_elapsed    | 380      |\n",
            "|    total_timesteps | 199411   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -23.7    |\n",
            "|    critic_loss     | 0.151    |\n",
            "|    ent_coef        | 0.0058   |\n",
            "|    ent_coef_loss   | 1.3      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 398620   |\n",
            "---------------------------------\n",
            "BipedalWalker - Step: 190001 | Mean Reward: 305.52 ± 1.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=4, batch size= 64, lr= 1e-4"
      ],
      "metadata": {
        "id": "A57LwjaZyn36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker5():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=4)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64/\",\n",
        "                learning_rate=1e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb64\")"
      ],
      "metadata": {
        "id": "NP9Rc1QVzA-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker5()"
      ],
      "metadata": {
        "id": "q_0x4o7wz-7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=4, batch size= 128, lr= 1e-4"
      ],
      "metadata": {
        "id": "zJKqGMFdyu9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker6():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=4)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128/\",\n",
        "                learning_rate=1e-4, buffer_size=500000, batch_size=128, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr1eb128\")"
      ],
      "metadata": {
        "id": "RmPsFe9Nzv1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker6()"
      ],
      "metadata": {
        "id": "izU9O7CV0BF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=4, batch size= 64, lr= 3e-4"
      ],
      "metadata": {
        "id": "tyP_scUayzA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker7():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=4)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64/\",\n",
        "                learning_rate=3e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb64\")"
      ],
      "metadata": {
        "id": "Zliw82kW0QhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker7()"
      ],
      "metadata": {
        "id": "F45QMaRa0ayM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "env=4, batch size= 128, lr= 3e-4"
      ],
      "metadata": {
        "id": "E3M98SlOy4c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bipedalwalker8():\n",
        "    # Create environment and model for BipedalWalker\n",
        "    env_bipedal = make_vec_env(\"BipedalWalker-v3\", n_envs=4)\n",
        "    model = SAC(\"MlpPolicy\", env_bipedal, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128/\",\n",
        "                learning_rate=3e-4, buffer_size=500000, batch_size=128, tau=1.68e-1,\n",
        "                gamma= 0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n",
        "\n",
        "    eval_freq = 10000  # Evaluate every 10,000 steps\n",
        "    n_eval_episodes = 10  # Number of episodes per evaluation\n",
        "\n",
        "    for step in range(1, 200001, eval_freq):\n",
        "        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n",
        "        mean_reward, std_reward = evaluate_model(model, env_bipedal, n_eval_episodes)\n",
        "        print(f\"BipedalWalker - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/RLmodels/sac_bipedalwalkerenv4lr3eb128\")"
      ],
      "metadata": {
        "id": "5IOF8ZMs0foG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_bipedalwalker8()"
      ],
      "metadata": {
        "id": "GSw85KrX035n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}