{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I08ysbNCpSI7","outputId":"3ee65951-89a1-47a6-dcfa-32776a0f17e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stable_baselines3\n","  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n","Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.0.0)\n","Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n","Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n","Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.5.0\n"]}],"source":["!pip install stable_baselines3"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BJ2vBZk1pVFP","outputId":"0d8c6a5d-88d4-4ac2-b99b-b29da6f41545"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install box2d"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECjjcZ-opzYL","outputId":"8e75074c-665b-43a2-b544-2018d66ba925"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting box2d\n","  Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (573 bytes)\n","Downloading Box2D-2.3.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: box2d\n","Successfully installed box2d-2.3.10\n"]}]},{"cell_type":"code","source":["import multiprocessing\n","from stable_baselines3 import SAC\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.env_util import make_vec_env"],"metadata":{"id":"EOJbyToUp4Zx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, env, n_eval_episodes=10):\n","    \"\"\"Evaluate the model on a given environment and return mean and std rewards.\"\"\"\n","    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes)\n","    return mean_reward, std_reward"],"metadata":{"id":"cwiNPKwzp8Xb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SAC Lunar"],"metadata":{"id":"0_W45wJuuRZK"}},{"cell_type":"code","source":["def train_lunarlander3():\n","    # Create environment and model for LunarLander (continuous version for SAC)\n","    env_lunar = make_vec_env(\"LunarLanderContinuous-v3\", n_envs=1)\n","    model = SAC(\"MlpPolicy\", env_lunar, verbose=1, tensorboard_log=\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/\",\n","                learning_rate=3e-4, buffer_size=500000, batch_size=64, tau=1.68e-1,\n","                gamma=0.99, train_freq=1, gradient_steps=2, ent_coef=\"auto\")\n","\n","    eval_freq = 10000  # Evaluate every 10,000 steps\n","    n_eval_episodes = 10  # Number of episodes per evaluation\n","\n","    for step in range(1, 200001, eval_freq):\n","        model.learn(total_timesteps=eval_freq, reset_num_timesteps=False)\n","        mean_reward, std_reward = evaluate_model(model, env_lunar, n_eval_episodes)\n","        print(f\"LunarLander - Step: {step} | Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n","\n","    model.save(\"/content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64\")"],"metadata":{"id":"tllAHJAG4P4l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_lunarlander3()"],"metadata":{"id":"TG82p7mE5_Ko","colab":{"base_uri":"https://localhost:8080/"},"outputId":"27734b76-5856-4173-9766-a3084404985d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n","<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n","<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n","/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n","  from pkg_resources import resource_stream, resource_exists\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n"]},{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 104      |\n","|    ep_rew_mean     | -346     |\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 31       |\n","|    time_elapsed    | 13       |\n","|    total_timesteps | 415      |\n","| train/             |          |\n","|    actor_loss      | -34.1    |\n","|    critic_loss     | 74.5     |\n","|    ent_coef        | 0.855    |\n","|    ent_coef_loss   | -0.282   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 628      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 113      |\n","|    ep_rew_mean     | -244     |\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 27       |\n","|    time_elapsed    | 32       |\n","|    total_timesteps | 904      |\n","| train/             |          |\n","|    actor_loss      | -38.6    |\n","|    critic_loss     | 146      |\n","|    ent_coef        | 0.663    |\n","|    ent_coef_loss   | -0.909   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 1606     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 118      |\n","|    ep_rew_mean     | -192     |\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 25       |\n","|    time_elapsed    | 55       |\n","|    total_timesteps | 1416     |\n","| train/             |          |\n","|    actor_loss      | 15.2     |\n","|    critic_loss     | 36.4     |\n","|    ent_coef        | 0.5      |\n","|    ent_coef_loss   | -1.21    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 2630     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 144      |\n","|    ep_rew_mean     | -192     |\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 25       |\n","|    time_elapsed    | 91       |\n","|    total_timesteps | 2301     |\n","| train/             |          |\n","|    actor_loss      | 1.53     |\n","|    critic_loss     | 12.2     |\n","|    ent_coef        | 0.318    |\n","|    ent_coef_loss   | -1.63    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 4400     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 178      |\n","|    ep_rew_mean     | -183     |\n","| time/              |          |\n","|    episodes        | 20       |\n","|    fps             | 24       |\n","|    time_elapsed    | 144      |\n","|    total_timesteps | 3552     |\n","| train/             |          |\n","|    actor_loss      | 0.669    |\n","|    critic_loss     | 3.33     |\n","|    ent_coef        | 0.172    |\n","|    ent_coef_loss   | -0.814   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 6902     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 211      |\n","|    ep_rew_mean     | -167     |\n","| time/              |          |\n","|    episodes        | 24       |\n","|    fps             | 24       |\n","|    time_elapsed    | 209      |\n","|    total_timesteps | 5055     |\n","| train/             |          |\n","|    actor_loss      | -15.4    |\n","|    critic_loss     | 3.45     |\n","|    ent_coef        | 0.105    |\n","|    ent_coef_loss   | -0.536   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 9908     |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 315      |\n","|    ep_rew_mean     | -156     |\n","| time/              |          |\n","|    episodes        | 28       |\n","|    fps             | 23       |\n","|    time_elapsed    | 376      |\n","|    total_timesteps | 8822     |\n","| train/             |          |\n","|    actor_loss      | -35      |\n","|    critic_loss     | 2.21     |\n","|    ent_coef        | 0.094    |\n","|    ent_coef_loss   | 0.605    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 17442    |\n","---------------------------------\n","LunarLander - Step: 1 | Mean Reward: -49.93 ± 33.34\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 401      |\n","|    ep_rew_mean     | -138     |\n","| time/              |          |\n","|    episodes        | 32       |\n","|    fps             | 22       |\n","|    time_elapsed    | 136      |\n","|    total_timesteps | 13000    |\n","| train/             |          |\n","|    actor_loss      | -17.9    |\n","|    critic_loss     | 2.77     |\n","|    ent_coef        | 0.0677   |\n","|    ent_coef_loss   | 0.621    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 25798    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 427      |\n","|    ep_rew_mean     | -115     |\n","| time/              |          |\n","|    episodes        | 36       |\n","|    fps             | 22       |\n","|    time_elapsed    | 245      |\n","|    total_timesteps | 15545    |\n","| train/             |          |\n","|    actor_loss      | -28.2    |\n","|    critic_loss     | 2.89     |\n","|    ent_coef        | 0.0841   |\n","|    ent_coef_loss   | 1.13     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 30888    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 412      |\n","|    ep_rew_mean     | -102     |\n","| time/              |          |\n","|    episodes        | 40       |\n","|    fps             | 22       |\n","|    time_elapsed    | 291      |\n","|    total_timesteps | 16677    |\n","| train/             |          |\n","|    actor_loss      | -25.4    |\n","|    critic_loss     | 2.87     |\n","|    ent_coef        | 0.0805   |\n","|    ent_coef_loss   | -1.08    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 33152    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 391      |\n","|    ep_rew_mean     | -101     |\n","| time/              |          |\n","|    episodes        | 44       |\n","|    fps             | 23       |\n","|    time_elapsed    | 320      |\n","|    total_timesteps | 17397    |\n","| train/             |          |\n","|    actor_loss      | -25      |\n","|    critic_loss     | 2.47     |\n","|    ent_coef        | 0.0696   |\n","|    ent_coef_loss   | -0.169   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 34592    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 390      |\n","|    ep_rew_mean     | -102     |\n","| time/              |          |\n","|    episodes        | 48       |\n","|    fps             | 23       |\n","|    time_elapsed    | 381      |\n","|    total_timesteps | 18892    |\n","| train/             |          |\n","|    actor_loss      | -23.6    |\n","|    critic_loss     | 4.13     |\n","|    ent_coef        | 0.0857   |\n","|    ent_coef_loss   | -0.179   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 37582    |\n","---------------------------------\n","LunarLander - Step: 10001 | Mean Reward: -420.02 ± 50.49\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 415      |\n","|    ep_rew_mean     | -114     |\n","| time/              |          |\n","|    episodes        | 52       |\n","|    fps             | 22       |\n","|    time_elapsed    | 87       |\n","|    total_timesteps | 22000    |\n","| train/             |          |\n","|    actor_loss      | -25.2    |\n","|    critic_loss     | 2.45     |\n","|    ent_coef        | 0.083    |\n","|    ent_coef_loss   | -0.949   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 43798    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 442      |\n","|    ep_rew_mean     | -106     |\n","| time/              |          |\n","|    episodes        | 56       |\n","|    fps             | 22       |\n","|    time_elapsed    | 226      |\n","|    total_timesteps | 25191    |\n","| train/             |          |\n","|    actor_loss      | -31.7    |\n","|    critic_loss     | 5.74     |\n","|    ent_coef        | 0.0597   |\n","|    ent_coef_loss   | -0.00561 |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 50180    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 464      |\n","|    ep_rew_mean     | -101     |\n","| time/              |          |\n","|    episodes        | 60       |\n","|    fps             | 22       |\n","|    time_elapsed    | 365      |\n","|    total_timesteps | 28309    |\n","| train/             |          |\n","|    actor_loss      | -22.5    |\n","|    critic_loss     | 1.9      |\n","|    ent_coef        | 0.0602   |\n","|    ent_coef_loss   | -0.259   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 56416    |\n","---------------------------------\n","LunarLander - Step: 20001 | Mean Reward: 10.27 ± 88.07\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 478      |\n","|    ep_rew_mean     | -98.6    |\n","| time/              |          |\n","|    episodes        | 64       |\n","|    fps             | 23       |\n","|    time_elapsed    | 65       |\n","|    total_timesteps | 31514    |\n","| train/             |          |\n","|    actor_loss      | -14.6    |\n","|    critic_loss     | 3.23     |\n","|    ent_coef        | 0.052    |\n","|    ent_coef_loss   | -1.02    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 62826    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 496      |\n","|    ep_rew_mean     | -96.3    |\n","| time/              |          |\n","|    episodes        | 68       |\n","|    fps             | 22       |\n","|    time_elapsed    | 210      |\n","|    total_timesteps | 34712    |\n","| train/             |          |\n","|    actor_loss      | -16.2    |\n","|    critic_loss     | 1.45     |\n","|    ent_coef        | 0.0568   |\n","|    ent_coef_loss   | -0.916   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 69222    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 524      |\n","|    ep_rew_mean     | -93.3    |\n","| time/              |          |\n","|    episodes        | 72       |\n","|    fps             | 21       |\n","|    time_elapsed    | 400      |\n","|    total_timesteps | 38712    |\n","| train/             |          |\n","|    actor_loss      | -19.1    |\n","|    critic_loss     | 1.63     |\n","|    ent_coef        | 0.0558   |\n","|    ent_coef_loss   | -0.806   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 77222    |\n","---------------------------------\n","LunarLander - Step: 30001 | Mean Reward: -30.76 ± 21.21\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 549      |\n","|    ep_rew_mean     | -89.6    |\n","| time/              |          |\n","|    episodes        | 76       |\n","|    fps             | 21       |\n","|    time_elapsed    | 138      |\n","|    total_timesteps | 43000    |\n","| train/             |          |\n","|    actor_loss      | -14.9    |\n","|    critic_loss     | 10.2     |\n","|    ent_coef        | 0.0658   |\n","|    ent_coef_loss   | 0.352    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 85798    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 569      |\n","|    ep_rew_mean     | -83.2    |\n","| time/              |          |\n","|    episodes        | 80       |\n","|    fps             | 21       |\n","|    time_elapsed    | 310      |\n","|    total_timesteps | 46728    |\n","| train/             |          |\n","|    actor_loss      | -9.49    |\n","|    critic_loss     | 17.7     |\n","|    ent_coef        | 0.0498   |\n","|    ent_coef_loss   | -0.471   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 93254    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 578      |\n","|    ep_rew_mean     | -80.2    |\n","| time/              |          |\n","|    episodes        | 84       |\n","|    fps             | 21       |\n","|    time_elapsed    | 451      |\n","|    total_timesteps | 49800    |\n","| train/             |          |\n","|    actor_loss      | -12      |\n","|    critic_loss     | 18.2     |\n","|    ent_coef        | 0.0494   |\n","|    ent_coef_loss   | 0.354    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 99398    |\n","---------------------------------\n","LunarLander - Step: 40001 | Mean Reward: -16.14 ± 24.98\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 587      |\n","|    ep_rew_mean     | -77.3    |\n","| time/              |          |\n","|    episodes        | 88       |\n","|    fps             | 21       |\n","|    time_elapsed    | 141      |\n","|    total_timesteps | 53086    |\n","| train/             |          |\n","|    actor_loss      | -8.93    |\n","|    critic_loss     | 0.836    |\n","|    ent_coef        | 0.0503   |\n","|    ent_coef_loss   | -1.01    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 105970   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 598      |\n","|    ep_rew_mean     | -75.5    |\n","| time/              |          |\n","|    episodes        | 92       |\n","|    fps             | 21       |\n","|    time_elapsed    | 293      |\n","|    total_timesteps | 56419    |\n","| train/             |          |\n","|    actor_loss      | -3.77    |\n","|    critic_loss     | 3.96     |\n","|    ent_coef        | 0.0402   |\n","|    ent_coef_loss   | 1.63     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 112636   |\n","---------------------------------\n","LunarLander - Step: 50001 | Mean Reward: 11.62 ± 88.32\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 608      |\n","|    ep_rew_mean     | -73.8    |\n","| time/              |          |\n","|    episodes        | 96       |\n","|    fps             | 21       |\n","|    time_elapsed    | 17       |\n","|    total_timesteps | 60388    |\n","| train/             |          |\n","|    actor_loss      | -5.01    |\n","|    critic_loss     | 0.973    |\n","|    ent_coef        | 0.0374   |\n","|    ent_coef_loss   | -0.242   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 120574   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 624      |\n","|    ep_rew_mean     | -72.2    |\n","| time/              |          |\n","|    episodes        | 100      |\n","|    fps             | 21       |\n","|    time_elapsed    | 205      |\n","|    total_timesteps | 64388    |\n","| train/             |          |\n","|    actor_loss      | -5.62    |\n","|    critic_loss     | 1        |\n","|    ent_coef        | 0.0364   |\n","|    ent_coef_loss   | 0.89     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 128574   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 646      |\n","|    ep_rew_mean     | -59.6    |\n","| time/              |          |\n","|    episodes        | 104      |\n","|    fps             | 21       |\n","|    time_elapsed    | 328      |\n","|    total_timesteps | 67013    |\n","| train/             |          |\n","|    actor_loss      | -3.92    |\n","|    critic_loss     | 1.05     |\n","|    ent_coef        | 0.0394   |\n","|    ent_coef_loss   | -1.09    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 133824   |\n","---------------------------------\n","LunarLander - Step: 60001 | Mean Reward: -19.43 ± 29.30\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 680      |\n","|    ep_rew_mean     | -61      |\n","| time/              |          |\n","|    episodes        | 108      |\n","|    fps             | 20       |\n","|    time_elapsed    | 48       |\n","|    total_timesteps | 71000    |\n","| train/             |          |\n","|    actor_loss      | -6.9     |\n","|    critic_loss     | 1.63     |\n","|    ent_coef        | 0.0362   |\n","|    ent_coef_loss   | -0.672   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 141798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 715      |\n","|    ep_rew_mean     | -58.6    |\n","| time/              |          |\n","|    episodes        | 112      |\n","|    fps             | 21       |\n","|    time_elapsed    | 234      |\n","|    total_timesteps | 75000    |\n","| train/             |          |\n","|    actor_loss      | -5.77    |\n","|    critic_loss     | 2.01     |\n","|    ent_coef        | 0.0344   |\n","|    ent_coef_loss   | 0.594    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 149798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 746      |\n","|    ep_rew_mean     | -52.1    |\n","| time/              |          |\n","|    episodes        | 116      |\n","|    fps             | 21       |\n","|    time_elapsed    | 421      |\n","|    total_timesteps | 79000    |\n","| train/             |          |\n","|    actor_loss      | 1.88     |\n","|    critic_loss     | 1        |\n","|    ent_coef        | 0.0287   |\n","|    ent_coef_loss   | -0.162   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 157798   |\n","---------------------------------\n","LunarLander - Step: 70001 | Mean Reward: -58.21 ± 55.02\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 774      |\n","|    ep_rew_mean     | -46.4    |\n","| time/              |          |\n","|    episodes        | 120      |\n","|    fps             | 21       |\n","|    time_elapsed    | 137      |\n","|    total_timesteps | 83000    |\n","| train/             |          |\n","|    actor_loss      | -2.41    |\n","|    critic_loss     | 3.06     |\n","|    ent_coef        | 0.0305   |\n","|    ent_coef_loss   | 0.0405   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 165798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 799      |\n","|    ep_rew_mean     | -43.6    |\n","| time/              |          |\n","|    episodes        | 124      |\n","|    fps             | 21       |\n","|    time_elapsed    | 319      |\n","|    total_timesteps | 87000    |\n","| train/             |          |\n","|    actor_loss      | -2.64    |\n","|    critic_loss     | 0.772    |\n","|    ent_coef        | 0.0305   |\n","|    ent_coef_loss   | -0.302   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 173798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 788      |\n","|    ep_rew_mean     | -45.3    |\n","| time/              |          |\n","|    episodes        | 128      |\n","|    fps             | 21       |\n","|    time_elapsed    | 444      |\n","|    total_timesteps | 89709    |\n","| train/             |          |\n","|    actor_loss      | -2.32    |\n","|    critic_loss     | 10.5     |\n","|    ent_coef        | 0.0291   |\n","|    ent_coef_loss   | -0.967   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 179216   |\n","---------------------------------\n","LunarLander - Step: 80001 | Mean Reward: -38.07 ± 99.79\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 785      |\n","|    ep_rew_mean     | -47.9    |\n","| time/              |          |\n","|    episodes        | 132      |\n","|    fps             | 21       |\n","|    time_elapsed    | 170      |\n","|    total_timesteps | 93686    |\n","| train/             |          |\n","|    actor_loss      | -4.58    |\n","|    critic_loss     | 1.72     |\n","|    ent_coef        | 0.0299   |\n","|    ent_coef_loss   | 2.39     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 187170   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 790      |\n","|    ep_rew_mean     | -51.9    |\n","| time/              |          |\n","|    episodes        | 136      |\n","|    fps             | 21       |\n","|    time_elapsed    | 308      |\n","|    total_timesteps | 96774    |\n","| train/             |          |\n","|    actor_loss      | -7.24    |\n","|    critic_loss     | 1.36     |\n","|    ent_coef        | 0.0396   |\n","|    ent_coef_loss   | 1.18     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 193346   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 799      |\n","|    ep_rew_mean     | -54      |\n","| time/              |          |\n","|    episodes        | 140      |\n","|    fps             | 22       |\n","|    time_elapsed    | 394      |\n","|    total_timesteps | 98755    |\n","| train/             |          |\n","|    actor_loss      | -4.49    |\n","|    critic_loss     | 3.05     |\n","|    ent_coef        | 0.0306   |\n","|    ent_coef_loss   | 0.317    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 197308   |\n","---------------------------------\n","LunarLander - Step: 90001 | Mean Reward: -30.58 ± 13.07\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 823      |\n","|    ep_rew_mean     | -51.5    |\n","| time/              |          |\n","|    episodes        | 144      |\n","|    fps             | 22       |\n","|    time_elapsed    | 103      |\n","|    total_timesteps | 102299   |\n","| train/             |          |\n","|    actor_loss      | -6.87    |\n","|    critic_loss     | 1.2      |\n","|    ent_coef        | 0.0292   |\n","|    ent_coef_loss   | -0.549   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 204396   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 848      |\n","|    ep_rew_mean     | -46.5    |\n","| time/              |          |\n","|    episodes        | 148      |\n","|    fps             | 21       |\n","|    time_elapsed    | 288      |\n","|    total_timesteps | 106293   |\n","| train/             |          |\n","|    actor_loss      | -0.0873  |\n","|    critic_loss     | 1.6      |\n","|    ent_coef        | 0.0281   |\n","|    ent_coef_loss   | -1.18    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 212384   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 854      |\n","|    ep_rew_mean     | -33.1    |\n","| time/              |          |\n","|    episodes        | 152      |\n","|    fps             | 21       |\n","|    time_elapsed    | 441      |\n","|    total_timesteps | 109666   |\n","| train/             |          |\n","|    actor_loss      | -8.55    |\n","|    critic_loss     | 0.943    |\n","|    ent_coef        | 0.0313   |\n","|    ent_coef_loss   | 2.32     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 219130   |\n","---------------------------------\n","LunarLander - Step: 100001 | Mean Reward: -28.08 ± 40.24\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 862      |\n","|    ep_rew_mean     | -32.9    |\n","| time/              |          |\n","|    episodes        | 156      |\n","|    fps             | 21       |\n","|    time_elapsed    | 184      |\n","|    total_timesteps | 114000   |\n","| train/             |          |\n","|    actor_loss      | -5.76    |\n","|    critic_loss     | 0.821    |\n","|    ent_coef        | 0.0364   |\n","|    ent_coef_loss   | 0.99     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 227798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 865      |\n","|    ep_rew_mean     | -29.7    |\n","| time/              |          |\n","|    episodes        | 160      |\n","|    fps             | 21       |\n","|    time_elapsed    | 341      |\n","|    total_timesteps | 117459   |\n","| train/             |          |\n","|    actor_loss      | -20.9    |\n","|    critic_loss     | 1.83     |\n","|    ent_coef        | 0.0503   |\n","|    ent_coef_loss   | 2.07     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 234716   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 855      |\n","|    ep_rew_mean     | -31.4    |\n","| time/              |          |\n","|    episodes        | 164      |\n","|    fps             | 21       |\n","|    time_elapsed    | 418      |\n","|    total_timesteps | 119165   |\n","| train/             |          |\n","|    actor_loss      | -12      |\n","|    critic_loss     | 1.57     |\n","|    ent_coef        | 0.0615   |\n","|    ent_coef_loss   | 0.52     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 238128   |\n","---------------------------------\n","LunarLander - Step: 110001 | Mean Reward: -98.08 ± 125.93\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 858      |\n","|    ep_rew_mean     | -30.8    |\n","| time/              |          |\n","|    episodes        | 168      |\n","|    fps             | 22       |\n","|    time_elapsed    | 155      |\n","|    total_timesteps | 123474   |\n","| train/             |          |\n","|    actor_loss      | -8.01    |\n","|    critic_loss     | 0.938    |\n","|    ent_coef        | 0.0453   |\n","|    ent_coef_loss   | -1.06    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 246746   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 844      |\n","|    ep_rew_mean     | -32      |\n","| time/              |          |\n","|    episodes        | 172      |\n","|    fps             | 22       |\n","|    time_elapsed    | 271      |\n","|    total_timesteps | 126095   |\n","| train/             |          |\n","|    actor_loss      | -12.2    |\n","|    critic_loss     | 3.82     |\n","|    ent_coef        | 0.0449   |\n","|    ent_coef_loss   | 1.09     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 251988   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 842      |\n","|    ep_rew_mean     | -34.3    |\n","| time/              |          |\n","|    episodes        | 176      |\n","|    fps             | 22       |\n","|    time_elapsed    | 444      |\n","|    total_timesteps | 129889   |\n","| train/             |          |\n","|    actor_loss      | -6.38    |\n","|    critic_loss     | 4.42     |\n","|    ent_coef        | 0.0381   |\n","|    ent_coef_loss   | 1.63     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 259576   |\n","---------------------------------\n","LunarLander - Step: 120001 | Mean Reward: -52.86 ± 47.26\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 835      |\n","|    ep_rew_mean     | -39.7    |\n","| time/              |          |\n","|    episodes        | 180      |\n","|    fps             | 22       |\n","|    time_elapsed    | 133      |\n","|    total_timesteps | 132950   |\n","| train/             |          |\n","|    actor_loss      | -6.54    |\n","|    critic_loss     | 1.82     |\n","|    ent_coef        | 0.0407   |\n","|    ent_coef_loss   | -0.675   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 265698   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 844      |\n","|    ep_rew_mean     | -39.4    |\n","| time/              |          |\n","|    episodes        | 184      |\n","|    fps             | 21       |\n","|    time_elapsed    | 317      |\n","|    total_timesteps | 136935   |\n","| train/             |          |\n","|    actor_loss      | -7.27    |\n","|    critic_loss     | 1.56     |\n","|    ent_coef        | 0.0361   |\n","|    ent_coef_loss   | -0.761   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 273668   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 841      |\n","|    ep_rew_mean     | -39.2    |\n","| time/              |          |\n","|    episodes        | 188      |\n","|    fps             | 21       |\n","|    time_elapsed    | 446      |\n","|    total_timesteps | 139786   |\n","| train/             |          |\n","|    actor_loss      | -12.4    |\n","|    critic_loss     | 0.607    |\n","|    ent_coef        | 0.0355   |\n","|    ent_coef_loss   | -0.0561  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 279370   |\n","---------------------------------\n","LunarLander - Step: 130001 | Mean Reward: 60.70 ± 111.31\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 835      |\n","|    ep_rew_mean     | -34.8    |\n","| time/              |          |\n","|    episodes        | 192      |\n","|    fps             | 22       |\n","|    time_elapsed    | 119      |\n","|    total_timesteps | 142684   |\n","| train/             |          |\n","|    actor_loss      | -6.15    |\n","|    critic_loss     | 0.928    |\n","|    ent_coef        | 0.0349   |\n","|    ent_coef_loss   | 0.543    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 285166   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 839      |\n","|    ep_rew_mean     | -33      |\n","| time/              |          |\n","|    episodes        | 196      |\n","|    fps             | 22       |\n","|    time_elapsed    | 295      |\n","|    total_timesteps | 146502   |\n","| train/             |          |\n","|    actor_loss      | -3.41    |\n","|    critic_loss     | 1.95     |\n","|    ent_coef        | 0.0348   |\n","|    ent_coef_loss   | 0.807    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 292802   |\n","---------------------------------\n","LunarLander - Step: 140001 | Mean Reward: -26.86 ± 86.52\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 834      |\n","|    ep_rew_mean     | -30.9    |\n","| time/              |          |\n","|    episodes        | 200      |\n","|    fps             | 21       |\n","|    time_elapsed    | 34       |\n","|    total_timesteps | 150750   |\n","| train/             |          |\n","|    actor_loss      | -5.34    |\n","|    critic_loss     | 20.4     |\n","|    ent_coef        | 0.0316   |\n","|    ent_coef_loss   | -0.891   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 301298   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 842      |\n","|    ep_rew_mean     | -27.4    |\n","| time/              |          |\n","|    episodes        | 204      |\n","|    fps             | 21       |\n","|    time_elapsed    | 196      |\n","|    total_timesteps | 154187   |\n","| train/             |          |\n","|    actor_loss      | -4.28    |\n","|    critic_loss     | 1.89     |\n","|    ent_coef        | 0.0344   |\n","|    ent_coef_loss   | -0.954   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 308172   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 842      |\n","|    ep_rew_mean     | -19.2    |\n","| time/              |          |\n","|    episodes        | 208      |\n","|    fps             | 21       |\n","|    time_elapsed    | 372      |\n","|    total_timesteps | 158070   |\n","| train/             |          |\n","|    actor_loss      | -1.48    |\n","|    critic_loss     | 1.18     |\n","|    ent_coef        | 0.029    |\n","|    ent_coef_loss   | 0.495    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 315938   |\n","---------------------------------\n","LunarLander - Step: 150001 | Mean Reward: 44.04 ± 108.79\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 841      |\n","|    ep_rew_mean     | -21.9    |\n","| time/              |          |\n","|    episodes        | 212      |\n","|    fps             | 21       |\n","|    time_elapsed    | 91       |\n","|    total_timesteps | 162000   |\n","| train/             |          |\n","|    actor_loss      | -9.98    |\n","|    critic_loss     | 1.93     |\n","|    ent_coef        | 0.0372   |\n","|    ent_coef_loss   | 0.163    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 323798   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 837      |\n","|    ep_rew_mean     | -20      |\n","| time/              |          |\n","|    episodes        | 216      |\n","|    fps             | 21       |\n","|    time_elapsed    | 252      |\n","|    total_timesteps | 165563   |\n","| train/             |          |\n","|    actor_loss      | 2.01     |\n","|    critic_loss     | 14.1     |\n","|    ent_coef        | 0.0299   |\n","|    ent_coef_loss   | 0.833    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 330924   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 837      |\n","|    ep_rew_mean     | -19.7    |\n","| time/              |          |\n","|    episodes        | 220      |\n","|    fps             | 21       |\n","|    time_elapsed    | 437      |\n","|    total_timesteps | 169563   |\n","| train/             |          |\n","|    actor_loss      | -0.226   |\n","|    critic_loss     | 1.11     |\n","|    ent_coef        | 0.0265   |\n","|    ent_coef_loss   | -0.169   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 338924   |\n","---------------------------------\n","LunarLander - Step: 160001 | Mean Reward: -0.89 ± 135.46\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 826      |\n","|    ep_rew_mean     | -18.4    |\n","| time/              |          |\n","|    episodes        | 224      |\n","|    fps             | 22       |\n","|    time_elapsed    | 133      |\n","|    total_timesteps | 172969   |\n","| train/             |          |\n","|    actor_loss      | -2.82    |\n","|    critic_loss     | 1.02     |\n","|    ent_coef        | 0.0306   |\n","|    ent_coef_loss   | -1.36    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 345736   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 835      |\n","|    ep_rew_mean     | -11.5    |\n","| time/              |          |\n","|    episodes        | 228      |\n","|    fps             | 22       |\n","|    time_elapsed    | 294      |\n","|    total_timesteps | 176525   |\n","| train/             |          |\n","|    actor_loss      | -4.84    |\n","|    critic_loss     | 1.21     |\n","|    ent_coef        | 0.0316   |\n","|    ent_coef_loss   | 0.111    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 352848   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 820      |\n","|    ep_rew_mean     | -2.3     |\n","| time/              |          |\n","|    episodes        | 232      |\n","|    fps             | 22       |\n","|    time_elapsed    | 391      |\n","|    total_timesteps | 178712   |\n","| train/             |          |\n","|    actor_loss      | -0.0948  |\n","|    critic_loss     | 2.15     |\n","|    ent_coef        | 0.0259   |\n","|    ent_coef_loss   | -1.73    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 357222   |\n","---------------------------------\n","LunarLander - Step: 170001 | Mean Reward: 8.95 ± 49.65\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 816      |\n","|    ep_rew_mean     | 6.32     |\n","| time/              |          |\n","|    episodes        | 236      |\n","|    fps             | 22       |\n","|    time_elapsed    | 91       |\n","|    total_timesteps | 182012   |\n","| train/             |          |\n","|    actor_loss      | -13.2    |\n","|    critic_loss     | 7.67     |\n","|    ent_coef        | 0.0337   |\n","|    ent_coef_loss   | 0.166    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 363822   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 815      |\n","|    ep_rew_mean     | 14.1     |\n","| time/              |          |\n","|    episodes        | 240      |\n","|    fps             | 22       |\n","|    time_elapsed    | 173      |\n","|    total_timesteps | 183892   |\n","| train/             |          |\n","|    actor_loss      | -18.4    |\n","|    critic_loss     | 15.5     |\n","|    ent_coef        | 0.0354   |\n","|    ent_coef_loss   | 0.564    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 367582   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 802      |\n","|    ep_rew_mean     | 23.4     |\n","| time/              |          |\n","|    episodes        | 244      |\n","|    fps             | 22       |\n","|    time_elapsed    | 256      |\n","|    total_timesteps | 185739   |\n","| train/             |          |\n","|    actor_loss      | -5.09    |\n","|    critic_loss     | 1.37     |\n","|    ent_coef        | 0.0326   |\n","|    ent_coef_loss   | -1.62    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 371276   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 781      |\n","|    ep_rew_mean     | 27.5     |\n","| time/              |          |\n","|    episodes        | 248      |\n","|    fps             | 22       |\n","|    time_elapsed    | 338      |\n","|    total_timesteps | 187607   |\n","| train/             |          |\n","|    actor_loss      | -5.11    |\n","|    critic_loss     | 4.36     |\n","|    ent_coef        | 0.0324   |\n","|    ent_coef_loss   | -0.291   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 375012   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 761      |\n","|    ep_rew_mean     | 33.2     |\n","| time/              |          |\n","|    episodes        | 252      |\n","|    fps             | 22       |\n","|    time_elapsed    | 401      |\n","|    total_timesteps | 189037   |\n","| train/             |          |\n","|    actor_loss      | -13.1    |\n","|    critic_loss     | 1.41     |\n","|    ent_coef        | 0.031    |\n","|    ent_coef_loss   | 0.57     |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 377872   |\n","---------------------------------\n","LunarLander - Step: 180001 | Mean Reward: 158.44 ± 68.48\n","Logging to /content/drive/MyDrive/RLmodels/sac_lunarlanderenv1lr3eb64/SAC_0\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 732      |\n","|    ep_rew_mean     | 40.4     |\n","| time/              |          |\n","|    episodes        | 256      |\n","|    fps             | 22       |\n","|    time_elapsed    | 14       |\n","|    total_timesteps | 190341   |\n","| train/             |          |\n","|    actor_loss      | -8.92    |\n","|    critic_loss     | 29.4     |\n","|    ent_coef        | 0.0332   |\n","|    ent_coef_loss   | -1.67    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 380480   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 713      |\n","|    ep_rew_mean     | 43.6     |\n","| time/              |          |\n","|    episodes        | 260      |\n","|    fps             | 22       |\n","|    time_elapsed    | 84       |\n","|    total_timesteps | 191906   |\n","| train/             |          |\n","|    actor_loss      | -7.89    |\n","|    critic_loss     | 1.3      |\n","|    ent_coef        | 0.0306   |\n","|    ent_coef_loss   | -0.727   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 383610   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 706      |\n","|    ep_rew_mean     | 56.9     |\n","| time/              |          |\n","|    episodes        | 264      |\n","|    fps             | 22       |\n","|    time_elapsed    | 126      |\n","|    total_timesteps | 192871   |\n","| train/             |          |\n","|    actor_loss      | -7.31    |\n","|    critic_loss     | 0.729    |\n","|    ent_coef        | 0.0284   |\n","|    ent_coef_loss   | -0.218   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 385540   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 682      |\n","|    ep_rew_mean     | 68.1     |\n","| time/              |          |\n","|    episodes        | 268      |\n","|    fps             | 22       |\n","|    time_elapsed    | 172      |\n","|    total_timesteps | 193936   |\n","| train/             |          |\n","|    actor_loss      | -5.72    |\n","|    critic_loss     | 1.08     |\n","|    ent_coef        | 0.0301   |\n","|    ent_coef_loss   | -1.35    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 387670   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 671      |\n","|    ep_rew_mean     | 77.6     |\n","| time/              |          |\n","|    episodes        | 272      |\n","|    fps             | 22       |\n","|    time_elapsed    | 240      |\n","|    total_timesteps | 195469   |\n","| train/             |          |\n","|    actor_loss      | -10.1    |\n","|    critic_loss     | 4.73     |\n","|    ent_coef        | 0.0348   |\n","|    ent_coef_loss   | 0.499    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 390736   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 646      |\n","|    ep_rew_mean     | 90.7     |\n","| time/              |          |\n","|    episodes        | 276      |\n","|    fps             | 22       |\n","|    time_elapsed    | 295      |\n","|    total_timesteps | 196737   |\n","| train/             |          |\n","|    actor_loss      | -13.1    |\n","|    critic_loss     | 4.54     |\n","|    ent_coef        | 0.0361   |\n","|    ent_coef_loss   | 0.373    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 393272   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 626      |\n","|    ep_rew_mean     | 102      |\n","| time/              |          |\n","|    episodes        | 280      |\n","|    fps             | 22       |\n","|    time_elapsed    | 337      |\n","|    total_timesteps | 197709   |\n","| train/             |          |\n","|    actor_loss      | -8.45    |\n","|    critic_loss     | 8.53     |\n","|    ent_coef        | 0.0329   |\n","|    ent_coef_loss   | -1.17    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 395216   |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 598      |\n","|    ep_rew_mean     | 112      |\n","| time/              |          |\n","|    episodes        | 284      |\n","|    fps             | 22       |\n","|    time_elapsed    | 387      |\n","|    total_timesteps | 198890   |\n","| train/             |          |\n","|    actor_loss      | -9.96    |\n","|    critic_loss     | 0.954    |\n","|    ent_coef        | 0.0341   |\n","|    ent_coef_loss   | -0.776   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 397578   |\n","---------------------------------\n","LunarLander - Step: 190001 | Mean Reward: 239.92 ± 77.95\n"]}]}]}